Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Hamana2011,
abstract = {Every Algebraic Datatype (ADT) is characterised as the initial algebra of a polynomial functor on sets. This paper extends the characterisation to the case of more advanced datatypes: Generalised Algebraic Datatypes (GADTs) and Inductive Families. Specifically, we show that GADTs and Inductive Families are characterised as initial algebras of dependent polynomial functors. The theoretical tool we use throughout is an abstract notion of polynomial between sets together with its associated general form of polynomial functor between categories of indexed sets introduced by Gambino and Hyland. In the context of ADTs, this fundamental result is the basis for various generic functional programming techniques. To establish the usefulness of our approach for such developments in the broader context of inductively defined dependent types, we apply the theory to construct zippers for Inductive Families. Copyright {\textcopyright} 2011 ACM.},
address = {New York, New York, USA},
author = {Hamana, Makoto and Fiore, Marcelo},
booktitle = {Proceedings of the seventh ACM SIGPLAN workshop on Generic programming - WGP '11},
doi = {10.1145/2036918.2036927},
file = {:Users/liang-tingchen/Dropbox/References/Hamana, Fiore - 2011 - A foundation for GADTs and inductive families.pdf:pdf},
isbn = {9781450308618},
keywords = {Categorical semantics,Dependent types},
pages = {59},
publisher = {ACM Press},
title = {{A foundation for GADTs and inductive families}},
url = {http://dl.acm.org/citation.cfm?doid=2036918.2036927},
year = {2011}
}
@incollection{Appelgate1969,
author = {Appelgate, Harry Wesley and Tierney, M},
booktitle = {Seminar on Triples and Categorical Homology Theory},
doi = {10.1007/BFb0083086},
editor = {{B. Eckmann}},
file = {:Users/liang-tingchen/Dropbox/References/Appelgate, Tierney - 1969 - Categories with models.pdf:pdf},
pages = {156--244},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Categories with models}},
url = {http://www.springerlink.com/index/10.1007/BFb0083086},
year = {1969}
}
@article{Sambin1976,
abstract = {Within the technical frame supplied by the algebraic variety of diagonalizable algebras, defined by R. Magari in [2], we prove the following: Let T be any first-order theory with a predicate Pr satisfying the canonical derivability conditions, including L{\"{o}}b's property. Then any formula in T built up from the propositional variables q, p1, ..., pn, using logical connectives and the predicate Pr, has the same "fixed-points" relative to q (that is, formulas $\psi$ (p1 ..., pn) for which for all p1, ..., pn ⊢T$\phi${\{}symbol{\}}($\psi$(p1, ..., pn), p1, ..., pn) ↔(p1, ..., pn)) of a formula $\phi${\{}symbol{\}}* of the same kind, obtained from $\phi${\{}symbol{\}} in an effective way. Moreover, such $\phi${\{}symbol{\}}* is provably equivalent to the formula obtained from $\phi${\{}symbol{\}} substituting with $\phi${\{}symbol{\}}* itself all the occurrences of q which are under Pr. In the particular case where q is always under Pr in $\phi${\{}symbol{\}}, $\phi${\{}symbol{\}}* is the unique (up to provable equivalence) "fixedpoint" of $\phi${\{}symbol{\}}. Since this result is proved only assuming Pr to be canonical, it can be deduced that L{\"{o}}b's property is, in a sense, equivalent to G{\"{o}}del's diagonalization lemma. All the results are proved more generally in the intuitionistic case. {\textcopyright} 1976 Warszawa.},
author = {Sambin, Giovanni},
doi = {10.1007/BF02123402},
file = {:Users/liang-tingchen/Dropbox/References/Sambin - 1976 - An effective fixed-point theorem in intuitionistic diagonalizable algebras.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
month = {dec},
number = {4},
pages = {345--361},
title = {{An effective fixed-point theorem in intuitionistic diagonalizable algebras}},
url = {http://link.springer.com/10.1007/BF02123402},
volume = {35},
year = {1976}
}
@article{Hintze2016,
author = {Hintze, Mike},
doi = {10.2139/ssrn.2909121},
file = {:Users/liang-tingchen/Dropbox/References/Hintze - 2016 - Viewing the GDPR through a De-Identification Lens A Tool for Clarification and Compliance.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
number = {October 1995},
pages = {1--22},
title = {{Viewing the GDPR through a De-Identification Lens: A Tool for Clarification and Compliance}},
url = {http://www.ssrn.com/abstract=2909121},
year = {2016}
}
@article{Vovk2017,
abstract = {We construct universal prediction systems in the spirit of Popper's falsifiability and Kolmogorov complexity and randomness. These prediction systems do not depend on any statistical assumptions (but under the IID assumption they dominate, to within the usual accuracy, conformal prediction). Our constructions give rise to a theory of algorithmic com-plexity and randomness of time containing analogues of several notions and results of the classical theory of Kolmogorov complexity and randomness.},
author = {Vovk, Vladimir and Pavlovi{\'{c}}, Dusko},
doi = {10.1007/s10472-017-9547-9},
file = {:Users/liang-tingchen/Dropbox/References/Vovk, Pavlovi{\'{c}} - 2017 - Universal probability-free prediction.pdf:pdf},
issn = {15737470},
journal = {Annals of Mathematics and Artificial Intelligence},
keywords = {Conformal prediction,Prediction systems,Probability-free learning,Universal prediction},
number = {1-2},
pages = {47--70},
publisher = {Annals of Mathematics and Artificial Intelligence},
title = {{Universal probability-free prediction}},
volume = {81},
year = {2017}
}
@article{Hinich2016,
abstract = {We present a version of the enriched Yoneda lemma for conventional (not ∞-) cate-gories. We do not require the base monoidal category M to be closed or symmetric monoidal. In the case M has colimits and the monoidal structure in M preserves colimits in each argument, we prove that the Yoneda embedding A → PM(A) is a universal functor from A to a category with colimits, left-tensored over M.},
author = {Hinich, Vladimir},
file = {:Users/liang-tingchen/Dropbox/References/Hinich - 2016 - Enriched yoneda lemma.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Enriched categories,Left-tensored categories,Yoneda embedding},
number = {29},
pages = {833--838},
title = {{Enriched yoneda lemma}},
volume = {31},
year = {2016}
}
@unpublished{Shulman2016,
author = {Shulman, Michael},
file = {:Users/liang-tingchen/Dropbox/References/Shulman - 2016 - Categorical logic from a categorical point of view.pdf:pdf},
title = {{Categorical logic from a categorical point of view}},
year = {2016}
}
@article{Mislove1991a,
abstract = {Motivated by ideas from the study of abstract data types, we show how to interpret non-well-founded sets as fixed points of continuous transformations of an initial continuous algebra. We conisder a preordered structure closely related to the set HF of well-founded, hereditarily finite sets. By taking its ideal completion, we obtain an initial continuous algebra in which we are able to solve all of the usual systems of equations that characterize hereditarily finite, non-well-founded sets. In this way, we are able to obtain a structure which is isomorphic to HF1, the non-well founded analog of HF.},
author = {Mislove, Michael W. and Moss, Lawrence S. and Oles, Frank J.},
doi = {10.1016/0890-5401(91)90051-3},
file = {:Users/liang-tingchen/Dropbox/References/Mislove, Moss, Oles - 1991 - Non-well-founded sets modeled as ideal fixed points.pdf:pdf},
isbn = {0890-5401},
issn = {08905401},
journal = {Information and Computation},
month = {jul},
number = {1},
pages = {16--54},
title = {{Non-well-founded sets modeled as ideal fixed points}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/0890540191900513 http://linkinghub.elsevier.com/retrieve/pii/0890540191900513},
volume = {93},
year = {1991}
}
@article{Kavvos2016,
abstract = {This is a survey of {\{}$\backslash$lambda{\}}-calculi that, through the Curry-Howard isomorphism, correspond to constructive modal logics. We cover the prehistory of the subject and then concentrate on the developments that took place in the 1990s and early 2000s. We discuss logical aspects, modal {\{}$\backslash$lambda{\}}-calculi, and their categorical semantics. The logics underlying the calculi surveyed are constructive versions of K, K4, S4, and LTL.},
archivePrefix = {arXiv},
arxivId = {1605.08106},
author = {Kavvos, G. Alex},
eprint = {1605.08106},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2016 - The Many Worlds of Modal {\{}lambda{\}}-calculi I. Curry-Howard for Necessity, Possibility and Time.pdf:pdf},
month = {may},
pages = {1--34},
title = {{The Many Worlds of Modal {\{}$\backslash$lambda{\}}-calculi: I. Curry-Howard for Necessity, Possibility and Time}},
url = {http://arxiv.org/abs/1605.08106},
year = {2016}
}
@article{Craig2016,
abstract = {Linking clinical and phenotype variables across data sets will both power precision medicine studies and introduce new privacy risks},
author = {Craig, David W.},
doi = {10.1038/nmeth.3779},
file = {:Users/liang-tingchen/Dropbox/References/Craig - 2016 - Understanding the links between privacy and public data sharing.pdf:pdf},
isbn = {doi:10.1038/nmeth.3779},
issn = {1548-7091},
journal = {Nature Methods},
month = {feb},
number = {3},
pages = {211--212},
pmid = {26914204},
publisher = {Nature Publishing Group},
title = {{Understanding the links between privacy and public data sharing}},
url = {http://dx.doi.org/10.1038/nmeth.3779 http://www.nature.com/doifinder/10.1038/nmeth.3779},
volume = {13},
year = {2016}
}
@article{Atkey2009,
abstract = {Moggi's Computational Monads and Power et al .'s equivalent notion of Freyd category have captured a large range of computational effects present in programming languages. Examples include non-termination, non-determinism, exceptions, continuations, side effects and input/output. We present generalisations of both computational monads and Freyd categories, which we call parameterised monads and parameterised Freyd categories, that also capture computational effects with parameters. Examples of such are composable continuations, side effects where the type of the state varies and input/output where the range of inputs and outputs varies. By considering structured parameterisation also, we extend the range of effects to cover separated side effects and multiple independent streams of I/O. We also present two typed $\lambda$-calculi that soundly and completely model our categorical definitions – with and without symmetric monoidal parameterisation – and act as prototypical languages with parameterised effects.},
author = {ATKEY, ROBERT},
doi = {10.1017/S095679680900728X},
file = {:Users/liang-tingchen/Dropbox/References/ATKEY - 2009 - Parameterised notions of computation.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {3-4},
pages = {335--376},
title = {{Parameterised notions of computation}},
url = {https://www.cambridge.org/core/product/identifier/S095679680900728X/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Nuyts2017,
abstract = {Polymorphic type systems such as System F enjoy the parametricity property: polymorphic functions cannot inspect their type argument and will therefore apply the same algorithm to any type they are instantiated on. This idea is formalized mathematically in Reynolds's theory of relational parametricity, which allows the metatheoretical derivation of parametricity theorems about all values of a given type. Although predicative System F embeds into dependent type systems such as Martin-L{\"{o}}f Type Theory (MLTT), parametricity does not carry over as easily. The identity extension lemma, which is crucial if we want to prove theorems involving equality, has only been shown to hold for small types, excluding the universe. We attribute this to the fact that MLTT uses a single type former $\Pi$ to generalize both the parametric quantifier ∀ and the type former → which is non-parametric in the sense that its elements may use their argument as a value. We equip MLTT with parametric quantifiers ∀ and ∃ alongside the existing $\Pi$ and $\Sigma$, and provide relation type formers for proving parametricity theorems internally. We show internally the existence of initial algebras and final co-algebras of indexed functors both by Church encoding and, for a large class of functors, by using sized types. We prove soundness of our type system by enhancing existing iterated reflexive graph (cubical set) models of dependently typed parametricity by distinguishing between edges that express relatedness of objects (bridges) and edges that express equality (paths). The parametric functions are those that map bridges to paths. We implement an extension to the Agda proof assistant that type-checks proofs in our type system.},
author = {Nuyts, Andreas and Vezzosi, Andrea and Devriese, Dominique},
doi = {10.1145/3110276},
file = {:Users/liang-tingchen/Dropbox/References/Nuyts, Vezzosi, Devriese - 2017 - Parametric quantifiers for dependent type theory.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Agda,Parametricity,cubical type theory,presheaf semantics,sized types},
month = {aug},
number = {ICFP},
pages = {1--29},
title = {{Parametric quantifiers for dependent type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3136534.3110276},
volume = {1},
year = {2017}
}
@inproceedings{Abadi1990,
address = {New York, New York, USA},
author = {Abadi, Martı́n and Curien, P. L. and Levy, J. J.},
booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '90},
doi = {10.1145/96709.96712},
file = {:Users/liang-tingchen/Dropbox/References/Abadi, Curien, Levy - 1990 - Explicit substitutions.pdf:pdf},
isbn = {0897913434},
pages = {31--46},
publisher = {ACM Press},
title = {{Explicit substitutions}},
url = {http://portal.acm.org/citation.cfm?doid=96709.96712},
year = {1990}
}
@article{Pattinson2010,
author = {Pattinson, Dirk and Schr{\"{o}}der, Lutz},
doi = {10.1016/j.ic.2009.11.008},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson, Schr{\"{o}}der - 2010 - Cut elimination in coalgebraic logics.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {dec},
number = {12},
pages = {1447--1468},
publisher = {Elsevier Inc.},
title = {{Cut elimination in coalgebraic logics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540110000982},
volume = {208},
year = {2010}
}
@article{Gabbay2013,
abstract = {The modal logic S4 can be used via a Curry-Howard style correspondence to obtain a $\lambda$-calculus. Modal (boxed) types are intuitively interpreted as 'closed syntax of the calculus'. This $\lambda$-calculus is called modal type theory - this is the basic case of a more general contextual modal type theory, or CMTT. CMTT has never been given a denotational semantics in which modal types are given denotation as closed syntax. We show how this can indeed be done, with a twist. We also use the denotation to prove some properties of the system. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Gabbay, Murdoch J. and Nanevski, Aleksandar},
doi = {10.1016/j.jal.2012.07.002},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Nanevski - 2013 - Denotation of contextual modal type theory (CMTT) Syntax and meta-programming.pdf:pdf},
issn = {15708683},
journal = {Journal of Applied Logic},
keywords = {Contextual modal type theory,Curry-Howard correspondence,Higher-order logic,Meta-programming,S4 modal logic,Syntax},
month = {mar},
number = {1},
pages = {1--29},
publisher = {Elsevier B.V.},
title = {{Denotation of contextual modal type theory (CMTT): Syntax and meta-programming}},
url = {http://dx.doi.org/10.1016/j.jal.2012.07.002 https://linkinghub.elsevier.com/retrieve/pii/S157086831200050X},
volume = {11},
year = {2013}
}
@article{Hinze2013,
abstract = {Folds over inductive datatypes are well understood and widely used. In their plain form, they are quite restricted; but many disparate generalisations have been proposed that enjoy similar calculational benefits. There have also been attempts to unify the various generalisations: two prominent such unifications are the 'recursion schemes from comonads' of Uustalu, Vene and Pardo, and our own 'adjoint folds'. Until now, these two unified schemes have appeared incompatible. We show that this appearance is illusory: in fact, adjoint folds subsume recursion schemes from comonads. The proof of this claim involves standard constructions in category theory that are nevertheless not well known in functional programming: Eilenberg-Moore categories and bialgebras.},
author = {Hinze, Ralf and Wu, Nicolas and Gibbons, Jeremy},
doi = {10.1145/2544174.2500578},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Wu, Gibbons - 2013 - Unifying structured recursion schemes.pdf:pdf},
isbn = {9781450323260},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {adjunctions,bialge-,bras,comonads,distributive laws,recursion schemes},
number = {9},
pages = {209--220},
title = {{Unifying structured recursion schemes}},
url = {http://dl.acm.org/citation.cfm?doid=2544174.2500578},
volume = {48},
year = {2013}
}
@inproceedings{Licata2011,
abstract = {Recent work on higher-dimensional type theory has explored connections between Martin-L{\"{o}}f type theory, higher-dimensional category theory, and homotopy theory. These connections suggest a generalization of dependent type theory to account for computationally relevant proofs of propositional equality-for example, taking IdSet A B to be the isomorphisms between A and B. The crucial observation is that all of the familiar type and term constructors can be equipped with a functorial action that describes how they preserve such proofs. The key benefit of higher-dimensional type theory is that programmers and mathematicians may work up to isomorphism and higher equivalence, such as equivalence of categories. In this paper, we consider a further generalization of higher-dimensional type theory, which associates each type with a directed notion of transformation between its elements. Directed type theory accounts for phenomena not expressible in symmetric higher-dimensional type theory, such as a universe set of sets and functions, and a type Ctx used in functorial abstract syntax. Our formulation requires two main ingredients: First, the types themselves must be reinterpreted to take account of variance; for example, a $\Pi$ type is contravariant in its domain, but covariant in its range. Second, whereas in symmetric type theory proofs of equivalence can be internalized using the Martin-L{\"{o}}f identity type, in directed type theory the two-dimensional structure must be made explicit at the judgemental level. We describe a 2-dimensional directed type theory, or 2DTT, which is validated by an interpretation into the strict 2-category Cat of categories, functors, and natural transformations. We also discuss applications of 2DTT for programming with abstract syntax, generalizing the functorial approach to syntax to the dependently typed and mixed-variance case. {\textcopyright} 2011 Elsevier B.V.All rights reserved.},
author = {Licata, Daniel R. and Harper, Robert},
booktitle = {Twenty-seventh Conference on the Mathematical Foundations of Programming Semantics (MFPS XXVII)},
doi = {10.1016/j.entcs.2011.09.026},
file = {:Users/liang-tingchen/Dropbox/References/Licata, Harper - 2011 - 2-Dimensional Directed Type Theory(2).pdf:pdf;:Users/liang-tingchen/Dropbox/References/Licata, Harper - 2011 - 2-Dimensional Directed Type Theory.pdf:pdf},
issn = {15710661},
keywords = {category theorey,dependent types,homotopy type theory,type theory},
month = {sep},
number = {1},
pages = {263--289},
publisher = {Elsevier B.V.},
series = {Electronic Notes in Theoretical Computer Science},
title = {{2-Dimensional Directed Type Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2011.09.026 https://linkinghub.elsevier.com/retrieve/pii/S1571066111001174},
volume = {276},
year = {2011}
}
@article{Ahrens2022a,
abstract = {We develop bicategory theory in univalent foundations. Guided by the notion of univalence for (1-)categories studied by Ahrens, Kapulkin, and Shulman, we define and study univalent bicategories. To construct examples of univalent bicategories in a modular fashion, we develop displayed bicategories , an analog of displayed 1-categories introduced by Ahrens and Lumsdaine. We demonstrate the applicability of this notion and prove that several bicategories of interest are univalent. Among these are the bicategory of univalent categories with families and the bicategory of pseudofunctors between univalent bicategories. Furthermore, we show that every bicategory with univalent hom-categories is weakly equivalent to a univalent bicategory. All of our work is formalized in Coq as part of the UniMath library of univalent mathematics.},
author = {Ahrens, Benedikt and Frumin, Dan and Maggesi, Marco and Veltri, Niccol{\`{o}} and van der Weide, Niels},
doi = {10.1017/S0960129522000032},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2022 - Bicategories in univalent foundations.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {Bicategory theory,Coq,dependent type theory,univalent mathematics},
month = {mar},
pages = {1--38},
title = {{Bicategories in univalent foundations}},
url = {https://www.cambridge.org/core/product/identifier/S0960129522000032/type/journal{\_}article},
year = {2022}
}
@inproceedings{Elsman2018,
address = {New York, New York, USA},
author = {Annenkov, Danil and Elsman, Martin},
booktitle = {Proceedings of the 20th International Symposium on Principles and Practice of Declarative Programming - PPDP '18},
doi = {10.1145/3236950.3236955},
file = {:Users/liang-tingchen/Dropbox/References/Annenkov, Elsman - 2018 - Certified Compilation of Financial Contracts.pdf:pdf},
isbn = {9781450364416},
keywords = {acm reference format,certified programming,contract languages,coq,domain-specific lan-,financial contracts,guages,software correctness},
pages = {1--13},
publisher = {ACM Press},
title = {{Certified Compilation of Financial Contracts}},
url = {http://dl.acm.org/citation.cfm?doid=3236950.3236955},
year = {2018}
}
@article{Gibbons2007,
abstract = {Unfolds generate data structures, and folds consume them. A hylomorphism is a fold after an unfold, generating then consuming a virtual data structure. A metamorphism is the opposite composition, an unfold after a fold; typically, it will convert from one data representation to another. In general, metamorphisms are less interesting than hylomorphisms: there is no automatic fusion to deforest the intermediate virtual data structure. However, under certain conditions fusion is possible: some of the work of the unfold can be done before all of the work of the fold is complete. This permits streaming metamorphisms, and among other things allows conversion of infinite data representations. We present a theory of metamorphisms and outline some examples. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Gibbons, Jeremy},
doi = {10.1016/j.scico.2006.01.006},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2007 - Metamorphisms Streaming representation-changers.pdf:pdf},
isbn = {0892-9912},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Conversion,Data representations,Folds,Fusion,Online algorithms,Streaming,Unfolds},
month = {mar},
number = {2},
pages = {108--139},
title = {{Metamorphisms: Streaming representation-changers}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167642306002103},
volume = {65},
year = {2007}
}
@article{Adamek2003,
abstract = {Continuous endofunctors F of locally finitely presentable categories carry a natural metric on their final coalgebra. Whenever F(0) has an element, this metric is proved to be a Cauchy completion of the initial algebra of F. This is illustrated on the poset of real numbers represented as a final coalgebra of an endofunctor of Pos by Pavlovi{\'{c}} and Pratt. Under additional assumptions on the locally finitely presentable category, all finitary endofunctors are proved to have a final coalgebra constructed in $\omega$+$\omega$ steps of the natural iteration construction.},
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
doi = {10.1016/S0304-3975(01)00240-7},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2003 - On final coalgebras of continuous functors.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {cauchy completion,complete metric space,continuous functor,final coalgebra},
month = {feb},
number = {1-2},
pages = {3--29},
title = {{On final coalgebras of continuous functors}},
url = {http://dx.doi.org/10.1016/S0304-3975(01)00240-7 http://linkinghub.elsevier.com/retrieve/pii/S0304397501002407},
volume = {294},
year = {2003}
}
@article{Shulman2013,
abstract = {We develop a theory of categories which are simultaneously (1) indexed over a base category {\$}S{\$} with finite products, and (2) enriched over an {\$}S{\$}-indexed monoidal category {\$}V{\$}. This includes classical enriched categories, indexed and fibered categories, and internal categories as special cases. We then describe the appropriate notion of ``limit'' for such enriched indexed categories, and show that they admit ``free cocompletions'' constructed as usual with a Yoneda embedding.},
author = {Shulman, Michael A.},
file = {:Users/liang-tingchen/Dropbox/References/Shulman - 2013 - Enriched indexed categories.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {enriched category,fibered category,indexed category,monoidal category},
number = {21},
pages = {616--695},
title = {{Enriched indexed categories}},
url = {http://www.tac.mta.ca/tac/volumes/28/21/28-21abs.html},
volume = {28},
year = {2013}
}
@book{Jacobs2012,
author = {Jacobs, Bart},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2016 - Introduction to Coalgebra Towards Mathematics of States and Observation.pdf:pdf},
isbn = {9781107177895},
month = {dec},
pages = {494},
publisher = {Cambridge University Press},
series = {Cambridge Tracts in Theoretical Computer Science},
title = {{Introduction to Coalgebra: Towards Mathematics of States and Observation}},
url = {http://www.cambridge.org/us/academic/subjects/mathematics/logic-categories-and-sets/introduction-coalgebra-towards-mathematics-states-and-observation?format=HB{\&}isbn=9781107177895{\#}6sq0pYgxKvtAzXrw.97},
volume = {59},
year = {2016}
}
@inproceedings{LopezJuan2020,
address = {New York, NY, USA},
author = {{L{\'{o}}pez Juan}, V{\'{i}}ctor and Danielsson, Nils Anders},
booktitle = {Proceedings of the 5th ACM SIGPLAN International Workshop on Type-Driven Development},
doi = {10.1145/3406089.3409030},
file = {:Users/liang-tingchen/Dropbox/References/L{\'{o}}pez Juan, Danielsson - 2020 - Practical dependent type checking using twin types.pdf:pdf},
isbn = {9781450380515},
keywords = {2020,acm reference format,dependent types,in proceedings of the,nils anders danielsson,pendent type checking using,practical de-,twin types,type checking,unification,v{\'{i}}ctor l{\'{o}}pez juan and},
month = {aug},
pages = {11--23},
publisher = {ACM},
title = {{Practical dependent type checking using twin types}},
url = {https://dl.acm.org/doi/10.1145/3406089.3409030},
year = {2020}
}
@inproceedings{Scibior2015,
abstract = {The machine learning community has recently shown a lot of inter-est in practical probabilistic programming systems that target the problem of Bayesian inference. Such systems come in different forms, but they all express probabilistic models as computational processes using syntax resembling programming languages. In the functional programming community monads are known to offer a convenient and elegant abstraction for programming with probabil-ity distributions, but their use is often limited to very simple in-ference problems. We show that it is possible to use the monad abstraction to construct probabilistic models for machine learning, while still offering good performance of inference in challenging models. We use a GADT as an underlying representation of a prob-ability distribution and apply Sequential Monte Carlo-based meth-ods to achieve efficient inference. We define a formal semantics via measure theory. We demonstrate a clean and elegant implementa-tion that achieves performance comparable with Anglican, a state-of-the-art probabilistic programming system.},
address = {New York, New York, USA},
author = {{\'{S}}cibior, Adam and Ghahramani, Zoubin and Gordon, Andrew D.},
booktitle = {Proceedings of the 8th ACM SIGPLAN Symposium on Haskell - Haskell 2015},
doi = {10.1145/2804302.2804317},
file = {:Users/liang-tingchen/Dropbox/References/{\'{S}}cibior, Ghahramani, Gordon - 2015 - Practical probabilistic programming with monads.pdf:pdf},
isbn = {9781450338080},
issn = {03621340},
keywords = {and z is a,bayesian statis-,given particular values of,haskell,monads,monte carlo,normalising con-,parameters,posterior is a proper,probabilistic programming,probability distribution,stant that ensures the,tics},
pages = {165--176},
publisher = {ACM Press},
title = {{Practical probabilistic programming with monads}},
url = {http://dl.acm.org/citation.cfm?doid=2804302.2804317},
year = {2015}
}
@incollection{Herbelin1995,
author = {Herbelin, Hugo},
booktitle = {Computer Science Logic. CSL 1994},
doi = {10.1007/BFb0022247},
editor = {Pacholski, Leszek and Tiuryn, Jerzy},
file = {:Users/liang-tingchen/Dropbox/References/Herbelin - 1995 - A $\lambda$-calculus structure isomorphic to Gentzen-style sequent calculus structure(3).pdf:pdf},
isbn = {3-540-60017-5},
issn = {16113349},
pages = {61--75},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A $\lambda$-calculus structure isomorphic to Gentzen-style sequent calculus structure}},
url = {http://link.springer.com/10.1007/BFb0022247},
volume = {933},
year = {1995}
}
@inproceedings{Flatt2016,
abstract = {Our new macro expander for Racket builds on a novel approach to hygiene. Instead of basing macro expansion on variable renamings that are mediated by expansion history, our new expander tracks binding through a set of scopes that an identifier acquires from both binding forms and macro expansions. The resulting model of macro expansion is simpler and more uniform than one based on renaming, and it is sufficiently compatible with Racket's old expander to be practical.},
address = {New York, NY, USA},
author = {Flatt, Matthew},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837620},
file = {:Users/liang-tingchen/Dropbox/References/Flatt - 2016 - Binding as sets of scopes.pdf:pdf},
isbn = {9781450335492},
issn = {15232867},
keywords = {Binding,Hygiene,Macros,Scope},
month = {jan},
number = {1},
pages = {705--717},
publisher = {ACM},
title = {{Binding as sets of scopes}},
url = {https://dl.acm.org/doi/10.1145/2837614.2837620},
volume = {51},
year = {2016}
}
@inproceedings{Schrijvers2008,
abstract = {We report on an extension of Haskell with open type-level functions and equality constraints that unifies earlier work on GADTs, functional dependencies, and associated types. The contribution of the paper is that we identify and characterise the key technical challenge of entailment checking; and we give a novel, decidable, sound, and complete algorithm to solve it, together with some practically-important variants. Our system is implemented in GHC, and is already in active use.},
address = {New York, New York, USA},
author = {Schrijvers, Tom and {Peyton Jones}, Simon and Chakravarty, Manuel and Sulzmann, Martin},
booktitle = {Proceeding of the 13th ACM SIGPLAN international conference on Functional programming - ICFP '08},
doi = {10.1145/1411204.1411215},
file = {:Users/liang-tingchen/Dropbox/References/Schrijvers et al. - 2008 - Type checking with open type functions.pdf:pdf},
isbn = {9781595939197},
issn = {03621340},
keywords = {and gadts,as much as possi-,ble of this research,earlier,haskell,in a backwards-compatible,johann and ghani,more foundational work by,our goal in this,paper is to unify,practical extension,to haskell,type checking,type families,type functions},
pages = {51},
publisher = {ACM Press},
title = {{Type checking with open type functions}},
url = {http://portal.acm.org/citation.cfm?doid=1411204.1411215},
year = {2008}
}
@article{Omar2019,
abstract = {This paper develops a dynamic semantics for incomplete functional programs, starting from the static semantics developed in recent work on Hazelnut. We model incomplete functional programs as expressions with holes, with empty holes standing for missing expressions or types, and non-empty holes operating as membranes around static and dynamic type inconsistencies. Rather than aborting when evaluation encounters any of these holes as in some existing systems, evaluation proceeds around holes, tracking the closure around each hole instance as it flows through the remainder of the program. Editor services can use the information in these hole closures to help the programmer develop and confirm their mental model of the behavior of the complete portions of the program as they decide how to fill the remaining holes. Hole closures also enable a fill-and-resume operation that avoids the need to restart evaluation after edits that amount to hole filling. Formally, the semantics borrows machinery from both gradual type theory (which supplies the basis for handling unfilled type holes) and contextual modal type theory (which supplies a logical basis for hole closures), combining these and developing additional machinery necessary to continue evaluation past holes while maintaining type safety. We have mechanized the metatheory of the core calculus, called Hazelnut Live, using the Agda proof assistant. We have also implemented these ideas into the Hazel programming environment. The implementation inserts holes automatically, following the Hazelnut edit action calculus, to guarantee that every editor state has some (possibly incomplete) type. Taken together with this paper's type safety property, the result is a proof-of-concept live programming environment where rich dynamic feedback is truly available without gaps, i.e. for every reachable editor state.},
archivePrefix = {arXiv},
arxivId = {1805.00155},
author = {Omar, Cyrus and Voysey, Ian and Chugh, Ravi and Hammer, Matthew A.},
doi = {10.1145/3290327},
eprint = {1805.00155},
file = {:Users/liang-tingchen/Dropbox/References/Omar et al. - 2019 - Live functional programming with typed holes(2).pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {contextual modal type theory,gradual typing,live programming,structured editing,typed holes},
month = {jan},
number = {POPL},
pages = {1--32},
title = {{Live functional programming with typed holes}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290327},
volume = {3},
year = {2019}
}
@article{Adamek2005a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1017/S0960129505004731},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2005 - A general final coalgebra theorem.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {3},
pages = {409--432},
title = {{A general final coalgebra theorem}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129505004731},
volume = {15},
year = {2005}
}
@incollection{Plotkin2001,
abstract = {Moggi proposed a monadic account of computational effects. He also presented the computational $\lambda$-calculus, $\lambda$ c , a core call-by-value functional programming language for effects; the effects are obtained by adding appropriate operations. The question arises as to whether one can give a corresponding treatment of operational semantics. We do this in the case of algebraic effects where the operations are given by a single-sorted algebraic signature, and their semantics is supported by the monad, in a certain sense. We consider call-by-value PCF with— and without—recursion, an extension of $\lambda$ c with arithmetic. We prove general adequacy theorems, and illustrate these with two examples: non-determinism and probabilistic nondeterminism.},
author = {Plotkin, Gordon and Power, John},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/3-540-45315-6_1},
editor = {Honsell, Furio and Miculan, Marino},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Power - 2001 - Adequacy for Algebraic Effects.pdf:pdf},
pages = {1--24},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Adequacy for Algebraic Effects}},
url = {http://link.springer.com/10.1007/3-540-45315-6{\_}1},
volume = {2030},
year = {2001}
}
@incollection{Lamport1985,
author = {Lamport, Leslie},
booktitle = {Distributed Systems: Methods and Tools for Specification An Advanced Course},
doi = {10.1007/3-540-15216-4_12},
editor = {Paul, M. and Siegert, H. J. and Alford, M. W. and Ansart, J. P. and Hommel, G. and Lamport, L. and Liskov, B. and Mullery, G. P. and Schneider, F. B.},
file = {:Users/liang-tingchen/Dropbox/References/Lamport - 1985 - Basic concepts.pdf:pdf},
pages = {7--43},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Basic concepts}},
url = {http://link.springer.com/10.1007/3-540-15216-4{\_}12},
volume = {190},
year = {1985}
}
@article{Jøsang2012,
author = {J{\o}sang, Audun and Pope, Simon},
doi = {10.1111/j.1467-8640.2012.00421.x},
file = {:Users/liang-tingchen/Dropbox/References/J{\o}sang, Pope - 2012 - DEMPSTER'S RULE AS SEEN BY LITTLE COLORED BALLS.pdf:pdf},
issn = {08247935},
journal = {Computational Intelligence},
keywords = {averaging operator,belief theory,cumulative operator,fusion,subjective logic},
month = {nov},
number = {4},
pages = {453--474},
title = {{DEMPSTER'S RULE AS SEEN BY LITTLE COLORED BALLS}},
url = {http://doi.wiley.com/10.1111/j.1467-8640.2012.00421.x},
volume = {28},
year = {2012}
}
@article{Rutten2000,
author = {Rutten, Jan J.M.M.},
doi = {10.1016/S0304-3975(00)00056-6},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 2000 - Universal coalgebra a theory of systems.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {oct},
number = {1},
pages = {3--80},
publisher = {Elsevier},
title = {{Universal coalgebra: a theory of systems}},
type = {Journal article},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397500000566},
volume = {249},
year = {2000}
}
@article{Ahrens2016,
abstract = {We give an algebraic characterization of the syntax and semantics of a class of untyped functional programming languages.},
author = {AHRENS, BENEDIKT},
doi = {10.1017/S0960129514000103},
file = {:Users/liang-tingchen/Dropbox/References/AHRENS - 2016 - Modules over relative monads for syntax and semantics.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jan},
number = {1},
pages = {3--37},
title = {{Modules over relative monads for syntax and semantics}},
url = {https://www.cambridge.org/core/product/identifier/S0960129514000103/type/journal{\_}article},
volume = {26},
year = {2016}
}
@article{Ghilardi1995a,
author = {Ghilardi, Silvio},
doi = {10.1016/0168-0072(93)E0084-2},
file = {:Users/liang-tingchen/Dropbox/References/Ghilardi - 1995 - An algebraic theory of normal forms.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {feb},
number = {3},
pages = {189--245},
title = {{An algebraic theory of normal forms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0168007293E00842},
volume = {71},
year = {1995}
}
@article{Zawadowski2012,
abstract = {We give a 3-categorical, purely formal argument explaining why on the category of Kleisli algebras for a lax monoidal monad, and dually on the category of Eilenberg-Moore algebras for an oplax monoidal monad, we always have a natural monoidal structures. The key observation is that the 2-category of lax monoidal monads in any 2-category D with finite products is isomorphic to the 2-category of monoidal objects with oplax morphisms in the 2-category of monads with lax morphisms in D. We explain at the end of the paper that a similar phenomenon occurs in many other situations. ?? 2012 Elsevier B.V..},
archivePrefix = {arXiv},
arxivId = {1012.0547},
author = {Zawadowski, Marek},
doi = {10.1016/j.jpaa.2012.02.030},
eprint = {1012.0547},
file = {:Users/liang-tingchen/Dropbox/References/Zawadowski - 2012 - The formal theory of monoidal monads.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {aug},
number = {8-9},
pages = {1932--1942},
publisher = {Elsevier B.V.},
title = {{The formal theory of monoidal monads}},
url = {http://dx.doi.org/10.1016/j.jpaa.2012.02.030 http://linkinghub.elsevier.com/retrieve/pii/S0022404912000692},
volume = {216},
year = {2012}
}
@article{Day2007,
abstract = {For a small category K enriched over a suitable monoidal category V, the free completion of K under colimits is the presheaf category [K op, V]. If K is large, its free completion under colimits is the V-category P K of small presheaves on K, where a presheaf is small if it is a left Kan extension of some presheaf with small domain. We study the existence of limits and of monoidal closed structures on P K. ?? 2006 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {math/0610439},
author = {Day, Brian J. and Lack, Stephen},
doi = {10.1016/j.jpaa.2006.10.019},
eprint = {0610439},
file = {:Users/liang-tingchen/Dropbox/References/Day, Lack - 2007 - Limits of small functors.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {3},
pages = {651--663},
primaryClass = {math},
title = {{Limits of small functors}},
volume = {210},
year = {2007}
}
@article{Davies2001b,
abstract = {We show that a type system based on the intuitionistic modal logic S4 provides an expressive framework for specifying and analyzing computation stages in the context of typed {\&}lgr;-calculi and functional languages. We directly demonstrate the sense in which our l→{\&}square;e -calculus captures staging, and also give a conservative embeddng of Nielson and Nielson's two-level functional language in our functional language Mini-ML {\&}square; , thus proving that binding-time correctness is equivalent to modal correctness on this fragment. In addition, Mini-ML{\&}square; can also express immediate evaluation and sharing of code across multiple stages, thus supporting run-time code generation as well as partial evaluation.},
author = {Davies, Rowan and Pfenning, Frank},
doi = {10.1145/382780.382785},
file = {:Users/liang-tingchen/Dropbox/References/Davies, Pfenning - 2001 - A modal analysis of staged computation.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
month = {may},
number = {3},
pages = {555--604},
title = {{A modal analysis of staged computation}},
url = {http://portal.acm.org/citation.cfm?doid=382780.382785},
volume = {48},
year = {2001}
}
@inproceedings{Birkedal2013,
abstract = {Guarded recursive functions and types are useful for giving semantics to advanced programming languages and for higher-order programming with infinite data types, such as streams, e.g., for modeling reactive systems. We propose an extension of in tensional type theory with rules for forming fixed points of guarded recursive functions. Guarded recursive types can be formed simply by taking fixed points of guarded recursive functions on the universe of types. Moreover, we present a general model construction for constructing models of the in tensional type theory with guarded recursive functions and types. When applied to the groupoid model of in tensional type theory with the universe of small discrete groupoids, the construction gives a model of guarded recursion for which there is a one-to-one correspondence between fixed points of functions on the universe of types and fixed points of (suitable) operators on types. In particular, we find that the functor category {\&}omega;op from the preordered set of natural numbers to the category of groupoids is a model of intensional type theory with guarded recursive types. {\textcopyright} 2013 IEEE.},
author = {Birkedal, Lars and M{\o}gelberg, Rasmus Ejlers},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.27},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal, M{\o}gelberg - 2013 - Intensional Type Theory with Guarded Recursive Types qua Fixed Points on Universes.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
month = {jun},
pages = {213--222},
publisher = {IEEE},
title = {{Intensional Type Theory with Guarded Recursive Types qua Fixed Points on Universes}},
url = {http://ieeexplore.ieee.org/document/6571553/},
year = {2013}
}
@article{Bezhanishvili1999,
abstract = {In this paper we continue the investigation of monadic Heyting algebras which we started in [2]. Here we present the representation theorem for monadic Heyting algebras and develop the duality theory for them. As a result we obtain an adequate topological semantics for intuitionistic modal logics over MIPC along with a Kripke-type semantics for them. It is also shown the importance and the effectiveness of the duality theory for further investigation of monadic Heyting algebras and logics over MIPC.},
author = {Bezhanishvili, Guram},
doi = {10.1023/A:1005173628262},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili - 1999 - Varieties of Monadic Heyting Algebras Part II. Duality Theory.pdf:pdf},
journal = {Studia Logica},
number = {1},
pages = {21--48},
title = {{Varieties of Monadic Heyting Algebras Part II. Duality Theory}},
url = {http://link.springer.com/article/10.1023{\%}2FA{\%}3A1005173628262},
volume = {62},
year = {1999}
}
@article{Farmer2018,
abstract = {[Figure presented] is a version of Church's type theory that includes quotation and evaluation operators that are similar to quote and eval in the Lisp programming language. With quotation and evaluation it is possible to reason in [Figure presented] about the interplay of the syntax and semantics of expressions and, as a result, to formalize syntax-based mathematical algorithms. We present the syntax and semantics of [Figure presented] as well as a proof system for [Figure presented]. The proof system is shown to be sound for all formulas and complete for formulas that do not contain evaluations. We give several examples that illustrate the usefulness of having quotation and evaluation in [Figure presented].},
archivePrefix = {arXiv},
arxivId = {1612.02785},
author = {Farmer, William M.},
doi = {10.1016/j.ic.2018.03.001},
eprint = {1612.02785},
file = {:Users/liang-tingchen/Dropbox/References/Farmer - 2018 - Incorporating quotation and evaluation into Church's type theory.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Church's type theory,Evaluation,Meaning formulas,Metareasoning,Quasiquotation,Quotation,Reasoning about syntax,Reflection,Schemas,Simple type theory,Substitution,Symbolic computation},
month = {jun},
pages = {9--50},
publisher = {Elsevier Inc.},
title = {{Incorporating quotation and evaluation into Church's type theory}},
url = {https://doi.org/10.1016/j.ic.2018.03.001 https://linkinghub.elsevier.com/retrieve/pii/S0890540118300567},
volume = {260},
year = {2018}
}
@inproceedings{McSherry2007,
abstract = {We study the role that privacy-preserving algorithms, which$\backslash$nprevent the leakage of specific information about participants, can play in$\backslash$nthe design of mechanisms for strategic agents, which must encourage players$\backslash$nto honestly report information. Specifically, we show that the recent notion$\backslash$nof differential privacv, in addition to its own intrinsic virtue, can ensure$\backslash$nthat participants have limited effect on the outcome of the mechanism, and as$\backslash$na consequence have limited incentive to lie. More precisely, mechanisms with$\backslash$ndifferential privacy are approximate dominant strategy under arbitrary player$\backslash$nutility functions, are automatically resilient to coalitions, and easily$\backslash$nallow repeatability. We study several special cases of the unlimited supply$\backslash$nauction problem, providing new results for digital goods auctions, attribute$\backslash$nauctions, and auctions with arbitrary structural constraints on the prices.$\backslash$nAs an important prelude to developing a privacy-preserving auction mechanism,$\backslash$nwe introduce and study a generalization of previous privacy work that$\backslash$naccommodates the high sensitivity of the auction setting, where a single$\backslash$nparticipant may dramatically alter the optimal fixed price, and a slight$\backslash$nchange in the offered price may take the revenue from optimal to zero.},
author = {McSherry, Frank and Talwar, Kunal},
booktitle = {48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)},
doi = {10.1109/FOCS.2007.66},
file = {:Users/liang-tingchen/Dropbox/References/McSherry, Talwar - 2007 - Mechanism Design via Differential Privacy.pdf:pdf},
isbn = {0-7695-3010-9},
issn = {0272-5428},
month = {oct},
pages = {94--103},
publisher = {IEEE},
title = {{Mechanism Design via Differential Privacy}},
url = {http://ieeexplore.ieee.org/document/4389483/},
year = {2007}
}
@incollection{Sakayori2019,
abstract = {This paper introduces a new categorical structure that is a model of a variant of the i/o-typed $\pi$-calculus, in the same way that a cartesian closed category is a model of the ⋋-calculus. To the best of our knowledge, no categorical model has been given for the i/o-typed $\pi$-calculus, in contrast to session-typed calculi, to which corresponding logic and categorical structure were given. The categorical structure introduced in this paper has a simple definition, combining two well-known structures, namely, closed Freyd category and compact closed category. The former is a model of effectful computation in a general setting, and the latter describes connections via channels, which cause the effect we focus on in this paper. To demonstrate the relevance of the categorical model, we show by a semantic consideration that the $\pi$ -calculus is equivalent to a core calculus of Concurrent ML.},
author = {Sakayori, Ken and Tsukada, Takeshi},
booktitle = {Programming Languages and Systems. ESOP 2019},
doi = {10.1007/978-3-030-17184-1_23},
editor = {Caires, Lu{\'{i}}s},
file = {:Users/liang-tingchen/Dropbox/References/Sakayori, Tsukada - 2019 - A Categorical Model of an {\$}{\$}mathbf {\{}io{\}}{\$}{\$} -typed {\$}{\$}pi {\$}{\$} -calculus.pdf:pdf},
isbn = {9783030171834},
issn = {16113349},
keywords = {Categorical type theory,Closed Freyd category,Compact closed category,$\pi$-calculus},
pages = {640--667},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Categorical Model of an {\$}{\$}$\backslash$mathbf {\{}i/o{\}}{\$}{\$} -typed {\$}{\$}$\backslash$pi {\$}{\$} -calculus}},
url = {http://dx.doi.org/10.1007/978-3-030-17184-1{\_}23 http://link.springer.com/10.1007/978-3-030-17184-1{\_}23},
volume = {11423},
year = {2019}
}
@inproceedings{Hasuo2013,
abstract = {Coinductive predicates express persisting "safety" specifications of transition systems. Previous observations by Hermida and Jacobs identify coinductive predicates as suitable final coalgebras in a fibration - a categorical abstraction of predicate logic. In this paper we follow the spirit of a seminal work by Worrell and study final sequences in a fibration. Our main contribution is to identify some categorical "size restriction" axioms that guarantee stabilization of final sequences after ?? steps. In its course we develop a relevant categorical infrastructure that relates fibrations and locally presentable categories, a combination that does not seem to be studied a lot. The genericity of our fibrational framework can be exploited for: binary relations (i.e. the logic of "binary predicates") for which a coinductive predicate is bisimilarity; constructive logics (where interests are growing in coinductive predicates); and logics for name-passing processes. ?? 2013 Elsevier B.V.},
author = {Hasuo, Ichiro and Cho, Kenta and Kataoka, Toshiki and Jacobs, Bart},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/j.entcs.2013.09.014},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo et al. - 2013 - Coinductive predicates and final sequences in a fibration.pdf:pdf},
issn = {15710661},
keywords = {(co)recursive predicate,coalgebra,fibration,locally presentable category,modal logic},
month = {nov},
pages = {197--214},
publisher = {Elsevier B.V.},
title = {{Coinductive predicates and final sequences in a fibration}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066113000601},
volume = {298},
year = {2013}
}
@book{Jones1999,
abstract = {Partial evaluation reconciles generality with efficiency by providing automated specialization and optimization of programs. This book covers the entire field of partial evaluation and takes the reader through a gentle introduction to state-of-the-art techniques. It is the first complete book on automatic partial evaluation to provide a practical and theoretically well-founded overview. Simple and complete algorithms are included and the book demonstrates by numerous examples that specialization can increase efficiency considerably.},
author = {Jones, Neil D. and Gomard, Carsten K. and Sestoft, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Jones, Gomard, Sestoft - 1999 - Partial Evaluation and Automatic Program Generation.pdf:pdf},
isbn = {0130202495},
month = {jun},
pages = {xii + 415},
publisher = {Prentice Hall International},
title = {{Partial Evaluation and Automatic Program Generation}},
url = {www.itu.dk/{~}sestoft/pebook/jonesgomardsestoft-a4.pdf?},
year = {1999}
}
@article{McBride2011,
abstract = {This paper re-examines the presentation of datatypes in dependently typed languages, addressing in particular the issue of what it means for one datatype to be in various ways more informative than another. Informal human observations like ‘lists are natural numbers with extra decoration' and ‘vectors are lists indexed by length' are expressed in a first class language of ornaments — presentations of fancy new types based on plain old ones — encompassing both decoration and, in the sense of Tim Freeman and Frank Pfenning (1991), refinement. Each ornament adds information, so it comes with a forgetful function from fancy data back to plain, expressible as the fold of its ornamental algebra: lists built from numbers acquire the ‘length' algebra. Conversely, each algebra for a datatype induces a way to index it — an algebraic ornament. The length algebra for lists induces the construction of the paradigmatic dependent vector types. Dependent types thus provide not only a new ‘axis of diversity' — indexing — for data structures, but also new abstractions to manage and exploit that diversity. In the spirit of ‘the new program- ming' (McBride {\&} McKinna, 2004), the engineering of coincidence is replaced by the propagation of consequence.},
author = {McBride, Conor},
file = {:Users/liang-tingchen/Dropbox/References/McBride - Unknown - Ornamental Algebras, Algebraic Ornaments.pdf:pdf},
keywords = {dependent types,generic programming},
title = {{Ornamental Algebras, Algebraic Ornaments}}
}
@book{Borceux1994c,
author = {Borceux, Francis},
isbn = {9780521061247},
pages = {544},
publisher = {Cambridge University Press},
series = {Encyclopedia of Mathematics and its Applications},
title = {{Handbook of Categorical Algebra 3: Sheaf Theory}},
year = {1994}
}
@article{Power2002,
author = {Power, A. John and Watanabe, Hiroshi},
doi = {10.1016/S0304-3975(01)00024-X},
file = {:Users/liang-tingchen/Dropbox/References/Power, Watanabe - 2002 - Combining a monad and a comonad.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {2-category,algebra,coalgebra,comonad,distributive,kleisli construction,monad},
month = {may},
number = {1-2},
pages = {137--162},
title = {{Combining a monad and a comonad}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030439750100024X},
volume = {280},
year = {2002}
}
@article{Boja2015,
abstract = {The principle behind algebraic language theory for various kinds of structures, such as words or trees, is to use a compositional function from the structures into a finite set. To talk about compositionality, one needs some way of composing structures into bigger structures. It so happens that category theory has an abstract concept for this, namely a monad. The goal of this paper is to propose monads as a unifying framework for discussing existing algebras and designing new algebras.},
archivePrefix = {arXiv},
arxivId = {1502.04898},
author = {Boja{\'{n}}czyk, Miko{\l}aj},
doi = {10.1007/978-3-319-21500-6_1},
editor = {Potapov, Igor},
eprint = {1502.04898},
file = {:Users/liang-tingchen/Dropbox/References/Boja{\'{n}}czyk - 2015 - Recognisable languages over monads.pdf:pdf},
isbn = {978-3-319-21499-3},
journal = {19th International Conference on Developments in Language Theory},
pages = {1--13},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Recognisable languages over monads}},
url = {http://arxiv.org/abs/1502.04898 http://link.springer.com/10.1007/978-3-319-21500-6 http://link.springer.com/10.1007/978-3-319-21500-6{\_}1},
year = {2015}
}
@article{Blanchette2019,
author = {Blanchette, Jasmin Christian and Gheri, Lorenzo and Popescu, Andrei and Traytel, Dmitriy},
doi = {10.1145/3290335},
file = {:Users/liang-tingchen/Dropbox/References/Blanchette et al. - 2019 - Bindings as bounded natural functors.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {inductive and coinductive da,syntax with bindings},
month = {jan},
number = {POPL},
pages = {1--34},
title = {{Bindings as bounded natural functors}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290335},
volume = {3},
year = {2019}
}
@incollection{Kurz2010b,
author = {Kurz, Alexander and Venema, Yde},
booktitle = {Advances in Modal Logic},
editor = {Beklemishev, Lev and Goranko, Valentin and Shehtman, Valentin},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Venema - 2010 - Coalgebraic Lindstr{\"{o}}m Theorems.pdf:pdf},
isbn = {978-1-84890-013-4},
keywords = {Lindstr{\"{o}}m,coalgebra,modal logic},
pages = {292--309},
publisher = {College Publications},
title = {{Coalgebraic Lindstr{\"{o}}m Theorems}},
volume = {8},
year = {2010}
}
@book{Wadler2019,
annote = {Available at $\backslash$url{\{}http://plfa.inf.ed.ac.uk/{\}}},
author = {Wadler, Philip and Kokke, Wen},
title = {{Programming Language Foundations in Agda}},
year = {2019}
}
@inproceedings{Mcbride2004,
address = {New York, New York, USA},
author = {McBride, Conor and McKinna, James},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell - Haskell '04},
doi = {10.1145/1017472.1017477},
file = {:Users/liang-tingchen/Dropbox/References/McBride, McKinna - 2004 - Functional pearl.pdf:pdf},
isbn = {1581138504},
keywords = {abstract syntax,bound variables,de bruijn representation,free,fresh names,haskell,implementing epigram,induction,variables},
number = {I},
pages = {1},
publisher = {ACM Press},
title = {{Functional pearl}},
url = {http://portal.acm.org/citation.cfm?doid=1017472.1017477},
year = {2004}
}
@article{VanOosten1997,
abstract = {Two straightforward "extensionalisations" of Kleene's realizability are considered; denoted re and e. It is shown that these realizabilities are not equivalent. While the re-notion is (as a relation between numbers and sentences) a subset of Kleene's realizability, the e-notion is not. The problem of an axiomatization of e-realizability is attacked and one arrives at an axiomatization over a conservative extension of arithmetic, in a language with variables for finite sets. A derived rule for arithmetic is obtained by the use of a q-variant of e-realizability; this rule subsumes the well-known Extended Church's Rule. The second part of the paper focuses on toposes for these realizabilities. By a relaxation of the notion of partial combinatory algebra, a new class of realizability toposes emerges. Relationships between the various realizability toposes are given, and results analogous to Robinson and Rosolini's characterization of the effective topos, are obtained for a topos generalizing e-realizability.},
author = {van Oosten, Jaap},
doi = {10.1016/S0168-0072(96)00050-4},
file = {:Users/liang-tingchen/Dropbox/References/Van Oosten - 1997 - Extensional realizability.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Extensional realizability,Intuitionistic arithmetic,Partial combinatory algebras,Realizability toposes},
month = {apr},
number = {3},
pages = {317--349},
title = {{Extensional realizability}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007296000504},
volume = {84},
year = {1997}
}
@inproceedings{Benton2010,
address = {Dagstuhl, Germany},
annote = {Keywords: Step-Indexing, Logical Relations, Low-Level Languages, Compiler Correctness},
author = {Benton, Nick and Hur, Chung-Kil},
booktitle = {Modelling, Controlling and Reasoning About State},
editor = {Ahmed, Amal and Benton, Nick and Birkedal, Lars and Hofmann, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Benton, Hur - 2010 - Step-Indexing The Good, the Bad and the Ugly.pdf:pdf},
issn = {1862-4405},
number = {10351},
publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, Germany},
series = {Dagstuhl Seminar Proceedings},
title = {{Step-Indexing: The Good, the Bad and the Ugly}},
url = {http://drops.dagstuhl.de/opus/volltexte/2010/2808},
year = {2010}
}
@phdthesis{Morphology,
abstract = {In this thesis, we study abstract and concrete type theories. We introduce an abstract notion of a type theory to obtain general results in the semantics of type theories, but we also provide a syntactic way of presenting a type theory to allow us a further investigation into a concrete type theory to obtain consistency and independence results.},
author = {Uemura, Taichi},
file = {:Users/liang-tingchen/Dropbox/References/Uemura - 2021 - Abstract and Concrete Type Theories.pdf:pdf},
isbn = {978-94-6421-376-8},
pages = {264},
publisher = {Amsterdam: Institute for Logic, Language and Computation},
school = {University of Amsterdam},
title = {{Abstract and Concrete Type Theories}},
type = {PhD thesis},
url = {https://hdl.handle.net/11245.1/41ff0b60-64d4-4003-8182-c244a9afab3b},
year = {2021}
}
@article{Santocanale2008,
abstract = {A $\mu$-algebra is a model of a first-order theory that is an extension of the theory of bounded lattices, that comes with pairs of terms (f, $\mu$x . f) where $\mu$x . f is axiomatized as the least prefixed point of f, whose axioms are equations or equational implications. Standard $\mu$-algebras are complete meaning that their lattice reduct is a complete lattice. We prove that any nontrivial quasivariety of $\mu$-algebras contains a $\mu$-algebra that has no embedding into a complete $\mu$-algebra. We then focus on modal $\mu$-algebras, i.e. algebraic models of the propositional modal $\mu$-calculus. We prove that free modal $\mu$-algebras satisfy a condition-reminiscent of Whitman's condition for free lattices-which allows us to prove that (i) modal operators are adjoints on free modal $\mu$-algebras, (ii) least prefixed points of $\Sigma$1-operations satisfy the constructive relation $\mu$x . f = {\{}n-ary logical or{\}}n ≥ 0 fn (⊥). These properties imply the following statement: the MacNeille-Dedekind completion of a free modal$\mu$ -algebra is a complete modal$\mu$ -algebra and moreover the canonical embedding preserves all the operations in the classComp ($\Sigma$1, $\Pi$1) of the fixed point alternation hierarchy. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Santocanale, Luigi},
doi = {10.1016/j.apal.2007.11.001},
file = {:Users/liang-tingchen/Dropbox/References/Santocanale - 2008 - Completions of $\mu$-algebras.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Completions,Least fixed point,Modal $\mu$-calculus},
number = {1},
pages = {27--50},
title = {{Completions of $\mu$-algebras}},
volume = {154},
year = {2008}
}
@inproceedings{Altenkirch2001,
abstract = {We solve the decision problem for simply typed lambda calculus with strong binary sums, equivalently the word problem for free cartesian closed categories with binary coproducts. Our method is based on the semantical technique known as "normalization by evaluation" and involves inverting the interpretation of the syntax into a suitable sheaf model and from this extracting appropriate unique normal forms. There is no rewriting theory involved, and the proof is completely constructive, allowing program extraction from the proof.},
author = {Altenkirch, Thorsten and Dybjer, Peter and Hofmann, Martin and Scott, Philip J.},
booktitle = {Proceedings 16th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2001.932506},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch et al. - 2001 - Normalization by evaluation for typed lambda calculus with coproducts.pdf:pdf},
isbn = {0-7695-1281-X},
issn = {10436871},
pages = {303--310},
publisher = {IEEE Comput. Soc},
title = {{Normalization by evaluation for typed lambda calculus with coproducts}},
url = {http://ieeexplore.ieee.org/document/932506/},
year = {2001}
}
@article{Wilke1996,
abstract = {The class of frontier testable (i.e., reverse definite) tree languages is characterized by a finite set of pseudoidentities for tree algebras, which are introduced here for this characterization. An efficient algorithm is presented that decides whether a given tree automaton recognizes a frontier testable tree language. The algorithm runs in time O(mn3 +m2n2), where m is the cardinality of the alphabet and n is the number of states of the automaton.},
author = {Wilke, Thomas},
doi = {10.1016/0304-3975(95)00131-X},
file = {:Users/liang-tingchen/Dropbox/References/Wilke - 1996 - An algebraic characterization of frontier testable tree languages.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {85--106},
title = {{An algebraic characterization of frontier testable tree languages}},
volume = {154},
year = {1996}
}
@inproceedings{10.1007/978-3-030-45231-5_14,
abstract = {This paper introduces an expressive class of quotient-inductive types, called QW-types. We show that in dependent type theory with uniqueness of identity proofs, even the infinitary case of QW-types can be encoded using the combination of inductive-inductive definitions involving strictly positive occurrences of Hofmann-style quotient types, and Abel's size types. The latter, which provide a convenient constructive abstraction of what classically would be accomplished with transfinite ordinals, are used to prove termination of the recursive definitions of the elimination and computation properties of our encoding of QW-types. The development is formalized using the Agda theorem prover.},
address = {Cham},
author = {Fiore, Marcelo P and Pitts, Andrew M and Steenkamp, S C},
booktitle = {Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-030-45231-5_14},
editor = {Goubault-Larrecq, Jean and K{\"{o}}nig, Barbara},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Pitts, Steenkamp - 2020 - Constructing Infinitary Quotient-Inductive Types.pdf:pdf},
isbn = {978-3-030-45231-5},
issn = {16113349},
keywords = {category theory,dependent type theory,higher inductive types,inductive-inductive definitions,quotient types,sized types},
pages = {257--276},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Constructing Infinitary Quotient-Inductive Types}},
url = {http://link.springer.com/10.1007/978-3-030-45231-5{\_}14},
volume = {12077},
year = {2020}
}
@article{Adamek2002,
abstract = {Weak factorization systems, important in homotopy theory, are related to injective objects in comma-categories. Our main result is that full functors and topological functors form a weak factorization system in the category of small categories, and that this is not cofibrantly generated. We also present a weak factorization system on the category of posets which is not cofibrantly generated. No such weak factorization systems were known until recently. This answers an open problem posed by M. Hovey.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Herrlich, Horst and Rosick{\'{y}}, Jiř{\'{i}} and Tholen, Walter},
doi = {10.1023/A:1015270120061},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2002 - Weak Factorization Systems and Topological Functors.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {Mathematics and Statistics},
month = {jun},
number = {3},
pages = {237--249},
publisher = {Springer Netherlands},
title = {{Weak Factorization Systems and Topological Functors}},
url = {http://www.springerlink.com/content/7qvpg23jcdeakk2a/},
volume = {10},
year = {2002}
}
@incollection{Turi1997,
author = {Turi, Daniele},
booktitle = {7th International Conference, CTCS '97},
doi = {10.1007/BFb0026985},
editor = {Moggi, Eugenio and Rosolini, Giuseppe},
file = {:Users/liang-tingchen/Dropbox/References/Turi - 1997 - Categorical Modelling of Structural Operational Rules.pdf:pdf},
isbn = {978-3-540-63455-3},
pages = {127--146},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Categorical Modelling of Structural Operational Rules}},
year = {1997}
}
@article{Longley1997,
abstract = {We propose a uniform way of isolating a subcategory of predomains within the category of modest sets determined by a partial combinatory algebra (PCA). Given a divergence on a PCA (which determines a notion of partiality), we identify a candidate category of predomains, the well-complete objects . We show that, whenever a single strong completeness axiom holds, the category satisfies appropriate closure properties. We consider a range of examples of PCAs with associated divergences and show that in each case the axiom does hold. These examples encompass models allowing a ‘parallel' style of computation (for example, by interleaving), as well as models that seemingly allow only ‘sequential' computation, such as those based on term-models for the lambda-calculus. Thus, our approach provides a uniform approach to domain theory across a wide class of realizability models. We compare our treatment with previous approaches to domain theory in realizability models. It appears that no other approach applies across such a wide range of models.},
author = {LONGLEY, JOHN R. and SIMPSON, ALEX K.},
doi = {10.1017/S0960129597002387},
file = {:Users/liang-tingchen/Dropbox/References/LONGLEY, SIMPSON - 1997 - A uniform approach to domain theory in realizability models.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {5},
pages = {469--505},
title = {{A uniform approach to domain theory in realizability models}},
url = {https://www.cambridge.org/core/product/identifier/S0960129597002387/type/journal{\_}article},
volume = {7},
year = {1997}
}
@article{Hyland2007a,
author = {Hyland, Martin and Power, A. John},
doi = {10.1016/j.entcs.2007.02.019},
file = {:Users/liang-tingchen/Dropbox/References/Hyland, Power - 2007 - The Category Theoretic Understanding of Universal Algebra Lawvere Theories and Monads.pdf:pdf},
issn = {1571-0661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Universal algebra,algebra,universal},
mendeley-tags = {algebra,universal},
number = {0},
pages = {437--458},
title = {{The Category Theoretic Understanding of Universal Algebra: Lawvere Theories and Monads}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/S1571066107000874},
volume = {172},
year = {2007}
}
@article{Pitts2002,
abstract = {The notion of tripos (Hyland et al. 1980; Pitts 1981) was motivated by the desire to explain in what sense Higg's description of sheaf toposes as H-valued sets and Hyland's realizability toposes are instances of the same construction. The construction itself can be seen as the universal solution to the problem of realizing the predicates of a first order hyperdoctrine as subobjects in a logos with effective equivalence relations. In this note it is shown that the resulting logos is actually a topos if and only if the original hyperdoctrine satisfies a certain comprehension property. Triposes satisfy this property, but there are examples of non-triposes satisfying this form of comprehension. {\textcopyright} 2002, Cambridge University Press. All rights reserved.},
author = {Pitts, Andrew M.},
doi = {10.1017/S096012950200364X},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2002 - Tripos theory in retrospect.pdf:pdf},
isbn = {0960129502},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {03},
pages = {265--279},
title = {{Tripos theory in retrospect}},
url = {http://www.journals.cambridge.org/abstract{\_}S096012950200364X},
volume = {12},
year = {2002}
}
@inproceedings{Altenkirch2009,
abstract = {We show that the syntactically rich notion of inductive families can be reduced to a core type theory with a fixed number of type constructors exploiting the novel notion of indexed containers. Indexed containers generalize simple containers, capturing strictly positive families instead of just strictly positive types, without having to extend the core type theory. Other applications of indexed containers include data type-generic programming and reasoning about polymorphic functions. The construction presented here has been formalized using the Agda system.},
author = {Altenkirch, Thorsten and Morris, Peter},
booktitle = {Logic in Computer Science},
doi = {10.1109/LICS.2009.33},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Morris - 2009 - Indexed containers.pdf:pdf},
isbn = {9780769537467},
issn = {10436871},
keywords = {Functional programming,Type theory},
pages = {277--285},
title = {{Indexed containers}},
year = {2009}
}
@inproceedings{Adams2015,
abstract = {Hygiene is an essential aspect of Scheme's macro system that prevents unintended variable capture. However, previous work on hygiene has focused on algorithmic implementation rather than precise, mathematical definition of what constitutes hygiene. This is in stark contrast with lexical scope, alpha-equivalence and captureavoiding substitution, which also deal with preventing unintended variable capture but have widely applicable and well-understood mathematical definitions. This paper presents such a precise, mathematical definition of hygiene. It reviews various kinds of hygiene violation and presents examples of how they occur. From these examples, we develop a practical algorithm for hygienic macro expansion. We then present algorithm-independent, mathematical criteria for whether a macro expansion algorithm is hygienic. This characterization corresponds closely to existing hygiene algorithms and sheds light on aspects of hygiene that are usually overlooked in informal definitions.},
address = {New York, NY, USA},
author = {Adams, Michael D.},
booktitle = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2676726.2677013},
file = {:Users/liang-tingchen/Dropbox/References/Adams - 2015 - Towards the Essence of Hygiene.pdf:pdf},
isbn = {9781450333009},
issn = {15232867},
keywords = {Hygiene,Macros,Nominal logic},
month = {jan},
number = {1},
pages = {457--469},
publisher = {ACM},
title = {{Towards the Essence of Hygiene}},
url = {https://dl.acm.org/doi/10.1145/2676726.2677013},
volume = {50},
year = {2015}
}
@article{Dawid2001,
author = {Dawid, A.P.},
doi = {10.1023/A:1016734104787},
file = {:Users/liang-tingchen/Dropbox/References/Dawid - 2001 - Separoids A mathematical framework for conditional independence and irrelevance.pdf:pdf},
issn = {10122443},
journal = {Annals of Mathematics and Artificial Intelligence},
keywords = {Basic separoid,Belief function,Belief independence,Covariance independence,Directed Markov,Distributive,Graphoid,Hyper independence,Irrelevance,Join-orthogonal,Lattice,Linear independence,Markov,Meta independence,Modular,Natural independence},
number = {1/4},
pages = {335--372},
title = {{Separoids: A mathematical framework for conditional independence and irrelevance}},
url = {http://link.springer.com/10.1023/A:1016734104787},
volume = {32},
year = {2001}
}
@article{Banaschewski2006,
abstract = {In this paper we bring together results from a series of previous papers to prove the constructive version of the Gelfand duality theorem in any Grothendieck topos E, obtaining a dual equivalence between the category of commutative C∗-algebras and the category of compact, completely regular locales in the topos E.},
author = {Banaschewski, Bernhard and Mulvey, Christopher J.},
doi = {10.1016/j.apal.2005.05.018},
file = {:Users/liang-tingchen/Dropbox/References/Banaschewski, Mulvey - 2006 - A globalisation of the Gelfand duality theorem.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {18f99,46l99},
month = {jan},
number = {1-3},
pages = {62--103},
title = {{A globalisation of the Gelfand duality theorem}},
url = {http://dx.doi.org/10.1016/j.apal.2005.05.018},
volume = {137},
year = {2006}
}
@article{Ponto2012,
abstract = {By the Lefschetz fixed point theorem, if an endomorphism of a topological space is fixed-point-free, then its Lefschetz number vanishes. This necessary condition is not usually sufficient, however; for that we need a refinement of the Lefschetz number called the Reidemeister trace. Abstractly, the Lefschetz number is a trace in a symmetric monoidal category, while the Reidemeister trace is a trace in a bicategory; in this paper we relate these contexts using indexed symmetric monoidal categories. In particular, we will show that for any symmetric monoidal category with an associated indexed symmetric monoidal category, there is an associated bicategory which produces refinements of trace analogous to the Reidemeister trace. This bicategory also produces a new notion of trace for parametrized spaces with dualizable fibers, which refines the obvious "fiberwise" traces by incorporating the action of the fundamental group of the base space. We also advance the basic theory of indexed monoidal categories, including introducing a string diagram calculus which makes calculations much more tractable. This abstract framework lays the foundation for generalizations of these ideas to other contexts.},
archivePrefix = {arXiv},
arxivId = {1211.1555},
author = {Ponto, Kate and Shulman, Michael},
eprint = {1211.1555},
file = {:Users/liang-tingchen/Dropbox/References/Ponto, Shulman - 2012 - Duality and traces for indexed monoidal categories.pdf:pdf},
month = {nov},
number = {23},
pages = {582--659},
title = {{Duality and traces for indexed monoidal categories}},
url = {http://arxiv.org/abs/1211.1555},
volume = {26},
year = {2012}
}
@article{Pattinson2003a,
author = {Pattinson, Dirk},
doi = {10.1016/S1571-0661(04)80642-X},
editor = {Gumm, H. Peter},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson - 2003 - Computable Functions on Final Coalgebras.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jul},
number = {1},
pages = {237--256},
publisher = {Elsevier B.V.},
title = {{Computable Functions on Final Coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S157106610480642X},
volume = {82},
year = {2003}
}
@article{Watanabe2002,
author = {Watanabe, Hiroshi},
doi = {10.1016/S1571-0661(04)80372-4},
file = {:Users/liang-tingchen/Dropbox/References/Watanabe - 2002 - Well-behaved Translations between Structural Operational Semantics.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {oct},
number = {1},
pages = {337--357},
title = {{Well-behaved Translations between Structural Operational Semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104803724},
volume = {65},
year = {2002}
}
@article{Yager1987,
abstract = {We discuss the basic concepts of the Dempster-Shafer approach, basic probability assignments, belief functions, and probability functions. We discuss how to represent various types of knowledge in this framework. We discuss measures of entropy and specificity for belief structures. We discuss the combination and extension of belief structures. We introduce some concerns associated with the Dempster rule of combination inherent in the normalization due to conflict. We introduce two alternative techniques for combining belief structures. The first uses Dempster's rule, while the second is based upon a modification of this rule. We discuss the issue of credibility of a witness. {\textcopyright} 1987.},
author = {Yager, Ronald R.},
doi = {10.1016/0020-0255(87)90007-7},
file = {:Users/liang-tingchen/Dropbox/References/Yager - 1987 - On the dempster-shafer framework and new combination rules.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
month = {mar},
number = {2},
pages = {93--137},
title = {{On the dempster-shafer framework and new combination rules}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0020025587900077},
volume = {41},
year = {1987}
}
@article{Barendregt1991,
abstract = {Programming languages often come with type systems. Some of these are simple, others are sophisticated. As a stylistic representation of types in programming languages several versions of typed lambda calculus are studied. During the last 20 years many of these systems have appeared, so there is some need of classification. Working towards a taxonomy, Barendregt (1991) gives a fine-structure of the theory of constructions (Coquand and Huet 1988) in the form of a canonical cube of eight type systems ordered by inclusion. Berardi (1988) and Terlouw (1988) have independently generalized the method of constructing systems in the $\lambda$-cube. Moreover, Berardi (1988, 1990) showed that the generalized type systems are flexible enough to describe many logical systems. In that way the well-known propositions-as-types interpretation obtains a nice canonical form.},
author = {Barendregt, Henk},
doi = {10.1017/S0956796800020025},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt - 1991 - Introduction to generalized type systems.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {apr},
number = {2},
pages = {125--154},
title = {{Introduction to generalized type systems}},
url = {https://www.cambridge.org/core/product/identifier/S0956796800020025/type/journal{\_}article},
volume = {1},
year = {1991}
}
@inproceedings{mellis_et_al:LIPIcs:2020:12328,
abstract = {Lawvere observed in his celebrated work on hyperdoctrines that the set-theoretic schema of comprehension can be elegantly expressed in the functorial language of categorical logic, as a comprehension structure on the functor {\$}p:\backslashmathscr{\{}E{\}}\backslashto\backslashmathscr{\{}B{\}}{\$} defining the hyperdoctrine. In this paper, we formulate and study a strictly ordered hierarchy of three notions of comprehension structure on a given functor {\$}p:\backslashmathscr{\{}E{\}}\backslashto\backslashmathscr{\{}B{\}}{\$}, which we call (i) comprehension structure, (ii) comprehension structure with section, and (iii) comprehension structure with image. Our approach is 2-categorical and we thus formulate the three levels of comprehension structure on a general morphism {\$}p:\backslashmathrm{\{}\backslashmathbf{\{}E{\}}{\}}\backslashto\backslashmathrm{\{}\backslashmathbf{\{}B{\}}{\}}{\$} in a 2-category {\$}\backslashmathscr{\{}K{\}}{\$}. This conceptual point of view on comprehension structures enables us to revisit the work by Fumex, Ghani and Johann on the duality between comprehension structures and quotient structures on a given functor {\$}p:\backslashmathscr{\{}E{\}}\backslashto\backslashmathscr{\{}B{\}}{\$}. In particular, we show how to lift the comprehension and quotient structures on a functor {\$}p:\backslashmathscr{\{}E{\}}\backslashto\backslashmathscr{\{}B{\}}{\$} to the categories of algebras or coalgebras associated to functors {\$}F{\_}{\{}\backslashmathscr{\{}E{\}}{\}}:\backslashmathscr{\{}E{\}}\backslashto\backslashmathscr{\{}E{\}}{\$} and {\$}F{\_}{\{}\backslashmathscr{\{}B{\}}{\}}:\backslashmathscr{\{}B{\}}\backslashto\backslashmathscr{\{}B{\}}{\$} of interest, in order to interpret reasoning by induction and coinduction in the traditional language of categorical logic, formulated in an appropriate 2-categorical way.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (Comprehension and Quotient Structures in the Language of 2-Categories - Melli{\`{e}}s, Paul-Andr{\'{e}}; Rolland, Nicolas)

Keywords: Comprehension structures, quotient structures, comprehension structures with section, comprehension structures with image, 2-categories, formal adjunctions, path objects, categorical logic, inductive reasoning on algebras, coinductive reasoning on coalgebras},
archivePrefix = {arXiv},
arxivId = {2005.10015},
author = {Melli{\`{e}}s, Paul-Andr{\'{e}} and Rolland, Nicolas},
booktitle = {5th International Conference on Formal Structures for Computation and Deduction (FSCD 2020)},
doi = {10.4230/LIPIcs.FSCD.2020.6},
editor = {Ariola, Zena M},
eprint = {2005.10015},
file = {:Users/liang-tingchen/Dropbox/References/Melli{\`{e}}s, Rolland - 2020 - Comprehension and Quotient Structures in the Language of 2-Categories.pdf:pdf},
isbn = {978-3-95977-155-9},
issn = {1868-8969},
keywords = {2-categories,2020,4230,6,and phrases comprehension structures,categorical logic,coinductive reasoning on coalgebras,comprehension structures,comprehension structures with image,digital object identifier 10,formal adjunctions,fscd,inductive reasoning on algebras,lipics,path objects,quotient structures,with section},
number = {6},
pages = {6:1----6:18},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Comprehension and Quotient Structures in the Language of 2-Categories}},
url = {http://arxiv.org/abs/2005.10015 https://drops.dagstuhl.de/opus/volltexte/2020/12328},
volume = {167},
year = {2020}
}
@incollection{Dy,
author = {Dybjer, Peter},
booktitle = {Logical Frameworks},
doi = {10.1017/CBO9780511569807.012},
editor = {Huet, G{\'{e}}rard and Plotkin, Gordon D.},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer - 1991 - Inductive sets and families in Martin-L{\"{o}}f's type theory and their set-theoretic semantics.pdf:pdf},
month = {sep},
pages = {280--306},
publisher = {Cambridge University Press},
title = {{Inductive sets and families in Martin-L{\"{o}}f's type theory and their set-theoretic semantics}},
url = {https://www.cambridge.org/core/product/identifier/CBO9780511569807A021/type/book{\_}part},
year = {1991}
}
@incollection{Preugschat2012,
abstract = {We present a framework for obtaining effective characterizations of simple fragments of future temporal logic (LTL) with the natural numbers as time domain. The framework is based on prophetic automata (also known as complete unambiguous B{\"{u}}chi automata), which enjoy strong structural properties, in particular, they separate the “finitary fraction” of a regular language of infinite words from its “infinitary fraction” in a natural fashion. Within our framework, we provide characterizations of all natural fragments of temporal logic, where, in some cases, no effective characterization had been known previously, and give lower and upper bounds for their computational complexity.},
annote = {10.1007/978-3-642-28729-9{\_}9},
author = {Preugschat, Sebastian and Wilke, Thomas},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Preugschat, Wilke - 2012 - Effective characterizations of simple fragments of temporal logic using prophetic automata.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {135--149},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Effective characterizations of simple fragments of temporal logic using prophetic automata}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}9},
volume = {7213},
year = {2012}
}
@inproceedings{Barthe2014,
abstract = {Differential privacy is a rigorous, worst-case notion of privacy-preserving computation. Informally, a probabilistic program is differentially private if the participation of a single individual in the input database has a limited effect on the program's distribution on outputs. More technically, differential privacy is a quantitative 2-safety property that bounds the distance between the output distributions of a probabilistic program on adjacent inputs. Like many 2-safety properties, differential privacy lies outside the scope of traditional verification techniques. Existing approaches to enforce privacy are based on intricate, non-conventional type systems, or customized relational logics. These approaches are difficult to implement and often cumbersome to use. We present an alternative approach that verifies differential privacy by standard, non-relational reasoning on non-probabilistic programs. Our approach transforms a probabilistic program into a non-probabilistic program which simulates two executions of the original program. We prove that if the target program is correct with respect to a Hoare specification, then the original probabilistic program is differentially private. We provide a variety of examples from the differential privacy literature to demonstrate the utility of our approach. Finally, we compare our approach with existing verification techniques for privacy.},
archivePrefix = {arXiv},
arxivId = {1407.2988},
author = {Barthe, Gilles and Gaboardi, Marco and {Gallego Arias}, Emilio Jesus and Hsu, Justin and Kunz, Cesar and Strub, Pierre-Yves},
booktitle = {2014 IEEE 27th Computer Security Foundations Symposium},
doi = {10.1109/CSF.2014.36},
eprint = {1407.2988},
file = {:Users/liang-tingchen/Dropbox/References/Barthe et al. - 2014 - Proving differential privacy in Hoare logic.pdf:pdf},
isbn = {978-1-4799-4290-9},
issn = {10636900},
keywords = {Differential privacy,Hoare logic,Privacy,Probabilistic hoare logic,Relational hoare logic,Verification},
month = {jul},
pages = {411--424},
publisher = {IEEE},
title = {{Proving differential privacy in Hoare logic}},
url = {http://ieeexplore.ieee.org/document/6957126/},
volume = {2014-Janua},
year = {2014}
}
@inproceedings{Cirstea2009,
abstract = {The coalgebraic approach to modal logic provides a uniform framework that captures the semantics of a large class of structurally different modal logics, including e.g. graded and probabilistic modal logics and coalition logic. In this paper, we introduce the coalgebraic mu-calculus, an extension of the general (coalgebraic) framework with fixpoint operators. Our main results are completeness of the associated tableau calculus and EXPTIME decidability. Technically, this is achieved by reducing satisfiability to the existence of non-wellfounded tableaux, which is in turn equivalent to the existence of winning strategies in parity games. Our results are parametric in the underlying class of models and yield, as concrete applications, previously unknown complexity bounds for the probabilistic mu-calculus and for an extension of coalition logic with fixpoints.},
address = {Berlin, Heidelberg},
author = {C{\^{i}}rstea, Corina and Kupke, Clemens and Pattinson, Dirk and Gr{\"{a}}del, Erich and Kahle, Reinhard},
booktitle = {Computer Science Logic},
doi = {10.1007/978-3-642-04027-6},
editor = {Gr{\"{a}}del, Erich and Kahle, Reinhard},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea et al. - 2009 - EXPTIME tableaux for the coalgebraic $\mu$-calculus.pdf:pdf},
isbn = {978-3-642-04026-9},
keywords = {Computer Science},
pages = {179--193},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{EXPTIME tableaux for the coalgebraic $\mu$-calculus}},
url = {http://www.springerlink.com/content/221705l8r3r7vn55/},
volume = {5771},
year = {2009}
}
@book{Roscoe1997,
abstract = {From the Publisher: Since the introduction of Hoares' Communicating Sequential Processes notation, powerful new tools have transformed CSP into a practical way of describing industrial-sized problems. This book gives you the fundamental grasp of CSP concepts you'll need to take advantage of those tools.Part I provides a detailed foundation for working with CSP, using as little mathematics as possible. It introduces the ideas behind operational, denotational and algebraic models of CSP. Parts II and III go into greater detail about theory and practice. Topics include{\&}58; parallel operators, hiding and renaming, piping and enslavement, buffers and communication, termination and sequencing, and semantic theory. Three detailed practical case studies are also presented.For anyone interested in modeling sequential processes.},
author = {Roscoe, A. William},
file = {:Users/liang-tingchen/Dropbox/References/Roscoe - 1997 - The Theory and Practice of Concurrency.pdf:pdf},
isbn = {0136744095},
pages = {512},
publisher = {Prentice Hall},
series = {Prentice Hall Internationa Series in Computer Science},
title = {{The Theory and Practice of Concurrency}},
year = {1997}
}
@article{Perkov2012,
author = {Perkov, Tin and Vukovi{\'{c}}, Mladen},
doi = {10.1016/j.apal.2012.07.001},
file = {:Users/liang-tingchen/Dropbox/References/Perkov, Vukovi{\'{c}} - 2012 - Some characterization and preservation theorems in modal logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {jul},
pages = {1--12},
title = {{Some characterization and preservation theorems in modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168007212001078},
volume = {1},
year = {2012}
}
@misc{AgdaReflection2.6,
author = {The, Agda Development Team},
title = {{Reflection}},
url = {https://agda.readthedocs.io/en/v2.6.0/language/reflection.html},
urldate = {2019-05-23},
year = {2018}
}
@inproceedings{Licata2008,
abstract = {Variable binding is a prevalent feature of the syntax and proof theory of many logical systems. In this paper, we define a programming language that provides intrinsic support for both representing and computing with binding. This language is extracted as the Curry-Howard interpretation of a focused sequent calculus with two kinds of implication, of opposite polarity. The representational arrow extends systems of definitional reflection with a notion of scoped inference rules, which are used to represent binding. On the other hand, the usual computational arrow classifies recursive functions defined by pattern-matching. Unlike many previous approaches, both kinds of implication are connectives in a single logic, which serves as a rich logical framework capable of representing inference rules that mix binding and computation. {\textcopyright} 2008 IEEE.},
author = {Licata, Daniel R. and Zeilberger, Noam and Harper, Robert},
booktitle = {2008 23rd Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2008.48},
file = {:Users/liang-tingchen/Dropbox/References/Licata, Zeilberger, Harper - 2008 - Focusing on Binding and Computation.pdf:pdf},
isbn = {978-0-7695-3183-0},
issn = {1043-6871},
month = {jun},
pages = {241--252},
publisher = {IEEE},
title = {{Focusing on Binding and Computation}},
url = {http://ieeexplore.ieee.org/document/4557915/},
year = {2008}
}
@article{Tholen2017,
abstract = {The paper proposes the notions of topological platform and quantalic topological theory for the presentation and investigation of categories of interest beyond the realm of algebra. These notions are nevertheless grounded in algebra, through the notions of monad and distributive law. The paper shows how they entail previously proposed concepts with similar goals.},
author = {Tholen, Walter},
doi = {10.1515/tmj-2017-0110},
file = {:Users/liang-tingchen/Dropbox/References/Tholen - 2017 - Quantalic topological theories.pdf:pdf},
issn = {1512-0139},
journal = {Tbilisi Mathematical Journal},
month = {nov},
number = {3},
pages = {91--104},
title = {{Quantalic topological theories}},
url = {http://www.degruyter.com/view/j/tmj.2017.10.issue-3/tmj-2017-0110/tmj-2017-0110.xml},
volume = {10},
year = {2017}
}
@book{Hobby1988,
author = {Hobby, David and McKenzie, Ralph},
doi = {10.1090/conm/076},
file = {:Users/liang-tingchen/Dropbox/References/Hobby, McKenzie - 1988 - The Structure of Finite Algebras.pdf:pdf},
publisher = {American Mathematical Society},
series = {Contemporary Mathematics},
title = {{The Structure of Finite Algebras}},
year = {1988}
}
@article{Crans2003,
author = {Crans, Sjoerd E},
doi = {10.1023/A:1024186923002},
file = {:Users/liang-tingchen/Dropbox/References/Crans - 2003 - Localizations of Transfors.pdf:pdf},
issn = {15730514},
journal = {K-Theory},
month = {jan},
number = {1},
pages = {39--105},
title = {{Localizations of Transfors}},
url = {http://www.portico.org/Portico/article?article=pgg1zfq15rz},
volume = {28},
year = {2003}
}
@article{Maietti2010,
abstract = {We explain in detail why the notion of list-arithmetic pretopos should be taken as the general categorical definition for the construction of arithmetic universes introduced by Andr{\'{e}} Joyal to give a categorical proof of G{\"{o}}del's incompleteness results. We motivate this definition for three reasons: first, Joyal's arithmetic universes are list-arithmetic pretopoi; second, the initial arithmetic universe among Joyal's constructions is equivalent to the initial list-arithmetic pretopos; third, any list-arithmetic pretopos enjoys the existence of free internal categories and diagrams as required to prove G{\"{o}}del's incompleteness. In doing our proofs we make an extensive use of the internal type theory of the categorical structures involved in Joyal's constructions. The definition of list-arithmetic pretopos is equivalent to the general one that I came to know in a recent talk by Andr{\'{e}} Joyal. {\textcopyright} Maria Emilia Maietti, 2010.},
author = {Maietti, Maria Emilia},
file = {:Users/liang-tingchen/Dropbox/References/Maietti - 2010 - Joyal's arithmetic universe as list-arithmetic pretopos.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Categorical logic,Dependent type theory,Pretopoi},
number = {3},
pages = {39--83},
title = {{Joyal's arithmetic universe as list-arithmetic pretopos}},
volume = {24},
year = {2010}
}
@article{Foulis1994,
abstract = {The effects in a quantum-mechanical system form a partial algebra and a partially ordered set which is the prototypical example of the effect algebras discussed in this paper. The relationships among effect algebras and such structures as orthoalgebras and orthomodular posets are investigated, as are morphisms and group- valued measures (or charges) on effect algebras. It is proved that there is a universal group for every effect algebra, as well as a universal vector space over an arbitrary field.},
author = {Foulis, D. J. and Bennett, M. K.},
doi = {10.1007/BF02283036},
file = {:Users/liang-tingchen/Dropbox/References/Foulis, Bennett - 1994 - Effect algebras and unsharp quantum logics.pdf:pdf},
issn = {0015-9018},
journal = {Foundations of Physics},
month = {oct},
number = {10},
pages = {1331--1352},
title = {{Effect algebras and unsharp quantum logics}},
url = {http://link.springer.com/10.1007/BF02283036},
volume = {24},
year = {1994}
}
@article{Day1977,
author = {Day, Brian J.},
doi = {10.1017/S0004972700023509},
file = {:Users/liang-tingchen/Dropbox/References/Day - 1977 - Density presentations of functors.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
number = {03},
pages = {427--448},
title = {{Density presentations of functors}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700023509},
volume = {16},
year = {1977}
}
@book{Mostowskit1977,
author = {Keisler, H. J. and Mostowskit, A. and Robinsont, A. and Suppes, P. and Troelstra, A. S.},
editor = {Barwise, Jon},
file = {:Users/liang-tingchen/Dropbox/References/Keisler et al. - 1977 - Handbook of Mathematical Logic.pdf:pdf},
isbn = {978-0-444-86388-1},
pages = {1165},
publisher = {North Holland},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{Handbook of Mathematical Logic}},
volume = {90},
year = {1977}
}
@article{Gabbay2009,
abstract = {We present the Lambda Context Calculus. This simple lambda-calculus features variables arranged in a hierarchy of strengths such that substitution of a strong variable does not avoid capture with respect to abstraction by a weaker variable. This allows the calculus to express both capture-avoiding and capturing substitution (instantiation). The reduction rules extend the 'vanilla' lambda-calculus in a simple and modular way and preserve the look and feel of a standard lambda-calculus with explicit substitutions. Good properties of the lambda-calculus are preserved. The LamCC is confluent, and a natural injection into the LamCC of the untyped lambda-calculus exists and preserves strong normalisation. We discuss the calculus and its design with full proofs. In the presence of the hierarchy of variables, functional binding splits into a functional abstraction $\lambda$ (lambda) and a name-binder i{\{}cyrillic{\}} (new). We investigate how the components of this calculus interact with each other and with the reduction rules, with examples. In two more extended case studies we demonstrate how global state can be expressed, and how contexts and contextual equivalence can be naturally internalised using function application. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Gabbay, Murdoch J. and Lengrand, St{\'{e}}phane},
doi = {10.1016/j.ic.2009.06.004},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Lengrand - 2009 - The lambda-context calculus (extended version).pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Binders,Calculi of contexts,Capturing substitution,Explicit substitutions,Functional programming,Lambda-calculus,Nominal techniques},
month = {dec},
number = {12},
pages = {1369--1400},
title = {{The lambda-context calculus (extended version)}},
url = {http://dx.doi.org/10.1016/j.ic.2009.06.004 https://linkinghub.elsevier.com/retrieve/pii/S0890540109001540},
volume = {207},
year = {2009}
}
@article{Barr2008,
author = {Barr, Michael and Kennison, John F. and Raphael, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Barr, Kennison, Raphael - 2008 - Isbell duality.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {duality,fixed categories,sober objects},
number = {15},
pages = {504--542},
title = {{Isbell duality}},
url = {http://www.tac.mta.ca/tac/volumes/20/15/20-15abs.html},
volume = {20},
year = {2008}
}
@article{Elgot1978,
author = {Elgot, Calvin C. and Bloom, Stephen L. and Tindell, Ralph},
doi = {10.1016/0022-0000(78)90024-7},
file = {:Users/liang-tingchen/Dropbox/References/Elgot, Bloom, Tindell - 1978 - On the algebraic structure of rooted trees.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
number = {3},
pages = {362--399},
title = {{On the algebraic structure of rooted trees}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000078900247},
volume = {16},
year = {1978}
}
@article{Hashmi2018a,
abstract = {Literature on business process compliance (BPC) has predominantly focused on the alignment of the regulatory rules with the design, verification and validation of business processes. Previously surveys on BPC have been conducted with specific context in mind; however, the literature on BPC management research is largely sparse and does not accumulate a detailed understanding on existing literature and related issues faced by the domain. This survey provides a holistic view of the literature on existing BPC management approaches, and categories them based on different compliance management strategies in the context of formulated research questions. A systematic literature approach is used where search terms pertaining keywords were used to identify literature related to the research questions from scholarly databases. From initially 183 papers, we selected 79 papers related to the themes of this survey published between 2000–2015. The survey results reveal that mostly compliance management approaches center around three distinct categories namely: design-time (28{\%}), run-time (32{\%}) and auditing (10{\%}). Also, organisational and internal control based compliance management frameworks (21{\%}) and hybrid approaches make (9{\%}) of the surveyed approaches. Furthermore, open research challenges and gaps are identified and discussed with respect to the compliance problem.},
author = {Hashmi, Mustafa and Governatori, Guido and Lam, Ho-Pun and Wynn, Moe Thandar},
doi = {10.1007/s10115-017-1142-1},
file = {:Users/liang-tingchen/Dropbox/References//Hashmi et al. - 2018 - Are we done with business process compliance state of the art and challenges ahead.pdf:pdf},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {Business process compliance,Business processes,Compliance management frameworks,Normative requirements,Norms compliance,business process compliance,business processes,compliance management frameworks,normative requirements,norms compliance},
month = {jan},
number = {1},
pages = {79--133},
publisher = {Springer London},
title = {{Are we done with business process compliance: state of the art and challenges ahead}},
url = {http://link.springer.com/10.1007/s10115-017-1142-1},
volume = {57},
year = {2018}
}
@incollection{Giry1982a,
author = {Giry, Mich{\`{e}}le},
booktitle = {Categorical Aspects of Topology and Analysis},
doi = {10.1007/BFb0092872},
editor = {Banaschewski, Bernhard},
file = {:Users/liang-tingchen/Dropbox/References/Giry - 1982 - A categorical approach to probability theory.pdf:pdf},
pages = {68--85},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{A categorical approach to probability theory}},
url = {http://dx.doi.org/10.1007/BFb0092872},
year = {1982}
}
@article{Milius2013,
author = {Milius, Stefan and Moss, Lawrence S. and Schwencke, Daniel},
doi = {10.2168/LMCS-9(3:28)2013},
editor = {unknown Anonymous},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Moss, Schwencke - 2013 - Abstract GSOS Rules and a Modular Treatment of Recursive Definitions.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {sep},
number = {3},
pages = {1--52},
title = {{Abstract GSOS Rules and a Modular Treatment of Recursive Definitions}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1404},
volume = {9},
year = {2013}
}
@inproceedings{Komendantskaya2011,
author = {Komendantskaya, Ekaterina and Power, John},
booktitle = {Computer Science Logic (CSL'11) - 25th International Workshop/20th Annual Conference of the EACSL},
doi = {10.4230/LIPIcs.CSL.2011.352},
editor = {Bezem, Marc},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Power - 2011 - Coalgebraic Derivations in Logic Programming.pdf:pdf},
keywords = {Lawvere theoriesm,Logic programming,SLD-resolution,coinduction,coinductive logic programming,concurrency,concurrent logic programming},
pages = {352--366},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Coalgebraic Derivations in Logic Programming}},
url = {http://drops.dagstuhl.de/opus/volltexte/2011/3242/},
volume = {12},
year = {2011}
}
@article{Birkedal2002a,
abstract = {The classical forms of both modified realizability and relative realizability are naturally described in terms of the Sierpinski topos. The paper puts these two observations together and explains abstractly the existence of the geometric morphisms and logical functors connecting the various toposes at issue. This is done by advancing the theory of triposes over internal partial combinatory algebras and by employing a novel notion of elementary map. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Birkedal, Lars and van Oosten, Jaap},
doi = {10.1016/S0168-0072(01)00122-1},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal, van Oosten - 2002 - Relative and modified relative realizability.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Internal partial combinatory algebras,Realizability toposes},
month = {dec},
number = {1-2},
pages = {115--132},
title = {{Relative and modified relative realizability}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007201001221},
volume = {118},
year = {2002}
}
@book{Leinster2004,
abstract = {Higher-dimensional category theory is the study of n-categories, operads, braided monoidal categories, and other such exotic structures. It draws its inspiration from areas as diverse as topology, quantum algebra, mathematical physics, logic, and theoretical computer science. This is the first book on the subject and lays its foundations. The heart of this book is the language of generalized operads. This is as natural and transparent a language for higher category theory as the language of sheaves is for algebraic geometry, or vector spaces for linear algebra. It is introduced carefully, then used to give simple descriptions of a variety of higher categorical structures. In particular, one possible definition of n-category is discussed in detail, and some common aspects of other possible definitions are established. Many examples are given throughout. There is also an introductory chapter motivating the subject for topologists.},
archivePrefix = {arXiv},
arxivId = {arXiv:math/0305049v1},
author = {Leinster, Tom},
eprint = {0305049v1},
file = {:Users/liang-tingchen/Dropbox/References/Leinster - 2004 - Higher Operads , Higher Categories.pdf:pdf},
isbn = {0-521-53215-9},
primaryClass = {arXiv:math},
publisher = {Cambridge University Press},
series = {London Mathematical Society Lecture Note},
title = {{Higher Operads , Higher Categories}},
year = {2004}
}
@article{Moss2006,
author = {Moss, Lawrence S. and Viglizzo, Ignacio Dario},
doi = {10.1016/j.ic.2005.04.006},
file = {:Users/liang-tingchen/Dropbox/References/Moss, Viglizzo - 2006 - Final coalgebras for functors on measurable spaces.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {coalgebra,final coalgebra,measurable space,modal logic,probability measure},
month = {apr},
number = {4},
pages = {610--636},
title = {{Final coalgebras for functors on measurable spaces}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089054010500204X},
volume = {204},
year = {2006}
}
@article{Esik2014,
abstract = {Recently, a novel fixed point operation has been introduced over certain non-monotonic functions between stratified complete lattices and used to give semantics to logic programs with negation and boolean context-free grammars. We prove that this new operation satisfies `the standard' identities of fixed point operations as described by the axioms of iteration theories. We also study this new fixed point operation in connection with lambda-abstraction.},
archivePrefix = {arXiv},
arxivId = {1410.8111},
author = {{\'{E}}sik, Zolt{\'{a}}n},
eprint = {1410.8111},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 2014 - Equational properties of stratified least fixed points.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {1--22},
title = {{Equational properties of stratified least fixed points}},
url = {http://arxiv.org/abs/1410.8111},
year = {2014}
}
@article{Kianpi2010,
author = {Kianpi, Maurice and Jugnia, Celestin Nkuimi},
file = {:Users/liang-tingchen/Dropbox/References/Kianpi, Jugnia - 2010 - On Simple and Extensional Coalgebras Beyond Set.pdf:pdf},
journal = {Arabian Journal for Science and Engineering},
keywords = {behavioral,bisimulation,coalgebra,complete lattice,congruence,extensional,extensionalization,extensionally split,horn covariety,orthogonal,simple,simplification,simply split,subcoalgebra,topos,unitary},
number = {2},
pages = {295--313},
title = {{On Simple and Extensional Coalgebras Beyond Set}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:ON+SIMPLE+AND+EXTENSIONAL+Coalgebras+Beyond+Set{\#}3},
volume = {33},
year = {2010}
}
@article{Fiore1993,
abstract = {The concept of bisimulation from concurrency$\backslash$ntheory{\~{}}$\backslash$cite{\{}Park81,Milner89{\}} is used to reason about$\backslash$nrecursively defined data types. From two$\backslash$nstrong-extensionality theorems stating that the$\backslash$nequality (resp.$\backslash$ inequality) relation is maximal among$\backslash$nall bisimulations, a proof principle for the final$\backslash$ncoalgebra of an endofunctor on a category of data types$\backslash$n(resp.$\backslash$ domains) is obtained. As an application of the$\backslash$ntheory developed, an internal full abstraction result$\backslash$n(in the sense of{\~{}}$\backslash$cite{\{}AbramskyOng92{\}}) for the$\backslash$ncanonical model of the untyped call-by-value$\backslash$n$\lambda$-calculus is proved. $\backslash$par Also, the$\backslash$noperational notion of bisimulation and the denotational$\backslash$nnotion of final semantics are related by means of$\backslash$nconditions under which both coincide.},
author = {Fiore, Marcelo P.},
doi = {10.1006/inco.1996.0058},
file = {:Users/liang-tingchen/Dropbox/References/Fiore - 1996 - A Coinduction Principle for Recursive Data Types Based on Bisimulation.pdf:pdf},
isbn = {0818631422},
issn = {08905401},
journal = {Information and Computation},
month = {jun},
number = {2},
pages = {186--198},
title = {{A Coinduction Principle for Recursive Data Types Based on Bisimulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540196900589},
volume = {127},
year = {1996}
}
@book{Prawitz1965,
author = {Prawitz, Dag},
doi = {10.2307/2271676},
issn = {0022-4812},
pages = {113},
publisher = {Almquist and Wiksell},
title = {{Natural Deduction: A Proof-Theoretical Study}},
year = {1965}
}
@book{Milner1999a,
author = {Milner, Robin},
isbn = {0521658691},
publisher = {Cambridge Univ Pr},
title = {{Communicating and mobile systems: the $\pi$-calculus}},
type = {Book},
year = {1999}
}
@article{Ahrens2019c,
abstract = {We introduce and develop the notion of displayed categories. A displayed category over a category C is equivalent to ‘a category D and functor F:D → C', but instead of having a single collection of ‘objects of D' with a map to the objects of C, the objects are given as a family indexed by objects of C, and similarly for the morphisms. This encapsulates a common way of building categories in practice, by starting with an existing category and adding extra data/properties to the objects and morphisms. The interest of this seemingly trivial reformulation is that various properties of functors are more naturally defined as properties of the corresponding displayed categories. Grothendieck fibrations, for example, when defined as certain functors, use equality on objects in their definition. When defined instead as certain displayed categories, no reference to equality on objects is required. Moreover, almost all examples of fibrations in nature are, in fact, categories whose standard construction can be seen as going via displayed categories. We therefore propose displayed categories as a basis for the development of fibrations in the type-theoretic setting, and similarly for various other notions whose classical definitions involve equality on objects. Besides giving a conceptual clarification of such issues, displayed categories also provide a powerful tool in computer formalisation, unifying and abstracting common constructions and proof techniques of category theory, and enabling modular reasoning about categories of multi-component structures. As such, most of the material of this article has been formalised in Coq over the UniMath library, with the aim of providing a practical library for use in further developments.},
archivePrefix = {arXiv},
arxivId = {1705.04296},
author = {Ahrens, Benedikt and Lumsdaine, Peter Lefanu},
doi = {10.23638/LMCS-15(1:20)2019},
eprint = {1705.04296},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Lumsdaine - 2019 - Displayed Categories.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Category theory,Computer proof assistants,Coq,Dependent type theory,Univalent mathematics},
number = {1},
pages = {20:1--20:18},
title = {{Displayed Categories}},
volume = {15},
year = {2019}
}
@article{Isbell1966,
author = {Isbell, John R.},
file = {:Users/liang-tingchen/Dropbox/References/Isbell - 1966 - Structure of categories.pdf:pdf},
issn = {1088-9485},
journal = {Bulletin (New Series) of the American Mathematical Society},
language = {EN},
month = {jul},
number = {4},
pages = {619--655},
title = {{Structure of categories}},
url = {http://projecteuclid.org/euclid.bams/1183528163},
volume = {72},
year = {1966}
}
@article{Yasuoka2014,
abstract = {We employ Clarkson and Schneider's "hyperproperties" to classify various verification problems of quantitative information flow. The results of this paper unify and extend the previous results on the hardness of checking and inferring quantitative information flow. In particular, we identify a subclass of liveness hyperproperties, which we call ". k-observable hyperproperties", that can be checked relative to a reachability oracle via self composition.},
author = {Yasuoka, Hirotoshi and Terauchi, Tachio},
doi = {10.1016/j.tcs.2013.07.031},
file = {:Users/liang-tingchen/Dropbox/References/Yasuoka, Terauchi - 2014 - Quantitative information flow as safety and liveness hyperproperties.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Hyperproperties,Quantitative information flow,Verification},
number = {C},
pages = {167--182},
publisher = {Elsevier B.V.},
title = {{Quantitative information flow as safety and liveness hyperproperties}},
url = {http://dx.doi.org/10.1016/j.tcs.2013.07.031},
volume = {538},
year = {2014}
}
@inproceedings{Anderson2014,
address = {New York, New York, USA},
author = {Anderson, Carolyn Jane and Foster, Nate and Guha, Arjun and Jeannin, Jean-Baptiste and Kozen, Dexter and Schlesinger, Cole and Walker, David},
booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL '14},
doi = {10.1145/2535838.2535862},
file = {:Users/liang-tingchen/Dropbox/References/Anderson et al. - 2014 - NetKAT Semantics foundations for networks.pdf:pdf},
isbn = {9781450325448},
keywords = {domain-specific languages,frenetic,gramming languages,kleene algebra,network pro-,software-defined networking},
pages = {113--126},
publisher = {ACM Press},
title = {{NetKAT: Semantics foundations for networks}},
url = {http://dl.acm.org/citation.cfm?doid=2535838.2535862},
year = {2014}
}
@article{Milner1992a,
author = {Milner, Robin and Parrow, Joachim and Walker, David},
doi = {10.1016/0890-5401(92)90009-5},
file = {:Users/liang-tingchen/Dropbox/References/Milner, Parrow, Walker - 1992 - A calculus of mobile processes, II.pdf:pdf},
isbn = {9781424443499},
issn = {08905401},
journal = {Information and Computation},
month = {sep},
number = {1},
pages = {41--77},
title = {{A calculus of mobile processes, II}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0890540192900095},
volume = {100},
year = {1992}
}
@inproceedings{Chen2019a,
author = {Chen, Liang-Ting},
booktitle = {The 4th Workshop on Type-Driven Development},
file = {:Users/liang-tingchen/Dropbox/References/Chen - 2019 - Monadic typed tactic programming by reflection (extended abstract).pdf:pdf},
keywords = {agda,elaboration,interactive theorem proving,meta-programming,monads,reflection,tactics},
title = {{Monadic typed tactic programming by reflection (extended abstract)}},
year = {2019}
}
@article{Appel2001,
abstract = {The proofs of {\{}"traditional"{\}} proof carrying code {\{}(PCC){\}} are type-specialized in the sense that they require axioms about a specific type system. In contrast, the proofs of foundational {\{}PCC{\}} explicitly define all required types and explicitly prove all the required properties of those types assuming only a fixed foundation of mathematics such as higher-order logic. Foundational {\{}PCC{\}} is both more flexible and more secure than type-specialized {\{}PCC.For{\}} foundational {\{}PCC{\}} we need semantic models of type systems on von Neumann machines. Previous models have been either too weak (lacking general recursive types and first-class function-pointers), too complex (requiring machine-checkable proofs of large bodies of computability theory), or not obviously applicable to von Neumann machines. Our new model is strong, simple, and works either in {\{}{\OE}{\}}�-calculus or on Pentiums.},
author = {Appel, Andrew W. and McAllester, David},
doi = {10.1145/504709.504712},
file = {:Users/liang-tingchen/Dropbox/References/Appel, McAllester - 2001 - An indexed model of recursive types for foundational proof-carrying code.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
month = {sep},
number = {5},
pages = {657--683},
title = {{An indexed model of recursive types for foundational proof-carrying code}},
url = {http://portal.acm.org/citation.cfm?doid=504709.504712},
volume = {23},
year = {2001}
}
@incollection{Adamek2007a,
address = {Berlin, Heidelberg},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
booktitle = {Proceedings of the 32nd International Symposium on Mathematical Foundations of Computer Science},
doi = {10.1007/978-3-540-74456-6_23},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2007 - What Are Iteration Theories.pdf:pdf},
isbn = {9783540744559},
issn = {03029743},
keywords = {eilenberg-moore alge-,iteration theory,monad,rational theory},
pages = {240--252},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{What Are Iteration Theories?}},
url = {http://link.springer.com/10.1007/978-3-540-74456-6{\_}23},
volume = {4708},
year = {2007}
}
@article{Bernardy2017,
abstract = {This paper proposes a new specification of pretty printing which is stronger than the state of the art: we require the output to be the shortest possible, and we also offer the ability to align sub-documents at will. We argue that our specification precludes a greedy implementation. Yet, we provide an implementation which behaves linearly in the size of the output. The derivation of the implementation demonstrates functional programming methodology.},
author = {Bernardy, Jean-Philippe},
doi = {10.1145/3110250},
file = {:Users/liang-tingchen/Dropbox/References/Bernardy - 2017 - A pretty but not greedy printer (functional pearl).pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Pretty Printing},
month = {aug},
number = {ICFP},
pages = {1--21},
title = {{A pretty but not greedy printer (functional pearl)}},
url = {https://dl.acm.org/doi/10.1145/3110250},
volume = {1},
year = {2017}
}
@article{Bacchus1996,
abstract = {An intelligent agent will often be uncertain about various properties of its environment, and when acting in that environment it will frequently need to quantify its uncertainty. For example, if the agent wishes to employ the expected-utility paradigm of decision theory to guide its actions, it will need to assign degrees of belief (subjective probabilities) to various assertions. Of course, these degrees of belief should not be arbitrary, but rather should be based on the information available to the agent. This paper describes one approach for inducing degrees of belief from very rich knowledge bases, that can include information about particular individuals, statistical correlations, physical laws, and default rules. We call our approach the random-worlds method. The method is based on the principle of indifference: it treats all of the worlds the agent considers possible as being equally likely. It is able to integrate qualitative default reasoning with quantitative probabilistic reasoning by providing a language in which both types of information can be easily expressed. Our results show that a number of desiderata that arise in direct inference (reasoning from statistical information to conclusions about individuals) and default reasoning follow directly from the semantics of random worlds. For example, random worlds captures important patterns of reasoning such as specificity, inheritance, indifference to irrelevant information, and default assumptions of independence. Furthermore, the expressive power of the language used and the intuitive semantics of random worlds allow the method to deal with problems that are beyond the scope of many other nondeductive reasoning systems.},
archivePrefix = {arXiv},
arxivId = {cs.AI/0307056},
author = {Bacchus, Fahiem and Grove, Adam J. and Halpern, Joseph Y. and Koller, Daphne},
doi = {10.1016/S0004-3702(96)00003-3},
eprint = {0307056},
file = {:Users/liang-tingchen/Dropbox/References/Bacchus et al. - 1996 - From statistical knowledge bases to degrees of belief.pdf:pdf},
isbn = {1595933182},
issn = {00043702},
journal = {Artificial Intelligence},
month = {nov},
number = {1-2},
pages = {75--143},
primaryClass = {cs.AI},
title = {{From statistical knowledge bases to degrees of belief}},
url = {http://www.sciencedirect.com/science/article/pii/S0004370296000033 http://linkinghub.elsevier.com/retrieve/pii/S0004370296000033},
volume = {87},
year = {1996}
}
@article{Goguen1977,
author = {Goguen, J. A. and Thatcher, J. W. and Wagner, E. G. and Wright, Jesse B.},
doi = {10.1145/321992.321997},
file = {:Users/liang-tingchen/Dropbox/References/Goguen et al. - 1977 - Initial Algebra Semantics and Continuous Algebras.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {algebras,and phrases algebraic semantics,continuous algebras,flow diagrams,free algebras,grammmg language semantics,posets,pro-,solutions of equations,syntax directed translation},
month = {jan},
number = {1},
pages = {68--95},
title = {{Initial Algebra Semantics and Continuous Algebras}},
url = {http://portal.acm.org/citation.cfm?doid=321992.321997},
volume = {24},
year = {1977}
}
@article{Codd1970,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Codd, E. F.},
doi = {10.1145/362384.362685},
file = {:Users/liang-tingchen/Dropbox/References/Codd - 1970 - A relational model of data for large shared data banks.pdf:pdf},
journal = {Communications of the ACM},
keywords = {icle},
number = {6},
pages = {377--387},
title = {{A relational model of data for large shared data banks}},
url = {http://portal.acm.org/citation.cfm?doid=362384.362685},
volume = {13},
year = {1970}
}
@article{Rijke2020,
abstract = {Univalent homotopy type theory (HoTT) may be seen as a language for the category of {\$}\backslashinfty{\$}-groupoids. It is being developed as a new foundation for mathematics and as an internal language for (elementary) higher toposes. We develop the theory of factorization systems, reflective subuniverses, and modalities in homotopy type theory, including their construction using a "localization" higher inductive type. This produces in particular the ({\$}n{\$}-connected, {\$}n{\$}-truncated) factorization system as well as internal presentations of subtoposes, through lex modalities. We also develop the semantics of these constructions.},
archivePrefix = {arXiv},
arxivId = {1706.07526},
author = {Rijke, Egbert and Shulman, Michael and Spitters, Bas},
doi = {10.23638/LMCS-16(1:2)2020},
eprint = {1706.07526},
file = {:Users/liang-tingchen/Dropbox/References/Rijke, Shulman, Spitters - 2020 - Modalities in homotopy type theory.pdf:pdf},
journal = {Logical Methods in Computer Science},
number = {1},
pages = {2:1--2:79},
title = {{Modalities in homotopy type theory}},
url = {http://arxiv.org/abs/1706.07526},
volume = {16},
year = {2020}
}
@inproceedings{Brown2017,
abstract = {Many popular languages have a self-interpreter, that is, an interpreter for the language written in itself. So far, work on polymorphically- typed self-interpreters has concentrated on self-recognizers that merely recover a program from its representation. A larger and until now unsolved challenge is to implement a polymorphicallytyped self-evaluator that evaluates the represented program and produces a representation of the result. We present F$\mu$i$\omega$, the first $\lambda$- calculus that supports a polymorphically-typed self-evaluator. Our calculus extends F$\omega$ with recursive types and intensional type functions and has decidable type checking. Our key innovation is a novel implementation of type equality proofs that enables us to define a versatile representation of programs. Our results establish a new category of languages that can support polymorphically-typed selfevaluators.},
address = {New York, New York, USA},
author = {Brown, Matt and Palsberg, Jens},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
doi = {10.1145/3009837.3009853},
file = {:Users/liang-tingchen/Dropbox/References/Brown, Palsberg - 2017 - Typed self-evaluation via intensional type functions.pdf:pdf},
isbn = {9781450346603},
issn = {07308566},
keywords = {Lambda Calculus,Meta Programming,Self Evaluation,Self Interpretation,Self Representation,Type Equality},
number = {1},
pages = {415--428},
publisher = {ACM Press},
title = {{Typed self-evaluation via intensional type functions}},
url = {http://dl.acm.org/citation.cfm?doid=3009837.3009853},
year = {2017}
}
@article{Rosicky1994,
abstract = {M. Richter has proved that whenever a class K of ?-structures has a finitary first-order axiomatization then the inclusion K ? Str ? preserves all existing directed colimits (see [7]). We will generalize this result to classes of ?-structures having an infinitary first-order axiomatization in a larger signature ?'. We will also show that, as categories, these classes have a natural characterization.},
author = {Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1007/BF00878503},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}} - 1994 - More on directed colimits of models.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {Mathematics and Statistics},
month = {mar},
number = {1},
pages = {71--76},
publisher = {Springer Netherlands},
title = {{More on directed colimits of models}},
url = {http://www.springerlink.com/index/10.1007/BF00878503},
volume = {2},
year = {1994}
}
@article{Cirstea2017,
abstract = {{\textcopyright} C. C{\^{i}}rstea.We consider state-based systems modelled as coalgebras whose type incorporates branching, and show that by suitably adapting the definition of coalgebraic bisimulation, one obtains a general and uniform account of the linear-time behaviour of a state in such a coalgebra. By moving away from a boolean universe of truth values, our approach can measure the extent to which a state in a system with branching is able to exhibit a particular linear-time behaviour. This instantiates to measuring the probability of a specific behaviour occurring in a probabilistic system, or measuring the minimal cost of exhibiting a specific behaviour in the case of weighted computations.},
annote = {NULL},
author = {C{\^{i}}rstea, Corina},
doi = {10.3233/FI-2017-1474},
editor = {Baelde, David and Carayol, Arnaud and Matthes, Ralph and Walukiewicz, Igor},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2017 - From branching to linear time, coalgebraically.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
keywords = {coalgebra,linear time,trace},
month = {mar},
number = {3-4},
pages = {379--406},
title = {{From branching to linear time, coalgebraically}},
url = {http://arxiv.org/abs/1309.0891v1 http://www.medra.org/servlet/aliasResolver?alias=iospress{\&}doi=10.3233/FI-2017-1474},
volume = {150},
year = {2017}
}
@inproceedings{Kavvos2017a,
abstract = {The use of a necessity-like modality in a typed {\$}\backslashlambda{\$}-calculus can be used as a device for separating the calculus in two separate regions. These can be thought of as intensional vs. extensional data: data in the first region, the modal one, are available as code, and their description can be examined, whereas data in the second region are only available as values up to ordinary equality. This allows us to add seemingly non-functional operations at modal types, whilst maintaining consistency. In this setting the G$\backslash$"odel-L$\backslash$"ob axiom acquires a novel constructive reading: it affords the programmer the possibility of a very strong kind of recursion, by enabling him to write programs that have access to their own code. This is a type of computational reflection that is strongly reminiscent of Kleene's Second Recursion Theorem. We prove that it is consistent with the rest of the system.},
archivePrefix = {arXiv},
arxivId = {1703.01288},
author = {Kavvos, G. Alex},
booktitle = {7th Workshop on Intuitionistic Modal Logic and Applications (IMLA)},
eprint = {1703.01288},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2017 - Intensionality, Intensional Recursion, and the G{\"{o}}del-L{\"{o}}b axiom.pdf:pdf},
month = {mar},
title = {{Intensionality, Intensional Recursion, and the G{\"{o}}del-L{\"{o}}b axiom}},
url = {http://arxiv.org/abs/1703.01288},
year = {2017}
}
@article{Hennessy1985a,
author = {Hennessy, Matthew and Milner, Robin},
doi = {10.1145/2455.2460},
file = {:Users/liang-tingchen/Dropbox/References/Hennessy, Milner - 1985 - Algebraic laws for nondeterminism and concurrency.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
month = {jan},
number = {1},
pages = {137--161},
title = {{Algebraic laws for nondeterminism and concurrency}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?doid=2455.2460},
volume = {32},
year = {1985}
}
@article{Moss1999b,
abstract = {This paper is concerned with the equational logic of corecursion, that is of definitions involving final coalgebra maps. The framework for our study is iteration theories (cf. e.g. [1,2]), recently reintroduced as models of the FLR0 fragment of the Formal Language of Recursion [5-7]. We present a new class of iteration theories derived from final coalgebras. This allows us to reason with a number of types of fixed-point equations which heretofore seemed to require to metric or order-theoretic ideas. All of the work can be done using finality properties and equational reasoning. Having a semantics, we obtain the following completeness result: the equations involving fixed-point terms which are valid for final coalgebra interpretations are exactly those valid in a number of contexts pertaining to recursion. For example, they coincide with the equations valid for least-fixed point recursion on cpo's. ??1999 Published by Elsevier Science B. V.},
author = {Moss, Lawrence S.},
doi = {10.1016/S1571-0661(04)80086-0},
file = {:Users/liang-tingchen/Dropbox/References/Moss - 1999 - Recursion and Corecursion Have the Same Equational Logic.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
pages = {413--432},
title = {{Recursion and Corecursion Have the Same Equational Logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104800860},
volume = {20},
year = {1999}
}
@incollection{Capretta2009,
author = {Capretta, Venanzio and Uustalu, Tarmo and Vene, Varmo},
booktitle = {Formal Methods: Foundations and Applications. SBMF 2009},
doi = {10.1007/978-3-642-10452-7_7},
editor = {Oliveira, Marcel Vin{\'{i}}cius Medeiros and Woodcock, Jim},
file = {:Users/liang-tingchen/Dropbox/References/Capretta, Uustalu, Vene - 2009 - Corecursive Algebras A Study of General Structured Corecursion.pdf:pdf},
isbn = {3642104517},
issn = {03029743},
pages = {84--100},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Corecursive Algebras: A Study of General Structured Corecursion}},
url = {http://link.springer.com/10.1007/978-3-642-10452-7{\_}7},
volume = {5902},
year = {2009}
}
@article{Nanevski2008,
abstract = {The intuitionistic modal logic of necessity is based on the judgmental notion of categorical truth. In this article we investigate the consequences of relativizing these concepts to explicitly specified contexts. We obtain contextual modal logic and its type-theoretic analogue. Contextual modal type theory provides an elegant, uniform foundation for understanding metavariables and explicit substitutions. We sketch some applications in functional programming and logical frameworks.},
author = {Nanevski, Aleksandar and Pfenning, Frank and Pientka, Brigitte},
doi = {10.1145/1352582.1352591},
file = {:Users/liang-tingchen/Dropbox/References/Nanevski, Pfenning, Pientka - 2008 - Contextual modal type theory.pdf:pdf},
isbn = {1529-3785},
issn = {15293785},
journal = {ACM Transactions on Computational Logic},
month = {jun},
number = {3},
pages = {1--49},
title = {{Contextual modal type theory}},
url = {http://portal.acm.org/citation.cfm?doid=1352582.1352591},
volume = {9},
year = {2008}
}
@inproceedings{kaposi_et_al:LIPIcs:2020:12345,
abstract = {Inductive families of types are a feature of most languages based on dependent types. They are usually described either by syntactic schemes or by encodings of strictly positive functors such as combinator languages or containers. The former approaches are informal and give only external signatures, the latter approaches suffer from encoding overheads and do not directly represent mutual types. In this paper we propose a direct method for describing signatures for mutual inductive families using a domain-specific type theory. A signature is a context (roughly speaking, a list of types) in this small type theory. Algebras, displayed algebras and sections are defined by models of this type theory: the standard model, the logical predicate and a logical relation interpretation, respectively. We reduce the existence of initial algebras for these signatures to the existence of the syntax of our domain-specific type theory. As this theory is very simple, its normal syntax can be encoded using indexed W-types. To the best of our knowledge, this is the first formalisation of the folklore fact that mutual inductive types can be reduced to indexed W-types. The contents of this paper were formalised in the proof assistant Agda.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (A Syntax for Mutual Inductive Families - Kaposi, Ambrus; von Raumer, Jakob)

Keywords: type theory, inductive types, mutual inductive types, W-types, Agda},
author = {Kaposi, Ambrus and von Raumer, Jakob},
booktitle = {5th International Conference on Formal Structures for Computation and Deduction (FSCD 2020)},
doi = {10.4230/LIPIcs.FSCD.2020.23},
editor = {Ariola, Zena M},
file = {:Users/liang-tingchen/Dropbox/References/Kaposi, von Raumer - 2020 - A Syntax for Mutual Inductive Families.pdf:pdf},
isbn = {978-3-95977-155-9},
issn = {1868-8969},
keywords = {Agda,Inductive types,Mutual inductive types,Type theory,W-types},
number = {23},
pages = {23:1----23:21},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{A Syntax for Mutual Inductive Families}},
url = {https://drops.dagstuhl.de/opus/volltexte/2020/12345},
volume = {167},
year = {2020}
}
@article{Fiore2022,
abstract = {Despite extensive research both on the theoretical and practical fronts, formalising, reasoning about, and implementing languages with variable binding is still a daunting endeavour – repetitive boilerplate and the overly complicated metatheory of capture-avoiding substitution often get in the way of progressing on to the actually interesting properties of a language. Existing developments offer some relief, however at the expense of inconvenient and error-prone term encodings and lack of formal foundations.},
author = {Fiore, Marcelo and Szamozvancev, Dmitrij},
doi = {10.1145/3498715},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Szamozvancev - 2022 - Formal metatheory of second-order abstract syntax.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Agda,abstract syntax,category theory,language formalisation},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Formal metatheory of second-order abstract syntax}},
url = {https://dl.acm.org/doi/10.1145/3498715},
volume = {6},
year = {2022}
}
@article{Menni2003,
abstract = {We characterize the categories with finite limits whose exact completions are toposes and discuss some examples and counter-examples. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Menni, Mat{\'{i}}as},
doi = {10.1016/S0022-4049(02)00261-X},
file = {:Users/liang-tingchen/Dropbox/References/Menni - 2003 - A characterization of the left exact categories whose exact completions are toposes.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
pages = {287--301},
title = {{A characterization of the left exact categories whose exact completions are toposes}},
volume = {177},
year = {2003}
}
@article{Dezani-Ciancaglini2003,
abstract = {We propose an extension of lambda calculus for which the Berarducci trees equality coincides with observational equivalence, when we observe rootstable or rootactive behavior of terms. In one direction the proof is an adaptation of the classical B{\"{o}}hm out technique. In the other direction the proof is based on confluence for strongly converging reductions in this extension. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Dezani-Ciancaglini, Mariangiola and Severi, Paula and de Vries, Fer-Jan},
doi = {10.1016/S0304-3975(02)00809-5},
file = {:Users/liang-tingchen/Dropbox/References/Dezani-Ciancaglini, Severi, de Vries - 2003 - Infinitary lambda calculus and discrimination of Berarducci trees.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Berarducci trees,B{\"{o}}hm out technique,Infinitary lambda calculus,Observational equivalence},
month = {apr},
number = {2},
pages = {275--302},
title = {{Infinitary lambda calculus and discrimination of Berarducci trees}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397502008095},
volume = {298},
year = {2003}
}
@article{Ahmed2011,
abstract = {Several programming languages are beginning to integrate static and dynamic typing, including Racket (formerly PLT Scheme), Perl 6, and C{\#} 4.0 and the research languages Sage (Gronski, Knowles, Tomb, Freund, and Flanagan, 2006) and Thorn (Wrigstad, Eugster, Field, Nystrom, and Vitek, 2009). However, an important open question remains, which is how to add parametric polymorphism to languages that combine static and dynamic typing. We present a system that permits a value of dynamic type to be cast to a polymorphic type and vice versa, with relational parametricity enforced by a kind of dynamic sealing along the lines proposed by Matthews and Ahmed (2008) and Neis, Dreyer, and Rossberg (2009). Our system includes a notion of blame, which allows us to show that when casting between a more-precise type and a less-precise type, any cast failures are due to the less-precisely-typed portion of the program. We also show that a cast from a subtype to its supertype cannot fail.},
author = {Ahmed, Amal and Findler, Robert Bruce and Siek, Jeremy G. and Wadler, Philip},
doi = {10.1145/1925844.1926409},
file = {:Users/liang-tingchen/Dropbox/References/Ahmed et al. - 2011 - Blame for all.pdf:pdf},
isbn = {9781450304900},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Blame tracking,Casts,Coercions,Lambda-calculus},
month = {jan},
number = {1},
pages = {201--214},
title = {{Blame for all}},
url = {https://dl.acm.org/doi/10.1145/1925844.1926409},
volume = {46},
year = {2011}
}
@article{Plotkin2003,
author = {Plotkin, Gordon D. and Power, A. John},
doi = {10.1023/A:1023064908962},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Power - 2003 - Algebraic Operations and Generic Effects.pdf:pdf},
journal = {Applied Categorical Structures},
keywords = {algebraic operation,computational effect,lawvere theory,monad},
number = {1},
pages = {69--94},
publisher = {Kluwer Academic Publishers},
title = {{Algebraic Operations and Generic Effects}},
volume = {11},
year = {2003}
}
@article{Brown2009,
abstract = {Inheritance is a mechanism for incrementally modifying recursive definitions. While inheritance is typically used in object-oriented languages, inheritance also has something to offer to functional programming. In this paper we illustrate the use of inheritance in a pure functional language by de- veloping a small library for memoization. We define monadic memoization mixins that compose—via inheritance—with an ordinary monadic function to create a memoized version of the function. A comparison of the perfor- mance of different approaches shows that memoization mixins are efficient for a small example.},
author = {Brown, Daniel and Cook, W.R.},
file = {:Users/liang-tingchen/Dropbox/References/Brown, Cook - 2009 - Function Inheritance Monadic memoization mixins.pdf:pdf},
journal = {Brazilian Symposium on Programming Languages (SBLP)},
pages = {1--11},
title = {{Function Inheritance: Monadic memoization mixins}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Monadic+Memoization+Mixins{\#}0},
year = {2009}
}
@article{Coquand2019,
archivePrefix = {arXiv},
arxivId = {1810.09367},
author = {Coquand, Thierry},
doi = {10.1016/j.tcs.2019.01.015},
eprint = {1810.09367},
file = {:Users/liang-tingchen/Dropbox/References/Coquand - 2019 - Canonicity and normalization for dependent type theory.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Dependent type theory,Higher-order abstract syntax,Normalisation proof},
month = {jul},
pages = {184--191},
title = {{Canonicity and normalization for dependent type theory}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397519300325},
volume = {777},
year = {2019}
}
@incollection{Abel2011c,
abstract = {While higher-order pattern unification for the $\lambda$ calculus is decidable and unique unifiers exists, we face several challenges in practice: 1) the pattern fragment itself is too restrictive for many applications; this is typically addressed by solving sub-problems which satisfy the pattern restriction eagerly but delay solving sub-problems which are non-patterns until we have accumulated more information. This leads to a dynamic pattern unification algorithm. 2) Many systems implement $\lambda$ calculus and hence the known pattern unification algorithms for $\lambda$ are too restrictive. In this paper, we present a constraint-based unification algorithm for $\lambda$ -calculus which solves a richer class of patterns than currently possible; in particular it takes into account type isomorphisms to translate unification problems containing ∑-types into problems only involving $\Pi$-types. We prove correctness of our algorithm and discuss its application. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Abel, Andreas and Pientka, Brigitte},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2011},
doi = {10.1007/978-3-642-21691-6_5},
editor = {Ong, Luke},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Pientka - 2011 - Higher-Order Dynamic Pattern Unification for Dependent Types and Records.pdf:pdf},
isbn = {9783642216909},
issn = {03029743},
pages = {10--26},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Higher-Order Dynamic Pattern Unification for Dependent Types and Records}},
url = {http://link.springer.com/10.1007/978-3-642-21691-6{\_}5},
volume = {6690},
year = {2011}
}
@incollection{Jay1991,
author = {Jay, C. Barry},
booktitle = {Proceedings of the IV Higher Order Workshop},
doi = {10.1007/978-1-4471-3182-3_10},
editor = {Birtwistle, Graham},
file = {:Users/liang-tingchen/Dropbox/References/Jay - 1991 - Partial functions, ordered categories, limits and cartesian closure.pdf:pdf},
pages = {151--161},
publisher = {Springer, London},
title = {{Partial functions, ordered categories, limits and cartesian closure}},
url = {http://link.springer.com/10.1007/978-1-4471-3182-3{\_}10},
year = {1991}
}
@article{Schubert2008,
author = {Schubert, Christoph and Seal, Gavin J.},
file = {:Users/liang-tingchen/Dropbox/References/Schubert, Seal - 2008 - Extensions in the theory of lax algebras.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {and phrases,initial extension,kleisli extension,lax algebra,strata extension,tower},
number = {7},
pages = {118--151},
title = {{Extensions in the theory of lax algebras}},
volume = {21},
year = {2008}
}
@incollection{Hirschowitz2007,
abstract = {Inspired by the classical theory of modules over a monoid, we give a first account of the natural notion of module over a monad. The associated notion of morphism of left modules ("Linear" natural transformations) captures an important property of compatibility with substitution, in the heterogeneous case where "terms" and variables therein could be of different types as well as in the homogeneous case. In this paper, we present basic constructions of modules and we show examples concerning in particular abstract syntax and lambda-calculus.},
author = {Hirschowitz, Andr{\'{e}} and Maggesi, Marco},
booktitle = {Logic, Language, Information and Computation. WoLLIC 2007.},
doi = {10.1007/978-3-540-73445-1_16},
editor = {Leivant, Daniel and de Queiroz, Ruy},
file = {:Users/liang-tingchen/Dropbox/References/Hirschowitz, Maggesi - 2007 - Modules over Monads and Linearity.pdf:pdf},
isbn = {9783540734437},
issn = {03029743},
pages = {218--237},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modules over Monads and Linearity}},
url = {http://link.springer.com/10.1007/978-3-540-73445-1{\_}16},
volume = {4576},
year = {2007}
}
@incollection{Avguleas2008,
abstract = {The development of the Semantic Web proceeds in steps, building each layer on top of the other. Currently, the focus of research efforts is concentrated on logic and proofs, both of which are essential, since they will allow systems to infer new knowledge by applying principles on the existing data and explain their actions. Research is shifting towards the study of non-monotonic systems that are capable of handling conflicts among rules and reasoning with partial information. As for the proof layer of the Semantic Web, it can play a vital role in increasing the reliability of Semantic Web systems, since it will be possible to provide explanations and/or justifications of the derived answers. This paper reports on the implementation of a system for visualizing proof explanations on the Semantic Web. The proposed system applies defeasible logic, a member of the non-monotonic logics family, as the underlying inference system. The proof representation schema is based on a graph-based methodology for visualizing defeasible logic rule bases. {\textcopyright} 2008 Springer Berlin Heidelberg.},
author = {Avguleas, Ioannis and Gkirtzou, Katerina and Triantafilou, Sofia and Bikakis, Antonis and Antoniou, Grigoris and Kontopoulos, Efstratios and Bassiliades, Nick},
booktitle = {Rule Representation, Interchange and Reasoning on the Web. RuleML 2008},
doi = {10.1007/978-3-540-88808-6_21},
editor = {Bassiliades, Nick and Governatori, Guido and Paschke, Adrian},
file = {:Users/liang-tingchen/Dropbox/References/Avguleas et al. - 2008 - Visualization of Proofs in Defeasible Logic.pdf:pdf},
isbn = {3540888071},
issn = {03029743},
pages = {197--210},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Visualization of Proofs in Defeasible Logic}},
url = {http://link.springer.com/10.1007/978-3-540-88808-6{\_}21},
volume = {5321},
year = {2008}
}
@incollection{Levy2002,
abstract = {We describe a simple denotational semantics, using possible worlds, for a call-by-value language with ML-like storage facilities, allowing the storage of values of any type, and the generation of new storage cells. We first present a criticism of traditional Strachey semantics for such a language: that it requires us to specify what happens when we read non-existent cells. We then obtain our model by modifying the Strachey semantics to avoid this problem. We describe our model in 3 stages: first no storage of functions or recursion (but allowing storage of cells), then we add recursion, and finally we allow storage of functions. We discuss similarities and differences between our model and Moggi's model of ground store. A significant difference is that our model does not use monadic decomposition of the function type.},
author = {Levy, Paul Blain},
booktitle = {Computer Science Logic},
doi = {10.1007/3-540-45793-3_16},
editor = {Bradfield, Julian},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2002 - Possible World Semantics for General Storage in Call-By-Value.pdf:pdf},
isbn = {978-3-540-44240-0},
pages = {559--594},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Possible World Semantics for General Storage in Call-By-Value}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/3-540-45793-3{\_}16},
volume = {2471},
year = {2002}
}
@incollection{Yasuoka2010,
abstract = {Researchers have proposed formal definitions of quantitative information flow based on information theoretic notions such as the Shannon entropy, the min entropy, the guessing entropy, belief, and channel capacity. This paper investigates the hardness of precisely checking the quantitative information flow of a program according to such definitions. More precisely, we study the "bounding problem" of quantitative information flow, defined as follows: Given a program M and a positive real number q, decide if the quantitative information flow of M is less than or equal to q. We prove that the bounding problem is not a k-safety property for any k (even when q is fixed, for the Shannon-entropy-based definition with the uniform distribution), and therefore is not amenable to the self-composition technique that has been successfully applied to checking non-interference. We also prove complexity theoretic hardness results for the case when the program is restricted to loop-free boolean programs. Specifically, we show that the problem is PP-hard for all definitions, showing a gap with non-interference which is coNP-complete for the same class of programs. The paper also compares the results with the recently proved results on the comparison problems of quantitative information flow.},
archivePrefix = {arXiv},
arxivId = {1112.4237},
author = {Yasuoka, Hirotoshi and Terauchi, Tachio},
booktitle = {Computer Security – ESORICS 2010},
doi = {10.1007/978-3-642-15497-3_22},
editor = {Gritzalis, Dimitris},
eprint = {1112.4237},
file = {:Users/liang-tingchen/Dropbox/References/Yasuoka, Terauchi - 2010 - On Bounding Problems of Quantitative Information Flow.pdf:pdf},
isbn = {3642154964},
issn = {18758924},
keywords = {Security,program verification,quantitative information flow},
pages = {357--372},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On Bounding Problems of Quantitative Information Flow}},
url = {http://www.medra.org/servlet/aliasResolver?alias=iospress{\&}doi=10.3233/JCS-2011-0437 http://link.springer.com/10.1007/978-3-642-15497-3{\_}22},
volume = {6345},
year = {2010}
}
@article{Chen2017,
abstract = {We consider the problem of bounded model checking (BMC) for linear tempo-ral logic (LTL). We present several efficient encodings that have size linear in the bound. Furthermore, we show how the encodings can be extended to LTL with past operators (PLTL). The generalised encoding is still of linear size, but cannot detect minimal length counterexamples. By using the virtual unrolling technique minimal length counterexam-ples can be captured, however, the size of the encoding is quadratic in the specification. B¨ uchi automata, enabling them to accept minimal We also extend virtual unrolling to B¨ uchi length counterexamples. Our BMC encodings can be made incremental in order to benefit from incremental SAT technology. With fairly small modifications the incremental encoding can be further enhanced with a termination check, allowing us to prove properties with BMC. An analysis of the liveness-to-safety transformation reveals many similarities to the BMC encodings in this paper. We conduct experiments to determine the advantage of em-ploying dedicated BMC encodings for PLTL over combining more general but potentially less efficient approaches with BMC: the liveness-to-safety transformation with invariant B¨ uchi automata with fair cycle detection. checking and B¨ uchi Experiments clearly show that our new encodings improve performance of BMC con-siderably, particularly in the case of the incremental encoding, and that they are very competitive for finding bugs. Dedicated encodings seem to have an advantage over using more general methods with BMC. Using the liveness-to-safety translation with BDD-based invariant checking results in an efficientmethod to find shortest counterexamples that com-plements the BMC-based approach. For proving complex properties BDD-based methods still tend to perform better.},
archivePrefix = {arXiv},
arxivId = {cs/0606062},
author = {Gallier, Jean},
doi = {10.2168/LMCS-2(5:3)2006},
editor = {Constable, Robert},
eprint = {0606062},
file = {:Users/liang-tingchen/Dropbox/References/Gallier - 2006 - The Completeness of Propositional Resolution A Simple and Constructive Proof.pdf:pdf},
isbn = {9781450346764},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {dynamic thermal,head mounted display,thermal display,thermal haptics},
month = {nov},
number = {5},
pages = {381--388},
primaryClass = {cs},
title = {{The Completeness of Propositional Resolution: A Simple and Constructive Proof}},
url = {http://dl.acm.org/citation.cfm?doid=3024969.3025060 https://lmcs.episciences.org/2234},
volume = {2},
year = {2006}
}
@article{Terwijn2019,
abstract = {We prove a number of elementary facts about computability in partial combinatory algebras (pca's). We disprove a suggestion made by Kreisel about using Friedberg numberings to construct extensional pca's. We then discuss separability and elements without total extensions. We relate this to Ershov's notion of precompleteness, and we show that precomplete numberings are not 1-1 in general.},
author = {Terwijn, Sebastiaan A.},
doi = {10.1017/bsl.2020.46},
file = {:Users/liang-tingchen/Dropbox/References/Terwijn - 2019 - Computability In Partial Combinatory Algebras.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {1-1 numberings,Extensional models,Partial combinatory algebra,Undecidability},
pages = {1--19},
title = {{Computability In Partial Combinatory Algebras}},
year = {2019}
}
@incollection{Perrin1995,
address = {Dordrecht},
author = {Perrin, Dominique and Pin, Jean-{\'{E}}ric},
booktitle = {Semigroups, Formal Languages and Groups},
doi = {10.1016/j.chiabu.2011.09.001},
editor = {Fountain, John},
file = {:Users/liang-tingchen/Dropbox/References/Perrin, Pin - 1995 - Semigroups and automata on infinite words.pdf:pdf},
issn = {1873-7757},
pages = {49--72},
pmid = {22015205},
publisher = {Kluwer Academic Publishers},
series = {Nato Science Series C: Mathematical and Physical Sciences},
title = {{Semigroups and automata on infinite words}},
year = {1995}
}
@article{Curien2005,
abstract = {This two-parts paper offers a survey of linear logic and ludics, which were introduced by Girard in 1986 and 2001, respectively. Both theories revisit mathematical logic from first principles, with inspiration from and applications to computer science. The present part I covers an introduction to the connectives and proof rules of linear logic, to its decidability properties, and to its models. Part II will deal with proof nets, a graph-like representation of proofs which is one of the major innovations of linear logic, and will present an introduction to ludics.},
archivePrefix = {arXiv},
arxivId = {cs/0501035},
author = {Curien, Pierre-Louis},
doi = {10.1039/c1cp21204d},
eprint = {0501035},
file = {:Users/liang-tingchen/Dropbox/References/Curien - 2005 - Introduction to linear logic and ludics, part I.pdf:pdf},
issn = {1463-9076},
keywords = {03b70,03f05,03f52,68n15,68q10,68q55,cut-elimination,in-,linear logic,logic in computer science,programming languages,semantics,teractive modes of computation},
month = {jan},
number = {42},
pages = {18844},
primaryClass = {cs},
title = {{Introduction to linear logic and ludics, part I}},
url = {http://arxiv.org/abs/cs/0501039 http://arxiv.org/abs/1106.1305 http://dx.doi.org/10.1039/C1CP21204D http://xlink.rsc.org/?DOI=c1cp21204d http://arxiv.org/abs/cs/0501035},
volume = {13},
year = {2005}
}
@inproceedings{Curien2016,
abstract = {We consider the Curry-Howard-Lambek correspondence for effectful computation and resource management, specifically proposing polarised calculi together with presheaf-enriched adjunction models as the starting point for a comprehensive semantic theory relating logical systems, typed calculi, and categorical models in this context. Our thesis is that the combination of effects and resources should be considered orthogonally. Model theoretically, this leads to an understanding of our categorical models from two complementary perspectives: (i) as a linearisation of CBPV (Call-by-Push-Value) adjunction models, and (ii) as an extension of linear/non-linear adjunction models with an adjoint resolution of computational effects. When the linear structure is cartesian and the resource structure is trivial we recover Levy's notion of CBPV adjunction model, while when the effect structure is trivial we have Benton's linear/nonlinear adjunction models. Further instances of our model theory include the dialogue categories with a resource modality of Melli{\`{e}}s and Tabareau, and the [E]EC ([Enriched] Effect Calculus) models of Egger, M{\o}gelberg and Simpson. Our development substantiates the approach by providing a lifting theorem of linear models into cartesian ones. To each of our categorical models we systematically associate a typed term calculus, each of which corresponds to a variant of the sequent calculi LJ (Intuitionistic Logic) or ILL (Intuitionistic Linear Logic). The adjoint resolution of effects corresponds to polarisation whereby, syntactically, types locally determine a strict or lazy evaluation order and, semantically, the associativity of cuts is relaxed. In particular, our results show that polarisation provides a computational interpretation of CBPV in direct style. Further, we characterise depolarised models: those where the cut is associative, and where the evaluation order is unimportant.We explain possible advantages of this style of calculi for the operational semantics of effects.},
address = {New York, NY, USA},
author = {Curien, Pierre-Louis and Fiore, Marcelo and Munch-Maccagnoni, Guillaume},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837652},
file = {:Users/liang-tingchen/Dropbox/References/Curien, Fiore, Munch-Maccagnoni - 2016 - A theory of effects and resources adjunction models and polarised calculi.pdf:pdf},
isbn = {9781450335492},
issn = {15232867},
keywords = {Adjunction models,Categorical semantics,Computational effects,Curry-Howard-Lambek correspondence,Intuitionistic logic,Linear logic,Polarised calculi,Resource modalities},
month = {jan},
number = {1},
pages = {44--56},
publisher = {ACM},
title = {{A theory of effects and resources: adjunction models and polarised calculi}},
url = {https://dl.acm.org/doi/10.1145/2837614.2837652},
volume = {51},
year = {2016}
}
@article{Adamek2005b,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2005 - Birkhoff's covariety theorem without limitations.pdf:pdf},
journal = {Commentationes Mathematicae Universitatis Carolinae},
keywords = {classification,coequation},
number = {2},
pages = {197--215},
title = {{Birkhoff's covariety theorem without limitations}},
url = {http://dml.cz/handle/10338.dmlcz/119520},
volume = {46},
year = {2005}
}
@inproceedings{Garcia2016,
abstract = {Language researchers and designers have extended a wide variety of type systems to support gradual typing, which enables languages to seamlessly combine dynamic and static checking. These efforts consistently demonstrate that designing a satisfactory gradual counterpart to a static type system is challenging, and this challenge only increases with the sophistication of the type system. Gradual type system designers need more formal tools to help them conceptualize, structure, and evaluate their designs. In this paper, we propose a new formal foundation for gradual typing, drawing on principles from abstract interpretation to give gradual types a semantics in terms of pre-existing static types. Abstracting Gradual Typing (AGT for short) yields a formal account of consistency-one of the cornerstones of the gradual typing approach-that subsumes existing notions of consistency, which were developed through intuition and ad hoc reasoning. Given a syntax-directed static typing judgment, the AGT approach induces a corresponding gradual typing judgment. Then the type safety proof for the underlying static discipline induces a dynamic semantics for gradual programs defined over sourcelanguage typing derivations. The AGT approach does not resort to an externally justified cast calculus: instead, run-time checks naturally arise by deducing evidence for consistent judgments during proof reduction. To illustrate the approach, we develop a novel gradually-typed counterpart for a language with record subtyping. Gradual languages designed with the AGT approach satisfy by construction the refined criteria for gradual typing set forth by Siek and colleagues.},
address = {New York, NY, USA},
author = {Garcia, Ronald and Clark, Alison M. and Tanter, {\'{E}}ric},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837670},
file = {:Users/liang-tingchen/Dropbox/References/Garcia, Clark, Tanter - 2016 - Abstracting gradual typing.pdf:pdf},
isbn = {9781450335492},
issn = {15232867},
keywords = {Abstract interpretation,Gradual typing,Subtyping},
month = {jan},
number = {1},
pages = {429--442},
publisher = {ACM},
title = {{Abstracting gradual typing}},
url = {https://dl.acm.org/doi/10.1145/2837614.2837670},
volume = {51},
year = {2016}
}
@inproceedings{Lane2012,
abstract = {Underpinning many recent advances in sensing applications (e.g., mHealth) is the ability to safely collect and share mobile sensor data. Research has shown that even from seemingly harmless sensors (e.g., accelerometers, gyroscopes, or magnetometers) an ever expanding set of potentially sensitive user behavior can be inferred. Providing robust anonymity assurances is a principal mechanism for protecting users when data is shared (e.g., with medical professionals or friends). In this paper, we study the feasibility of user de-anonymization from mobile sensor datasets routinely collected on commodity devices (e.g., smartphones). We perform a systematic investigation to quantify the threat of de-anonymization using existing sparsity-based techniques adapted to exploit mobile sensor data characteristics. This preliminary study indicates significant threats to user anonymity exist within shared mobile sensor data and further investigation is warranted.},
address = {New York, New York, USA},
author = {Lane, Nicholas D. and Xie, Junyuan and Moscibroda, Thomas and Zhao, Feng},
booktitle = {Proceedings of the Third International Workshop on Sensing Applications on Mobile Phones - PhoneSense '12},
doi = {10.1145/2389148.2389151},
file = {:Users/liang-tingchen/Dropbox/References/Lane et al. - 2012 - On the feasibility of user de-anonymization from shared mobile sensor data.pdf:pdf},
isbn = {9781450317788},
pages = {1--5},
publisher = {ACM Press},
title = {{On the feasibility of user de-anonymization from shared mobile sensor data}},
url = {http://dl.acm.org/citation.cfm?id=2389148.2389151 http://dl.acm.org/citation.cfm?doid=2389148.2389151},
year = {2012}
}
@inproceedings{Wiegley2017,
abstract = {Correctness and performance are ooen at odds in the of sys-tems engineering, either because correct programs are too costly to write or impractical to execute, or because well-performing code involves so many tricks of the trade that formal analysis is unable to isolate the main properties of the algorithm. As a prime example of this tension, Coq is an established proof environment that allows writing correct, dependently-typed code, but it has been criticized for exorbitant development times, forcing the developer to choose between optimal code or tractable proofs. On the other side of the divide, Haskell has proven itself to be a capable, well-typed programming environment, yet easy-to-read, straightforward code must all too ooen be replaced by highly opti-mized variants that obscure the author's original intention. paper builds on the existing Fiat reenement framework to bridge this divide, demonstrating how to derive a correct-by-construction implementation that meets (or exceeds) the perfor-mance characteristics of highly optimized Haskell, starting from a high-level Coq speciication. To achieve this goal, we extend Fiat with a stateful notion of reenement of abstract data types and add support for extracting stateful code via a free monad equipped with an algebra of heap-manipulating operations. As a case study, we reimplement a subset of the popular bytestring library, with liile to no loss of performance, while retaining a high guarantee of program correctness.},
address = {New York, New York, USA},
author = {Wiegley, John and Delaware, Benjamin},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell - Haskell 2017},
doi = {10.1145/3122955.3122962},
file = {:Users/liang-tingchen/Dropbox/References/Wiegley, Delaware - 2017 - Using Coq to write fast and correct Haskell.pdf:pdf},
isbn = {9781450351829},
keywords = {2017,Performant Certified Software,Stepwise Refinement,acm reference format,acm sigplan international haskell,correct haskell,delaware,fast and,in proceedings of 10th,john wiegley and benjamin,performant certified software,stepwise refinement,using coq to write},
pages = {52--62},
publisher = {ACM Press},
title = {{Using Coq to write fast and correct Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=3122955.3122962},
year = {2017}
}
@article{Eilenberg1967,
author = {Eilenberg, Samuel and Wright, Jesse B.},
doi = {10.1016/S0019-9958(67)90670-5},
file = {:Users/liang-tingchen/Dropbox/References/Eilenberg, Wright - 1967 - Automata in general algebras.pdf:pdf},
issn = {00199958},
journal = {Information and Control},
number = {4},
pages = {452--470},
title = {{Automata in general algebras}},
volume = {11},
year = {1967}
}
@article{Hindley1969,
author = {Hindley, R.},
doi = {10.2307/1995158},
file = {:Users/liang-tingchen/Dropbox/References/Hindley - 1969 - The Principal Type-Scheme of an Object in Combinatory Logic.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
month = {dec},
pages = {29},
title = {{The Principal Type-Scheme of an Object in Combinatory Logic}},
url = {https://www.jstor.org/stable/1995158?origin=crossref},
volume = {146},
year = {1969}
}
@article{Makkai1987a,
author = {Makkai, Michael and Pitts, Andrew M.},
doi = {10.2307/2000508},
file = {:Users/liang-tingchen/Dropbox/References/Makkai, Pitts - 1987 - Some Results on Locally Finitely Presentable Categories.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
month = {feb},
number = {2},
pages = {473},
title = {{Some Results on Locally Finitely Presentable Categories}},
url = {http://www.jstor.org/stable/2000508?origin=crossref},
volume = {299},
year = {1987}
}
@article{Floridi2011,
author = {Floridi, Luciano},
doi = {10.1023/B:MIND.0000021684.50925.c9},
file = {:Users/liang-tingchen/Dropbox/References/Floridi - 2004 - Outline of a Theory of Strongly Semantic Information.pdf:pdf},
isbn = {9780199232383},
issn = {0924-6495},
journal = {Minds and Machines},
keywords = {bar-hillel,carnap paradox,data,either it is raining,how,how the information has,i know,information,is another,one is inclined to,or it isn,probability distributions,reached me,say,semantic information,t,theory of strongly semantic,theory of weakly semantic,truth-values},
month = {may},
number = {2},
pages = {197--221},
title = {{Outline of a Theory of Strongly Semantic Information}},
url = {http://link.springer.com/10.1023/B:MIND.0000021684.50925.c9},
volume = {14},
year = {2004}
}
@article{Palmgren1992,
author = {Palmgren, Erik},
doi = {10.1007/BF01269951},
file = {:Users/liang-tingchen/Dropbox/References/Palmgren - 1992 - Type-theoretic interpretation of iterated, strictly positive inductive definitions.pdf:pdf},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
month = {mar},
number = {2},
pages = {75--99},
title = {{Type-theoretic interpretation of iterated, strictly positive inductive definitions}},
url = {http://link.springer.com/10.1007/BF01269951},
volume = {32},
year = {1992}
}
@incollection{Rutten1998,
author = {Rutten, Jan J.M.M.},
booktitle = {CONCUR'98 Concurrency Theory},
doi = {10.1007/BFb0055624},
editor = {Sangiorgi, Davide and Simone, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 1998 - Automata and coinduction (an exercise in coalgebra).pdf:pdf},
isbn = {978-3-540-64896-3},
pages = {193--217},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Automata and coinduction (an exercise in coalgebra)}},
year = {1998}
}
@article{Sano2011,
author = {Sano, Katsuhiko},
doi = {10.1016/j.entcs.2011.06.012},
file = {:Users/liang-tingchen/Dropbox/References/Sano - 2011 - Axiomatizing Hybrid Products of Monotone Neighborhood Frames.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {frames,hybrid logic,monotone neighborhood,product of neighborhood frames,product of topologies,pure completeness},
month = {jul},
pages = {51--67},
publisher = {Elsevier B.V.},
title = {{Axiomatizing Hybrid Products of Monotone Neighborhood Frames}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066111000831},
volume = {273},
year = {2011}
}
@article{Dwork2011,
abstract = {In the information realm, loss of privacy is usually associated with failure to control access to information, to control the flow of information, or to control the purposes for which information is employed. Differential privacy arose in a context in which ensuring privacy is a challenge even if all these control problems are solved: privacy-preserving statistical analysis of data. The problem of statistical disclosure control— revealing accurate statistics about a set of respondents while preserving the privacy of individuals—has a venerable history, with an extensive literature spanning statistics, theoretical computer science, security, databases, and cryptography (see, for example, the excellent survey of Adam and Wortmann,1 the discussion of related work in Blum et al.,2 and the Journal of Official Statistics dedicated to confidentiality and disclosure control).},
author = {Dwork, Cynthia},
doi = {10.1145/1866739.1866758},
file = {:Users/liang-tingchen/Dropbox/References/Dwork - 2011 - A firm foundation for private data analysis.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {1},
pages = {86},
title = {{A firm foundation for private data analysis}},
url = {http://portal.acm.org/citation.cfm?doid=1866739.1866758},
volume = {54},
year = {2011}
}
@article{Gibbons1999,
author = {GIBBONS, JEREMY},
doi = {10.1017/S0956796899003354},
file = {:Users/liang-tingchen/Dropbox/References/GIBBONS - 1999 - A pointless derivation of radix sort.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {may},
number = {3},
pages = {S0956796899003354},
publisher = {Swansea University Libraries},
title = {{A pointless derivation of radix sort}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796899003354},
volume = {9},
year = {1999}
}
@incollection{Uustalu2006,
abstract = {We propose a novel, comonadic approach to dataflow (stream-based) computation. This is based on the observation that both general and causal stream functions can be characterized as coKleisli arrows of comonads and on the intuition that comonads in general must be a good means to structure context-dependent computation. In particular, we develop a generic comonadic interpreter of languages for context-dependent computation and instantiate it for stream-based computation. We also discuss distributive laws of a comonad over a monad as a means to structure combinations of effectful and context-dependent computation. We apply the latter to analyse clocked dataflow (partial stream based) computation.},
author = {Uustalu, Tarmo and Vene, Varmo},
booktitle = {Central European Functional Programming School. CEFP 2005},
doi = {10.1007/11894100_5},
editor = {Horv{\'{a}}th, Zolt{\'{a}}n},
file = {:Users/liang-tingchen/Dropbox/References/Uustalu, Vene - 2006 - The essence of dataflow programming.pdf:pdf},
pages = {135--167},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The essence of dataflow programming}},
volume = {4164},
year = {2006}
}
@article{Elliott2017,
abstract = {It is well-known that the simply typed lambda-calculus is modeled by any cartesian closed category (CCC). This correspondence suggests giving typed functional programs a variety of interpretations, each corresponding to a different category. A convenient way to realize this idea is as a collection of meaning-preserving transformations added to an existing compiler, such as GHC for Haskell. This paper describes such an implementation and demonstrates its use for a variety of interpretations including hardware circuits, automatic differentiation, incremental computation, and interval analysis. Each such interpretation is a category easily defined in Haskell (outside of the compiler). The general technique appears to provide a compelling alternative to deeply embedded domain-specific languages.},
author = {Elliott, Conal},
doi = {10.1145/3110271},
file = {:Users/liang-tingchen/Dropbox/References/Elliott - 2017 - Compiling to categories.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {category theory,compile-time optimization,domain-specific languages},
month = {aug},
number = {ICFP},
pages = {1--27},
title = {{Compiling to categories}},
url = {http://dl.acm.org/citation.cfm?doid=3136534.3110271},
volume = {1},
year = {2017}
}
@article{Rosicky1995,
author = {Rosick{\'{y}}, Jiř{\'{i}} and Tholen, Walter},
doi = {10.1016/0022-4049(94)00035-H},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}}, Tholen - 1995 - Accessibility and the solution set condition.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jan},
number = {2},
pages = {189--208},
title = {{Accessibility and the solution set condition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499400035H},
volume = {98},
year = {1995}
}
@incollection{Munch-Maccagnoni2014,
author = {Munch-Maccagnoni, Guillaume},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2014},
doi = {10.1007/978-3-642-54830-7_26},
editor = {Muscholl, Anca},
file = {:Users/liang-tingchen/Dropbox/References/Munch-Maccagnoni - 2014 - Models of a Non-associative Composition.pdf:pdf},
pages = {396--410},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Models of a Non-associative Composition}},
url = {http://link.springer.com/10.1007/978-3-642-54830-7{\_}26},
volume = {8412},
year = {2014}
}
@phdthesis{Forsberg2013,
author = {Forsberg, Fredrik Nordvall},
file = {:Users/liang-tingchen/Dropbox/References/Forsberg - 2013 - Inductive-inductive Definitions.pdf:pdf},
school = {Swansea University},
title = {{Inductive-inductive Definitions}},
type = {PhD Thesis},
year = {2013}
}
@article{Makinson2000,
abstract = {In a range of contexts, one comes across processes resembling inference, but where input propositions are not in general included among outputs, and the opera- tion is not in any way reversible. Examples arise in contexts of conditional obligations, goals, ideals, preferences, actions, and beliefs. Our purpose is to develop a theory of such input/output operations. Four are singled out: simple-minded, basic (making intelligent use of disjunctive inputs), simple-minded reusable (in which outputs may be recycled as inputs), and basic reusable. They are defined semantically and characterised by derivation rules, as well as in terms of relabeling procedures and modal operators. Their behaviour is studied on both semantic and syntactic levels.},
author = {Makinson, David and van der Torre, Leendert},
doi = {10.1023/A:1004748624537},
file = {:Users/liang-tingchen/Dropbox/References/Makinson, van der Torre - 2000 - InputOutput Logics.pdf:pdf},
isbn = {8572440143 9788572440141},
issn = {0022-3611},
journal = {Journal of Philosophical Logic},
keywords = {Conditional goals,Conditional obligations,Deontic logic,Identity,Input/output logic,Reusability},
month = {aug},
number = {4},
pages = {383--408},
pmid = {22780200},
title = {{Input/Output Logics}},
url = {http://link.springer.com/10.1023/A:1004748624537},
volume = {29},
year = {2000}
}
@article{Coquand2018a,
abstract = {Any formal system for representing mathematics should address the two questions of how to represent collections of mathematical objects and how to decide the laws of identifications of these objects. These laws of identifications have become quite subtle. While it has been clear for a long time that it is good mathematical practice to identify isomorphic algebraic structures [11], or at least to use only notions and facts about algebraic structures that are invariant under isomorphisms, category theory extends this to the notion of categorical equivalences 1 , which themselves have been generalized to higher forms of equivalences [25]. Voevodsky noticed that, by extending some versions of dependent type theory with one further axiom - the univalence axiom - one obtains a formal system in which all notions and operations are automatically invariant under isomorphisms and even under higher notions of equivalence.},
author = {Coquand, Thierry},
doi = {10.1145/3242953.3242962},
file = {:Users/liang-tingchen/Dropbox/References/Coquand - 2018 - A survey of constructive presheaf models of univalence.pdf:pdf},
issn = {2372-3491},
journal = {ACM SIGLOG News},
month = {jul},
number = {3},
pages = {54--65},
title = {{A survey of constructive presheaf models of univalence}},
url = {https://dl.acm.org/citation.cfm?id=3242962 https://dl.acm.org/doi/10.1145/3242953.3242962},
volume = {5},
year = {2018}
}
@inproceedings{Colcombet2009,
author = {Colcombet, Thomas},
booktitle = {Proceedings of the 36th International Collogquium on Automata, Languages, and Programmings, Part II},
doi = {10.1007/978-3-642-02930-1_12},
file = {:Users/liang-tingchen/Dropbox/References/Colcombet - 2009 - The theory of stabilisation monoids and regular cost functions.pdf:pdf},
isbn = {3642029299},
issn = {03029743},
pages = {139--150},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The theory of stabilisation monoids and regular cost functions}},
url = {http://link.springer.com/10.1007/978-3-642-02930-1{\_}12},
volume = {5556},
year = {2009}
}
@article{Cox2010,
author = {Cox, Lawrence H},
file = {:Users/liang-tingchen/Dropbox/References/Cox - 2010 - Vulnerability of Complementary Cell Suppression to Intruder Attack.pdf:pdf},
journal = {Journal of Privacy and Confidentiality},
keywords = {controlled tabular adjustment,exact intervals,magnitude data,p,p-percent rule,q-ambiguity rule,sensitivity measure,statistical disclo-,sure},
number = {2},
pages = {8},
title = {{Vulnerability of Complementary Cell Suppression to Intruder Attack}},
url = {http://repository.cmu.edu/jpc/vol1/iss2/8/},
volume = {1},
year = {2010}
}
@incollection{Wyner2015,
abstract = {The concept of “definition” refers both to a propositional structure, namely a type of convertible relation between the definiens and the definiendum, and a speech act that can have various definitional purposes. On the one hand, definitions can have different subject matter. For instance, it is possible to define a concept (essential definitions), themeaning of its linguistic expression (etymolog- ical definition), its possible extension (definition by enumeration), an illustration of its possible denotations (definition by example), or the operation that can be used to classify the entities falling under it (operational definition). On the other hand, definitions are the propositional content of acts aimed at producing specific effects. Definitions can impose a new meaning, or remind or inform the interlocutors of criteria of classification. However, from an argumentative perspective the acts of stipulating, reminding or informing of, or committing to a definition are not as dangerous as the implicit acts of omitting a definition and implicitly defining and redefining a concept. Sometimes crucial concepts, especially the ones concerning problematic ethical or political issues, are ill described or are left (intentionally or unintentionally) undefined. This gap can become the ground of extremely effective strategies based on tacit (re)definitions.These uses of definition can shed light on the definitional activity of the lawmakers. Statutory definitions become in this sense a limitation of the interpreters' freedomof redefining strategically a concept. For this reason, the choice of leaving a concept undefined or underdefined can be regarded as},
author = {Wyner, Adam Z.},
booktitle = {Logic in the Theory and Practice of Lawmaking},
doi = {10.1007/978-3-319-19575-9_15},
editor = {Araszkiewicz, Micha{\l} and P{\l}eszka, Krzysztof},
file = {:Users/liang-tingchen/Dropbox/References/Wyner - 2015 - From the Language of Legislation to Executable Logic Programs.pdf:pdf},
isbn = {978-3-319-19574-2},
issn = {15431649},
keywords = {language,legislation,logic programs},
pages = {409--434},
publisher = {Springer, Cham},
series = {Legisprudence Library (Studies on the Theory and Practice of Legislation)},
title = {{From the Language of Legislation to Executable Logic Programs}},
url = {http://link.springer.com/10.1007/978-3-319-19575-9},
volume = {2},
year = {2015}
}
@article{Rosebrugh2002,
author = {Rosebrugh, Robert and Wood, R. J.},
doi = {10.1016/S0022-4049(02)00140-8},
file = {:Users/liang-tingchen/Dropbox/References/Rosebrugh, Wood - 2002 - Distributive laws and factorization.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-3},
pages = {327--353},
title = {{Distributive laws and factorization}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404902001408},
volume = {175},
year = {2002}
}
@article{Hernandez2014,
archivePrefix = {arXiv},
arxivId = {1407.6969},
author = {Hern{\'{a}}ndez, Juan L. L{\'{o}}pez and Cuevas, Luis J. Turcio and V{\'{a}}zquez-M{\'{a}}rquez, Adri{\'{a}}n},
eprint = {1407.6969},
file = {:Users/liang-tingchen/Dropbox/References/Hern{\'{a}}ndez, Cuevas, V{\'{a}}zquez-M{\'{a}}rquez - 2014 - Review on the Kleisli and Eilenberg-Moore 2-adjunctions.pdf:pdf},
journal = {ArXiv e-prints},
month = {jul},
pages = {1--33},
title = {{Review on the Kleisli and Eilenberg-Moore 2-adjunctions}},
url = {http://arxiv.org/abs/1407.6969v1},
year = {2014}
}
@article{Nguyen1978,
author = {Nguyen, Hung T.},
doi = {10.1016/B978-0-444-88650-7.50019-6},
file = {:Users/liang-tingchen/Dropbox/References/Nguyen - 1978 - On random sets and belief functions.pdf:pdf},
issn = {0022247X},
journal = {Journal of Mathematical Analysis and Applications},
month = {oct},
number = {3},
pages = {531--542},
title = {{On random sets and belief functions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022247X78901610},
volume = {65},
year = {1978}
}
@inproceedings{Fiore2019,
abstract = {We construct an internal language for cartesian closed bicategories. Precisely, we introduce a type theory modelling the structure of a cartesian closed bicategory and show that its syntactic model satisfies an appropriate universal property, thereby lifting the Curry-Howard-Lambek correspondence to the bicategorical setting. Our approach is principled and practical. Weak substitution structure is constructed using a bicategori-fication of the notion of abstract clone from universal algebra, and the rules for products and exponentials are synthesised from semantic considerations. The result is a type theory that employs a novel combination of 2-dimensional type theory and explicit substitution, and directly generalises the Simply-Typed Lambda Calculus. This work is the first step in a programme aimed at proving coherence for cartesian closed bicategories.},
author = {Fiore, Marcelo and Saville, Philip},
booktitle = {2019 34th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2019.8785708},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Saville - 2019 - A type theory for cartesian closed bicategories (Extended Abstract).pdf:pdf},
isbn = {978-1-7281-3608-0},
issn = {10436871},
keywords = {Cartesian closed bicate-gories,Curry-Howard-Lambek correspondence,Higher category theory,Typed lambda calculus},
month = {jun},
pages = {1--13},
publisher = {IEEE},
title = {{A type theory for cartesian closed bicategories (Extended Abstract)}},
url = {https://ieeexplore.ieee.org/document/8785708/},
volume = {2019-June},
year = {2019}
}
@inproceedings{Saito2016,
annote = {NULL},
author = {Saito, Kenji and Yamada, Hiroyuki},
booktitle = {2016 IEEE 36th International Conference on Distributed Computing Systems Workshops (ICDCSW)},
doi = {10.1109/ICDCSW.2016.28},
file = {:Users/liang-tingchen/Dropbox/References/Saito, Yamada - 2016 - What's so Different about blockchain — blockchain is a probabilistic state machine.pdf:pdf},
isbn = {978-1-5090-3686-8},
month = {jun},
pages = {168--175},
publisher = {IEEE},
title = {{What's so Different about blockchain? — blockchain is a probabilistic state machine}},
url = {http://ieeexplore.ieee.org/document/7756226/},
year = {2016}
}
@article{Adamek2001,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}} - 2001 - On sifted colimits and generalized varieties.pdf:pdf},
journal = {Theory and Applications of Categories},
number = {3},
pages = {33--53},
title = {{On sifted colimits and generalized varieties}},
url = {http://www.emis.ams.org/journals/TAC/volumes/8/n3/n3.pdf},
volume = {8},
year = {2001}
}
@article{Parrow2015,
author = {Parrow, Joachim and Borgstr{\"{o}}m, Johannes and Eriksson, Lars-Henrik and Gutkovas, Ramunas and Weber, Tjark},
doi = {http://dx.doi.org/10.4230/LIPIcs.CONCUR.2015.198},
file = {:Users/liang-tingchen/Dropbox/References/Parrow et al. - 2015 - Modal logics for nominal transition systems.pdf:pdf},
isbn = {978-3-939897-91-0},
issn = {1868-8969},
journal = {26th International Conference on Concurrency Theory},
keywords = {198,2015,4230,and phrases process algebra,bisimulation,concur,digital object identifier 10,lipics,modal logic,nominal sets},
number = {Concur},
pages = {198--211},
title = {{Modal logics for nominal transition systems}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5382},
volume = {42},
year = {2015}
}
@incollection{Ferreira2017,
abstract = {We present the semantics and proof system for an object-oriented language with active objects, asynchronous method calls,$\backslash$n and futures. The language, based on Creol, distinguishes itself in that unlike active object models, it permits more than$\backslash$n one thread of control within an object, though, unlike Java, only one thread can be active within an object at a given time$\backslash$n and rescheduling occurs only at specific release points. Consequently, reestablishing an object's monitor invariant is possible$\backslash$n at specific well-defined points in the code. The resulting proof system shows that this approach to concurrency is simpler$\backslash$n for reasoning than, say, Java's multithreaded concurrency model. From a methodological perspective, we identify constructs$\backslash$n which admit a simple proof system and those which require, for example, interference freedom tests.},
author = {Ferreira, Francisco and Pientka, Brigitte},
booktitle = {Programming Languages and Systems. ESOP 2017.},
doi = {10.1007/978-3-662-54434-1_3},
editor = {Yang, Hongseok},
file = {:Users/liang-tingchen/Dropbox/References/Ferreira, Pientka - 2017 - Programs Using Syntax with First-Class Binders.pdf:pdf},
isbn = {978-3-540-64302-9},
keywords = {functional programming,higher-order abstract syntax,ml,programming with binders},
pages = {504--529},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Programs Using Syntax with First-Class Binders}},
url = {http://link.springer.com/10.1007/978-3-662-54434-1{\_}19},
volume = {10201},
year = {2017}
}
@article{Hackett2019,
author = {Hackett, Jennifer and Hutton, Graham},
doi = {10.1145/3341718},
file = {:Users/liang-tingchen/Dropbox/References/Hackett, Hutton - 2019 - Call-by-need is clairvoyant call-by-value.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {lazy evaluation},
month = {jul},
number = {ICFP},
pages = {1--23},
title = {{Call-by-need is clairvoyant call-by-value}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341718},
volume = {3},
year = {2019}
}
@book{Johnstone1982,
author = {Johnstone, Peter T.},
isbn = {0521337798, 9780521337793},
pages = {398},
publisher = {Cambridge University Press},
title = {{Stone spaces}},
type = {Book},
year = {1982}
}
@article{Reynolds1998,
abstract = {To introduce the republication of ``Definitional Interpreters for$\backslash$nHigher-Order Programming Languages'', the author recounts the circumstances of its$\backslash$ncreation, clarifies several obscurities, corrects a few mistakes, and briefly$\backslash$nsummarizes some more recent developments.},
author = {Reynolds, John C.},
doi = {10.1023/A:1010075320153},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds - 1998 - Definitional Interpreters Revisited.pdf:pdf},
issn = {13883690},
journal = {Higher-Order and Symbolic Computation},
keywords = {Applicative language,Call by name,Call by value,Closure,Continuation,Defunctionalization,Denotational semantics,Functional language,Higher-order function,Interpreter,Lambda calculus,Metacircularity,Operational semantics},
number = {4},
pages = {355--361},
title = {{Definitional Interpreters Revisited}},
volume = {11},
year = {1998}
}
@article{VandenBerg2008,
abstract = {This is the first in a series of papers on Predicative Algebraic Set Theory, where we lay the necessary groundwork for the subsequent parts, one on realizability [B. van den Berg, I. Moerdijk, Aspects of predicative algebraic set theory II: Realizability, Theoret. Comput. Sci. (in press). Available from: arXiv:0801.2305, 2008], and the other on sheaves [B. van den Berg, I. Moerdijk, Aspects of predicative algebraic set theory III: Sheaf models, 2008 (in preparation)]. We introduce the notion of a predicative category with small maps and show that it provides a sound and complete semantics for constructive set theories like IZF and CZF. The main technical contribution of this paper is that it shows in detail that such categories can always be conservatively embedded in categories that are exact. These exactness properties play a crucial r{\^{o}}le in showing that predicative categories with small maps contain models of set theory and that they are closed under sheaves and realizability. We will prove the former statement in this paper as well, leaving a proof of the closure properties to the papers on realizability and sheaves as mentioned above. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:0801.2305},
author = {van den Berg, Benno and Moerdijk, Ieke},
doi = {10.1016/j.apal.2008.06.013},
eprint = {arXiv:0801.2305},
file = {:Users/liang-tingchen/Dropbox/References/van den Berg, Moerdijk - 2008 - Aspects of predicative algebraic set theory I Exact completion.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Categorical logic,Constructive set theory,Exact completion},
number = {1},
pages = {123--159},
publisher = {Elsevier B.V.},
title = {{Aspects of predicative algebraic set theory I: Exact completion}},
url = {http://dx.doi.org/10.1016/j.apal.2008.06.013},
volume = {156},
year = {2008}
}
@article{Mendler1991,
abstract = {Mendler, N.P., Inductive types and type constraints in the second-order lambda calculus, Annals of Pure and Applied Logic 51 (1991) 159-172. We add to the second-order lambda calculus the type constructors $\mu$ and $\nu$, which give the least and greatest solutions to positively defined type expressions. Strong normalizability of typed terms is shown using Girard's candidat de r{\'{e}}ductibilit{\'{e}} method. Using the same structure built for that proof, we prove a necessary and sufficient condition for determining when a collection of equational type constraints admit the typing of only strongly normalizable terms. {\textcopyright} 1991.},
author = {Mendler, Nax Paul},
doi = {10.1016/0168-0072(91)90069-X},
file = {:Users/liang-tingchen/Dropbox/References/Mendler - 1991 - Inductive types and type constraints in the second-order lambda calculus.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {mar},
number = {1-2},
pages = {159--172},
title = {{Inductive types and type constraints in the second-order lambda calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/016800729190069X},
volume = {51},
year = {1991}
}
@article{Dybjer2016a,
abstract = {The first example of a simultaneous inductive-recursive definition in intuitionistic type theory is Martin-L{\"{o}}fs universe {\`{a}} la Tarski. A set U 0 of codes for small sets is generated inductively at the same time as a function T 0 , which maps a code to the corresponding small set, is defined by recursion on the way the elements of U 0 are generated.},
author = {Dybjer, Peter},
doi = {10.2307/2586554},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer - 2000 - A general formulation of simultaneous inductive-recursive definitions in type theory.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Dybjer - 2000 - A general formulation of simultaneous inductive-recursive definitions in type theory(2).pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {jun},
number = {2},
pages = {525--549},
title = {{A general formulation of simultaneous inductive-recursive definitions in type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200012044/type/journal{\_}article},
volume = {65},
year = {2000}
}
@incollection{Kiselyov2018,
abstract = {We present a technique for compiling lambda-calculus expressions into SKI combinators. Unlike the well-known bracket abstraction based on (syntactic) term re-writing, our algorithm relies on a specially chosen, compositional semantic model of generally open lambda terms. The meaning of a closed lambda term is the corresponding SKI combination. For simply-typed as well as unityped terms, the meaning derivation mirrors the typing derivation. One may also view the algorithm as an algebra, or a non-standard evaluator for lambda-terms (i.e., denotational semantics). The algorithm is implemented as a tagless-final compiler for (uni)typed lambda-calculus embedded as a DSL into OCaml. Its type preservation is clear even to OCaml. The correctness of both the algorithm and of its implementation becomes clear. Our algorithm is easily amenable to optimizations. In particular, its output and the running time can both be made linear in the size (i.e., the number of all constructors) of the input De Bruijn-indexed term.},
author = {Kiselyov, Oleg},
booktitle = {Functional and Logic Programming. FLOPS 201},
doi = {10.1007/978-3-319-90686-7_3},
editor = {Gallagher, John P. and Sulzmann, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov - 2018 - $\lambda$ to SKI, Semantically.pdf:pdf},
isbn = {978-3-642-29821-9},
issn = {03029743},
pages = {33--50},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{$\lambda$ to SKI, Semantically}},
url = {http://link.springer.com/10.1007/978-3-319-90686-7{\_}3},
volume = {10818},
year = {2018}
}
@incollection{McBride2015,
author = {McBride, Conor},
booktitle = {Mathematics of Program Construction. MPC 2015},
doi = {10.1007/978-3-319-19797-5_13},
editor = {Hinze, Ralf and Voigtl{\"{a}}nder, J.},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2015 - Turing-Completeness Totally Free.pdf:pdf},
isbn = {9783319197968},
issn = {16113349},
pages = {257--275},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Turing-Completeness Totally Free}},
url = {http://link.springer.com/10.1007/978-3-319-19797-5{\_}13},
volume = {9129},
year = {2015}
}
@article{Kennaway1997,
abstract = {In a previous paper we have established the theory of transfinite reduction for orthogonal term rewriting systems. In this paper we perform the same task for the lambda calculus. From the viewpoint of infinitary rewriting, the B{\"{o}}hm model of the lambda calculus can be seen as an infinitary term model. In contrast to term rewriting, there are several different possible notions of infinite term, which give rise to different B{\"{o}}hm-likc models, which embody different notions of lazy or eager computation.},
author = {Kennaway, J.R. and Klop, J.W. and Sleep, M.R. and de Vries, F.J.},
doi = {10.1016/S0304-3975(96)00171-5},
file = {:Users/liang-tingchen/Dropbox/References/Kennaway et al. - 1997 - Infinitary lambda calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {1},
pages = {93--125},
title = {{Infinitary lambda calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397596001715},
volume = {175},
year = {1997}
}
@article{Huwig1990,
author = {Huwig, Hagen and Poign{\'{e}}, Axel},
doi = {10.1016/0304-3975(90)90165-E},
file = {:Users/liang-tingchen/Dropbox/References/Huwig, Poign{\'{e}} - 1990 - A note on inconsistencies caused by fixpoints in a cartesian closed category.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jun},
number = {1},
pages = {101--112},
title = {{A note on inconsistencies caused by fixpoints in a cartesian closed category}},
url = {https://linkinghub.elsevier.com/retrieve/pii/030439759090165E},
volume = {73},
year = {1990}
}
@article{White2012,
abstract = {We analyse the philosopher Davidson's semantics of actions, using a strongly typed logic with contexts given by sets of partial equations between the outcomes of actions. This provides a perspicuous and elegant treatment of reasoning about action, analogous to Reiter's work on artificial intelligence. We define a sequent calculus for this logic, prove cut elimination, and give a semantics based on fibrations over partial cartesian categories: we give a structure theory for such fibrations. The existence of lax comma objects is necessary for the proof of cut elimination, and we give conditions on the domain fibration of a partial cartesian category for such comma objects to exist.},
archivePrefix = {arXiv},
arxivId = {1202.0255},
author = {White, Graham},
eprint = {1202.0255},
file = {:Users/liang-tingchen/Dropbox/References/White - 2012 - Reasoning about Unreliable Actions.pdf:pdf},
month = {feb},
title = {{Reasoning about Unreliable Actions}},
url = {http://arxiv.org/abs/1202.0255},
year = {2012}
}
@book{Ben-Ari2012,
address = {London},
author = {Ben-Ari, Mordechai},
doi = {10.1007/978-1-4471-4129-7},
edition = {3},
file = {:Users/liang-tingchen/Dropbox/References/Ben-Ari - 2012 - Mathematical Logic for Computer Science.pdf:pdf},
isbn = {978-1-4471-4128-0},
publisher = {Springer London},
title = {{Mathematical Logic for Computer Science}},
url = {http://link.springer.com/10.1007/978-1-4471-4129-7},
year = {2012}
}
@book{Klir2006,
address = {Hoboken, NJ, USA},
author = {Klir, George J},
doi = {10.1002/0471755575},
file = {:Users/liang-tingchen/Dropbox/References/Klir - 2005 - Uncertainty and Information.pdf:pdf},
isbn = {9780471755579},
month = {nov},
pages = {511},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Uncertainty and Information}},
url = {http://doi.wiley.com/10.1002/0471755575},
year = {2005}
}
@incollection{Martin-Lof1975a,
abstract = {The theory of types is intended to be a full-scale system for formalizing intuitionistic mathematics as developed. The language of the theory is richer than the languages of traditional intuitionistic systems in permitting proofs to appear as parts of propositions so that the propositions of the theory can express properties of proofs. There are axioms for universes that link the generation of objects and types and play somewhat the same role for the present theory as does the replacement axiom for Zermelo–Fraenkel set theory. The present theory is based on a strongly impredicative axiom that there is a type of all types in symbols. This axiom has to be abandoned, however, after it has been shown to lead to a contraction. This chapter discusses Normalization theorem, which can be strengthened in two ways: it can be made to cover open terms and it can be proved that every reduction sequence starting from an arbitrary term leads to a unique normal term after a finite number of steps. The definition of the notion of convertibility and the proof that an arbitrary term is convertible can no longer be separated because the type symbols and the terms are generated simultaneously. {\textcopyright} 1975, North-Holland Publishing Company},
author = {Martin-L{\"{o}}f, Per},
booktitle = {Proceedings of the Logic Colloquium '73},
doi = {10.1016/S0049-237X(08)71945-1},
file = {:Users/liang-tingchen/Dropbox/References//Martin-L{\"{o}}f - 1975 - An Intuitionistic Theory of Types Predicative Part.pdf:pdf},
issn = {0049237X},
number = {C},
pages = {73--118},
publisher = {North-Holland Publishing Company},
title = {{An Intuitionistic Theory of Types: Predicative Part}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0049237X08719451 http://dx.doi.org/10.1016/S0049-237X(08)71945-1},
volume = {80},
year = {1975}
}
@incollection{Muralidhar2010,
abstract = {The concept of differential privacy was motivated through the example of Terry Gross' height in Dwork (2006). In this paper, we show that when a procedure based on differential privacy is implemented, it neither protects Terry Gross' privacy nor does it provide meaningful responses to queries. We also provide an additional illustration using income data from the US Census. These illustrations raise serious questions regarding the efficacy of using differential privacy based masking mechanism for numerical data.},
author = {Muralidhar, Krish and Sarathy, Rathindra},
booktitle = {Privacy in Statistical Databases},
doi = {10.1007/978-3-642-15838-4_18},
editor = {Domingo-Ferrer, Josep and Magkos, Emmanouil},
file = {:Users/liang-tingchen/Dropbox/References/Muralidhar, Sarathy - 2010 - Does Differential Privacy Protect Terry Gross' Privacy.pdf:pdf},
isbn = {3642158374},
issn = {03029743},
keywords = {Differential privacy,Laplace noise addition,Numerical data},
pages = {200--209},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Does Differential Privacy Protect Terry Gross' Privacy?}},
url = {http://link.springer.com/10.1007/978-3-642-15838-4{\_}18},
volume = {6344},
year = {2010}
}
@inproceedings{Abel2019a,
abstract = {We observe that normalization by evaluation for simply-typed lambda-calculus with weak coproducts can be carried out in a weak bi-cartesian closed category of presheaves equipped with a monad that allows us to perform case distinction on neutral terms of sum type. The placement of the monad influences the normal forms we obtain: for instance, placing the monad on coproducts gives us eta-long beta-pi normal forms where pi refers to permutation of case distinctions out of elimination positions. We further observe that placing the monad on every coproduct is rather wasteful, and an optimal placement of the monad can be determined by considering polarized simple types inspired by focalization. Polarization classifies types into positive and negative, and it is sufficient to place the monad at the embedding of positive types into negative ones. We consider two calculi based on polarized types: pure call-by-push-value (CBPV) and polarized lambda-calculus, the natural deduction calculus corresponding to focalized sequent calculus. For these two calculi, we present algorithms for normalization by evaluation. We further discuss different implementations of the monad and their relation to existing normalization proofs for lambda-calculus with sums. Our developments have been partially formalized in the Agda proof assistant.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1902.06097},
author = {Abel, Andreas and Sattler, Christian},
booktitle = {Proceedings of the 21st International Symposium on Principles and Practice of Programming Languages 2019},
doi = {10.1145/3354166.3354168},
eprint = {1902.06097},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Sattler - 2019 - Normalization by evaluation for call-by-push-value and polarized lambda calculus.pdf:pdf},
isbn = {9781450372497},
keywords = {Evaluation,Intuitionistic Propositional Logic,Lambda-Calculus,Monad,Normalization,Polarized Logic,Semantics},
month = {oct},
pages = {1--12},
publisher = {ACM},
title = {{Normalization by Evaluation for Call-By-Push-Value and Polarized Lambda Calculus}},
url = {https://dl.acm.org/doi/10.1145/3354166.3354168},
year = {2019}
}
@incollection{Bonsangue1995,
author = {Bonsangue, Marcello M. and Kwiatkowska, Marta Z.},
booktitle = {Modal Logic and Process Algebra: A Bisimulation Perspective},
editor = {Ponse, Alban and de Rijke, Maarten and Venema, Yde},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Kwiatkowska - 1995 - Re-interpreting modal $\mu$-calculus:},
pages = {65--83},
publisher = {Stanford CLSI publications},
series = {CLSI Lecture Notes},
title = {{Re-interpreting modal $\mu$-calculus}},
year = {1995}
}
@article{Lack2005,
author = {Lack, Stephen},
doi = {10.1007/s10485-005-2958-5},
file = {:Users/liang-tingchen/Dropbox/References/Lack - 2005 - Limits for Lax Morphisms.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {2-monad,lax limit,lax morphism,monoidal functor},
month = {jun},
number = {3},
pages = {189--203},
title = {{Limits for Lax Morphisms}},
url = {http://link.springer.com/10.1007/s10485-005-2958-5},
volume = {13},
year = {2005}
}
@book{Goodfellow2016,
abstract = {Deep learning draws upon many modeling formalisms that researchers can use to guide their design efforts and describe their algorithms. One of these formalisms is the idea of structured probabilistic models. We have already discussed structured probabilistic models briefly in Chapter 3.14. That brief presentation was sufficient to understand how to use structured probabilistic models as a language to describe some of the algorithms in part II of this book. Now, in part III, structured probabilistic models are a key ingredient of many of the most important research topics in deep learning. In order to prepare to discuss these research ideas, this chapter describes structured probabilistic models in much greater detail. This chapter is intended to be self-contained; the reader does not need to review the earlier introduction before continuing with this chapter. A structured probabilistic model is a way of describing a probability distribu-tion, using a graph to describe which random variables in the probability distri-bution interact with each other directly. Here we use " graph " in the graph theory sense–a set of vertices connected to one another by a set of edges. Because the structure of the model is defined by a graph, these models are often also referred to as graphical models. The graphical models research community is large and has developed many different models, training algorithms, and inference algorithms. In this chap-ter, we provide basic background on some of the most central ideas of graphical models, with an emphasis on the concepts that have proven most useful to the deep learning research community. If you already have a strong background in graphical models, you may wish to skip most of this chapter. However, even a graphical model expert may benefit from reading the final section of this chap-ter, section 13.6, in which we highlight some of the unique ways that graphical 412 CHAPTER 13. STRUCTURED PROBABILISTIC MODELS FOR DEEP LEARNING models are used for deep learning algorithms. Deep learning practitioners tend to use very different model structures, learning algorithms, and inference procedures than are commonly used by the rest of the graphical models research community. In this chapter, we identify these differences in preferences and explain the reasons for them. In this chapter we first describe the challenges of building large-scale proba-bilistic models in section 13.1. Next, we describe how to use a graph to describe the structure of a probability distribution in section 13.2. We then revisit the challenges we described in section 13.1 and show how the structured approach to probabilistic modeling can overcome these challenges in section 13.3. One of the major difficulties in graphical modeling is understanding which variables need to be able to interact directly, i.e., which graph structures are most suitable for a given problem. We outline two approaches to resolving this difficulty by learning about the dependencies in section 13.4. Finally, we close with a discussion of the unique emphasis that deep learning practitioners place on specific approaches to graphical modeling in section 13.6. 13.1 The Challenge of Unstructured Modeling},
author = {Goodfellow, Ian and Yoshua, Bengio and Aaron, Courville},
file = {:Users/liang-tingchen/Dropbox/References/Goodfellow, Yoshua, Aaron - 2016 - Deep Learning.pdf:pdf},
isbn = {978-0262035613},
keywords = {machine learning},
pages = {800},
publisher = {The MIT Press},
series = {Adaptive Computation and Machine Learning series},
title = {{Deep Learning}},
url = {http://www.deeplearningbook.org},
year = {2016}
}
@incollection{Girard1989,
abstract = {This chapter describes the development of a semantics of computation free from the twin drawbacks of reductionism (that leads to static modification) and subjectivism (that leads to syntactical abuses, in other terms, bureaucracy). The new approach initiated in this chapter rests on the use of a specific C∗-algebra $\Lambda$∗ that has the distinguished property of bearing a (non associative) inner tensor product. The chapter describes that a representative class of algorithms can be modelized by means of standard mathematics. {\textcopyright} 1989, Elsevier Inc.},
author = {Girard, Jean-Yves},
booktitle = {Studies in Logic and the Foundations of Mathematics},
doi = {10.1016/S0049-237X(08)70271-4},
file = {:Users/liang-tingchen/Dropbox/References/Girard - 1989 - Geometry of Interaction 1 Interpretation of System F.pdf:pdf},
isbn = {9780444874559},
issn = {0049237X},
number = {C},
pages = {221--260},
title = {{Geometry of Interaction 1: Interpretation of System F}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0049237X08702714},
volume = {127},
year = {1989}
}
@techreport{McBride2001,
abstract = {Polymorphic regular types are tree-like datatypes generated by polynomial type expressions over a set of free variables and closed under least fixed point. The 'equality types' of Core ML can be expressed in this form. Given such a type expression T with x free, this paper shows a way to represent the one-hole contexts for elements of x within elements of T, together with an operation which will plug an element of x into the hole of such a context. One-hole contexts are given as inhabitants of a regular type dxT, computed generically from the syntactic structure fo T by a mechanism better known as partial differentiation. The relevant notion of containment is shown to be appropriately characterized in terms of derivatives and pluggin in. The technology is then exploited to give the one-hole contexts for sub-elements of recursive types in a manner similar to Huet's 'zippers'.},
author = {McBride, Conor},
booktitle = {Unpublished manuscript},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2001 - The derivative of a regular type is its type of one-hole contexts.pdf:pdf},
pages = {1--11},
title = {{The derivative of a regular type is its type of one-hole contexts}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:The+Derivative+of+a+Regular+Type+is+its+Type+of+One-Hole+Contexts{\#}0},
year = {2001}
}
@inproceedings{Harper1990,
abstract = {In earlier work, we used a typed function calculus, XML, with dependent types to analyze several aspects of the Standard ML type system. In this paper, we introduce a refinement of XML with a clear compile-time/run-time phase distinction, and a direct compile-time type checking algorithm. The calculus uses a finer separation of types into universes than XML and enforces the phase distinction using a nonstandard equational theory for module and signature expressions. While unusual from a type-theoretic point of view, the nonstandard equational theory arises naturally from the well-known Grothendieck construction on an indexed category.},
address = {New York, New York, USA},
author = {Harper, Robert and Mitchell, John C. and Moggi, Eugenio},
booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '90},
doi = {10.1145/96709.96744},
file = {:Users/liang-tingchen/Dropbox/References/Harper, Mitchell, Moggi - 1990 - Higher-order modules and the phase distinction.pdf:pdf},
isbn = {0897913434},
issn = {07308566},
pages = {341--354},
publisher = {ACM Press},
title = {{Higher-order modules and the phase distinction}},
url = {http://portal.acm.org/citation.cfm?doid=96709.96744},
year = {1990}
}
@article{GonzalezHuesca2020,
author = {{Gonz{\'{a}}lez Huesca}, Lourdes del Carmen and Miranda-Perea, Favio E. and Linares-Ar{\'{e}}valo, P. Selene},
doi = {10.1016/j.entcs.2020.02.005},
file = {:Users/liang-tingchen/Dropbox/References/Gonz{\'{a}}lez Huesca, Miranda-Perea, Linares-Ar{\'{e}}valo - 2020 - Dual and Axiomatic Systems for Constructive S4, a Formally Verified Equivalen.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {constructive logic,coq,dual calculus,formal verification,modal logic s4,natural deduction},
month = {mar},
pages = {61--83},
publisher = {Elsevier B.V.},
title = {{Dual and Axiomatic Systems for Constructive S4, a Formally Verified Equivalence}},
url = {https://doi.org/10.1016/j.entcs.2020.02.005 https://linkinghub.elsevier.com/retrieve/pii/S1571066120300050},
volume = {348},
year = {2020}
}
@inproceedings{Wadler1993,
author = {Wadler, Philip},
booktitle = {Proceedings of the 18th International Symposium on Mathematical Foundations of Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 1993 - A Taste of Linear Logic(2).pdf:pdf},
isbn = {3-540-57182-5},
month = {aug},
pages = {185--210},
title = {{A Taste of Linear Logic}},
url = {http://dl.acm.org/citation.cfm?id=645722.666394},
year = {1993}
}
@inproceedings{Bell2005a,
author = {Bell, D.E.},
booktitle = {21st Annual Computer Security Applications Conference (ACSAC'05)},
doi = {10.1109/CSAC.2005.37},
file = {:Users/liang-tingchen/Dropbox/References/Bell - 2005 - Looking Back at the Bell-La Padula Model.pdf:pdf},
isbn = {0-7695-2461-3},
number = {Acsac},
pages = {337--351},
publisher = {IEEE},
title = {{Looking Back at the Bell-La Padula Model}},
url = {http://ieeexplore.ieee.org/document/1565261/},
year = {2005}
}
@inproceedings{Munch-Maccagnoni2015,
abstract = {The theory of the $\lambda$-calculus with extensional sums is more complex than with only pairs and functions. We propose an untyped representation - an intermediate calculus - for the $\lambda$-calculus with sums, based on the following principles: 1) Computation is described as the reduction of pairs of an expression and a context, the context must be represented inside-out, 2) Operations are represented abstractly by their transition rule, 3) Positive and negative expressions are respectively eager and lazy, this polarity is an approximation of the type. We offer an introduction from the ground up to our approach, and we review the benefits. A structure of alternating phases naturally emerges through the study of normal forms, offering a reconstruction of focusing. Considering further purity assumption, we obtain maximal multi-focusing. As an application, we can deduce a syntax-directed algorithm to decide the equivalence of normal forms in the simply-typed $\lambda$-calculus with sums, and justify it with our intermediate calculus.},
author = {Munch-Maccagnoni, Guillaume and Scherer, Gabriel},
booktitle = {2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2015.22},
file = {:Users/liang-tingchen/Dropbox/References/Munch-Maccagnoni, Scherer - 2015 - Polarised Intermediate Representation of Lambda Calculus with Sums.pdf:pdf},
isbn = {978-1-4799-8875-4},
issn = {10436871},
keywords = {Abstract machines,Continuation-passing style,Defunctionalization,Focalization,Intuitionistic logic,Polarization,Sequent calculus,$\lambda$-calculus with sums},
month = {jul},
pages = {127--140},
publisher = {IEEE},
title = {{Polarised Intermediate Representation of Lambda Calculus with Sums}},
url = {http://ieeexplore.ieee.org/document/7174876/},
volume = {2015-July},
year = {2015}
}
@article{Choe1977,
author = {Choe, Tae H.},
doi = {10.1007/BF02485423},
file = {:Users/liang-tingchen/Dropbox/References/Choe - 1977 - Injective and projective zero-dimensional compact universal algebras.pdf:pdf},
issn = {00025270},
journal = {Algebra Universalis},
number = {1},
pages = {137--142},
title = {{Injective and projective zero-dimensional compact universal algebras}},
volume = {7},
year = {1977}
}
@article{Diers1976,
author = {Diers, Yves},
file = {:Users/liang-tingchen/Dropbox/References/Diers - 1976 - Compl{\'{e}}tion monadique.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {4},
pages = {363--396},
title = {{Compl{\'{e}}tion monadique}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1976{\_}{\_}17{\_}4{\_}363{\_}0},
volume = {17},
year = {1976}
}
@article{Ishihara2018,
abstract = {Consistency with the formal Church's thesis, for short CT, and the axiom of choice, for short AC, was one of the requirements asked to be satisfied by the intensional level of a two-level foundation for constructive mathematics as proposed by Maietti and Sambin (in Crosilla, Schuster (eds) From sets and types to topology and analysis: practicable foundations for constructive mathematics, Oxford University Press, Oxford, 2005). Here we show that this is the case for the intensional level of the two-level Minimalist Foundation, for short MF, completed in 2009 by the second author. The intensional level of MF consists of an intensional type theory {\`{a}} la Martin-L{\"{o}}f, called mTT. The consistency of mTT with CT and AC is obtained by showing the consistency with the formal Church's thesis of a fragment of intensional Martin-L{\"{o}}f's type theory, called MLtt1, where mTT can be easily interpreted. Then to show the consistency of MLtt1 with CT we interpret it within Feferman's predicative theory of non-iterative fixpoints ID1{\^{}} by extending the well known Kleene's realizability semantics of intuitionistic arithmetics so that CT is trivially validated. More in detail the fragment MLtt1 we interpret consists of first order intensional Martin-L{\"{o}}f's type theory with one universe and with explicit substitution rules in place of usual equality rules preserving type constructors (hence without the so called $\xi$-rule which is not valid in our realizability semantics). A key difficulty encountered in our interpretation was to use the right interpretation of lambda abstraction in the applicative structure of natural numbers in order to model all the equality rules of MLtt1 correctly. In particular the universe of MLtt1 is modelled by means of ID1{\^{}} -fixpoints following a technique due first to Aczel and used by Feferman and Beeson.},
author = {Ishihara, Hajime and Maietti, Maria Emilia and Maschio, Samuele and Streicher, Thomas},
doi = {10.1007/s00153-018-0612-9},
file = {:Users/liang-tingchen/Dropbox/References/Ishihara et al. - 2018 - Consistency of the intensional level of the Minimalist Foundation with Church's thesis and axiom of choice.pdf:pdf},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
keywords = {Formal Church's thesis,Realizability,Type theory},
month = {nov},
number = {7-8},
pages = {873--888},
publisher = {Springer Berlin Heidelberg},
title = {{Consistency of the intensional level of the Minimalist Foundation with Church's thesis and axiom of choice}},
url = {https://doi.org/10.1007/s00153-018-0612-9 http://link.springer.com/10.1007/s00153-018-0612-9},
volume = {57},
year = {2018}
}
@article{Mokhov2020,
abstract = {Build systems are awesome, terrifying - and unloved. They are used by every developer around the world, but are rarely the object of study. In this paper, we offer a systematic, and executable, framework for developing and comparing build systems, viewing them as related points in a landscape rather than as isolated phenomena. By teasing apart existing build systems, we can recombine their components, allowing us to prototype new build systems with desired properties.},
author = {Mokhov, Andrey and Mitchell, N. E.I.L. and {Peyton Jones}, S. I.M.O.N.},
doi = {10.1017/S0956796820000088},
file = {:Users/liang-tingchen/Dropbox/References/Mokhov, Mitchell, Peyton Jones - 2020 - Build systems {\`{a}} la carte Theory and practice.pdf:pdf},
issn = {14697653},
journal = {Journal of Functional Programming},
title = {{Build systems {\`{a}} la carte: Theory and practice}},
year = {2020}
}
@article{Bunge1974,
annote = {NULL},
author = {Bunge, Marta C.},
doi = {10.1090/S0002-9947-1974-0344305-0},
file = {:Users/liang-tingchen/Dropbox/References/Bunge - 1974 - Coherent extensions and relational algebras.pdf:pdf},
issn = {0002-9947},
journal = {Transactions of the American Mathematical Society},
pages = {355--355},
title = {{Coherent extensions and relational algebras}},
url = {http://www.ams.org/jourcgi/jour-getitem?pii=S0002-9947-1974-0344305-0},
volume = {197},
year = {1974}
}
@article{Ohm2010,
abstract = {Computer scientists have recently undermined our faith in the privacy- protecting power of anonymization, the name for techniques that protect the privacy of individuals in large databases by deleting information like names and social security numbers. These scientists have demonstrated that they can often “reidentify” or “deanonymize” individuals hidden in anonymized data with astonishing ease. By understanding this research, we realize we have made a mistake, labored beneath a fundamental misunderstanding, which has assured us much less privacy than we have assumed. This mistake pervades nearly every information privacy law, regulation, and debate, yet regulators and legal scholars have paid it scant attention. We must respond to the surprising failure of anonymization, and this Article provides the tools to do so.},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Ohm, Paul},
doi = {10.2139/ssrn.1450006},
eprint = {9809069v1},
file = {:Users/liang-tingchen/Dropbox/References/Ohm - 2010 - Broken Promises of Privacy Responding to the Surprising Failure of Anonymization.pdf:pdf},
isbn = {0041-5650},
issn = {00415650},
journal = {UCLA Law Review},
number = {6},
pages = {1701--1777},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{Broken Promises of Privacy: Responding to the Surprising Failure of Anonymization}},
url = {http://www.uclalawreview.org/broken-promises-of-privacy-responding-to-the-surprising-failure-of-anonymization-2/},
volume = {57},
year = {2010}
}
@incollection{Gibbons2007a,
author = {Gibbons, Jeremy},
booktitle = {Datatype-Generic Programming--- International Spring School, SSDGP 2006, Nottingham, UK, April 24–27, 2006, Revised Lectures},
doi = {10.1007/978-3-540-76786-2_1},
editor = {Backhouse, Roland and Gibbons, Jeremy and Hinze, Ralf and Jeuring, Johan},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2007 - Datatype-Generic Programming.pdf:pdf},
pages = {1--71},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Datatype-Generic Programming}},
url = {http://link.springer.com/10.1007/978-3-540-76786-2{\_}1},
volume = {4719},
year = {2007}
}
@article{Williams1969,
author = {Williams, N. H.},
file = {:Users/liang-tingchen/Dropbox/References/Williams - 1969 - On Grothendieck universes.pdf:pdf},
journal = {Compositio Mathematica},
pages = {1--3},
title = {{On Grothendieck universes}},
url = {https://eudml.org/doc/88991},
volume = {1},
year = {1969}
}
@article{Gabbay2010,
author = {Gabbay, Murdoch J. and Mathijssen, Aad},
doi = {10.1093/logcom/exp049},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Mathijssen - 2010 - A nominal axiomatization of the lambda calculus.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Equational logic,Lambda calculus,Nominal techniques},
month = {apr},
number = {2},
pages = {501--531},
title = {{A nominal axiomatization of the lambda calculus}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exp049},
volume = {20},
year = {2010}
}
@article{Kohler1999,
author = {Driscoll, James R. and Sarnak, Neil and Sleator, Daniel D. and Tarjan, Robert E.},
doi = {10.1016/0022-0000(89)90034-2},
file = {:Users/liang-tingchen/Dropbox/References/Driscoll et al. - 1989 - Making data structures persistent.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {feb},
number = {1},
pages = {86--124},
title = {{Making data structures persistent}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000089900342},
volume = {38},
year = {1989}
}
@article{Krivine2021,
abstract = {The theory of classical realizability is a framework for the Curry-Howard correspondence which enables to associate a program with each proof in Zermelo-Fraenkel set theory. But, almost all the applications of mathematics in physics, probability, statistics, etc. use Analysis i.e. the axiom of dependent choice (DC) or even the (full) axiom of choice (AC). It is therefore important to find explicit programs for these axioms. Various solutions have been found for DC, for instance the lambda-term called "bar recursion" or the instruction "quote" of LISP. We present here the first program for AC.},
author = {Krivine, Jean-Louis},
doi = {10.46298/lmcs-17(3:21)2021},
file = {:Users/liang-tingchen/Dropbox/References/Krivine - 2021 - A program for the full axiom of choice.pdf:pdf},
issn = {1860-5974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,combinatory logic,curry-howard correspondence,lambda-calculus,set theory},
month = {sep},
number = {3},
pages = {21},
title = {{A program for the full axiom of choice}},
url = {https://lmcs.episciences.org/6549},
volume = {17},
year = {2021}
}
@article{Coleman2006,
abstract = {A nonexpansive algebra is a pseudometric algebra in which the operations are all nonexpansive. We study such algebras, particularly in the case of algebras in permutable and n -permutable varieties, leading to new characterizations of such varieties. Free nonexpansive algebras are also investigated.},
annote = {10.1007/s00012-006-1997-6},
author = {Coleman, J. P.},
doi = {10.1007/s00012-006-1997-6},
file = {:Users/liang-tingchen/Dropbox/References/Coleman - 2006 - Nonexpansive algebras.pdf:pdf},
issn = {0002-5240},
journal = {Algebra universalis},
month = {sep},
number = {4},
pages = {479--494},
publisher = {Birkh{\"{a}}user Basel},
title = {{Nonexpansive algebras}},
url = {http://www.springerlink.com/index/10.1007/s00012-006-1997-6},
volume = {55},
year = {2006}
}
@article{Bruse2014,
abstract = {Guarded normal form requires occurrences of fixpoint variables in a {\{}$\backslash$mu{\}}-calculus-formula to occur under the scope of a modal operator. The literature contains guarded transformations that effectively bring a {\{}$\backslash$mu{\}}-calculus-formula into guarded normal form. We show that the known guarded transformations can cause an exponential blowup in formula size, contrary to existing claims of polynomial behaviour. We also show that any polynomial guarded transformation for {\{}$\backslash$mu{\}}-calculus-formulas in the more relaxed vectorial form gives rise to a polynomial solution algorithm for parity games, the existence of which is an open problem. We also investigate transformations between the {\{}$\backslash$mu{\}}-calculus, vectorial form and hierarchical equation systems, which are an alternative syntax for alternating parity tree automata.},
archivePrefix = {arXiv},
arxivId = {1305.0648},
author = {Bruse, Florian and Friedmann, Oliver and Lange, Martin},
doi = {10.1093/jigpal/jzu030},
eprint = {1305.0648},
file = {:Users/liang-tingchen/Dropbox/References/Bruse, Friedmann, Lange - 2015 - On guarded transformation in the modal $\mu$-calculus.pdf:pdf},
issn = {1367-0751},
journal = {Logic Journal of IGPL},
keywords = {Modal equation systems,Modal $\mu$-calculus,Parity games,guarded transformation},
month = {apr},
number = {2},
pages = {194--216},
title = {{On guarded transformation in the modal $\mu$-calculus}},
url = {http://jigpal.oxfordjournals.org/cgi/doi/10.1093/jigpal/jzu030},
volume = {23},
year = {2015}
}
@article{Frey2015,
abstract = {We characterize the tripos-to-topos construction of Hyland, Johnstone and Pitts as a biadjunction in a 2-category enriched category of equipment-like structures. These abstract concepts are necessary to handle the presence of oplax constructs - the construction is only oplax functorial on a certain class of tripos morphisms. A by-product of our analysis is the decomposition of the tripos-to-topos construction into two steps, the intermediate step being a generalization of quasitoposes.},
author = {Frey, Jonas},
doi = {10.1016/j.apal.2014.10.005},
file = {:Users/liang-tingchen/Dropbox/References/Frey - 2015 - Triposes, q-toposes and toposes.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Proarrow equipment,Quasitopos,Tripos-to-topos construction},
month = {feb},
number = {2},
pages = {232--259},
publisher = {Elsevier B.V.},
title = {{Triposes, q-toposes and toposes}},
url = {http://dx.doi.org/10.1016/j.apal.2014.10.005 https://linkinghub.elsevier.com/retrieve/pii/S0168007214001109},
volume = {166},
year = {2015}
}
@inproceedings{Angiuli,
author = {Angiuli, Carlo and Hou, Kuen-Bang (Favonia) and Harper, Robert},
booktitle = {27th EACSL Annual Conference on Computer Science Logic (CSL 2018)},
doi = {10.4230/LIPIcs.CSL.2018.6},
editor = {Ghica, Dan and Jung, Achim},
file = {:Users/liang-tingchen/Dropbox/References/Angiuli, Hou, Harper - 2018 - Cartesian Cubical Computational Type Theory Constructive Reasoning with Paths and Equalities.pdf:pdf},
keywords = {01800,1712,2018,4230,5,abs,and phrases homotopy type,arxiv,computational type,csl,cubical sets,digital object identifier 10,lipics,org,related version https,theory,two-level type theory},
pages = {6:1----6:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Cartesian Cubical Computational Type Theory: Constructive Reasoning with Paths and Equalities}},
volume = {119},
year = {2018}
}
@incollection{Suenaga2011,
author = {Suenaga, Kohei and Hasuo, Ichiro},
booktitle = {Automata, Languages and Programming},
doi = {10.1007/978-3-642-22012-8_31},
editor = {Aceto, Luca and Henzinger, Monika and {Jiř{\'{i}} Sgall}},
file = {:Users/liang-tingchen/Dropbox/References/Suenaga, Hasuo - 2011 - Programming with Infinitesimals A While-Language for Hybrid System Modeling.pdf:pdf},
pages = {392--403},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Programming with Infinitesimals: A While-Language for Hybrid System Modeling}},
year = {2011}
}
@article{Kock1970,
author = {Kock, Anders},
doi = {10.1007/BF01220868},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 1970 - Monads on symmetric monoidal closed categories.pdf:pdf},
issn = {0003-889X},
journal = {Archiv der Mathematik},
month = {dec},
number = {1},
pages = {1--10},
title = {{Monads on symmetric monoidal closed categories}},
url = {http://link.springer.com/10.1007/BF01220868},
volume = {21},
year = {1970}
}
@article{Peterson2015,
abstract = {This paper provides an analysis of contrary-to-duty reasoning from the proof-theoretical perspective of category theory. While Chisholm's paradox hints at the need of dyadic deontic logic by showing that monadic deontic logics are not able to adequately model conditional obligations and contrary-to-duties, other arguments can be objected to dyadic approaches in favor of non-monotonic foundations. We show that all these objections can be answered at one fell swoop by modeling conditional obligations within a deductive system defined as an instance of a symmetric monoidal closed category. Using category theory as a foundational framework for logic, we show that it is possible to model conditional normative reasoning and conflicting obligations within a monadic approach without adding further operators or considering deontic conditionals as primitive.},
author = {Peterson, Clayton},
doi = {10.1007/s11787-014-0111-7},
file = {:Users/liang-tingchen/Dropbox/References/Peterson - 2015 - Contrary-to-Duty Reasoning A Categorical Approach.pdf:pdf},
issn = {1661-8297},
journal = {Logica Universalis},
keywords = {Primary 03B45,Secondary 03B60},
month = {mar},
number = {1},
pages = {47--92},
title = {{Contrary-to-Duty Reasoning: A Categorical Approach}},
url = {http://link.springer.com/10.1007/s11787-014-0111-7},
volume = {9},
year = {2015}
}
@article{Corfield2011,
author = {Corfield, David},
doi = {10.1016/j.shpsa.2011.09.013},
file = {:Users/liang-tingchen/Dropbox/References/Corfield - 2011 - Understanding the infinite II Coalgebra.pdf:pdf},
issn = {00393681},
journal = {Studies in History and Philosophy of Science Part A},
month = {dec},
number = {4},
pages = {571--579},
publisher = {Elsevier Ltd},
title = {{Understanding the infinite II: Coalgebra}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003936811100077X},
volume = {42},
year = {2011}
}
@incollection{Dinesh2008a,
abstract = {This paper considers the problem of checking whether an organization conforms to a body of regulation. Conformance is cast as a trace checking question {\^{a}}€“ the regulation is represented in a logic that is evaluated against an abstract trace or run representing the operations of an organization. We focus on a problem in designing a logic to represent regulation.$\backslash$nA common phenomenon in regulatory texts is for sentences to refer to others for conditions or exceptions. We motivate the need for a formal representation of regulation to accomodate such references between statements. We then extend linear temporal logic to allow statements to refer to others. The semantics of the resulting logic is defined via a combination of techniques from Reiter{\^{a}}€™s default logic and Kripke{\^{a}}€™s theory of truth.$\backslash$n},
author = {Dinesh, Nikhil and Joshi, Aravind and Lee, Insup and Sokolsky, Oleg},
booktitle = {Logic in Computer Science. DEON 2008},
doi = {10.1007/978-3-540-70525-3_10},
editor = {van der Meyden, Ron and van der Torre, Leendert},
file = {:Users/liang-tingchen/Dropbox/References/Dinesh et al. - 2008 - Reasoning about conditions and exceptions to laws in regulatory conformance checking.pdf:pdf},
isbn = {3540705244},
issn = {03029743},
pages = {110--124},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Reasoning about conditions and exceptions to laws in regulatory conformance checking}},
volume = {5076},
year = {2008}
}
@phdthesis{Rivieccio2010,
author = {Rivieccio, Umberto},
file = {:Users/liang-tingchen/Dropbox/References/Rivieccio - 2010 - An Algebraic Study of Bilattice-based Logics.pdf:pdf},
month = {mar},
pages = {191},
school = {Universit{\`{a}} di Genova},
title = {{An Algebraic Study of Bilattice-based Logics}},
year = {2010}
}
@book{Constable1986,
address = {USA},
author = {Constable, Robert L. and Allen, S. F. and Bromley, H. M. and Cleaveland, W R and Cremer, J F and Harper, Robert W. and Howe, D J and Knoblock, T B and Mendler, N P and Panangaden, P and Sasaki, J T and Smith, S F},
isbn = {0134518322},
publisher = {Prentice-Hall, Inc.},
title = {{Implementing Mathematics with the Nuprl Proof Development System}},
year = {1986}
}
@inproceedings{Milius2012,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Bowler, Nathan and Levy, Paul Blain},
booktitle = {2012 27th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2012.16},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2012 - Coproducts of Monads on Set.pdf:pdf},
isbn = {978-1-4673-2263-8},
month = {jun},
pages = {45--54},
publisher = {Ieee},
title = {{Coproducts of Monads on Set}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6280423},
year = {2012}
}
@article{Vezzosi2019,
author = {Vezzosi, Andrea and M{\"{o}}rtberg, Anders and Abel, Andreas},
doi = {10.1145/3341691},
file = {:Users/liang-tingchen/Dropbox/References/Vezzosi, M{\"{o}}rtberg, Abel - 2019 - Cubical Agda a dependently typed programming language with univalence and higher inductive types.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Cubical Agda: a dependently typed programming language with univalence and higher inductive types}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341691},
volume = {3},
year = {2019}
}
@article{Dimov1993,
author = {Dimov, Georgi D. and Tholen, Walter},
file = {:Users/liang-tingchen/Dropbox/References/Dimov, Tholen - 1993 - Groups of dualities.pdf:pdf},
journal = {Transactions of the American Mathematical Society},
number = {2},
pages = {901--913},
title = {{Groups of dualities}},
url = {http://www.ams.org/journals/tran/1993-336-02/S0002-9947-1993-1100693-0/S0002-9947-1993-1100693-0.pdf},
volume = {336},
year = {1993}
}
@incollection{Lack2010,
archivePrefix = {arXiv},
arxivId = {math/0702535},
author = {Lack, Stephen},
booktitle = {Towards Higher Categories},
doi = {10.1007/978-1-4419-1524-5_4},
editor = {Baez, John C. and May, J. Peter},
eprint = {0702535},
file = {:Users/liang-tingchen/Dropbox/References/Lack - 2010 - A 2-categories companion.pdf:pdf},
month = {feb},
pages = {1--73},
primaryClass = {math},
publisher = {Springer New York},
series = {The IMA Volumes in Mathematics and its Applications},
title = {{A 2-categories companion}},
url = {http://arxiv.org/abs/math/0702535v1},
year = {2010}
}
@article{Adamek2011,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1017/S0960129510000496},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2011 - Elgot theories a new perspective on the equational properties of iteration.pdf:pdf},
isbn = {0960129510},
journal = {Mathematical Structures in Computer Science},
number = {Special Issue 02},
pages = {417--480},
title = {{Elgot theories: a new perspective on the equational properties of iteration}},
url = {http://journals.cambridge.org/abstract{\_}S0960129510000496},
volume = {21},
year = {2011}
}
@article{Kerstan2013a,
abstract = {We investigate some basic questions about the interaction of regular and$\backslash$nrational relations on words. The primary motivation comes from the study of$\backslash$nlogics for querying graph topology, which have recently found numerous$\backslash$napplications. Such logics use conditions on paths expressed by regular$\backslash$nlanguages and relations, but they often need to be extended by rational$\backslash$nrelations such as subword or subsequence. Evaluating formulae in such extended$\backslash$ngraph logics boils down to checking nonemptiness of the intersection of$\backslash$nrational relations with regular or recognizable relations (or, more generally,$\backslash$nto the generalized intersection problem, asking whether some projections of a$\backslash$nregular relation have a nonempty intersection with a given rational relation).$\backslash$n We prove that for several basic and commonly used rational relations, the$\backslash$nintersection problem with regular relations is either undecidable (e.g., for$\backslash$nsubword or su?x, and some generalizations), or decidable with$\backslash$nnon-primitive-recursive complexity (e.g., for subsequence and its$\backslash$ngeneralizations). These results are used to rule out many classes of graph$\backslash$nlogics that freely combine regular and rational relations, as well as to$\backslash$nprovide the simplest problem related to verifying lossy channel systems that$\backslash$nhas non-primitive-recursive complexity. We then prove a dichotomy result for$\backslash$nlogics combining regular conditions on individual paths and rational relations$\backslash$non paths, by showing that the syntactic form of formulae classi?es them into$\backslash$neither e?ciently checkable or undecidable cases. We also give examples of$\backslash$nrational relations for which such logics are decidable even without syntactic$\backslash$nrestrictions.},
archivePrefix = {arXiv},
arxivId = {1310.7417},
author = {Kerstan, Henning and K{\"{o}}nig, Barbara},
doi = {10.2168/LMCS-9(4:16)2013},
editor = {Koutny, Maciej},
eprint = {1310.7417},
file = {:Users/liang-tingchen/Dropbox/References/Kerstan, K{\"{o}}nig - 2013 - Coalgebraic trace semantics for continuous probabilistic transition systems.pdf:pdf},
isbn = {2009256492},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Coalgebra,Markov processes,Probabilistic transition systems,Trace semantics},
month = {dec},
number = {4},
pages = {1--44},
title = {{Coalgebraic trace semantics for continuous probabilistic transition systems}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1311},
volume = {9},
year = {2013}
}
@article{Dybjer2003,
abstract = {Induction-recursion is a powerful definition method in intuitionistic type theory. It extends (generalized) inductive definitions and allows us to define all standard sets of Martin-L{\"{o}}f type theory as well as a large collection of commonly occurring inductive data structures. It also includes a variety of universes which are constructive analogues of inaccessibles and other large cardinals below the first Mahlo cardinal. In this article we give a new compact formalization of inductive-recursive definitions by modeling them as initial algebras in slice categories. We give generic formation, introduction, elimination, and equality rules generalizing the usual rules of type theory. Moreover, we prove that the elimination and equality rules are equivalent to the principle of the existence of initial algebras for certain endofunctors. We also show the equivalence of the current formulation with the formulation of induction-recursion as a reflection principle given in Dybjer and Setzer (Lecture Notes in Comput. Sci. 2183 (2001) 93). Finally, we discuss two type-theoretic analogues of Mahlo cardinals in set theory: an external Mahlo universe which is defined by induction-recursion and captured by our formalization, and an internal Mahlo universe, which goes beyond induction-recursion. We show that the external Mahlo universe, and therefore also the theory of inductive-recursive definitions, have proof-theoretical strength of at least Rathjen's theory KPM. {\textcopyright} 2003 Published by Elsevier B.V. All rights reserved.},
author = {Dybjer, Peter and Setzer, Anton},
doi = {10.1016/S0168-0072(02)00096-9},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer, Setzer - 2003 - Induction–recursion and initial algebras.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Dependent type theory,Inductive definitions,Inductive-recursive definitions,Initial algebras,Large cardinals,Mahlo cardinals,Mahlo universes,Martin-L{\"{o}}f type theory},
month = {dec},
number = {1-3},
pages = {1--47},
title = {{Induction–recursion and initial algebras}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007202000969},
volume = {124},
year = {2003}
}
@article{VanDenBerg2012,
abstract = {This is the third instalment in a series of papers on algebraic set theory. In it, we develop a uniform approach to sheaf models of constructive set theories based on ideas from categorical logic. The key notion is that of a 'predicative category with small maps' which axiomatizes the idea of a category of classes and class morphisms, together with a selected class of maps whose fibres are sets (in some axiomatic set theory). The main result of the present paper is that such predicative categories with small maps are stable under internal sheaves. We discuss the sheaf models of constructive set theory this leads to, as well as ideas for future work. {\textcopyright} 2012 London Mathematical Society.},
author = {van den Berg, Benno and Moerdijk, Ieke},
doi = {10.1112/plms/pdr066},
file = {:Users/liang-tingchen/Dropbox/References/van den Berg, Moerdijk - 2012 - Aspects of predicative algebraic set theory III sheaves.pdf:pdf},
issn = {00246115},
journal = {Proceedings of the London Mathematical Society},
month = {nov},
number = {5},
pages = {1076--1122},
title = {{Aspects of predicative algebraic set theory III: sheaves}},
url = {http://doi.wiley.com/10.1112/plms/pdr066},
volume = {105},
year = {2012}
}
@article{Doberkat2009,
abstract = {We generalize stochastic Kripke models and Markov transition systems to stochastic right coalgebras. These are coalgebras for a functor F⋅S with F as an endofunctor on the category of analytic spaces, and S is the subprobability functor. The modal operators are generalized through predicate liftings which are set-valued natural transformations involving the functor. Two states are equivalent iff they cannot be separated by a formula. This equivalence relation is used to construct a cospan for logical equivalent coalgebras under a separation condition for the set of predicate liftings. Consequently, behavioral and logical equivalence are really the same. From the cospan we construct a span. The central argument is a selection argument giving us the dynamics of a mediating coalgebra from the domains of the cospan. This construction is used to establish that behavioral equivalent coalgebras are bisimilar, yielding the equivalence of all three characterizations of a coalgebra's behavior as in the case of Kripke models or Markov transition systems.},
author = {Doberkat, Ernst-Erich and Schubert, Christoph},
doi = {10.1016/j.apal.2008.06.018},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat, Schubert - 2009 - Coalgebraic logic for stochastic right coalgebras.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {jun},
number = {3},
pages = {268--284},
title = {{Coalgebraic logic for stochastic right coalgebras}},
url = {http://dx.doi.org/10.1016/j.apal.2008.06.018},
volume = {159},
year = {2009}
}
@incollection{Voigtlander2008,
abstract = {We present a low-effort program transformation to improve the efficiency of computations over free monads in Haskell. The development is calculational and carried out in a generic setting, thus applying to a variety of datatypes. An important aspect of our approach is the utilisation of type class mechanisms to make the transformation as transparent as possible, requiring no restructuring of code at all. There is also no extra support necessary from the compiler (apart from an up-to-date type checker). Despite this simplicity of use, our technique is able to achieve true asymptotic runtime improvements. We demonstrate this by examples for which the complexity is reduced from quadratic to linear.},
address = {Berlin, Heidelberg},
author = {Voigtl{\"{a}}nder, Janis},
booktitle = {Mathematics of Program Construction. MPC 2008},
doi = {10.1007/978-3-540-70594-9_20},
editor = {Audebaud, Philippe and Paulin-Mohring, Christine},
file = {:Users/liang-tingchen/Dropbox/References/Voigtl{\"{a}}nder - 2008 - Asymptotic Improvement of Computations over Free Monads.pdf:pdf},
isbn = {3540705937},
issn = {03029743},
pages = {388--403},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Asymptotic Improvement of Computations over Free Monads}},
url = {http://link.springer.com/10.1007/978-3-540-70594-9{\_}20},
volume = {5133},
year = {2008}
}
@inproceedings{Kiselyov2004,
abstract = {A heterogeneous collection is a datatype that is capable of storing data of different types, while providing operations for look-up, update, iteration, and others. There are various kinds of heteroge- neous collections, differing in representation, invariants, and access operations. We describe HLIST - a Haskell library for strongly typed heterogeneous collections including extensible records. We illustrate HLIST's benefits in the context of type-safe database access in Haskell. The HLIST library relies on common extensions of Haskell 98. Our exploration raises interesting issues regarding Haskell's type system, in particular, avoidance of overlapping instances, and reification of type equality and type unification.},
address = {New York, New York, USA},
author = {Kiselyov, Oleg and L{\"{a}}mmel, Ralf and Schupke, Keean},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell - Haskell '04},
doi = {10.1145/1017472.1017488},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov, L{\"{a}}mmel, Schupke - 2004 - Strongly typed heterogeneous collections.pdf:pdf},
isbn = {1581138504},
keywords = {cess,collections,dependently typed programming,equality,extensible records,haskell,type,type improvement,type-indexed rows,type-safe database ac-},
pages = {96},
publisher = {ACM Press},
title = {{Strongly typed heterogeneous collections}},
url = {http://portal.acm.org/citation.cfm?doid=1017472.1017488},
year = {2004}
}
@article{Barendregt2009,
abstract = {We present an introduction to infinitary lambda calculus, highlighting its main properties. Subsequently we give three applications of infinitary lambda calculus. The first addresses the non-definability of Surjective Pairing, which was shown by the first author not to be definable in lambda calculus. We show how this result follows easily as an application of Berry's Sequentiality Theorem, which itself can be proved in the setting of infinitary lambda calculus. The second pertains to the notion of relative recursiveness of number-theoretic functions. The third application concerns an explanation of counterexamples to confluence of lambda calculus extended with non-left-linear reduction rules: Adding non-left-linear reduction rules such as $\delta$ xx → x or the reduction rules for Surjective Pairing to the lambda calculus yields non-confluence, as proved by the second author. We discuss how an extension to the infinitary lambda calculus, where B{\"{o}}hm trees can be directly manipulated as infinite terms, yields a more simple and intuitive explanation of the correctness of these Church-Rosser counterexamples. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Barendregt, Henk and Klop, Jan Willem},
doi = {10.1016/j.ic.2008.09.003},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt, Klop - 2009 - Applications of infinitary lambda calculus.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {may},
number = {5},
pages = {559--582},
publisher = {Elsevier Inc.},
title = {{Applications of infinitary lambda calculus}},
url = {http://dx.doi.org/10.1016/j.ic.2008.09.003 https://linkinghub.elsevier.com/retrieve/pii/S089054010900025X},
volume = {207},
year = {2009}
}
@book{Wehrung2015,
address = {Cham},
author = {Wehrung, Friedrich},
doi = {10.1007/978-3-319-61599-8},
file = {:Users/liang-tingchen/Dropbox/References/Wehrung - 2017 - Refinement Monoids, Equidecomposability Types, and Boolean Inverse Semigroups.pdf:pdf},
isbn = {978-3-319-61598-1},
keywords = {V-congruence,V-homomorphism,group-induced,semig},
publisher = {Springer International Publishing},
series = {Lecture Notes in Mathematics},
title = {{Refinement Monoids, Equidecomposability Types, and Boolean Inverse Semigroups}},
url = {http://link.springer.com/10.1007/978-3-319-61599-8},
volume = {2188},
year = {2017}
}
@article{Longo1991,
abstract = {Various Theories of Types are introduced, by stressing the analogy ‘propositions-as-types': from propositional to higher order types (and Logic). In accordance with this, proofs are described as terms of various calculi, in particular of polymorphic (second order) $\lambda$-calculus. A semantic explanation is then given by interpreting individual types and the collection of all types in two simple categories built out of the natural numbers (the modest sets and the universe of $\omega$-sets). The first part of this paper (syntax) may be viewed as a short tutorial with a constructive understanding of the deduction theorem and some work on the expressive power of first and second order quantification. Also in the second part (semantics, {\S}{\S}6–7) the presentation is meant to be elementary, even though we introduce some new facts on types as quotient sets in order to interpret ‘explicit polymorphism'. (The experienced reader in Type Theory may directly go, at first reading, to {\S}{\S}6–8).},
author = {Longo, Giuseppe and Moggi, Eugenio},
doi = {10.1017/S0960129500001298},
file = {:Users/liang-tingchen/Dropbox/References/Longo, Moggi - 1991 - Constructive natural deduction and its ‘$\omega$-set' interpretation.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jul},
number = {2},
pages = {215--254},
title = {{Constructive natural deduction and its ‘$\omega$-set' interpretation}},
url = {https://www.cambridge.org/core/product/identifier/S0960129500001298/type/journal{\_}article},
volume = {1},
year = {1991}
}
@incollection{Pole1977,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
booktitle = {Computer Science Logic: 19th International Workshop, CSL 2005, 14th Annual Conference of the EACSL, Oxford, UK, August 22-25, 2005. Proceedings},
doi = {10.1007/11538363_7},
editor = {Ong, Luke},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2005 - A Logic of Coequations.pdf:pdf},
issn = {00224812},
month = {sep},
number = {3},
pages = {70--86},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Logic of Coequations}},
year = {2005}
}
@article{Ulidowski2004,
author = {Plotkin, Gordon D.},
doi = {10.1016/j.jlap.2004.05.001},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin - 2004 - A structural approach to operational semantics.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
month = {jul},
pages = {17--139},
title = {{A structural approach to operational semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832604000335},
volume = {60-61},
year = {2004}
}
@article{Hofmann2012a,
abstract = {We combine two research directions of the past decade, namely the development of a lax-algebraic framework for categories of interest to topologists and analysts, and the exploration of key topological concepts, like separation and compactness, in an abstract category which comes equipped with an axiomatic notion of "closed" or "proper" map. Hence, we present various candidates for such notions in the context of the category of (T,V)-categories, with a Set-monad T=(T,e,m) laxly extended to the category of sets and V-valued relations, for a quantale V. Suitable categories of ordered sets, metric spaces, topological spaces, closure spaces, and approach spaces all fit into this framework and allow for applications of the the general theory. {\textcopyright} 2012 Elsevier B.V.},
author = {Hofmann, Dirk and Tholen, Walter},
doi = {10.1016/j.topol.2011.09.049},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann, Tholen - 2012 - Lax algebra meets topology.pdf:pdf},
issn = {01668641},
journal = {Topology and its Applications},
keywords = {Compact object,Lax algebra,Lax extension,Monad,Perfect morphism,Separated object},
month = {jun},
number = {9},
pages = {2434--2452},
publisher = {Elsevier B.V.},
title = {{Lax algebra meets topology}},
url = {http://dx.doi.org/10.1016/j.topol.2011.09.049 http://linkinghub.elsevier.com/retrieve/pii/S0166864112000417},
volume = {159},
year = {2012}
}
@inproceedings{Danvy1996,
address = {New York, New York, USA},
author = {Danvy, Olivier},
booktitle = {Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '96},
doi = {10.1145/237721.237784},
file = {:Users/liang-tingchen/Dropbox/References/Danvy - 1996 - Type-directed partial evaluation.pdf:pdf},
isbn = {0897917693},
pages = {242--257},
publisher = {ACM Press},
title = {{Type-directed partial evaluation}},
url = {http://repository.upi.edu/1360/1/s{\_}d5451{\_}0604180{\_}chapter1.pdf http://portal.acm.org/citation.cfm?doid=237721.237784},
year = {1996}
}
@book{Gabriel1971,
author = {Gabriel, Peter and Ulmer, Friedrich},
doi = {10.1007/BFb0059396},
isbn = {978-3-540-05578-5},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Lokal pr{\"{a}}sentierbare Kategorien}},
url = {http://www.springerlink.com/index/10.1007/BFb0059396},
volume = {221},
year = {1971}
}
@article{Artemov2001,
abstract = {In 1933 G{\"{o}}del introduced a calculus of provability (also known as modal logic S4 ) and left open the question of its exact intended semantics. In this paper we give a solution to this problem. We find the logic LP of propositions and proofs and show that G{\"{o}}del's provability calculus is nothing but the forgetful projection of LP . This also achieves G{\"{o}}del's objective of defining intuitionistic propositional logic Int via classical proofs and provides a Brouwer-Heyting-Kolmogorov style provability semantics for Int which resisted formalization since the early 1930s. LP may be regarded as a unified underlying structure for intuitionistic, modal logics, typed combinatory logic and $\lambda$-calculus.},
author = {Artemov, Sergei N},
doi = {10.2307/2687821},
file = {:Users/liang-tingchen/Dropbox/References/Artemov - 2001 - Explicit Provability and Constructive Semantics.pdf:pdf},
issn = {1079-8986},
journal = {Bulletin of Symbolic Logic},
month = {mar},
number = {1},
pages = {1--36},
title = {{Explicit Provability and Constructive Semantics}},
url = {https://www.cambridge.org/core/product/identifier/S1079898600005989/type/journal{\_}article},
volume = {7},
year = {2001}
}
@book{Cortier2014,
author = {Cortier, V{\'{e}}ronique and Kremer, Steve},
booktitle = {Foundations and Trends{\textregistered} in Programming Languages},
doi = {10.1561/2500000001},
file = {:Users/liang-tingchen/Dropbox/References/Cortier, Kremer - 2014 - Formal Models and Techniques for Analyzing Security Protocols A Tutorial.pdf:pdf},
isbn = {2500000001},
issn = {2325-1107},
number = {3},
pages = {151--167},
title = {{Formal Models and Techniques for Analyzing Security Protocols: A Tutorial}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-programming-languages/PGL-001},
volume = {1},
year = {2014}
}
@inproceedings{Halpern2009,
address = {New York, New York, USA},
author = {Halpern, Joseph Y. and Pass, Rafael and Raman, Vasumathi},
booktitle = {Proceedings of the 11th Conference on Theoretical Aspects of Rationality and Knowledge - TARK '09},
doi = {10.1145/1562814.1562837},
file = {:Users/liang-tingchen/Dropbox/References/Halpern, Pass, Raman - 2009 - An epistemic characterization of zero knowledge.pdf:pdf},
isbn = {9781605585604},
pages = {156--165},
publisher = {ACM Press},
title = {{An epistemic characterization of zero knowledge}},
url = {http://portal.acm.org/citation.cfm?id=1562814.1562837 http://portal.acm.org/citation.cfm?doid=1562814.1562837},
year = {2009}
}
@article{Abel2014,
abstract = {In this paper, we present an Agda formalization of a normalizer for simply-typed lambda terms. The normalizer consists of two coinductively defined functions in the delay monad: One is a standard evaluator of lambda terms to closures, the other a type-directed reifier from values to h-long b-normal forms. Their composition, normalization-by-evaluation, is shown to be a total function a posteriori, using a standard logical-relations argument. The successful formalization serves as a proof-of-concept for coinductive programming and reasoning using sized types and copatterns, a new and presently experimental feature of Agda.},
author = {Abel, Andreas and Chapman, James},
doi = {10.4204/EPTCS.153.4},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Chapman - 2014 - Normalization by Evaluation in the Delay Monad A Case Study for Coinduction via Copatterns and Sized Types.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {jun},
number = {Msfp},
pages = {51--67},
title = {{Normalization by Evaluation in the Delay Monad: A Case Study for Coinduction via Copatterns and Sized Types}},
url = {http://arxiv.org/abs/1406.2059v1},
volume = {153},
year = {2014}
}
@article{Xie2022,
abstract = {Multi-stage programming using typed code quotation is an established technique for writing optimizing code generators with strong type-safety guarantees. Unfortunately, quotation in Haskell interacts poorly with type classes, making it difficult to write robust multi-stage programs.},
author = {Xie, Ningning and Pickering, Matthew and L{\"{o}}h, Andres and Wu, Nicolas and Yallop, Jeremy and Wang, Meng},
doi = {10.1145/3498723},
file = {:Users/liang-tingchen/Dropbox/References/Xie et al. - 2022 - Staging with class a specification for typed template Haskell.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--30},
title = {{Staging with class: a specification for typed template Haskell}},
url = {https://dl.acm.org/doi/10.1145/3498723},
volume = {6},
year = {2022}
}
@article{Denniston2014,
author = {Denniston, Jeffrey T. and Melton, Austin C. and Rodabaugh, Stephen E.},
doi = {10.1016/j.fss.2014.05.008},
file = {:Users/liang-tingchen/Dropbox/References/Denniston, Melton, Rodabaugh - 2014 - Enriched categories and many-valued preorders Categorical, semantical, and topological perspective.pdf:pdf},
issn = {0165-0114},
journal = {Fuzzy Sets and Systems},
keywords = {1,Antisymmetry,Data-mining,Enriched categories,Enriched/preordered sets,Left- and right-residuations,Many-valued preorders,Order-reversing and order-preserving involutions,Partially ordered groupoids and ringoids,Pattern-matching,Skeletons,T0 separation axiom,Unital quantales,and spectra,and topological spaces,antisymmetry,data-mining,enriched,enriched categories,hemimetrics,introduction and motivations,left- and right-residuations,many-valued preorders,order-preserving involutions,order-reversing and,partially ordered groupoids and,pattern-matching,preordered sets,ringoids,skeletons,specialization orders,t 0 separation axiom,topological systems,unital quantales},
pages = {4--56},
publisher = {Elsevier},
title = {{Enriched categories and many-valued preorders: Categorical, semantical, and topological perspectives}},
url = {http://dx.doi.org/10.1016/j.fss.2014.05.008},
volume = {256},
year = {2014}
}
@article{Kinoshita1998,
author = {Kinoshita, Yoshiki},
file = {:Users/liang-tingchen/Dropbox/References/Kinoshita - 1998 - A bicategorical analysis of E-categories.pdf:pdf},
journal = {Mathematica Japonica},
number = {1},
pages = {157--169},
title = {{A bicategorical analysis of E-categories}},
volume = {47},
year = {1998}
}
@phdthesis{Fontaine2010,
author = {Fontaine, Ga{\"{e}}lle M.M.},
file = {:Users/liang-tingchen/Dropbox/References/Fontaine - 2010 - Modal fixpoint logic some model theoretic questions.pdf:pdf},
isbn = {9789057762154},
pages = {246},
publisher = {Institute for Logic, Language and Computation},
title = {{Modal fixpoint logic: some model theoretic questions}},
url = {http://hdl.handle.net/11245/1.329510},
year = {2010}
}
@incollection{Kiselyov2012,
abstract = {The so-called 'typed tagless final' approach of Carette et al. [6] has collected and polished a number of techniques for representing typed higher-order languages in a typed metalanguage, along with type-preserving interpretation, compilation and partial evaluation. The ap-proach is an alternative to the traditional, or 'initial' encoding of an object language as a (generalized) algebraic data type. Both approaches permit multiple interpretations of an expression, to evaluate it, pretty-print, etc. The final encoding represents all and only typed object terms without resorting to generalized algebraic data types, dependent or other fancy types. The final encoding lets us add new language forms and in-terpretations without breaking the existing terms and interpreters. These lecture notes introduce the final approach slowly and in detail, highlighting extensibility, the solution to the expression problem, and the seemingly impossible pattern-matching. We develop the approach further, to type-safe cast, run-time-type representation, Dynamics, and type reconstruction. We finish with telling examples of type-directed partial evaluation and encodings of type-and-effect systems and linear lambda-calculus.},
author = {Kiselyov, Oleg},
booktitle = {Generic and Indexed Programming},
doi = {10.1007/978-3-642-32202-0_3},
editor = {Gibbons, Jeremy},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov - 2012 - Typed Tagless Final Interpreters.pdf:pdf},
pages = {130--174},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Typed Tagless Final Interpreters}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F978-3-642-32202-0{\_}3.pdf http://link.springer.com/10.1007/978-3-642-32202-0{\_}3},
volume = {7470},
year = {2012}
}
@incollection{Gehrke2008,
address = {Berlin, Heidelberg},
author = {Gehrke, Mai and Grigorieff, Serge and Pin, Jean-{\'{E}}ric},
booktitle = {ICALP 2008, Part II},
doi = {10.1007/978-3-540-70583-3_21},
editor = {Aceto, Luca and Damg{\aa}rd, Ivan and Goldberg, Leslie Ann and Halld{\'{o}}rsson, Magn{\'{u}}s M. and Ing{\'{o}}lfsd{\'{o}}ttir, Anna and Walukiewicz, Igor},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke, Grigorieff, Pin - 2008 - Duality and Equational Theory of Regular Languages.pdf:pdf},
pages = {246--257},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Duality and Equational Theory of Regular Languages}},
url = {http://link.springer.com/10.1007/978-3-540-70583-3{\_}21},
year = {2008}
}
@book{Admek2003a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Porst, Hans-E.},
booktitle = {Mathematical Structures in Computer Science},
doi = {10.1017/S0960129502003882},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Porst - 2003 - On varieties and covarieties in a category.pdf:pdf},
isbn = {0960129502},
issn = {09601295},
number = {2},
pages = {201--232},
title = {{On varieties and covarieties in a category}},
volume = {13},
year = {2003}
}
@article{1990a,
author = {Wadler, Philip},
doi = {10.1016/0304-3975(90)90147-A},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 1990 - Deforestation transforming programs to eliminate trees.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jun},
number = {2},
pages = {231--248},
title = {{Deforestation: transforming programs to eliminate trees}},
url = {http://linkinghub.elsevier.com/retrieve/pii/030439759090147A},
volume = {73},
year = {1990}
}
@article{Sulzmann2007,
author = {Sulzmann, Martin and Stuckey, Peter J.},
doi = {10.1017/S0956796807006569},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {02},
title = {{HM(X) type inference is CLP(X) solving}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796807006569},
volume = {18},
year = {2007}
}
@article{Lenisa2004,
author = {Lenisa, Marina and Power, A. John and Watanabe, Hiroshi},
doi = {10.1016/j.tcs.2004.07.024},
file = {:Users/liang-tingchen/Dropbox/References/Lenisa, Power, Watanabe - 2004 - Category theory for operational semantics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {abstract operational semantics,distributive law,final semantics,gsos -rule,initial},
month = {oct},
number = {1-2},
pages = {135--154},
title = {{Category theory for operational semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504004463},
volume = {327},
year = {2004}
}
@article{Sweeney1997,
author = {Sweeney, Latanya},
doi = {10.1111/j.1748-720X.1997.tb01885.x},
file = {:Users/liang-tingchen/Dropbox/References/Sweeney - 1997 - Weaving Technology and Policy Together to Maintain Confidentiality.pdf:pdf},
issn = {1073-1105},
journal = {The Journal of Law, Medicine $\backslash${\&} Ethics},
keywords = {necting research},
month = {jun},
number = {2-3},
pages = {98--110},
title = {{Weaving Technology and Policy Together to Maintain Confidentiality}},
url = {http://journals.sagepub.com/doi/10.1111/j.1748-720X.1997.tb01885.x},
volume = {25},
year = {1997}
}
@article{Adamek2011a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Trnkov{\'{a}}, V{\v{e}}ra},
doi = {10.1017/S0960129510000502},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Trnkov{\'{a}} - 2011 - Initial algebras and terminal coalgebras in many-sorted sets.pdf:pdf},
isbn = {0960129510},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {02},
pages = {481--509},
title = {{Initial algebras and terminal coalgebras in many-sorted sets}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129510000502},
volume = {21},
year = {2011}
}
@article{Plotkin2004a,
author = {Plotkin, Gordon D.},
doi = {10.1016/j.jlap.2004.03.009},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin - 2004 - The origins of structural operational semantics.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
keywords = {59,abstract machines,big step semantics,concurrency,i am delighted to,induction,labelled,on sos,operational semantics,see my aarhus notes,semantics,semantics of programming languages,small-step,static semantics,structural,structural operational semantics,transition systems,$\lambda$ -calculus},
month = {jul},
pages = {3--15},
title = {{The origins of structural operational semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832604000268},
volume = {60-61},
year = {2004}
}
@article{Uustalu2016,
author = {Uustalu, Tarmo},
doi = {10.1016/j.jlamp.2016.06.004},
file = {:Users/liang-tingchen/Dropbox/References/Uustalu - 2016 - A divertimento on MonadPlus and nondeterminism.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
number = {5},
pages = {1086--1094},
publisher = {Elsevier Inc.},
title = {{A divertimento on MonadPlus and nondeterminism}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2352220816300530},
volume = {85},
year = {2016}
}
@article{Zhang2019,
abstract = {Curators of sensitive datasets sometimes need to know whether queries against the data are differentially private [Dwork et al. 2006]. Two sorts of logics have been proposed for checking this property: (1) type systems and other static analyses, which fully automate straightforward reasoning with concepts like "program sensitivity" and "privacy loss," and (2) full-blown program logics such as apRHL (an approximate, probabilistic, relational Hoare logic) [Barthe et al. 2016], which support more flexible reasoning about subtle privacy-preserving algorithmic techniques but offer only minimal automation. We propose a three-level logic for differential privacy in an imperative setting and present a prototype implementation called Fuzzi. Fuzzi's lowest level is a general-purpose logic; its middle level is apRHL; and its top level is a novel sensitivity logic adapted from the linear-logic-inspired type system of Fuzz, a differentially private functional language [Reed and Pierce 2010]. The key novelty is a high degree of integration between the sensitivity logic and the two lower-level logics: the judgments and proofs of the sensitivity logic can be easily translated into apRHL; conversely, privacy properties of key algorithmic building blocks can be proved manually in apRHL and the base logic, then packaged up as typing rules that can be applied by a checker for the sensitivity logic to automatically construct privacy proofs for composite programs of arbitrary size. We demonstrate Fuzzi's utility by implementing four different private machine-learning algorithms and showing that Fuzzi's checker is able to derive tight sensitivity bounds.},
archivePrefix = {arXiv},
arxivId = {1905.12594},
author = {Zhang, Hengchu and Roth, Edo and Haeberlen, Andreas and Pierce, Benjamin C. and Roth, Aaron},
doi = {10.1145/3341697},
eprint = {1905.12594},
file = {:Users/liang-tingchen/Dropbox/References/Zhang et al. - 2019 - Fuzzi a three-level logic for differential privacy.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Differential privacy,Fuzz,Fuzzi,apRHL,static analysis,typechecking},
month = {jul},
number = {ICFP},
pages = {1--28},
title = {{Fuzzi: a three-level logic for differential privacy}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341697},
volume = {3},
year = {2019}
}
@article{Thiemann2019,
author = {Thiemann, Peter and Vasconcelos, Vasco T},
doi = {10.1145/3371135},
file = {:Users/liang-tingchen/Dropbox/References/Thiemann, Vasconcelos - 2019 - Label-dependent session types.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {dependent types,linear types,session types},
month = {dec},
number = {POPL},
pages = {1--29},
title = {{Label-dependent session types}},
url = {http://dl.acm.org/citation.cfm?doid=3377388.3371135},
volume = {4},
year = {2019}
}
@article{Kurz2011,
abstract = {of “algebras” that arise from a schizophrenic object $\Omega$, which is both an “algebra” and a “space”. We call such adjunctions logical connections. We prove that the exact nature of $\Omega$ is that of a module that allows to lift optimally the structure of a “space” and an “algebra” to certain diagrams. Our approach allows to give a unified framework known from logical connections over the category of sets and analyzed, e.g., by Hans Porst and Walter Tholen, with future applications of logical connections in coalgebraic logic and elsewhere, where typically, both the category of “spaces” and the category of “algebras” consist of “structured presheaves”.},
author = {Kurz, Alexander and Velebil, Jiř{\'{i}}},
doi = {10.1007/s10485-011-9267-y},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Velebil - 2011 - Enriched logical connections.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {logical connection,module,schizophrenic object},
month = {sep},
pages = {1--29},
publisher = {Springer Netherlands},
title = {{Enriched logical connections}},
url = {http://www.springerlink.com/index/10.1007/s10485-011-9267-y http://www.springerlink.com/content/4qv5g5p3x721kx15/},
year = {2011}
}
@article{Adamek2008,
abstract = {For accessible set-valued functors it is well known that weak preservation of limits is equivalent to representability, and weak preservation of connected limits to familial representability. In contrast, preservation of weak wide pullbacks is equivalent to being a coproduct of quotients of hom-functors modulo groups of automorphisms. For ﬁnitary functors this was proved by Andr´e Joyal who called these functors analytic. We introduce a generalization of Joyal's concept from endofunctors of Set to endofunctors of a symmetric monoidal category.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Velebil, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Velebil - 2008 - Analytic functors and weak pullbacks.pdf:pdf},
journal = {Theory and Applications of Categories},
number = {11},
pages = {191--209},
title = {{Analytic functors and weak pullbacks}},
url = {http://www.tac.mta.ca/tac/volumes/21/11/21-11.pdf},
volume = {21},
year = {2008}
}
@incollection{Kelly1974b,
author = {Kelly, Gregory Maxwell},
booktitle = {Category Seminar},
doi = {10.1007/BFb0063106},
editor = {Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1974 - Coherence theorems for lax algebras and for distributive laws.pdf:pdf},
pages = {281--375},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Coherence theorems for lax algebras and for distributive laws}},
url = {http://link.springer.com/10.1007/BFb0063106},
volume = {420},
year = {1974}
}
@article{Pitts2006,
abstract = {The nominal approach to abstract syntax deals with the issues of bound names and $\alpha$-equivalence by considering constructions and properties that are invariant with respect to permuting names. The use of permutations gives rise to an attractively simple formalization of common, but often technically incorrect uses of structural recursion and induction for abstract syntax modulo $\alpha$-equivalence. At the heart of this approach is the notion of finitely supported mathematical objects. This article explains the idea in as concrete a way as possible and gives a new derivation within higher-order classical logic of principles of $\alpha$-structural recursion and induction for $\alpha$-equivalence classes from the ordinary versions of these principles for abstract syntax trees. [ABSTRACT FROM AUTHOR]},
author = {Pitts, Andrew M.},
doi = {10.1145/1147954.1147961},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2006 - Alpha-structural recursion and induction.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
month = {may},
number = {3},
pages = {459--506},
title = {{Alpha-structural recursion and induction}},
url = {http://portal.acm.org/citation.cfm?doid=1147954.1147961},
volume = {53},
year = {2006}
}
@article{Sokolova2011,
abstract = {We survey the work on both discrete and continuous-space probabilistic systems as coalgebras, starting with how probabilistic systems are modeled as coalgebras and followed by a discussion of their bisimilarity and behavioral equivalence, mentioning results that follow from the coalgebraic treatment of probabilistic systems. It is interesting to note that, for different reasons, for both discrete and continuous probabilistic systems it may be more convenient to work with behavioral equivalence than with bisimilarity.},
author = {Sokolova, Ana},
doi = {10.1016/j.tcs.2011.05.008},
file = {:Users/liang-tingchen/Dropbox/References/Sokolova - 2011 - Probabilistic systems coalgebraically A survey.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical computer science},
keywords = {coalgebra,markov chains,markov processes,probabilistic systems},
month = {sep},
number = {38},
pages = {5095--5110},
pmid = {21998490},
title = {{Probabilistic systems coalgebraically: A survey}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.05.008 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3185909{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {412},
year = {2011}
}
@article{Adamek2013a,
abstract = {Every ideal monad M on the category of sets is known to have a reflection M̂ in the category of all iterative monads of Elgot. Here we describe the iterative reflection M̂ as the monad of free iterative Eilenberg-Moore algebras for M. This yields numerous concrete examples: if M is the free-semigroup monad, then M̂ is obtained by adding a single absorbing element; if M is the monad of finite trees then M̂ is the monad of rational trees, etc. {\textcopyright} 2013 Elsevier Inc.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1016/j.ic.2013.02.003},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2013 - How iterative reflections of monads are constructed.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Equational laws,Iterative theory,Monad,Recursive equations},
pages = {83--118},
title = {{How iterative reflections of monads are constructed}},
volume = {225},
year = {2013}
}
@article{Manes2015,
author = {Manes, Ernie},
file = {:Users/liang-tingchen/Dropbox/References/Manes - 2015 - Extensive categories and the size of an orbit.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Burnside-Frobenius lemma,Conjugacy class of subgroups,Extensive category},
number = {17},
pages = {599--619},
title = {{Extensive categories and the size of an orbit}},
volume = {30},
year = {2015}
}
@incollection{Ionescu2018,
address = {Cham},
author = {Ionescu, Cezar and Jansson, Patrik and Botta, Nicola},
booktitle = {Leveraging Applications of Formal Methods, Verification and Validation. Modeling},
doi = {10.1007/978-3-030-03418-4_8},
editor = {Margaria, Tiziana and Steffen, Bernhard},
file = {:Users/liang-tingchen/Dropbox/References/Ionescu, Jansson, Botta - 2018 - Type Theory as a Framework for Modelling and Programming.pdf:pdf},
isbn = {978-3-030-03417-7},
keywords = {Dependent types,Domain-specific languages,Functional programming,Software technology,Specification,dependent types,domain-specific languages,functional programming,software technology,specification},
pages = {119--133},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Type Theory as a Framework for Modelling and Programming}},
url = {http://link.springer.com/10.1007/978-3-030-03418-4{\_}8},
volume = {11244},
year = {2018}
}
@phdthesis{Stekelenburg2013,
abstract = {This is the author's Ph.D. Thesis. It contains results from four years of research into realizability and categorical logic. The main subjects are the axiomatisation of realizable propositions, and a characterization of realizability categories as pseudoinitial objects. Realizability is a collection of techniques in the study of constructive logic. Some forms of realizability induce realizability categories, which are Heyting categories and therefore have a first order intuitionistic logic as internal language. The axiomatisation chapter of the thesis explains how and to what extend we can axiomatise the set of valid propositions in this internal language. The realizability categories chapter explains how to find regular functors from realizability categories into other categories.},
archivePrefix = {arXiv},
arxivId = {1301.2134},
author = {Stekelenburg, Wouter Pieter},
eprint = {1301.2134},
file = {:Users/liang-tingchen/Dropbox/References/Stekelenburg - 2013 - Realizability Categories.pdf:pdf},
isbn = {9789039358962},
publisher = {Uitgeverij BOXPress},
school = {Utrecht University},
title = {{Realizability Categories}},
type = {Doctoral dissertation},
url = {http://arxiv.org/abs/1301.2134},
year = {2013}
}
@book{Lau2006,
abstract = {"This book gives a broad introduction to the theory of function algebras and leads to the cutting edge of research. To familiarize the reader from the very beginning on with the algebraic side of function algebras the more general concepts of the Universal Algebra is given in the first part of the book. The second part on function algebras covers the following topics: Galois-connection between function algebras and relation algebras, completeness criterions, clone theory."--Jacket.},
author = {Lau, Dietlinde.},
doi = {10.1007/3-540-36023-9},
file = {:Users/liang-tingchen/Dropbox/References/Lau - 2006 - Function Algebras on Finite Sets.pdf:pdf},
isbn = {978-3-540-36022-3},
issn = {1439-7382},
publisher = {Springer Berlin Heidelberg},
series = {Springer Monographs in Mathematics},
title = {{Function Algebras on Finite Sets}},
url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=371887 http://link.springer.com/10.1007/3-540-36023-9},
year = {2006}
}
@incollection{Filinski1999,
abstract = {We formally characterize partial evaluation of functional pro- grams as a normalization problem in an equational theory, and derive a type-based normalization-by-evaluation algorithm for computing normal forms in this setting. We then establish the correctness of this algorithm using a semantic argument based on Kripke logical relations. For simplic- ity, the results are stated for a non-strict, purely functional language; but the methods are directly applicable to stating and proving correctness of type-directed partial evaluation in ML-like languages as well.},
author = {Filinski, Andrzej},
booktitle = {Principles and Practice of Declarative Programming. PPDP 1999},
doi = {10.1007/10704567_23},
editor = {Nadathur, Gopalan},
file = {:Users/liang-tingchen/Dropbox/References/Filinski - 1999 - A Semantic Account of Type-Directed Partial Evaluation.pdf:pdf},
isbn = {3540665404},
issn = {16113349},
pages = {378--395},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Semantic Account of Type-Directed Partial Evaluation}},
url = {http://link.springer.com/10.1007/10704567{\_}23},
volume = {1702},
year = {1999}
}
@inproceedings{Abel2013b,
address = {New York, New York, USA},
author = {Abel, Andreas M. and Pientka, Brigitte and Thibodeau, David and Setzer, Anton},
booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '13},
doi = {10.1145/2429069.2429075},
file = {:Users/liang-tingchen/Dropbox/References/Abel et al. - 2013 - Copatterns.pdf:pdf},
isbn = {9781450318327},
keywords = {2008,by the graduiertenkol-,coinduction,elimination,functional programming,introduction,leg programm und modellanalyse,message passing,of the deutsche,pattern matching,puma,thibodeau acknowledges financial support,vs},
pages = {27},
publisher = {ACM Press},
title = {{Copatterns}},
url = {http://dl.acm.org/citation.cfm?doid=2429069.2429075},
year = {2013}
}
@article{Huttel2016,
abstract = {Behavioural type systems, usually associated to concurrent or distributed computations, encompass con- cepts such as interfaces, communication protocols, and contracts, in addition to the traditional input/output operations. The behavioural type of a software component specifies its expected patterns of interaction using expressive type languages, so types can be used to determine automatically whether the component interacts correctly with other components. Two related important notions of behavioural types are those of session types and behavioural contracts. This article surveys the main accomplishments of the last 20 years within these two approaches.},
author = {H{\"{u}}ttel, Hans and Tuosto, Emilio and Vieira, Hugo Torres and Zavattaro, Gianluigi and Lanese, Ivan and Vasconcelos, Vasco T. and Caires, Lu{\'{i}}s and Carbone, Marco and Deni{\'{e}}lou, Pierre-Malo and Mostrous, Dimitris and Padovani, Luca and Ravara, Ant{\'{o}}nio},
doi = {10.1145/2873052},
file = {:Users/liang-tingchen/Dropbox/References/H{\"{u}}ttel et al. - 2016 - Foundations of Session Types and Behavioural Contracts.pdf:pdf},
isbn = {13:978-1-292-02196-6},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {apr},
number = {1},
pages = {1--36},
title = {{Foundations of Session Types and Behavioural Contracts}},
url = {http://dl.acm.org/citation.cfm?doid=2911992.2873052},
volume = {49},
year = {2016}
}
@article{Gratzer2021,
abstract = {We introduce MTT, a dependent type theory which supports multiple modalities. MTT is parametrized by a mode theory which specifies a collection of modes, modalities, and transformations between them. We show that different choices of mode theory allow us to use the same type theory to compute and reason in many modal situations, including guarded recursion, axiomatic cohesion, and parametric quantification. We reproduce examples from prior work in guarded recursion and axiomatic cohesion, thereby demonstrating that MTT constitutes a simple and usable syntax whose instantiations intuitively correspond to previous handcrafted modal type theories. In some cases, instantiating MTT to a particular situation unearths a previously unknown type theory that improves upon prior systems. Finally, we investigate the metatheory of MTT. We prove the consistency of MTT and establish canonicity through an extension of recent type-theoretic gluing techniques. These results hold irrespective of the choice of mode theory, and thus apply to a wide variety of modal situations.},
author = {Gratzer, Daniel and Kavvos, G. A. and Nuyts, Andreas and Birkedal, Lars},
doi = {10.46298/lmcs-17(3:11)2021},
file = {:Users/liang-tingchen/Dropbox/References/Gratzer et al. - 2021 - Multimodal Dependent Type Theory.pdf:pdf},
issn = {1860-5974},
journal = {Logical Methods in Computer Science},
month = {jul},
number = {3},
pages = {1--11},
title = {{Multimodal Dependent Type Theory}},
url = {https://lmcs.episciences.org/7571},
volume = {Volume 17,},
year = {2021}
}
@book{Axler2006,
author = {Rautenberg, Wolfgang},
doi = {10.1007/0-387-34241-9},
file = {:Users/liang-tingchen/Dropbox/References/Rautenberg - 2006 - A Concise Introduction to Mathematical Logic.pdf:pdf},
isbn = {978-0-387-30294-2},
publisher = {Springer New York},
series = {Universitext},
title = {{A Concise Introduction to Mathematical Logic}},
url = {http://link.springer.com/10.1007/0-387-34241-9},
year = {2006}
}
@incollection{Bezhanishvili2007a,
abstract = {In this paper we discuss a uniform method for constructing free modal and distributive modal algebras. This method draws on works by (Abramsky 2005) and (Ghilardi 1995). We revisit the theory of normal forms for modal logic and derive a normal form representation for positive modal logic. We also show that every finitely generated free modal and distributive modal algebra axiomatised by equations of rank 1 is a reduct of a temporal algebra.},
author = {Bezhanishvili, Nick and Kurz, Alexander},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-540-73859-6_10},
editor = {Mossakowski, Till and Montanari, Ugo and Haveraaen, Magne},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili, Kurz - 2007 - Free modal algebras A coalgebraic perspective.pdf:pdf},
pages = {143--157},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Free modal algebras: A coalgebraic perspective}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/978-3-540-73859-6{\_}10},
volume = {4624},
year = {2007}
}
@incollection{Alvim2011,
author = {Alvim, M{\'{a}}rio S. and Andr{\'{e}}s, Miguel E. and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
booktitle = {Foundations of Security Analysis and Design VI. FOSAD 2011},
doi = {10.1007/978-3-642-23082-0_8},
editor = {Aldini, Alessandro and Gorrieri, Roberto},
file = {:Users/liang-tingchen/Dropbox/References/Alvim et al. - 2011 - Quantitative Information Flow and Applications to Differential Privacy.pdf:pdf},
isbn = {978-3-642-23081-3},
pages = {211--230},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Quantitative Information Flow and Applications to Differential Privacy}},
url = {http://link.springer.com/10.1007/978-3-642-23082-0{\_}8},
volume = {6858},
year = {2011}
}
@article{Reus1999,
abstract = {This tutorial aims at giving an account on the realizability models for several constructive type theories. These range from simply typed $\lambda$-calculus over second-order polymorphic $\lambda$-calculus to the Calculus of Constructions as an example of dependent type theory. The models are made from partial equivalence relations (pers) and realizability sets over an arbitrary partial combinatory algebra. Realizability semantics does not only provide intuitive models but can also be used for proving independence results of type theories. Finally, by considering complete extensional pers, an approach to bridge the gap from type theory to constructive domain theory is discussed. {\textcopyright} 1999 Published by Elsevier B.V.},
author = {Reus, Bernhard},
doi = {10.1016/S1571-0661(04)00108-2},
file = {:Users/liang-tingchen/Dropbox/References/Reus - 1999 - Realizability Models for Type Theories.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {1},
pages = {128--158},
title = {{Realizability Models for Type Theories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066104001082},
volume = {23},
year = {1999}
}
@inproceedings{Kapulkin2012,
annote = {
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:bold{\textgreater}From Duplicate 1 ( {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:bold{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:italic{\textgreater}Expressiveness of Positive Coalgebraic Logic{\textless}/m:italic{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:bold{\textgreater} - Kapulkin, Krzysztof; Kurz, Alexander; Velebil, Jiř{\'{i}} ){\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Kapulkin, Krzysztof and Kurz, Alexander and Velebil, Jiř{\'{i}}},
booktitle = {Advances in Modal Logic},
file = {:Users/liang-tingchen/Dropbox/References/Kapulkin, Kurz, Velebil - 2012 - Expressiveness of positive coalgebraic logic.pdf:pdf},
keywords = {coalgebra,modal logic,poset},
pages = {368--385},
title = {{Expressiveness of positive coalgebraic logic}},
year = {2012}
}
@article{Zhang2016,
abstract = {We study how to communicate findings of Bayesian inference to third parties, while preserving the strong guarantee of differential privacy. Our main contributions are four different algorithms for private Bayesian inference on proba-bilistic graphical models. These include two mechanisms for adding noise to the Bayesian updates, either directly to the posterior parameters, or to their Fourier transform so as to preserve update consistency. We also utilise a recently introduced posterior sampling mechanism, for which we prove bounds for the specific but general case of discrete Bayesian networks; and we introduce a maximum-a-posteriori private mechanism. Our analysis includes utility and privacy bounds, with a novel focus on the influence of graph structure on privacy. Worked examples and experiments with Bayesian na{\{}$\backslash$"i{\}}ve Bayes and Bayesian linear regression illustrate the application of our mechanisms.},
archivePrefix = {arXiv},
arxivId = {1512.06992},
author = {Zhang, Zuhe and Rubinstein, Benjamin and Dimitrakakis, Christos},
eprint = {1512.06992},
file = {:Users/liang-tingchen/Dropbox/References/Zhang, Rubinstein, Dimitrakakis - 2016 - On the Differential Privacy of Bayesian Inference.pdf:pdf},
isbn = {9781577357605},
journal = {Proceedings of the 30th Conference on Artificial Intelligence (AAAI 2016)},
keywords = {Technical Papers: Machine Learning Methods},
pages = {1--23},
title = {{On the Differential Privacy of Bayesian Inference}},
url = {http://arxiv.org/abs/1512.06992},
year = {2016}
}
@article{Gabbay1998,
author = {Gabbay, Dov and Shehtman, Valentin},
doi = {10.1093/jigpal/6.1.73},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Shehtman - 1998 - Products of modal logics, part 1.pdf:pdf},
issn = {1367-0751},
journal = {Logic Journal of IGPL},
month = {jan},
number = {1},
pages = {73--146},
title = {{Products of modal logics, part 1}},
url = {http://jigpal.oupjournals.org/cgi/doi/10.1093/jigpal/6.1.73},
volume = {6},
year = {1998}
}
@inproceedings{Ahrens2019,
author = {Ahrens, Benedikt and Maggesi, Marco and {Ambroise Lafont} and Maggesi, Marco},
booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
doi = {10.4230/LIPIcs.FSCD.2019.6},
editor = {Geuvers, Herman},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2019 - Modular Specification of Monads Through Higher-Order Presentations.pdf:pdf},
keywords = {2019,4230,6,and phrases free monads,computer-checked proofs,digital object identifier 10,fscd,github,https,initial semantics,lipics,monadic substitution,presentation of monads,signatures,supplement material computer-checked proofs,syntax,with compilation instructions on},
pages = {6:1--6:19},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Modular Specification of Monads Through Higher-Order Presentations}},
url = {http://drops.dagstuhl.de/opus/volltexte/2019/10513/},
volume = {131},
year = {2019}
}
@incollection{Kupke2009,
author = {Kupke, Clemens and Leal, Raul Andres},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-03741-2_8},
editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Leal - 2009 - Characterising Behavioural Equivalence Three Sides of One Coin.pdf:pdf},
isbn = {978-3-642-03740-5},
pages = {97--112},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Characterising Behavioural Equivalence: Three Sides of One Coin}},
url = {http://link.springer.com/10.1007/978-3-642-03741-2{\_}8},
year = {2009}
}
@article{Velebil2011,
author = {Velebil, Jiř{\'{i}} and Kurz, Alexander},
doi = {10.1017/S0960129510000575},
file = {:Users/liang-tingchen/Dropbox/References/Velebil, Kurz - 2011 - Equational presentations of functors and monads.pdf:pdf},
isbn = {0960129510},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {02},
pages = {363--381},
title = {{Equational presentations of functors and monads}},
type = {Journal article},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129510000575 http://dx.doi.org/10.1017/S0960129510000575},
volume = {21},
year = {2011}
}
@incollection{Damgard2007,
abstract = {In this paper, we identify some issues in the interplay between practice and theory in cryptography, issues that have repeatedly appeared in different incarnations over the years. These issues are related to fundamental concepts in the field, e.g., to what extent we can prove that a system is secure and what theoretic results on security mean for practical applications. We argue that several such issues are often overlooked or misunderstood, and that it may be very productive if both theoreticians and practitioners think more consciously about these issues and act accordingly.},
address = {Berlin, Heidelberg},
author = {Damg{\aa}rd, Ivan},
booktitle = {Automata, Languages and Programming},
doi = {10.1007/978-3-540-73420-8_2},
file = {:Users/liang-tingchen/Dropbox/References/Damg{\aa}rd - 2007 - A “proof-reading” of some issues in cryptography.pdf:pdf},
isbn = {978-3-540-73419-2, 978-3-540-73420-8},
issn = {03029743},
pages = {2--11},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A “proof-reading” of some issues in cryptography}},
url = {http://link.springer.com/10.1007/978-3-540-73420-8{\_}2},
volume = {4596},
year = {2007}
}
@article{Cirstea2011,
abstract = {This paper gives a general coalgebraic account of temporal logics whose semantics involves a notion of computation path. Examples of such logics include the logic CTL* for transition systems and the logic PCTL for probabilistic transition systems. Our path-based temporal logics are interpreted over coalgebras of endofunctors obtained as the composition of a computation type (e.g. non-deterministic or stochastic) with a general transition type. The semantics of such logics relies on the existence of execution maps similar to the trace maps introduced by Jacobs and co-authors as part of the coalgebraic theory of finite traces (Hasuo et al., 2007 [1]). We consider finite execution maps derived from the theory of finite traces, and a new notion of maximal execution map that accounts for maximal, possibly infinite executions. The latter is needed to recover the logics CTL* and PCTL as specific path-based logics. ?? 2011 Elsevier B.V. All rights reserved.},
author = {C{\^{i}}rstea, Corina},
doi = {10.1016/j.tcs.2011.04.025},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2011 - Maximal traces and path-based coalgebraic temporal logics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Coalgebra,Computation path,Non-determinism,Probability,Temporal logic,Trace semantics},
month = {sep},
number = {38},
pages = {5025--5042},
publisher = {Elsevier B.V.},
title = {{Maximal traces and path-based coalgebraic temporal logics}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.04.025 http://linkinghub.elsevier.com/retrieve/pii/S0304397511003239},
volume = {412},
year = {2011}
}
@incollection{Matsubara2009,
author = {Czarnetzki, Silke and Krebs, Andreas},
booktitle = {Proceedings of the 10th International Conference on Language and Automata Theory and Applications},
doi = {10.1007/978-3-319-30000-9_22},
editor = {Truthe, Adrian-Horia Dediu and Janou{\v{s}}ek, Jan and Mart{\'{i}}n-Vide, Carlos and Truthe, Bianca},
file = {:Users/liang-tingchen/Dropbox/References/Czarnetzki, Krebs - 2016 - Using Duality in Circuit Complexity.pdf:pdf},
isbn = {978-3-642-00981-5},
pages = {283--294},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Using Duality in Circuit Complexity}},
url = {http://dblp.uni-trier.de/db/conf/lata/lata2009.html{\#}MatsubaraKBS09 http://link.springer.com/10.1007/978-3-319-30000-9{\_}22},
volume = {5457},
year = {2016}
}
@incollection{Brodal2006,
abstract = {We present a purely functional implementation of search trees that$\backslash$nrequires O(log n) time for search and update operations and supports$\backslash$nthe join of two trees in worst case constant time. Hence, we solve an$\backslash$nopen problem posed by Kaplan and Tarjan as to whether it is possible to$\backslash$nenvisage a data structure supporting simultaneously the join operation$\backslash$nin O(1) time and the search and update operations in O(log n) time.},
author = {Brodal, Gerth St{\o}lting and Makris, Christos and Tsichlas, Kostas},
booktitle = {Algorithms – ESA 2006},
doi = {10.1007/11841036_18},
editor = {Azar, Yossi and Erlebach, Thomas},
file = {:Users/liang-tingchen/Dropbox/References/Brodal, Makris, Tsichlas - 2006 - Purely Functional Worst Case Constant Time Catenable Sorted Lists.pdf:pdf},
isbn = {0897917855},
issn = {03029743},
keywords = {data structures,purely functional programming,sorted lists},
pages = {172--183},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Purely Functional Worst Case Constant Time Catenable Sorted Lists}},
url = {http://link.springer.com/10.1007/11841036{\_}18},
volume = {4168},
year = {2006}
}
@book{Borceux1994a,
author = {Borceux, Francis},
pages = {364},
publisher = {Cambridge University Press},
series = {Encyclopedia of Mathematics and its Applications},
title = {{Handbook of Categorical Algebra 2: Categories and Structures}},
year = {1994}
}
@article{Esik2015,
author = {{\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1093/logcom/ext001},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 2015 - Residuated Park theories.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Least fixed points,equational theory,iteration theory,residuals},
month = {apr},
number = {2},
pages = {453--471},
title = {{Residuated Park theories}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/ext001},
volume = {25},
year = {2015}
}
@inproceedings{LeFevre2006,
abstract = {K-Anonymity has been proposed as a mechanism for protecting privacy in microdata publishing, and numerous recoding "models" have been considered for achieving {\{}{\&}{\}}{\{}{\#}{\}}55349;{\{}{\&}{\}}{\{}{\#}{\}}56408;anonymity. This paper proposes a new multidimensional model, which provides an additional degree of flexibility not seen in previous (single-dimensional) approaches. Often this flexibility leads to higher-quality anonymizations, as measured both by general-purpose metrics and more specific notions of query answerability. Optimal multidimensional anonymization is NP-hard (like previous optimal {\{}{\&}{\}}{\{}{\#}{\}}55349;{\{}{\&}{\}}{\{}{\#}{\}}56408;-anonymity problems). However, we introduce a simple greedy approximation algorithm, and experimental results show that this greedy algorithm frequently leads to more desirable anonymizations than exhaustive optimal algorithms for two single-dimensional models.},
author = {LeFevre, Kristen and DeWitt, D.J. and Ramakrishnan, Raghu},
booktitle = {22nd International Conference on Data Engineering (ICDE'06)},
doi = {10.1109/ICDE.2006.101},
file = {:Users/liang-tingchen/Dropbox/References/LeFevre, DeWitt, Ramakrishnan - 2006 - Mondrian Multidimensional K-Anonymity.pdf:pdf},
isbn = {0-7695-2570-9},
issn = {10844627},
pages = {25--25},
publisher = {IEEE},
title = {{Mondrian Multidimensional K-Anonymity}},
url = {http://ieeexplore.ieee.org/document/1617393/},
volume = {2006},
year = {2006}
}
@article{Plotkin2001a,
author = {Plotkin, Gordon D. and Power, A. John},
doi = {10.1016/S1571-0661(04)80970-8},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Power - 2001 - Semantics for algebraic operations.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {nov},
pages = {332--345},
title = {{Semantics for algebraic operations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104809708},
volume = {45},
year = {2001}
}
@article{Adamek2014b,
abstract = {An algebra is called corecursive if from every coalgebra a unique coalgebra-to-algebra homomorphism exists into it. We prove that free corecursive algebras are obtained as coproducts of the terminal coalgebra (considered as an algebra) and free algebras. The monad of free corecursive algebras is proved to be the free corecursive monad, where the concept of corecursive monad is a generalization of Elgot's iterative monads, analogous to corecursive algebras generalizing completely iterative algebras. We also characterize the Eilenberg-Moore algebras for the free corecursive monad and call them Bloom algebras.},
archivePrefix = {arXiv},
arxivId = {1407.4425},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Haddadi, Mahdie and Milius, Stefan},
doi = {10.2168/LMCS-10(3:19)2014},
eprint = {1407.4425},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Haddadi, Milius - 2014 - Corecursive algebras, corecursive monads and Bloom monads.pdf:pdf},
journal = {Logical Methods in Computer Science},
month = {jul},
number = {3:19},
pages = {1--51},
title = {{Corecursive algebras, corecursive monads and Bloom monads}},
url = {http://arxiv.org/abs/1407.4425},
volume = {10},
year = {2014}
}
@article{Prakken1996,
author = {Prakken, Henry},
doi = {10.1007/BF00370670},
file = {:Users/liang-tingchen/Dropbox/References/Prakken - 1996 - Two approaches to the formalisation of defeasible deontic reasoning.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {Defeasible reasoning,Deontic reasoning,Moral dilemmas},
month = {jul},
number = {1},
pages = {73--90},
title = {{Two approaches to the formalisation of defeasible deontic reasoning}},
url = {http://link.springer.com/10.1007/BF00370670},
volume = {57},
year = {1996}
}
@article{Abel2005,
address = {New York, New York, USA},
author = {Abel, Andreas M. and Benke, Marcin and Bove, Ana and Hughes, John and Norell, Ulf},
doi = {10.1145/1088348.1088355},
file = {:Users/liang-tingchen/Dropbox/References/Abel et al. - 2005 - Verifying haskell programs using constructive type theory.pdf:pdf},
isbn = {159593071X},
journal = {Proceedings of the 2005 ACM SIGPLAN workshop on Haskell - Haskell '05},
keywords = {ghc core,haskell,monadic transla-,partiality,tion,type theory,verification},
pages = {62--73},
publisher = {ACM Press},
title = {{Verifying haskell programs using constructive type theory}},
url = {http://portal.acm.org/citation.cfm?doid=1088348.1088355},
year = {2005}
}
@article{Litak2016,
abstract = {Relational lattices are obtained by interpreting lattice connectives as natural join and inner union between database relations. Our study of their equational theory reveals that the variety generated by relational lattices has not been discussed in the existing literature. Furthermore, we show that addition of just the header constant to the lattice signature leads to undecidability of the quasiequational theory. Nevertheless, we also demonstrate that relational lattices are not as intangible as one may fear: for example, they do form a pseudoelementary class. We also apply the tools of Formal Concept Analysis and investigate the structure of relational lattices via their standard contexts. Furthermore, we show that the addition of typing rules and singleton constants allows a direct comparison with monotonic relational expressions of Sagiv and Yannakakis.},
author = {Litak, Tadeusz and Mikul{\'{a}}s, Szabolcs and Hidders, Jan},
doi = {10.1016/j.jlamp.2015.11.008},
file = {:Users/liang-tingchen/Dropbox/References/Litak, Mikul{\'{a}}s, Hidders - 2016 - Relational lattices From databases to universal algebra.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
keywords = {1,34,38,39,algebraic logic,attention of algebraists,by vadim tropashko,connections,database theory,even those investigating the,introduction and motivation,it does not seem,lattice theory,natural database interpretation proposed,of lattices with a,relational algebra,relational lattices,to have attracted the,we study a class},
month = {jun},
number = {4},
pages = {540--573},
publisher = {Elsevier Inc.},
title = {{Relational lattices: From databases to universal algebra}},
url = {http://dx.doi.org/10.1016/j.jlamp.2015.11.008 http://linkinghub.elsevier.com/retrieve/pii/S2352220815001455},
volume = {85},
year = {2016}
}
@article{VanHorn2017,
abstract = {We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox's Theorem and its variants. As with Cox's Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the “possible cases.”},
archivePrefix = {arXiv},
arxivId = {1706.05261},
author = {{Van Horn}, Kevin S.},
doi = {10.1016/j.ijar.2017.06.003},
eprint = {1706.05261},
file = {:Users/liang-tingchen/Dropbox/References/Van Horn - 2017 - From propositional logic to plausible reasoning A uniqueness theorem.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Bayesian,Carnap,Cox,Jaynes,Logic,Probability},
pages = {309--332},
publisher = {Elsevier Inc.},
title = {{From propositional logic to plausible reasoning: A uniqueness theorem}},
url = {http://dx.doi.org/10.1016/j.ijar.2017.06.003},
volume = {88},
year = {2017}
}
@incollection{Beklemishev2006,
abstract = {In the first part of the paper we discuss some conceptual problems related to the notion of proof.$\backslash$nIn the second part we survey five major open problems in Provability Logic$\backslash$nas well as possible directions for future research in this area.},
address = {New York},
author = {Beklemishev, Lev and Visser, Albert},
booktitle = {Mathematical Problems from Applied Logic I},
doi = {10.1007/0-387-31072-X_2},
file = {:Users/liang-tingchen/Dropbox/References/Beklemishev, Visser - 2006 - Problems in the Logic of Provability.pdf:pdf},
pages = {77--136},
publisher = {Springer-Verlag},
title = {{Problems in the Logic of Provability}},
url = {http://link.springer.com/10.1007/0-387-31072-X{\_}2},
year = {2006}
}
@book{Lloyd1987,
address = {New York, NY, USA},
author = {Lloyd, John W.},
edition = {2},
isbn = {0387181997},
publisher = {Springer},
title = {{Foundations of Logic Programming}},
year = {1987}
}
@book{Lamport2002,
author = {Lamport, Leslie},
edition = {1},
file = {:Users/liang-tingchen/Dropbox/References/Lamport - 2002 - Specifying Systems The TLA Language and Tools for Hardware and Software Engineers.pdf:pdf},
isbn = {032114306X},
pages = {384},
publisher = {Addison-Wesley Professional},
title = {{Specifying Systems: The TLA+ Language and Tools for Hardware and Software Engineers}},
year = {2002}
}
@inproceedings{Simpson2007,
author = {M{\o}gelberg, Rasmus Ejlers and Simpson, Alex},
booktitle = {22nd Annual IEEE Symposium on Logic in Computer Science (LICS 2007)},
doi = {10.1109/LICS.2007.40},
file = {:Users/liang-tingchen/Dropbox/References/M{\o}gelberg, Simpson - 2007 - Relational Parametricity for Computational Effects.pdf:pdf},
isbn = {0-7695-2908-9},
month = {jul},
number = {December},
pages = {346--355},
publisher = {IEEE},
title = {{Relational Parametricity for Computational Effects}},
url = {http://ieeexplore.ieee.org/document/4276578/},
year = {2007}
}
@article{Ohearn1995,
author = {O'Hearn, Peter W. and Riecke, Jon G.},
doi = {10.1006/inco.1995.1103},
file = {:Users/liang-tingchen/Dropbox/References/O'Hearn, Riecke - 1995 - Kripke Logical Relations and PCF.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {jul},
number = {1},
pages = {107--116},
title = {{Kripke Logical Relations and PCF}},
url = {http://dl.acm.org/citation.cfm?id=208753.208764},
volume = {120},
year = {1995}
}
@article{Bezhanishvili2012,
abstract = {We introduce modal compact Hausdor spaces as generalizations of modal spaces, and show these are coalgebras for the Vietoris functor on compact Hausdor spaces. Modal compact regular frames and modal de Vries algebras are introduced as algebraic counterparts of modal compact Hausdor spaces, and dualities are given for the categories involved. These extend the familiar Isbell and de Vries dualities for compact Hausdor spaces, as well as the duality between modal spaces and modal algebras. As the first step in the logical treatment of modal compact Hausdor spaces, a version of Sahlqvist correspondence is given for the positive modal language.},
author = {Bezhanishvili, Guram and Bezhanishvili, Nick and Harding, John},
doi = {10.1093/logcom/exs030},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili, Bezhanishvili, Harding - 2012 - Modal compact Hausdorff spaces.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {compact hausdorff space,de vries duality,modal algebra,vietoris space},
month = {jul},
title = {{Modal compact Hausdorff spaces}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exs030},
year = {2012}
}
@article{Rivieccio2017,
abstract = {We introduce a family of modal expansions of Belnap-Dunn four-valued logic and related systems, and interpret them in many-valued Kripke structures. Using algebraic logic techniques and topological duality for modal algebras, and generalizing the so-called twist-structure representation, we axiomatize by means of Hilbert-style calculi the least modal logic over the four-element Belnap lattice and some of its axiomatic extensions. We study the algebraic models of these systems, relating them to the algebraic semantics of classical multi-modal logic. This link allows us to prove that both local and global consequence of the least four-valued modal logic enjoy the finite model property and are therefore decidable.},
author = {Rivieccio, Umberto and Jung, Achim and Jansana, Ramon},
doi = {10.1093/logcom/exv038},
file = {:Users/liang-tingchen/Dropbox/References/Rivieccio, Jung, Jansana - 2017 - Four-valued modal logic Kripke semantics and duality.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Belnap logic,Bilattices,Many-valued modal logic,Paraconsistent Nelson logic},
month = {feb},
number = {1},
pages = {155--199},
title = {{Four-valued modal logic: Kripke semantics and duality}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exv038},
volume = {27},
year = {2017}
}
@inproceedings{Adamek2012,
abstract = {Coalgebra offers a unified theory of state based systems, including infinite streams, labelled transition systems and deterministic automata. In this paper, we use the coalgebraic view on systems to derive, in a uniform way, abstract procedures for checking behavioural equivalence in coalgebras, which perform (a combination of) minimization and determinization. First, we show that for coalgebras in categories equipped with factorization structures , there exists an abstract procedure for equivalence checking. Then, we consider coalgebras in categories without suitable factorization structures: under certain conditions, it is possible to apply the above procedure after transforming coalgebras with reflections . This transformation can be thought of as some kind of determinization. We will apply our theory to the following examples: conditional transition systems and (non-deterministic) automata.},
annote = {From Duplicate 1 ( 




















A Coalgebraic Perspective on Minimization and Determinization




















- Ad{\'{a}}mek, Jiř{\'{i}}; Bonchi, Filippo; H{\"{u}}lsbusch, Mathias; K{\"{o}}nig, Barbara; Milius, Stefan; Silva, Alexandra )






































From Duplicate 2 ( 




















A Coalgebraic Perspective on Minimization and Determinization




















- Ad{\'{a}}mek, Jiř{\'{i}}; Bonchi, Filippo; H{\"{u}}lsbusch, Mathias; K{\"{o}}nig, Barbara; Milius, Stefan; Silva, Alexandra )















10.1007/978-3-642-28729-9{\_}4},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Bonchi, Filippo and H{\"{u}}lsbusch, Mathias and K{\"{o}}nig, Barbara and Milius, Stefan and Silva, Alexandra},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-642-28729-9_4},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2012 - A coalgebraic perspective on minimization and determinization.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {58--73},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A coalgebraic perspective on minimization and determinization}},
type = {Conference proceedings (article)},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}4},
volume = {7213},
year = {2012}
}
@article{Ahrens2011,
author = {Ahrens, Benedikt and Zsido, Julianna},
doi = {10.6092/issn.1972-5787/2066},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Zsido - 2011 - Initial Semantics for higher-order typed syntax in Coq.pdf:pdf},
journal = {Journal of Formalized Reasoning},
number = {1},
pages = {25--69},
title = {{Initial Semantics for higher-order typed syntax in Coq}},
url = {https://jfr.unibo.it/article/view/2066},
volume = {4},
year = {2011}
}
@article{Cheng2006,
abstract = {We give a precise description of combed trees in terms of Kelly-Mac Lane graphs. We show that any combed tree is uniquely expressed as an allowable Kelly-Mac Lane graph of a certain shape. Conversely, we show that any such Kelly-Mac Lane graph uniquely defines a combed tree.},
archivePrefix = {arXiv},
arxivId = {math/0304287},
author = {CHENG, EUGENIA},
doi = {10.1017/S0305004105009060},
eprint = {0304287},
file = {:Users/liang-tingchen/Dropbox/References/CHENG - 2006 - A relationship between trees and Kelly–Mac Lane graphs.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {jul},
number = {01},
pages = {33},
primaryClass = {math},
title = {{A relationship between trees and Kelly–Mac Lane graphs}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004105009060},
volume = {141},
year = {2006}
}
@article{Plotkin2013,
abstract = {TheBayesianapproachtomachinelearningamountstoinferringpos- terior distributions of random variables from a probabilistic model of how the variables are related (that is, a prior distribution) and a set of observations of variables. There is a trend in machine learning towards expressing Bayesian models as probabilistic programs. As a foundation for this kind of programming, we pro- pose a core functional calculus with primitives for sampling prior distributions and observing variables. We define combinators for measure transformers, based on theorems in measure theory, and use these to give a rigorous semantics to our core calculus. The original features of our semantics include its support for discrete, continuous, and hybrid measures, and, in particular, for observations of zero-probability events. We compile our core language to a small imperative lan- guage that has a straightforward semantics via factor graphs, data structures that enable many efficient inference algorithms. We use an existing inference engine for efficient approximate inference of posterior marginal distributions, treating thousands of observations per second for large instances of realistic models.},
archivePrefix = {arXiv},
arxivId = {1310.7417},
author = {Plotkin, Gordon D. and Pretnar, Matija},
doi = {10.2168/LMCS-9(4:23)2013},
editor = {Tarlecki, Andrzej},
eprint = {1310.7417},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Pretnar - 2013 - Handling algebraic effects.pdf:pdf},
isbn = {978-3-642-19717-8},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {()},
month = {dec},
number = {4},
pages = {77--96},
title = {{Handling algebraic effects}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-19718-5{\_}5{\%}5Cnfile:///Users/jobo/Library/Application Support/Papers2/Articles/Borgstr�m/2011/2011 Borgstr�m-2.pdf{\%}5Cnpapers2://publication/doi/10.1007/978-3-642-19718-5{\_}5 http://www.lmcs-online.org/ojs/viewar},
volume = {9},
year = {2013}
}
@article{Ko2017,
abstract = {Dependently typed programming advocates the use of various indexed versions of the same shape of data, but the formal relationship amongst these structurally similar datatypes usually needs to be established manually and tediously. Ornaments have been proposed as a formal mechanism to manage the relationships between such datatype variants. In this paper, we conduct a case study under an ornament framework; the case study concerns programming binomial heaps and their operations — including insertion and minimum extraction — by viewing them as lifted versions of binary numbers and numeric operations. We show how current dependently typed programming technology can lead to a clean treatment of the binomial heap constraints when implementing heap operations. We also identify some gaps between the current technology and an ideal dependently typed programming language that we would wish to have for our development.},
author = {Ko, Hsiang-Shang and Gibbons, Jeremy},
doi = {10.1017/S0956796816000307},
file = {:Users/liang-tingchen/Dropbox/References/Ko, Gibbons - 2016 - Programming with ornaments.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {dec},
pages = {e2},
title = {{Programming with ornaments}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796816000307},
volume = {27},
year = {2016}
}
@phdthesis{Ghiorzi2019,
author = {Ghiorzi, Enrico},
file = {:Users/liang-tingchen/Dropbox/References/Ghiorzi - 2019 - Internal Enriched Categories.pdf:pdf},
keywords = {category theory,enriched categories},
school = {University of Cambridge},
title = {{Internal Enriched Categories}},
type = {Doctoral dissertation},
year = {2019}
}
@inproceedings{Sulzmann2007a,
abstract = {We introduce System FC, which extends System F with support for non-syntactic type equality. There are two main extensions: (i) explicit witnesses for type equalities, and (ii) open, non-parametric type functions, given meaning by top-level equality axioms. Unlike System F, FC is expressive enough to serve as a target for several different source-language features, including Haskell's newtype, generalised algebraic data types, associated types, functional dependencies, and perhaps more besides.},
address = {New York, New York, USA},
author = {Sulzmann, Martin and Chakravarty, Manuel M. T. and Jones, Simon Peyton and Donnelly, Kevin},
booktitle = {Proceedings of the 2007 ACM SIGPLAN international workshop on Types in languages design and implementation - TLDI '07},
doi = {10.1145/1190315.1190324},
file = {:Users/liang-tingchen/Dropbox/References/Sulzmann et al. - 2007 - System F with type equality coercions.pdf:pdf},
isbn = {159593393X},
pages = {53},
publisher = {ACM Press},
title = {{System F with type equality coercions}},
url = {http://portal.acm.org/citation.cfm?doid=1190315.1190324},
year = {2007}
}
@article{Komendantskaya1987,
abstract = {Logic programming (LP) is a programming language based on first-order Horn clause logic that uses SLD-resolution as a semi-decision procedure. Finite SLD-computations are inductively sound and complete with respect to least Herbrand models of logic programs. Dually, the corecursive approach to SLD-resolution views infinite SLD-computations as successively approximating infinite terms contained in programs' greatest complete Herbrand models. State-of-the-art algorithms implementing corecursion in LP are based on loop detection. However, such algorithms support inference of logical entailment only for rational terms, and they do not account for the important property of productivity in infinite SLD-computations. Loop detection thus lags behind coinductive methods in interactive theorem proving (ITP) and term-rewriting systems (TRS). Structural resolution is a newly proposed alternative to SLD-resolution that makes it possible to define and semi-decide a notion of productivity appropriate to LP. In this paper, we prove soundness of structural resolution relative to Herbrand model semantics for productive inductive, coinductive, and mixed inductive-coinductive logic programs. We introduce two algorithms that support coinductive proof search for infinite productive terms. One algorithm combines the method of loop detection with productive structural resolution, thus guaranteeing productivity of coinductive proofs for infinite rational terms. The other allows to make lazy sound observations of fragments of infinite irrational productive terms. This puts coinductive methods in LP on par with productivity-based observational approaches to coinduction in ITP and TRS.},
archivePrefix = {arXiv},
arxivId = {1511.07865},
author = {Komendantskaya, Ekaterina and Johann, Patricia and Schmidt, Martin},
eprint = {1511.07865},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Johann, Schmidt - 2015 - Structural Resolution a Framework for Coinductive Proof Search and Proof Construction in Horn C.pdf:pdf},
month = {nov},
number = {212},
pages = {1--26},
title = {{Structural Resolution: a Framework for Coinductive Proof Search and Proof Construction in Horn Clause Logic}},
url = {http://arxiv.org/abs/1511.07865},
volume = {V},
year = {2015}
}
@article{Gabbay2012,
author = {Gabbay, Murdoch J. and Ghica, Dan R.},
doi = {10.1016/j.entcs.2012.08.012},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Ghica - 2012 - Game semantics in the nominal model.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {equivariance,game semantics,nominal abstraction and coabstraction,nominal sets},
month = {sep},
pages = {173--189},
title = {{Game semantics in the nominal model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066112000424},
volume = {286},
year = {2012}
}
@article{Lee2007,
author = {Lee, Daniel K. and Crary, Karl and Harper, Robert},
doi = {10.1145/1190215.1190245},
file = {:Users/liang-tingchen/Dropbox/References/Lee, Crary, Harper - 2007 - Towards a mechanized metatheory of standard ML.pdf:pdf},
isbn = {1595935754},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {anized metatheory,language definitions,logical frameworks,mech-,standard ml,twelf,type safety},
month = {jan},
number = {1},
pages = {173},
title = {{Towards a mechanized metatheory of standard ML}},
url = {http://portal.acm.org/citation.cfm?doid=1190215.1190245},
volume = {42},
year = {2007}
}
@inproceedings{Lindley2016,
address = {New York, New York, USA},
author = {Lindley, Sam and Morris, J Garrett},
booktitle = {Proceedings of the 9th International Symposium on Haskell - Haskell 2016},
doi = {10.1145/2976002.2976018},
file = {:Users/liang-tingchen/Dropbox/References/Lindley, Morris - 2016 - Embedding session types in Haskell.pdf:pdf},
isbn = {9781450344340},
keywords = {embedded languages,linear types,session types},
pages = {133--145},
publisher = {ACM Press},
title = {{Embedding session types in Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=2976002.2976018},
year = {2016}
}
@article{Isbell1972,
author = {Isbell, John R.},
file = {:Users/liang-tingchen/Dropbox/References/Isbell - 1972 - General Functorial Semantics, I.pdf:pdf},
journal = {American Journal of Mathematics},
number = {2},
pages = {535--596},
title = {{General Functorial Semantics, I}},
url = {http://www.jstor.org/stable/2374638},
volume = {94},
year = {1972}
}
@article{Longley1999,
abstract = {Realizability interpretations of logics are given by saying what it means for computational objects of some kind to realize logical formulae. The computational objects in question might be drawn from an untyped universe of computation, such as a partial combinatory algebra, or they might be typed objects such as terms of a PCF-style programming language. In some instances, one can show that a particular untyped realizability interpretation matches a particular typed one, in the sense that they give the same set of realizable formulae. In this case, we have a very good fit indeed between the typed language and the untyped realizability model - we refer to this condition as (constructive) logical full abstraction. We give some examples of this situation for a variety of extensions of PCF. Of particular interest are some models that are logically fully abstract for typed languages including non-functional features. Our results establish connections between what is computable in various programming languages and what is true inside various realizability toposes. We consider some examples of logical formulae to illustrate these ideas, in particular their application to exact real-number computability. {\textcopyright} 1999 Published by Elsevier B.V.},
author = {Longley, John},
doi = {10.1016/S1571-0661(04)00105-7},
file = {:Users/liang-tingchen/Dropbox/References/Longley - 1999 - Matching typed and untyped realizability.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {1},
pages = {74--100},
title = {{Matching typed and untyped realizability}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066104001057},
volume = {23},
year = {1999}
}
@phdthesis{Holohan2016,
author = {Holohan, Naoise},
file = {:Users/liang-tingchen/Dropbox/References/Holohan - 2016 - Mathematical Foundations of Differential Privacy.pdf:pdf},
school = {Trinity College Dublin},
title = {{Mathematical Foundations of Differential Privacy}},
year = {2016}
}
@article{Domingo-Ferrer2018,
abstract = {We explore some novel connections between the main privacy models in use and we recall a few known ones. We show these models to be more related than commonly understood, around two main principles: deniability and permutation. In particular, randomized response turns out to be very modern in spite of it having been introduced over 50 years ago: it is a local anonymization method and it allows understanding the protection offered by {\$}\backslashepsilon{\$}-differential privacy when {\$}\backslashepsilon{\$} is increased to improve utility. A similar understanding on the effect of large {\$}\backslashepsilon{\$} in terms of deniability is obtained from the connection between {\$}\backslashepsilon{\$}-differential privacy and t-closeness. Finally, the post-randomization method (PRAM) is shown to be viewable as permutation and to be connected with randomized response and differential privacy. Since the latter is also connected with t-closeness, it follows that the permutation principle can explain the guarantees offered by all those models. Thus, calibrating permutation is very relevant in anonymization, and we conclude by sketching two ways of doing it.},
archivePrefix = {arXiv},
arxivId = {1803.02139},
author = {Domingo-Ferrer, Josep and Soria-Comas, Jordi},
eprint = {1803.02139},
file = {:Users/liang-tingchen/Dropbox/References/Domingo-Ferrer, Soria-Comas - 2018 - Connecting Randomized Response, Post-Randomization, Differential Privacy and t-Closeness via Deniab.pdf:pdf},
keywords = {Differential privacy,PRAM,permutation paradigm,randomized response,risk and loss aversion,t-closeness},
month = {mar},
title = {{Connecting Randomized Response, Post-Randomization, Differential Privacy and t-Closeness via Deniability and Permutation}},
url = {https://arxiv.org/pdf/1803.02139.pdf http://arxiv.org/abs/1803.02139},
year = {2018}
}
@article{Gabbay2009a,
abstract = {Two-level lambda-calculus is designed to provide a mathematical model of capturing substitution, also called instantiation. Instantiation is a feature of the 'informal meta-level'; it appears pervasively in specifications of the syntax and semantics of formal languages. The two-level lambda-calculus has two levels of variable. Lambda-abstraction and beta-reduction exist for both levels. A level 2 beta-reduct, triggering a substitution of a term for a level 2 variable, does not avoid capture for level 1 abstractions. This models meta-variables and instantiation as appears at the informal meta-level. In this paper we lay down the syntax of the two-level lambda-calculus; we develop theories of freshness, alpha-equivalence, and beta-reduction; and we prove confluence. In doing this we give nominal terms unknowns - which are level 2 variables and appear in several previous papers - a functional meaning. In doing this we take a step towards longer-term goals of developing a foundation for theorem-provers which directly support reasoning in the style of nominal rewriting and nominal algebra, and towards a mathematics of functions which can bind names in their arguments. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Gabbay, Murdoch J. and Mulligan, Dominic P.},
doi = {10.1016/j.entcs.2009.07.018},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Mulligan - 2009 - Two-level Lambda-calculus.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Confluence,Functional programming,Lambda Calculus,Meta-variables,Nominal terms},
month = {aug},
pages = {107--129},
publisher = {Elsevier B.V.},
title = {{Two-level Lambda-calculus}},
url = {http://dx.doi.org/10.1016/j.entcs.2009.07.018 https://linkinghub.elsevier.com/retrieve/pii/S1571066109002400},
volume = {246},
year = {2009}
}
@article{Manes2007,
author = {Manes, Ernie and Mulry, Philip S.},
file = {:Users/liang-tingchen/Dropbox/References/Manes, Mulry - 2007 - Monad compositions I general constructions and recursive distributive laws.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {2007,and phrases,c ernie manes and,distributive law,linear equation,permission to copy for,philip mulry,private use granted},
number = {7},
pages = {172--208},
title = {{Monad compositions I: general constructions and recursive distributive laws}},
volume = {18},
year = {2007}
}
@article{Esik1997,
author = {{\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1016/S0304-3975(96)00240-X},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 1997 - Completeness of Park induction.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {apr},
number = {1},
pages = {217--283},
title = {{Completeness of Park induction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030439759600240X},
volume = {177},
year = {1997}
}
@inproceedings{Muroya2018,
address = {New York, New York, USA},
author = {Muroya, Koko and Cheung, Steven W T and Ghica, Dan R.},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '18},
doi = {10.1145/3209108.3209127},
file = {:Users/liang-tingchen/Dropbox/References/Muroya, Cheung, Ghica - 2018 - The Geometry of Computation-Graph Abstraction.pdf:pdf},
isbn = {9781450355834},
keywords = {2018,acm reference format,and dan r,cheung,e geometry,geometry of interaction,ghica,koko muroya,languages,semantics of programming,steven w,t,tensorflow,•Software and its engineering  Formal language def,•Theory of computation  Semantics and reasoning},
pages = {749--758},
publisher = {ACM Press},
title = {{The Geometry of Computation-Graph Abstraction}},
url = {http://dl.acm.org/citation.cfm?doid=3209108.3209127},
year = {2018}
}
@incollection{Sokolova2004,
abstract = {We survey various notions of probabilistic automata and probabilistic$\backslash$nbisimulation, accumulating in an expressiveness hierarchy of probabilistic$\backslash$nsystem types. The aim of this paper is twofold: On the one hand it$\backslash$nprovides an overview of existing types of probabilistic systems and,$\backslash$non the other hand, it explains the relationship between these models.$\backslash$nWe overview probabilistic systems with discrete probabilities only.$\backslash$nThe expressiveness order used to built the hierarchy is defined via$\backslash$nthe existence of mappings between the corresponding system types$\backslash$nthat preserve and reflect bisimilarity. Additionally, we discuss$\backslash$nparallel composition for the presented types of systems, augmenting$\backslash$nthe map of probabilistic automata with closedness under this compositional$\backslash$noperator. Keywords: probabilistic automata (transition systems),$\backslash$nprobabilistic bisimulation, preservation and reflection of bisimulation,$\backslash$nnon-determinism, parallel composition.},
author = {Sokolova, Ana and de Vink, Erik P},
booktitle = {Validation of Stochastic Systems},
doi = {10.1007/978-3-540-24611-4_1},
file = {:Users/liang-tingchen/Dropbox/References/Sokolova, de Vink - 2004 - Probabilistic Automata System Types, Parallel Composition and Comparison.pdf:pdf},
isbn = {3-540-22265-0},
issn = {03029743},
keywords = {bisimulation,non-determinism,parallel,preservation and reflection of,probabilistic automata,probabilistic bisim-,transition systems,ulation},
pages = {1--43},
title = {{Probabilistic Automata: System Types, Parallel Composition and Comparison}},
url = {http://dx.doi.org/10.1007/978-3-540-24611-4{\_}1 http://link.springer.com/10.1007/978-3-540-24611-4{\_}1},
volume = {2925},
year = {2004}
}
@article{Kohlas2012,
abstract = {Many problems of artificial intelligence, or more generally, many problems of information processing, have a generic solution based on local computation on join trees or acyclic hypertrees. There are several variants of this method all based on the algebraic structure of valuation algebras. A strong requirement underlying this approach is that the elements of a problem decomposition form a join tree. Although it is always possible to construct covering join trees, if the requirement is originally not satisfied, it is not always possible or not efficient to extend the elements of the decomposition to the covering join tree. Therefore in this paper different variants of an axiomatic framework of valuation algebras are introduced which prove sufficient for local computation without the need of an extension of the factors of a decomposition. This framework covers the axiomatic system proposed by Shenoy and Shafer (1990) [1]. A particular emphasis is laid on the important special cases of idempotent algebras and algebras with some notion of division. It is shown that all well-known architectures for local computation like the Shenoy-Shafer architecture, Lauritzen-Spiegelhalter and HUGIN architectures may be adapted to this new framework. Further a new architecture for idempotent algebras is presented. As examples, in addition to the classical instances of valuation algebras, semiring-based valuation algebras, Gaussian potentials and the relational algebra are presented. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
author = {Kohlas, J{\"{u}}rg and Pouly, Marc and Schneuwly, Cesar},
doi = {10.1016/j.jcss.2011.05.012},
file = {:Users/liang-tingchen/Dropbox/References/Kohlas, Pouly, Schneuwly - 2012 - Generic local computation.pdf:pdf},
isbn = {9782879710341},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
keywords = {Generic computation,Hypertree decomposition,Join trees,Local computation,Valuation algebras},
month = {jan},
number = {1},
pages = {348--369},
publisher = {Elsevier Inc.},
title = {{Generic local computation}},
url = {http://dx.doi.org/10.1016/j.jcss.2011.05.012 http://linkinghub.elsevier.com/retrieve/pii/S0022000011000717},
volume = {78},
year = {2012}
}
@incollection{Abramsky2014,
abstract = {This book illustrates the program of Logical-Informational Dynamics. Rational agents exploit the information available in the world in delicate ways, adopt a wide range of epistemic attitudes, and in that process, constantly change the world itself. Logical-Informational Dynamics is about logical systems putting such activities at center stage, focusing on the events by which we acquire information and change attitudes. Its contributions show many current logics of information and change at work, often in multi-agent settings where social behavior is essential, and often stressing Johan van Benthem's pioneering work in establishing this program. However, this is not a Festschrift, but a rich tapestry for a field with a wealth of strands of its own. The reader will see the state of the art in such topics as information update, belief change, preference, learning over time, and strategic interaction in games. Moreover, no tight boundary has been enforced, and some chapters add more general mathematical or philosophical foundations or links to current trends in computer science. The theme of this book lies at the interface of many disciplines. Logic is the main methodology, but the various chapters cross easily between mathematics, computer science, philosophy, linguistics, cognitive and social sciences, while also ranging from pure theory to empirical work. Accordingly, the authors of this book represent a wide variety of original thinkers from different research communities. And their interconnected themes challenge at the same time how we think of logic, philosophy and computation. Thus, very much in line with van Benthem's work over many decades, the volume shows how all these disciplines form a natural unity in the perspective of dynamic logicians (broadly conceived) exploring their new themes today. And at the same time, in doing so, it offers a broader conception of logic with a certain grandeur, moving its horizons beyond the traditional study of consequence relations.},
address = {Cham},
author = {Abramsky, Samson},
booktitle = {Outstanding Contributions to Logic},
doi = {10.1007/978-3-319-06025-5_5},
editor = {Baltag, Alexandru and Smets, Sonja},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2014 - Intensionality, Definability and Computation.pdf:pdf},
isbn = {978-3-319-06024-8},
number = {August},
pages = {121--142},
publisher = {Springer International Publishing},
series = {Outstanding Contributions to Logic},
title = {{Intensionality, Definability and Computation}},
url = {http://link.springer.com/10.1007/978-3-319-06025-5{\_}5},
volume = {5},
year = {2014}
}
@article{Cerrito2004a,
abstract = {We present a typed pattern calculus with explicit pattern matching and explicit substitutions, where both the typing rules and the reduction rules are modeled on the same logical proof system, namely Gentzen sequent calculus for intuitionistic minimal logic. Our calculus is inspired by the Curry-Howard Isomorphism, in the sense that types, both for patterns and terms, correspond to propositions, terms correspond to proofs, and term reduction corresponds to sequences of sequent proof normalization steps performed by cut elimination. The calculus enjoys subject reduction, confluence, preservation of strong normalization w.r.t a system with meta-level substitutions and strong normalization for well-typed terms. As a consequence, it can be seen as an implementation calculus for functional formalisms defined with meta-level operations for pattern matching and substitutions. This work is a revised and extended version of Cerrito and Kesner (14th Annual IEEE Symposium on Logic in Computer Science (LICS), IEEE Computer Society Press, Silver Spring, MD, 1999, pp. 98-108). {\textcopyright} 2004 Published by Elsevier B.V.},
author = {Cerrito, Serenella and Kesner, Delia},
doi = {10.1016/j.tcs.2004.03.032},
file = {:Users/liang-tingchen/Dropbox/References/Cerrito, Kesner - 2004 - Pattern matching as cut elimination(2).pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {sep},
number = {1-3},
pages = {71--127},
title = {{Pattern matching as cut elimination}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397504001835},
volume = {323},
year = {2004}
}
@article{Sobocinski2016,
abstract = {Compositionality and process equivalence are both standard concepts of process algebra. Compositionality means that the behaviour of a compound system relies only on the behaviour of its components, i.e. there is no emergent behaviour. Process equivalence means that the explicit statespace of a system takes a back seat to its interaction patterns: the information that an environment can obtain though interaction. Petri nets are a classical, yet widely used and understood, model of concurrency. Nevertheless, they have often been described as a non-compositional model, and tools tend to deal with monolithic, globally-specified models. This tutorial paper concentrates on Petri Nets with Boundaries (PNB): a compositional, graphical algebra of 1-safe nets, and its applications to reachability checking within the tool Penrose. The algorithms feature the use of compositionality and process equivalence, a powerful combination that can be harnessed to improve the performance of checking reachability and coverability in several common examples where Petri nets model realistic concurrent systems.},
archivePrefix = {arXiv},
arxivId = {1603.00976},
author = {Soboci{\'{n}}ski, Pawe{\l}},
doi = {10.4204/EPTCS.204.3},
eprint = {1603.00976},
file = {:Users/liang-tingchen/Dropbox/References/Soboci{\'{n}}ski - 2016 - Compositional model checking of concurrent systems, with Petri nets.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {mar},
pages = {19--30},
title = {{Compositional model checking of concurrent systems, with Petri nets}},
url = {http://arxiv.org/abs/1603.00976},
volume = {204},
year = {2016}
}
@article{Honda2010,
abstract = {This paper presents an exact correspondence in typing and dynamics between polarised linear logic and a typed $\pi$-calculus based on IO-typing. The respective incremental constraints, one on geometric structures of proof-nets and one based on types, precisely correspond to each other, leading to the exact correspondence of the respective formalisms as they appear in Olivier Laurent (2003) [27] (for proof-nets) and Kohei Honda et al. (2004) [24] (for the $\pi$-calculus). {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Honda, Kohei and Laurent, Olivier},
doi = {10.1016/j.tcs.2010.01.028},
file = {:Users/liang-tingchen/Dropbox/References/Honda, Laurent - 2010 - An exact correspondence between a typed pi-calculus and polarised proof-nets.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Concurrency,Determinism,Embedding,Interaction,Linear Logic,Logics,Non-determinism,Pi-calculus,Polarity,Processes,Proof-nets,Proofs,Types},
month = {may},
number = {22-24},
pages = {2223--2238},
publisher = {Elsevier B.V.},
title = {{An exact correspondence between a typed pi-calculus and polarised proof-nets}},
url = {http://dx.doi.org/10.1016/j.tcs.2010.01.028 https://linkinghub.elsevier.com/retrieve/pii/S0304397510000538},
volume = {411},
year = {2010}
}
@article{Adamek2007,
abstract = {Injectivity of objects with respect to a set {\$}\backslashch{\$} of morphisms is an important concept of algebra, model theory and homotopy theory. Here we study the logic of injectivity consequences of {\$}\backslashch{\$}, by which we understand morphisms {\$}h{\$} such that injectivity with respect to {\$}\backslashch{\$} implies injectivity with respect to {\$}h{\$}. We formulate three simple deduction rules for the injectivity logic and for its finitary version where $\backslash$mor s between finitely ranked objects are considered only, and prove that they are sound in all categories, and complete in all "reasonable" categories.},
archivePrefix = {arXiv},
arxivId = {0709.2461},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Hebert, M. and Sousa, Lurdes},
eprint = {0709.2461},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Hebert, Sousa - 2007 - A Logic of Injectivity.pdf:pdf},
journal = {Journal of Homotopy and Related Structures},
number = {2},
pages = {13--47},
title = {{A Logic of Injectivity}},
url = {http://arxiv.org/abs/0709.2461},
volume = {2},
year = {2007}
}
@article{Paulson1986,
abstract = {Martin-L{\"{o}}f's Intuitionistic Theory of Types is becoming popular for formal reasoning about computer programs. To handle recursion schemes other than primitive recursion, a theory of well-founded relations is presented. Using primitive recursion over higher types, induction and recursion are formally derived for a large class of well-founded relations. Included are {\textless} on natural numbers, and relations formed by inverse images, addition, multiplication, and exponentiation of other relations. The constructions are given in full detail to allow their use in theorem provers for Type Theory, such as PRL. The theory is compared with work in the field of ordinal recursion over higher types. {\textcopyright} 1986, Academic Press Inc. (London) Ltd.. All rights reserved.},
author = {Paulson, Lawrence C.},
doi = {10.1016/S0747-7171(86)80002-5},
file = {:Users/liang-tingchen/Dropbox/References/Paulson - 1986 - Constructing recursion operators in intuitionistic type theory.pdf:pdf},
issn = {07477171},
journal = {Journal of Symbolic Computation},
month = {dec},
number = {4},
pages = {325--355},
title = {{Constructing recursion operators in intuitionistic type theory}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0747717186800025},
volume = {2},
year = {1986}
}
@article{VanBreugel2005,
abstract = {Discrete notions of behavioural equivalence sit uneasily with semantic models featuring quantitative data, like probabilistic transition systems. In this paper, we present a pseudometric on a class of probabilistic transition systems yielding a quantitative notion of behavioural equivalence. The pseudometric is defined via the terminal coalgebra of a functor based on a metric on the space of Borel probability measures on a metric space. States of a probabilistic transition system have distance 0 if and only if they are probabilistic bisimilar. We also characterize our distance function in terms of a real-valued modal logic.},
author = {van Breugel, Franck and Worrell, James},
doi = {10.1016/j.tcs.2004.09.035},
file = {:Users/liang-tingchen/Dropbox/References/van Breugel, Worrell - 2005 - A behavioural pseudometric for probabilistic transition systems.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {bisimilarity,probabilistic,probabilistic bisimilarity,probabilistic transition system,pseudometric,real-valued modal logic,terminal coalgebra},
month = {feb},
number = {1},
pages = {115--142},
publisher = {Elsevier},
title = {{A behavioural pseudometric for probabilistic transition systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504006711 http://dl.acm.org/citation.cfm?id=1062956.1062964},
volume = {331},
year = {2005}
}
@article{Schwichtenberg1976,
author = {Schwichtenberg, H.},
journal = {Archiv Logik Grundlagenforsch.},
pages = {113--114},
title = {{Definierbare Funktionen im Lambda-Kalkul mit Typen}},
volume = {17},
year = {1976}
}
@article{Mogelberg2019a,
abstract = {In type theory, coinductive types are used to represent processes, and are thus crucial for the formal verification of non-terminating reactive programs in proof assistants based on type theory, such as Coq and Agda. Currently, programming and reasoning about coinductive types is difficult for two reasons: The need for recursive definitions to be productive, and the lack of coincidence of the built-in identity types and the important notion of bisimilarity. Guarded recursion in the sense of Nakano has recently been suggested as a possible approach to dealing with the problem of productivity, allowing this to be encoded in types. Indeed, coinductive types can be encoded using a combination of guarded recursion and universal quantification over clocks. This paper studies the notion of bisimilarity for guarded recursive types in Ticked Cubical Type Theory, an extension of Cubical Type Theory with guarded recursion. We prove that, for any functor, an abstract, category theoretic notion of bisimilarity for the final guarded coalgebra is equivalent (in the sense of homotopy type theory) to path equality (the primitive notion of equality in cubical type theory). As a worked example we study a guarded notion of labelled transition systems, and show that, as a special case of the general theorem, path equality coincides with an adaptation of the usual notion of bisimulation for processes. In particular, this implies that guarded recursion can be used to give simple equational reasoning proofs of bisimilarity. This work should be seen as a step towards obtaining bisimilarity as path equality for coinductive types using the encodings mentioned above.},
archivePrefix = {arXiv},
arxivId = {1810.13261},
author = {M{\o}gelberg, Rasmus Ejlers and Veltri, Niccol{\`{o}}},
doi = {10.1145/3290317},
eprint = {1810.13261},
file = {:Users/liang-tingchen/Dropbox/References/M{\o}gelberg, Veltri - 2019 - Bisimulation as path type for guarded recursive types.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Bisimulation as path type for guarded recursive types}},
url = {https://dl.acm.org/doi/10.1145/3290317},
volume = {3},
year = {2019}
}
@inproceedings{Pedrot2020,
abstract = {The results from this paper are twofold. First, we give a purely syntactic presheaf model of CIC. Contrarily to similar endeavours, this variant both preserves conversion and interprets full dependent elimination. Using a particular instance of this model, we show how to extend CIC with Markov's principle, while preserving all good meta-theoretical properties like canonicity and decidability of type-checking. The resulting construction can be seen as a synthetic presentation of Coquand-Hofmann's syntactic model of PRA$\omega$ + MP as the composition of P{\'{e}}drot-Tabareau's exceptional model with our presheaf interpretation.},
address = {New York, NY, USA},
author = {P{\'{e}}drot, Pierre-Marie},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394740},
file = {:Users/liang-tingchen/Dropbox/References/P{\'{e}}drot - 2020 - Russian Constructivism in a Prefascist Theory.pdf:pdf},
isbn = {9781450371049},
keywords = {Markov's principle,dependent types,exceptions,presheaf,strict propositions,syntactic model},
month = {jul},
pages = {782--794},
publisher = {ACM},
title = {{Russian Constructivism in a Prefascist Theory}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394740},
year = {2020}
}
@inproceedings{Governatori2005,
abstract = {This paper presents a formal system for reasoning about violations of obligations in contracts. The system is based on the formalism for the representation of contrary-to-duty obligations. These are the obligations that take place when other obligations are violated as typically applied to penalties in contracts. The paper shows how this formalism can be mapped onto the key policy concepts of a contract specification language. This language, called Business Contract Language (BCL) was previously developed to express contract conditions of relevance for run time contract monitoring. The aim of this mapping is to establish a formal underpinning for this key subset of BCL.},
author = {Governatori, Guido and Milosevic, Zoran},
booktitle = {Ninth IEEE International EDOC Enterprise Computing Conference (EDOC'05)},
doi = {10.1109/EDOC.2005.13},
file = {:Users/liang-tingchen/Dropbox/References/Governatori, Milosevic - 2005 - Dealing with contract violations formalism and domain specific language.pdf:pdf},
isbn = {0-7695-2441-9},
issn = {15417719},
pages = {46--57},
publisher = {IEEE},
title = {{Dealing with contract violations: formalism and domain specific language}},
url = {http://ieeexplore.ieee.org/document/1540667/},
year = {2005}
}
@article{Brodal1996,
abstract = {Brodal recently introduced the first implementation of imperative priority queues to support findMin, insert and meld in O (1) worst-case time, and deleteMin in O (log n ) worst-case time. These bounds are asymptotically optimal among all comparison-based priority queues. In this paper, we adapt Brodal's data structure to a purely functional setting. In doing so, we both simplify the data structure and clarify its relationship to the binomial queues of Vuillemin, which support all four operations in O (log n ) time. Specifically, we derive our implementation from binomial queues in three steps: first, we reduce the running time of insert to O (1) by eliminating the possibility of cascading links; second, we reduce the running time of findMin to O (1) by adding a global root to hold the minimum element; and finally, we reduce the running time of meld to O (1) by allowing priority queues to contain other priority queues. Each of these steps is expressed using ML-style functors. The last transformation, known as data-structural bootstrapping, is an interesting application of higher-order functors and recursive structures.},
author = {Brodal, Gerth St{\o}lting and Okasaki, Chris},
doi = {10.1017/S095679680000201X},
file = {:Users/liang-tingchen/Dropbox/References/Brodal, Okasaki - 1996 - Optimal purely functional priority queues.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {nov},
number = {06},
pages = {839--857},
pmid = {19332050},
title = {{Optimal purely functional priority queues}},
url = {http://www.journals.cambridge.org/abstract{\_}S095679680000201X},
volume = {6},
year = {1996}
}
@article{Swierstra2008,
author = {Swierstra, Wouter},
doi = {10.1017/S0956796808006758},
file = {:Users/liang-tingchen/Dropbox/References/Swierstra - 2008 - Data types {\`{a}} la carte.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {04},
pages = {423--436},
title = {{Data types {\`{a}} la carte}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796808006758},
volume = {18},
year = {2008}
}
@article{Kohlas2014,
abstract = {This review examines some particular, but important and basic aspects of information: Information is related to questions and should provide at least partial answers. Information comes in pieces, and it should be possible to aggregate these pieces. Finally, it should be possible to extract that part of a piece of information which relates to a given question. Modeling these concepts leads to an algebraic theory of information. This theory centers around two different but closely related types of information algebras, each containing operations for aggregation or combination of information and for extracting information relevant to a given question. Generic constructions of instances of such algebras are presented. In particular, the close connection of information algebras to logic and domain theory will be exhibited.},
author = {Kohlas, J{\"{u}}rg and Schmid, J{\"{u}}rg},
doi = {10.3390/info5020219},
issn = {2078-2489},
journal = {Information},
keywords = {Domain theory,Information,Information theory,Order theory,Universal logic},
month = {apr},
number = {2},
pages = {219--254},
title = {{An Algebraic Theory of Information: An Introduction and Survey}},
url = {http://www.mdpi.com/2078-2489/5/2/219/},
volume = {5},
year = {2014}
}
@article{Im2009,
abstract = {An adjoint-triangle theorem contemplates functors P: C → A and T: A → B where T and TP have left adjoints, and gives sufficient conditions for P also to have a left adjoint. We are concerned with the case where T is conservative - that is, isomorphism-reflecting; then P has a left adjoint under various combinations of completeness or cocompleteness conditions on C and A, with no explicit condition on P itself. We list systematically the strongest results we know of in this direction, augmenting those in the literature by some new ones.},
author = {Im, G. B. and Kelly, Gregory Maxwell},
doi = {10.1017/S000497270002637X},
file = {:Users/liang-tingchen/Dropbox/References/Im, Kelly - 2009 - Adjoint-triangle theorems for conservative functors.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
number = {01},
pages = {133},
title = {{Adjoint-triangle theorems for conservative functors}},
url = {http://www.journals.cambridge.org/abstract{\_}S000497270002637X},
volume = {36},
year = {2009}
}
@inproceedings{Ganta2008,
abstract = {Privacy is an increasingly important aspect of data publishing. Reasoning about privacy, however, is fraught with pitfalls. One of the most significant is the auxiliary information (also called external knowledge, background knowledge, or side information) that an adversary gleans from other channels such as the web, public records, or domain knowledge. This paper explores how one can reason about privacy in the face of rich, realistic sources of auxiliary information. Specifically, we investigate the effectiveness of current anonymization schemes in preserving privacy when multiple organizations independently release anonymized data about overlapping populations. 1. We investigate composition attacks, in which an adversary uses independent anonymized releases to breach privacy. We explain why recently proposed models of limited auxiliary information fail to capture composition attacks. Our experiments demonstrate that even a simple instance of a composition attack can breach privacy in practice, for a large class of currently proposed techniques. The class includes k-anonymity and several recent variants. 2. On a more positive note, certain randomization-based notions of privacy (such as differential privacy) provably resist composition attacks and, in fact, the use of arbitrary side information.This resistance enables ``stand-alone'' design of anonymization schemes, without the need for explicitly keeping track of other releases. We provide a precise formulation of this property, and prove that an important class of relaxations of differential privacy also satisfy the property. This significantly enlarges the class of protocols known to enable modular design.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {0803.0032},
author = {Ganta, Srivatsava Ranjit and Kasiviswanathan, Shiva Prasad and Smith, Adam},
booktitle = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD 08},
doi = {10.1145/1401890.1401926},
eprint = {0803.0032},
file = {:Users/liang-tingchen/Dropbox/References/Ganta, Kasiviswanathan, Smith - 2008 - Composition attacks and auxiliary information in data privacy.pdf:pdf},
isbn = {9781605581934},
keywords = {adversarial attacks,anonymization,privacy},
pages = {265},
publisher = {ACM Press},
title = {{Composition attacks and auxiliary information in data privacy}},
url = {http://dl.acm.org/citation.cfm?doid=1401890.1401926},
year = {2008}
}
@article{Adamek1995a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Koubek, V{\'{a}}clav},
doi = {10.1016/0304-3975(95)00011-K},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Koubek - 1995 - On the greatest fixed point of a set functor.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {oct},
number = {1},
pages = {57--75},
title = {{On the greatest fixed point of a set functor}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/B6V1G-3Y5MMNV-21/2/4ef1f15e1787aa77e61dab8f1b8907b8 http://linkinghub.elsevier.com/retrieve/pii/030439759500011K},
volume = {150},
year = {1995}
}
@article{Tschantz2011a,
abstract = {Differential privacy is a promising approach to privacy preserving data analysis with a well-developed theory for functions. Despite recent work on implementing systems that aim to provide differential privacy, the problem of formally verifying that these systems have differential privacy has not been adequately addressed. This paper presents the first results towards automated verification of source code for differentially private interactive systems. We develop a formal probabilistic automaton model of differential privacy for systems by adapting prior work on differential privacy for functions. The main technical result of the paper is a sound proof technique based on a form of probabilistic bisimulation relation for proving that a system modeled as a probabilistic automaton satisfies differential privacy. The novelty lies in the way we track quantitative privacy leakage bounds using a relation family instead of a single relation. We illustrate the proof technique on a representative automaton motivated by PINQ, an implemented system that is intended to provide differential privacy. To make our proof technique easier to apply to realistic systems, we prove a form of refinement theorem and apply it to show that a refinement of the abstract PINQ automaton also satisfies our differential privacy definition. Finally, we begin the process of automating our proof technique by providing an algorithm for mechanically checking a restricted class of relations from the proof technique.},
archivePrefix = {arXiv},
arxivId = {1101.2819},
author = {Tschantz, Michael Carl and Kaynar, Dilsun and Datta, Anupam},
doi = {10.1016/j.entcs.2011.09.015},
eprint = {1101.2819},
file = {:Users/liang-tingchen/Dropbox/References/Tschantz, Kaynar, Datta - 2011 - Formal verification of differential privacy for interactive systems.pdf:pdf},
issn = {15710661},
journal = {ArXiv preprint},
keywords = {Bisimulation,Differential Privacy,Formal Methods,Privacy,Verification},
month = {jan},
title = {{Formal verification of differential privacy for interactive systems}},
url = {http://arxiv.org/abs/1101.2819},
year = {2011}
}
@article{Katsumata2018,
abstract = {We introduce a method to lift monads on the base category of a fibration to its total category. This method, which we call codensity lifting, is applicable to various fibrations which were not supported by its precursor, categorical TT-lifting. After introducing the codensity lifting, we illustrate some examples of codensity liftings of monads along the fibrations from the category of preorders, topological spaces and extended pseudometric spaces to the category of sets, and also the fibration from the category of binary relations between measurable spaces. We also introduce the dual method called density lifting of comonads. We next study the liftings of algebraic operations to the codensity liftings of monads. We also give a characterisation of the class of liftings of monads along posetal fibrations with fibred small meets as a limit of a certain large diagram.},
author = {Katsumata, Shin-ya and Sato, Tetsuya and Uustalu, Tarmo},
doi = {10.23638/LMCS-14(4:6)2018},
file = {:Users/liang-tingchen/Dropbox/References/Katsumata, Sato, Uustalu - 2018 - Codensity lifting of monads and its dual.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Comonad,Fibration,Giry Monad,Lifting,Monad},
number = {4},
pages = {1--31},
title = {{Codensity lifting of monads and its dual}},
volume = {14},
year = {2018}
}
@article{Fine1975,
author = {Fine, Kit},
doi = {10.1305/ndjfl/1093891703},
file = {:Users/liang-tingchen/Dropbox/References/Fine - 1975 - Normal forms in modal logic.pdf:pdf},
issn = {0029-4527},
journal = {Notre Dame Journal of Formal Logic},
month = {apr},
number = {2},
pages = {229--237},
title = {{Normal forms in modal logic}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ndjfl/1093891703/},
volume = {16},
year = {1975}
}
@inproceedings{Pickering2020,
abstract = {Generic programming libraries have historically traded efficiency in return for convenience, and the generics-sop library is no exception. It offers a simple, uniform, representation of all datatypes precisely as a sum of products, making it easy to write generic functions. We show how to finally make generics-sop fast through the use of staging with Typed Template Haskell.},
address = {New York, NY, USA},
author = {Pickering, Matthew and L{\"{o}}h, Andres and Wu, Nicolas},
booktitle = {Proceedings of the 13th ACM SIGPLAN International Symposium on Haskell},
doi = {10.1145/3406088.3409021},
file = {:Users/liang-tingchen/Dropbox/References/Pickering, L{\"{o}}h, Wu - 2020 - Staged sums of products.pdf:pdf},
isbn = {9781450380508},
keywords = {generic programming,staging},
month = {aug},
pages = {122--135},
publisher = {ACM},
title = {{Staged sums of products}},
url = {https://dl.acm.org/doi/10.1145/3406088.3409021},
year = {2020}
}
@article{Kiefer2011,
abstract = {Checking two probabilistic automata for equivalence has been shown to be a key problem for efficiently establishing various behavioural and anonymity properties of probabilistic systems. In recent experiments a randomised equivalence test based on polynomial identity testing outperformed deterministic algorithms. In this paper we show that polynomial identity testing yields efficient algorithms for various generalisations of the equivalence problem. First, we provide a randomized NC procedure that also outputs a counterexample trace in case of inequivalence. Second, we show how to check for equivalence two probabilistic automata with (cumulative) rewards. Our algorithm runs in deterministic polynomial time, if the number of reward counters is fixed. Finally we show that the equivalence problem for probabilistic visibly pushdown automata is logspace equivalent to the Arithmetic Circuit Identity Testing problem, which is to decide whether a polynomial represented by an arithmetic circuit is identically zero.},
archivePrefix = {arXiv},
arxivId = {1112.4644},
author = {Kiefer, Stefan and Murawski, Andrzej S. and Ouaknine, Jo{\"{e}}l and Wachter, Bj{\"{o}}rn and Worrell, James},
eprint = {1112.4644},
file = {:Users/liang-tingchen/Dropbox/References/Kiefer et al. - 2011 - On the Complexity of the Equivalence Problem for Probabilistic Automata.pdf:pdf},
journal = {ArXiv e-prints},
month = {dec},
title = {{On the Complexity of the Equivalence Problem for Probabilistic Automata}},
url = {http://arxiv.org/abs/1112.4644},
year = {2011}
}
@article{lmcs:7511,
author = {Ahrens, Benedikt and Hirschowitz, Andr{\'{e}} and Lafont, Ambroise and Maggesi, Marco},
doi = {10.23638/LMCS-17(2:17)2021},
file = {:Users/liang-tingchen/Dropbox/References//Ahrens et al. - 2021 - Presentable signatures and initial semantics.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages},
month = {may},
number = {2},
pages = {1--17},
title = {{Presentable signatures and initial semantics}},
url = {https://lmcs.episciences.org/7511},
volume = {17},
year = {2021}
}
@article{Grandis2002,
abstract = {It is known that factorisation systems in categories can be viewed as unitary pseudo-algebras for the monad ??? = (-)2, in Cat. We show in this note that an analogous fact holds for proper (i.e., epi-mono) factorisation systems and a suitable quotient of the former monad, deriving from a construct introduced by Freyd for stable homotopy. Some similarities of ??? with the structure of the path endofunctor of topological spaces are considered. ?? 2002 Elsevier Science B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {math/0101154},
author = {Grandis, Marco},
doi = {10.1016/S0022-4049(01)00114-1},
eprint = {0101154},
file = {:Users/liang-tingchen/Dropbox/References/Grandis - 2002 - On the monad of proper factorisation systems in categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jun},
number = {1},
pages = {17--26},
primaryClass = {math},
title = {{On the monad of proper factorisation systems in categories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0022404901001141},
volume = {171},
year = {2002}
}
@inproceedings{Christiansen2016,
abstract = {Many programming languages and proof assistants are defined by elaboration from a high-level language with a great deal of implicit information to a highly explicit core language. In many advanced languages, these elaboration facilities contain powerful tools for program construction, but these tools are rarely designed to be repurposed by users. We describe elaborator reflection, a paradigm for metaprogramming in which the elaboration machinery is made directly available to metaprograms, as well as a concrete realization of elaborator reflection in Idris, a functional language with full dependent types. We demonstrate the applicability of Idris's reflected elaboration framework to a number of realistic problems, we discuss the motivation for the specific features of its design, and we explore the broader meaning of elaborator reflection as it can relate to other languages.},
address = {New York, New York, USA},
author = {Christiansen, David and Brady, Edwin},
booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming - ICFP 2016},
doi = {10.1145/2951913.2951932},
file = {:Users/liang-tingchen/Dropbox/References/Christiansen, Brady - 2016 - Elaborator reflection extending Idris in Idris.pdf:pdf},
isbn = {9781450342193},
issn = {03621340},
keywords = {dependent types,elaboration,metaprogramming},
month = {sep},
number = {9},
pages = {284--297},
publisher = {ACM Press},
title = {{Elaborator reflection: extending Idris in Idris}},
url = {http://dl.acm.org/citation.cfm?doid=3022670.2951932 http://dl.acm.org/citation.cfm?doid=2951913.2951932},
volume = {51},
year = {2016}
}
@article{Berarducci1999,
abstract = {Recent work on infinitary versions of the lambda calculus has shown that the infinite lambda calculus can be a useful tool to study the unsolvable terms of the classical lambda calculus. Working in the framework of the intersection type disciplines, we devise a type assignment system such that two terms are equal in the infinite lambda calculus iff they can be assigned the same types in any basis. A novel feature of the system is the presence of a type constant to denote the set of all terms of order zero, and the possibility of applying a type to another type. We prove a completeness and an approximation theorem for our system. Our results can be considered as a first step towards the goal of giving a denotational semantics for the lambda calculus which is suited for the study of the unsolvable terms. However, some noncontinuity phenomena of the infinite lambda calculus make a full realization of this idea (namely the construction of a filter model) a quite difficult task. {\textcopyright} 1999 Published by Elsevier Science B.V. All rights reserved.},
author = {Berarducci, Alessandro and Dezani-Ciancaglini, Mariangiola},
doi = {10.1016/S0304-3975(98)00135-2},
file = {:Users/liang-tingchen/Dropbox/References/Berarducci, Dezani-Ciancaglini - 1999 - Infinite $\lambda$-calculus and types.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Infinite $\lambda$-calculus,Intersection types,$\lambda$-algebras},
month = {feb},
number = {1-2},
pages = {29--75},
title = {{Infinite $\lambda$-calculus and types}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397598001352},
volume = {212},
year = {1999}
}
@article{Provan,
author = {Provan, Gregory M},
doi = {10.1016/0888-613X(90)90016-U},
file = {:Users/liang-tingchen/Dropbox/References/Provan - 1990 - A logic-based analysis of Dempster-Shafer theory.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {assumption-based truth maintenance system,dempster-shafer theory,ing,logic,reasoning system,theorem prov-,uncertainty},
month = {sep},
number = {5-6},
pages = {451--495},
title = {{A logic-based analysis of Dempster-Shafer theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0888613X9090016U},
volume = {4},
year = {1990}
}
@article{Adamek2003a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Lawvere, F. William and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1007/s000120300002},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Lawvere, Rosick{\'{y}} - 2003 - On the duality between varieties and algebraic theories.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {apr},
number = {1},
pages = {35--49},
title = {{On the duality between varieties and algebraic theories}},
url = {http://link.springer.com/10.1007/s000120300002},
volume = {49},
year = {2003}
}
@inproceedings{Kapitsaki2018,
author = {Kapitsaki, Georgia and Ioannou, Joseph and Cardoso, Jorge and Pedrinaci, Carlos},
booktitle = {2018 IEEE International Conference on Web Services (ICWS)},
doi = {10.1109/ICWS.2018.00014},
file = {:Users/liang-tingchen/Dropbox/References/Kapitsaki et al. - 2018 - Linked USDL Privacy Describing Privacy Policies for Services.pdf:pdf},
isbn = {978-1-5386-7247-1},
month = {jul},
pages = {50--57},
publisher = {IEEE},
title = {{Linked USDL Privacy: Describing Privacy Policies for Services}},
url = {https://ieeexplore.ieee.org/document/8456331/},
year = {2018}
}
@inproceedings{Ahman2016,
abstract = {Dijkstra monads enable a dependent type theory to be enhanced with support for specifying and verifying effectful code via weakest preconditions. Together with their closely related counterparts, Hoare monads, they provide the basis on which verification tools like F*, Hoare Type Theory (HTT), and Ynot are built. We show that Dijkstra monads can be derived "for free" by applying a continuation-passing style (CPS) translation to the standard monadic definitions of the underlying computational effects. Automatically deriving Dijkstra monads in this way provides a correct-by-construction and efficient way of reasoning about user-defined effects in dependent type theories. We demonstrate these ideas in EMF*, a new dependently typed calculus, validating it via both formal proof and a prototype implementation within F*. Besides equipping F* with a more uniform and extensible effect system, EMF* enables a novel mixture of intrinsic and extrinsic proofs within F*.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1608.06499},
author = {Ahman, Danel and Hriţcu, Cătălin and Maillard, Kenji and Mart{\'{i}}nez, Guido and Plotkin, Gordon and Protzenko, Jonathan and Rastogi, Aseem and Swamy, Nikhil},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
doi = {10.1145/3009837.3009878},
eprint = {1608.06499},
file = {:Users/liang-tingchen/Dropbox/References/Ahman et al. - 2017 - Dijkstra monads for free.pdf:pdf},
isbn = {9781450346603},
issn = {0362-1340},
keywords = {effectful programming,proof assistants,verification},
pages = {515--529},
publisher = {ACM Press},
title = {{Dijkstra monads for free}},
url = {http://arxiv.org/abs/1608.06499 http://dl.acm.org/citation.cfm?doid=3009837.3009878},
year = {2017}
}
@incollection{Wadler2009,
author = {Wadler, Philip and Findler, Robert Bruce},
booktitle = {Programming Languages and Systems. ESOP 2009},
doi = {10.1007/978-3-642-00590-9_1},
editor = {Castagna, Giuseppe},
file = {:Users/liang-tingchen/Dropbox/References/Wadler, Findler - 2009 - Well-Typed Programs Can't Be Blamed.pdf:pdf},
pages = {1--16},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Well-Typed Programs Can't Be Blamed}},
url = {http://link.springer.com/10.1007/978-3-642-00590-9{\_}1},
volume = {5502},
year = {2009}
}
@incollection{Grillet1971,
author = {Grillet, Pierre Antoine},
booktitle = {Exact Categories and Categories of Sheaves},
doi = {10.1007/BFb0058581},
file = {:Users/liang-tingchen/Dropbox/References/Grillet - 1971 - Regular categories.pdf:pdf},
isbn = {978-3-540-05678-2},
pages = {121--222},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Regular categories}},
volume = {i},
year = {1971}
}
@book{Pierce2002,
author = {Pierce, Benjamin C.},
isbn = {0-262-16209-1},
publisher = {MIT Press},
title = {{Types and Programming Languages}},
year = {2002}
}
@article{Edwards2017,
abstract = {ABSTRACT This article reflects the kinds of situations and spaces where people and algorithms meet. In what situations do people become aware of algorithms? How do they experience and make sense of these algorithms, given their often hidden and invisible nature? To what extent does an awareness of algorithms affect people's use of these platforms, if at all? To help answer these questions, this article examines people's personal stories about the Facebook algorithm through tweets and interviews with 25 ordinary users. To understand the spaces where people and algorithms meet, this article develops the notion of the algorithmic imaginary. It is argued that the algorithmic imaginary – ways of thinking about what algorithms are, what they should be and how they function – is not just productive of different moods and sensations but plays a generative role in moulding the Facebook algorithm itself. Examining how algorithms make people feel, then, seems crucial if we want to understand their social power.},
author = {Edwards, Lilian and Veale, Michael},
doi = {10.2139/ssrn.2972855},
file = {:Users/liang-tingchen/Dropbox/References/Edwards, Veale - 2017 - Slave to the Algorithm Why a Right to Explanationn is Probably Not the Remedy You are Looking for.pdf:pdf},
isbn = {3540445668},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {International},
title = {{Slave to the Algorithm? Why a Right to Explanationn is Probably Not the Remedy You are Looking for}},
url = {https://www.ssrn.com/abstract=2972855},
volume = {2017},
year = {2017}
}
@inproceedings{Ahmed2009,
address = {New York, New York, USA},
author = {Ahmed, Amal and Dreyer, Derek and Rossberg, Andreas},
booktitle = {Proceedings of the 36th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '09},
doi = {10.1145/1480881.1480925},
file = {:Users/liang-tingchen/Dropbox/References/Ahmed, Dreyer, Rossberg - 2008 - State-dependent representation independence.pdf:pdf},
isbn = {9781605583792},
issn = {0362-1340},
keywords = {Abstract data types,Existential types,Local state,Representation independence,Step-indexed logical relations},
month = {jan},
pages = {340},
publisher = {ACM Press},
title = {{State-dependent representation independence}},
url = {https://dl.acm.org/doi/10.1145/1594834.1480925 http://portal.acm.org/citation.cfm?doid=1480881.1480925},
year = {2008}
}
@inproceedings{Mainland2007,
abstract = {Quasiquoting allows programmers to use domain specific syntax to construct program fragments. By providing concrete syntax for complex data types, programs become easier to read, easier to write, and easier to reason about and maintain. Haskell is an ex- cellent host language for embedded domain specific languages, and quasiquoting ideally complements the language features that make Haskell perform so well in this area. Unfortunately, until now no Haskell compiler has provided support for quasiquoting. We present an implementation in GHC and demonstrate that by lever- aging existing compiler capabilities, building a full quasiquoter re- quires little more work than writing a parser. Furthermore, we pro- vide a compile-time guarantee that all quasiquoted data is type- correct.},
address = {New York, New York, USA},
author = {Mainland, Geoffrey},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell workshop - Haskell '07},
doi = {10.1145/1291201.1291211},
file = {:Users/liang-tingchen/Dropbox/References/Mainland - 2007 - Why it's nice to be quoted.pdf:pdf},
isbn = {9781595936745},
keywords = {meta programming,quasiquoting},
pages = {73},
publisher = {ACM Press},
title = {{Why it's nice to be quoted}},
url = {http://portal.acm.org/citation.cfm?doid=1291201.1291211},
year = {2007}
}
@incollection{Klin2005,
author = {Klin, Bartek},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/11548133_16},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2005 - The least fibred lifting and the expressivity of coalgebraic modal logic.pdf:pdf},
pages = {247--262},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The least fibred lifting and the expressivity of coalgebraic modal logic}},
year = {2005}
}
@incollection{Hughes2016,
author = {Atkey, Robert and Lindley, Sam and Morris, J. Garrett},
booktitle = {A List of Successes That Can Change the World},
doi = {10.1007/978-3-319-30936-1_2},
editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, Lindley, Morris - 2016 - Conflation Confers Concurrency.pdf:pdf},
isbn = {978-3-319-30935-4},
pages = {32--55},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Conflation Confers Concurrency}},
url = {http://link.springer.com/10.1007/978-3-319-30936-1{\_}2},
volume = {9600},
year = {2016}
}
@article{Blaauw2013,
abstract = {Privacy is valued by many. But what it means to have privacy remains less than clear. In this paper, I argue that the notion of privacy should be understood in epistemic terms. What it means to have (some degree of) privacy is that other persons do not stand in significant epistemic relations to those truths one wishes to keep private.},
author = {Blaauw, Martijn},
doi = {10.1017/epi.2013.12},
file = {:Users/liang-tingchen/Dropbox/References/Blaauw - 2013 - THE EPISTEMIC ACCOUNT OF PRIVACY.pdf:pdf},
isbn = {9780494603031},
issn = {1742-3600},
journal = {Episteme},
month = {jun},
number = {02},
pages = {167--177},
title = {{THE EPISTEMIC ACCOUNT OF PRIVACY}},
url = {http://www.journals.cambridge.org/abstract{\_}S1742360013000129},
volume = {10},
year = {2013}
}
@article{Polonsky2011,
abstract = {We study reflection in the Lambda Calculus from an axiomatic point of view. Specifically, we consider various properties that the quote {\textperiodcentered} must satisfy as a function from $\Lambda$ to $\Lambda$. The most important of these is the existence of a definable left inverse: a term E, called the evaluator for {\textperiodcentered}, that satisfies EM = M for all M ∈ $\Lambda$. Usually the quote M∼l encodes the syntax of a given term, and the evaluator proceeds by analyzing the syntax and reifying all constructors by their actual meaning in the calculus. Working in Combinatory Logic, Raymond Smullyan [12] investigated which elements of the syntax must be accessible via the quote in order for an evaluator to exist. He asked three specific questions, to which we provide negative answers. On the positive side, we give a characterization of quotes which possess all of the desired properties, equivalently defined as being equitranslatable with a standard quote. As an application, we show that Scott's coding is not complete in this sense, but can be slightly modified to be such. This results in a minimal definition of a complete quoting for Combinatory Logic. {\textcopyright} Andrew Polonsky.},
author = {Polonsky, Andrew},
doi = {10.4230/LIPIcs.CSL.2011.458},
file = {:Users/liang-tingchen/Dropbox/References/Polonsky - 2011 - Axiomatizing the quote.pdf:pdf},
isbn = {9783939897323},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Combinatory logic,Enumerator,Lambda calculus,Quote operator},
pages = {458--469},
title = {{Axiomatizing the quote}},
volume = {12},
year = {2011}
}
@incollection{Bradfield2005,
author = {Bradfield, Julian and Stirling, Colin},
booktitle = {Handbook of Modal Logic},
doi = {10.1016/S1570-2464(07)80015-2},
editor = {Blackburn, Patrick and van Benthem, Johan and Wolter, Frank},
file = {:Users/liang-tingchen/Dropbox/References/Bradfield, Stirling - 2007 - Modal mu-calculi.pdf:pdf},
pages = {721--756},
publisher = {Elsevier B.V.},
series = {Studies in Logic and Practical Reasoning},
title = {{Modal mu-calculi}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1570246407800152},
volume = {3},
year = {2007}
}
@article{Hinze2001,
abstract = {This paper presents a new implementation technique for priority search queues. This abstract data type is an amazing blend of finite maps and priority queues. Our implementation supports logarithmic access to a binding with a given key and constant access to a binding with the minimum value. Priority search queues can be used, for instance, to give a simple, purely functional implementation of Dijkstra's single-source shortest-paths algorithm. A non-technical concern of the paper is to foster abstract data types and views. Priority search queues have been largely ignored by the functional programming community and we believe that they deserve to be known better. Views prove their worth both in defining a convenient interface to the abstract data type and in providing a readable implementation.},
author = {Hinze, Ralf},
doi = {10.1145/507669.507650},
file = {:Users/liang-tingchen/Dropbox/References/Hinze - 2001 - A simple implementation technique for priority search queues.pdf:pdf},
isbn = {1581134150},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {haskell,priority search queues,tournament,views},
month = {oct},
number = {10},
pages = {110},
title = {{A simple implementation technique for priority search queues}},
url = {http://portal.acm.org/citation.cfm?doid=507669.507650},
volume = {36},
year = {2001}
}
@article{Abramsky2020,
abstract = {We discuss how mathematical semantics has evolved, and suggest some new directions for future work. As an example, we discuss some recent work on encapsulating model comparison games as comonads, in the context of finite model theory.},
author = {Abramsky, Samson},
doi = {10.1016/j.tcs.2019.06.029},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2020 - Whither semantics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Category theory,Comonads,Finite model theory,Mathematical semantics,Model-theoretic games},
month = {feb},
pages = {3--14},
publisher = {Elsevier B.V.},
title = {{Whither semantics?}},
url = {https://doi.org/10.1016/j.tcs.2019.06.029 https://linkinghub.elsevier.com/retrieve/pii/S030439751930444X},
volume = {807},
year = {2020}
}
@article{Castro2011,
abstract = {In this paper, we investigate formal mechanisms to enable designers to decompose specifications (stated in a given logic) into several interacting components in such a way that the composition of these components preserves their encapsulation and internal non-determinism. The preservation of encapsulation (or locality) enables a modular form of reasoning over specifications, while the conservation of the internal non-determinism is important to guarantee that the branching time properties of components are not lost when the entire system is obtained. The basic ideas come from the work of Fiadeiro and Maibaum where notions from category theory are used to structure logical specifications. As the work of Fiadeiro and Maibaum is stated in a linear temporal logic, here we investigate how to extend these notions to a branching time logic, which can be used to reason about systems where non-determinism is present. To illustrate the practical applications of these ideas, we introduce deontic operators in our logic and we show that the modularization of specifications also allows designers to maintain the encapsulation of deontic prescriptions; this is in particular useful to reason about fault-tolerant systems, as we demonstrate with a small example.},
author = {Castro, Pablo F. and Maibaum, Thomas S.E.},
doi = {10.1016/j.tcs.2011.12.016},
file = {:Users/liang-tingchen/Dropbox/References/Castro, Maibaum - 2011 - Encapsulating deontic and branching time specifications.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {Category theory},
number = {0},
pages = {--},
title = {{Encapsulating deontic and branching time specifications}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/S0304397511009820},
year = {2011}
}
@article{Cancila2006,
author = {Cancila, Daniela and Honsell, Furio and Lenisa, Marina},
doi = {10.1016/j.entcs.2006.06.005},
file = {:Users/liang-tingchen/Dropbox/References/Cancila, Honsell, Lenisa - 2006 - Some Properties and Some Problems on Set Functors.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {category of sets,final coalgebra,functor,functor uniform on maps,inclusion preserving functor,set functor,$\kappa$-based functor,$\kappa$-reachable},
month = {oct},
number = {1},
pages = {67--84},
title = {{Some Properties and Some Problems on Set Functors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066106004701},
volume = {164},
year = {2006}
}
@article{Gupta2001,
author = {Gupta, Gopal and Pontelli, Enrico and Ali, Khayri A.M. and Carlsson, Mats and Hermenegildo, Manuel V.},
doi = {10.1145/504083.504085},
file = {:Users/liang-tingchen/Dropbox/References/Gupta et al. - 2001 - Parallel execution of prolog programs a survey.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
month = {jul},
number = {4},
pages = {472--602},
title = {{Parallel execution of prolog programs: a survey}},
url = {http://portal.acm.org/citation.cfm?doid=504083.504085},
volume = {23},
year = {2001}
}
@inproceedings{Johann2020,
abstract = {This paper introduces deep induction, and shows that it is the notion of induction most appropriate to nested types and other data types defined over, or mutually recursively with, (other) such types. Standard induction rules induct over only the top-level structure of data, leaving any data internal to the top-level structure untouched. By contrast, deep induction rules induct over all of the structured data present. We give a grammar generating a robust class of nested types (and thus ADTs), and develop a fundamental theory of deep induction for them using their recently defined semantics as fixed points of accessible functors on locally presentable categories. We then use our theory to derive deep induction rules for some common ADTs and nested types, and show how these rules specialize to give the standard structural induction rules for these types. We also show how deep induction specializes to solve the long-standing problem of deriving principled and practically useful structural induction rules for bushes and other truly nested types. Overall, deep induction opens the way to making induction principles appropriate to richly structured data types available in programming languages and proof assistants. Agda implementations of our development and examples, including two extended case studies, are available.},
author = {Johann, Patricia and Polonsky, Andrew},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2020},
doi = {10.1007/978-3-030-45231-5_18},
editor = {Goubault-Larrecq, Jean and K{\"{o}}nig, Barbara},
file = {:Users/liang-tingchen/Dropbox/References/Johann, Polonsky - 2020 - Deep Induction Induction Rules for (Truly) Nested Types.pdf:pdf},
isbn = {9783030452308},
issn = {16113349},
pages = {339--358},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Deep Induction: Induction Rules for (Truly) Nested Types}},
volume = {12077},
year = {2020}
}
@article{Kelly1997,
author = {Kelly, Gregory Maxwell and Lack, Stephen},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Lack - 1997 - On property-like structures.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {1997,2-category,and phrases,c g,kelly and stephen lack,m,monad,permission to copy for,private use granted,property,structure},
number = {9},
pages = {213--250},
title = {{On property-like structures}},
volume = {3},
year = {1997}
}
@article{Alur1994,
abstract = {We propose timed (finite) automata to model the behavior of real-time systems over time. Our definition provides a simple, and yet powerful, way to annotate state-transition graphs with timing constraints using finitely many real-valued clocks. A timed automaton accepts timed words–infinite sequences in which a real-valued time of occurrence is associated with each symbol. We study timed automata from the perspective of formal language theory: we consider closure properties, decision problems, and subclasses. We consider both nondeterministic and deterministic transition structures, and both B{\"{u}}chi and Muller acceptance conditions. We show that nondeterministic timed automata are closed under union and intersection, but not under complementation, whereas deterministic timed Muller automata are closed under all Boolean operations. The main construction of the paper is an (PSPACE) algorithm for checking the emptiness of the language of a (nondeterministic) timed automaton. We also prove that the universality problem and the language inclusion problem are solvable only for the deterministic automata: both problems are undecidable ($\Pi$11-hard) in the nondeterministic case and PSPACE-complete in the deterministic case. Finally, we discuss the application of this theory to automatic verification of real-time requirements of finite-state systems.},
author = {Alur, Rajeev and Dill, David L.},
doi = {10.1016/0304-3975(94)90010-8},
file = {:Users/liang-tingchen/Dropbox/References/Alur, Dill - 1994 - A theory of timed automata.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {apr},
number = {2},
pages = {183--235},
title = {{A theory of timed automata}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397594900108},
volume = {126},
year = {1994}
}
@article{Ducournau2011,
abstract = {Object-oriented programming represents an original implementation issue due to its philosophy of making the program behavior depend on the dynamic type of objects. This is expressed by the late binding mechanism, aka message sending. The underlying principle is that the address of the actually called procedure is not statically determined at compile-time, but depends on the dynamic type of a distinguished parameter known as the receiver. A similar issue arises with attributes, because their position in the object layout may also depend on the object's dynamic type. Furthermore, subtyping introduces another original feature (i.e., runtime subtype checks). All three mechanisms need specific implementations and data structures. In static typing, late binding is generally implemented with so-called virtual function tables. These tables reduce method calls to pointers to functions via a small fixed number of extra indirections. It follows that object-oriented programming yields some overhead, as compared to the usual procedural languages. The different techniques and their resulting overhead depend on several parameters. First, inheritance and subtyping may be single or multiple, and even a mixing is possible, as in Java and ˙NET which present single inheritance for classes and multiple subtyping for interfaces. Multiple inheritance is a well-known complication. Second, the production of executable programs may involve various schemes, from global compilation, which implies the closed-world assumption (CWA), as the whole program is known at compile time, to separate compilation and dynamic loading, where each program unit is compiled and loaded independently of any usage, hence under the open-world assumption (OWA). Global compilation is well-known to facilitate optimization. This article reviews the various implementation techniques available in static typing and in the three cases of single inheritance, multiple inheritance, and multiple subtyping. This language-independent survey focuses on separate compilation and dynamic loading, as they represent the most commonly used and the most demanding framework. However, many works have been undertaken in the global compilation framework, mostly for dynamically typed languages, but also applied to the EIFFEL language. Hence, we also examine global techniques and how they can improve implementation efficiency. Finally, mixed frameworks that combine open and closed world assumptions are considered. For instance, just-in-time (JIT) compilers work under provisional CWA, at the expense of possible recompilations. In contrast, we present an experimental compiler-linker, where separate compilation implies the OWA, whereas the whole program is finally linked under the CWA.},
author = {Ducournau, Roland},
doi = {10.1145/1922649.1922655},
file = {:Users/liang-tingchen/Dropbox/References/Ducournau - 2011 - Implementing statically typed object-oriented programming languages.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {apr},
number = {3},
pages = {1--48},
title = {{Implementing statically typed object-oriented programming languages}},
url = {http://portal.acm.org/citation.cfm?doid=1922649.1922655},
volume = {43},
year = {2011}
}
@book{Unknown,
address = {London},
author = {Hofmann, Martin},
doi = {10.1007/978-1-4471-0963-1},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann - 1997 - Extensional Constructs in Intensional Type Theory.pdf:pdf},
isbn = {978-1-4471-1243-3},
publisher = {Springer, London},
series = {CPHC/BCS Distinguished Dissertations},
title = {{Extensional Constructs in Intensional Type Theory}},
url = {http://link.springer.com/10.1007/978-1-4471-0963-1},
year = {1997}
}
@article{Isaksen2002,
abstract = {We present some constructions of limits and colimits in pro-categories. These are critical tools in several applications. In particular, certain technical arguments concerning strict pro-maps are essential for a theorem about $\backslash$'etale homotopy types. Also, we show that cofiltered limits in pro-categories commute with finite colimits.},
archivePrefix = {arXiv},
arxivId = {math/0106094},
author = {Isaksen, Daniel C.},
doi = {10.4064/fm175-2-7},
eprint = {0106094},
file = {:Users/liang-tingchen/Dropbox/References/Isaksen - 2002 - Calculating limits and colimits in pro-categories.pdf:pdf},
issn = {00162736},
journal = {Fundamenta Mathematicae},
keywords = {Colimit,Essentially of type C,Limit,Pro-abelian category,Pro-category},
number = {2},
pages = {175--194},
primaryClass = {math},
title = {{Calculating limits and colimits in pro-categories}},
volume = {175},
year = {2002}
}
@incollection{Fu2016,
author = {Fu, Peng and Komendantskaya, Ekaterina and Schrijvers, Tom and Pond, Andrew},
booktitle = {Functional and Logic Programming. FLOPS 2016},
doi = {10.1007/978-3-319-29604-3_9},
editor = {Kiselyov, Oleg and King, Andy},
file = {:Users/liang-tingchen/Dropbox/References/Fu et al. - 2016 - Proof Relevant Corecursive Resolution.pdf:pdf},
isbn = {9783319296036},
issn = {16113349},
keywords = {class inference,coinductive proofs,corecursion,haskell type,horn clause logic,resolution},
pages = {126--143},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Proof Relevant Corecursive Resolution}},
url = {http://link.springer.com/10.1007/978-3-319-29604-3{\_}9},
volume = {9613},
year = {2016}
}
@inproceedings{Kammar2013,
address = {New York, New York, USA},
author = {Kammar, Ohad and Lindley, Sam and Oury, Nicolas},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500590},
file = {:Users/liang-tingchen/Dropbox/References/Kammar, Lindley, Oury - 2013 - Handlers in action.pdf:pdf},
isbn = {9781450323260},
keywords = {algebraic effects,continuations,effect handlers,effect typing,haskell,instance monad,modularity},
pages = {145},
publisher = {ACM Press},
title = {{Handlers in action}},
url = {http://dl.acm.org/citation.cfm?doid=2500365.2500590},
year = {2013}
}
@article{Sabelfeld2003,
abstract = {Current standard security practices do not provide substantial assurance that the end-to-end behavior of a computing system satisfies important security policies such as confidentiality. An end-to-end confidentiality policy might assert that secret input data cannot be inferred by an attacker through the attacker's observations of system output; this policy regulates information flow. Conventional security mechanisms such as access control and encryption do not directly address the enforcement of information-flow policies. Previously, a promising new approach has been developed: the use of programming-language techniques for specifying and enforcing information-flow policies. In this paper, we survey the past three decades of research on information-flow security, particularly focusing on work that uses static program analysis to enforce information-flow policies. We give a structured view of work in the area and identify some important open challenges.},
author = {Sabelfeld, Andrei and Myers, A.C.},
doi = {10.1109/JSAC.2002.806121},
file = {:Users/liang-tingchen/Dropbox/References/Sabelfeld, Myers - 2003 - Language-based information-flow security.pdf:pdf},
isbn = {0733-8716},
issn = {0733-8716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Computer security,Concurrency,Confidentiality,Covert channels,Information flow,Noninterference,Security policies,Security-type systems},
month = {jan},
number = {1},
pages = {5--19},
title = {{Language-based information-flow security}},
url = {http://ieeexplore.ieee.org/document/1159651/},
volume = {21},
year = {2003}
}
@article{Hakli2012,
abstract = {Various sources in the literature claim that the deduction theorem does not hold for normal modal or epistemic logic, whereas others present versions of the deduction theorem for several normal modal systems. It is shown here that the apparent problem arises from an objectionable notion of derivability from assumptions in an axiomatic system. When a traditional Hilbert-type system of axiomatic logic is generalized into a system for derivations from assumptions, the necessitation rule has to be modified in a way that restricts its use to cases in which the premiss does not depend on assumptions. This restriction is entirely analogous to the restriction of the rule of universal generalization of first-order logic. A necessitation rule with this restriction permits a proof of the deduction theorem in its usual formulation. Other suggestions presented in the literature to deal with the problem are reviewed, and the present solution is argued to be preferable to the other alternatives. A contraction- and cut-free sequent calculus equivalent to the Hilbert system for basic modal logic shows the standard failure argument untenable by proving the underivability of □A from A. {\textcopyright} 2011 Springer Science+Business Media B.V.},
author = {Hakli, Raul and Negri, Sara},
doi = {10.1007/s11229-011-9905-9},
file = {:Users/liang-tingchen/Dropbox/References/Hakli, Negri - 2012 - Does the deduction theorem fail for modal logic.pdf:pdf},
issn = {0039-7857},
journal = {Synthese},
keywords = {Deduction theorem,Modal logic,Sequent calculus},
month = {aug},
number = {3},
pages = {849--867},
title = {{Does the deduction theorem fail for modal logic?}},
url = {http://link.springer.com/10.1007/s11229-011-9905-9},
volume = {187},
year = {2012}
}
@phdthesis{Silva2010,
author = {Silva, Alexandra},
file = {:Users/liang-tingchen/Dropbox/References/Silva - 2010 - Kleene Coalgebra.pdf:pdf},
isbn = {9789064644337},
month = {aug},
school = {Centrum Wiskunde {\&} Informatica},
title = {{Kleene Coalgebra}},
year = {2010}
}
@article{Omar2018,
abstract = {This paper develops a dynamic semantics for incomplete functional programs, based in part on the static semantics for incomplete functional programs developed in our recent work. We model incomplete functional programs as expressions with holes, with empty holes standing for missing expressions or types, and non-empty holes operating as "membranes" around static and dynamic type inconsistencies. Rather than aborting with an exception when evaluation encounters any of these holes (as in several existing systems), evaluation proceeds "around" the holes, performing as much of the remaining computation as is possible and tracking the closure around each hole instance as it flows through the program. Various editor services can report information from these hole closures to help the programmer decide how to fill a hole. They also enable a "fill-and-resume" feature that avoids the need to restart evaluation after edits that amount to hole filling. Formally, the semantics draws from both gradual type theory (to handle type holes) and contextual modal type theory (which provides a logical foundation for hole closures), and develops additional technical machinery necessary to continue evaluation past the various hole forms and to prove important metatheoretic properties. We have mechanized the core formal development using the Agda proof assistant. We also describe a simple implementation, called HazelnutLive, that inserts holes as necessary during the editing process to guarantee that every edit state has some (possibly incomplete) type, based in part on the Hazelnut edit action calculus in our recent work. Taken together with the type safety property that this paper establishes, the result is a proof-of-concept live typed functional programming environment where dynamic feedback is truly continuous, i.e. it is available for every possible edit state.},
archivePrefix = {arXiv},
arxivId = {1805.00155},
author = {Omar, Cyrus and Voysey, Ian and Chugh, Ravi and Hammer, Matthew A.},
doi = {10.1145/3290327},
eprint = {1805.00155},
file = {:Users/liang-tingchen/Dropbox/References/Omar et al. - 2019 - Live functional programming with typed holes.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {contextual modal type theory,gradual typing,live programming,structured editing,typed holes},
month = {jan},
number = {POPL},
pages = {1--32},
title = {{Live functional programming with typed holes}},
url = {http://arxiv.org/abs/1805.00155 http://dl.acm.org/citation.cfm?doid=3302515.3290327},
volume = {3},
year = {2019}
}
@inproceedings{Fiore2020a,
abstract = {We present two proofs of coherence for cartesian closed bicategories. Precisely, we show that in the free cartesian closed bicategory on a set of objects there is at most one structural 2-cell between any parallel pair of 1-cells. We thereby reduce the difficulty of constructing structure in arbitrary cartesian closed bicategories to the level of 1-dimensional category theory. Our first proof follows a traditional approach using the Yoneda lemma. For the second proof, we adapt Fiore's categorical analysis of normalisation-by-evaluation for the simply-typed lambda calculus. Modulo the construction of suitable bicategorical structures, the argument is not significantly more complex than its 1-categorical counterpart. It also opens the way for further proofs of coherence using (adaptations of) tools from categorical semantics.},
address = {New York, NY, USA},
author = {Fiore, Marcelo and Saville, Philip},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394769},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Saville - 2020 - Coherence and normalisation-by-evaluation for bicategorical cartesian closed structure.pdf:pdf},
isbn = {9781450371049},
keywords = {bicategories,cartesian closure,coherence,normalisation,normalisation-by-evaluation,type theory},
month = {jul},
pages = {425--439},
publisher = {ACM},
title = {{Coherence and normalisation-by-evaluation for bicategorical cartesian closed structure}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394769},
year = {2020}
}
@inproceedings{Hofmann2008,
author = {Hofmann, M.},
booktitle = {Proceedings. 14th Symposium on Logic in Computer Science (Cat. No. PR00158)},
doi = {10.1109/LICS.1999.782616},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann - 2008 - Semantical analysis of higher-order abstract syntax.pdf:pdf},
isbn = {0-7695-0158-3},
pages = {204--213},
publisher = {IEEE Comput. Soc},
title = {{Semantical analysis of higher-order abstract syntax}},
url = {http://ieeexplore.ieee.org/document/782616/},
year = {2008}
}
@book{Levy2003,
abstract = {Call-by-push-value is a programming language paradigm that, surprisingly, breaks down the call-by-value and call-by-name paradigms into simple primitives. This monograph, written for graduate students and researchers, exposes the call-by-push-value structure underlying a remarkable range of semantics, including operational semantics, domains, possible worlds, continuations and games.},
author = {Levy, Paul Blain},
doi = {10.1007/978-94-007-0954-6},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2003 - Call-By-Push-Value.pdf:pdf},
isbn = {978-94-010-3752-5},
publisher = {Springer, Dordrecht},
series = {Semantic Structures in Computation},
title = {{Call-By-Push-Value}},
type = {Book},
url = {http://link.springer.com/10.1007/978-94-007-0954-6},
year = {2003}
}
@article{Esik1983,
abstract = {The equational class generated by rational algebraic theories was characterized in Esik, Comput. Linguistics and Comput. Languages XIV (1980), 183-207. Here, this class will be called the class of iteration theories. Also, there is a close connection between Elgot's iterative theories and iteration theories. In this paper we introduce algebras for iteration theories, called iteration algebras. Iteration algebras are natural generalization of regular algebras and they are closely related to iterative algebras as well. It is shown that the absolutely free iteration algebras are the algebras of regular trees. {\textcopyright} 1983.},
author = {{\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1016/0022-0000(83)90044-2},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 1983 - Algebras of iteration theories.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {oct},
number = {2},
pages = {291--303},
title = {{Algebras of iteration theories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000083900442},
volume = {27},
year = {1983}
}
@article{Lamport1977,
abstract = {The inductive assertion method is generalized to permit formal, machine-verifiable proofs of correctness for multiprocess programs. Individual processes are represented by ordinary flowcharts, and no special synchronization mechanisms are assumed, so the method can be applied to a large class of multiprocess programs. A correctness proof can be designed together with the program by a hierarchical process of stepwise refinement, making the method practical for larger programs. The resulting proofs tend to be natural formalizations of the informal proofs that are now used.},
author = {Lamport, Leslie},
doi = {10.1109/TSE.1977.229904},
file = {:Users/liang-tingchen/Dropbox/References/Lamport - 1977 - Proving the correctness of multiprocess programs.pdf:pdf},
isbn = {10.1109/TSE.1977.229904},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {assertions,concufrent programming,correctness,multiprocessing,synchronization},
month = {mar},
number = {2},
pages = {125--143},
title = {{Proving the correctness of multiprocess programs}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1702415 http://ieeexplore.ieee.org/document/1702415/},
volume = {SE-3},
year = {1977}
}
@inproceedings{Lago2017,
abstract = {We introduce a geometry of interaction model for Mazza's multiport interaction combinators, a graph-theoretic formalism which is able to faithfully capture concurrent computation as embodied by process algebras like the {\$}\backslashpi{\$}-calculus. The introduced model is based on token machines in which not one but multiple tokens are allowed to traverse the underlying net at the same time. We prove soundness and adequacy of the introduced model. The former is proved as a simulation result between the token machines one obtains along any reduction sequence. The latter is obtained by a fine analysis of convergence, both in nets and in token machines.},
archivePrefix = {arXiv},
arxivId = {1704.04620},
author = {Lago, Ugo Dal and Tanaka, Ryo and Yoshimizu, Akira},
booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2017.8005112},
eprint = {1704.04620},
file = {:Users/liang-tingchen/Dropbox/References/Lago, Tanaka, Yoshimizu - 2017 - The geometry of concurrent interaction Handling multiple ports by way of multiple tokens.pdf:pdf},
isbn = {978-1-5090-3018-7},
issn = {10436871},
month = {jun},
pages = {1--12},
publisher = {IEEE},
title = {{The geometry of concurrent interaction: Handling multiple ports by way of multiple tokens}},
url = {http://ieeexplore.ieee.org/document/8005112/},
year = {2017}
}
@article{Eklund2013,
abstract = {In this paper we will show how purely categorical constructions of terms are advantageous when investigating situations concerning uncertainty; more specifically where uncertainty comes from and how uncertainty is integrated when dealing with terms over selected signatures. There are basically two ways of invoking uncertainty for terms. On one hand, we may proceed by building composed monads where uncertainty is provided by some suitable monad composed with the traditional term monad. On the other hand, we can provide a strictly formal basis for term monads being created over categories themselves carrying uncertainty. This is the distinction between 'computing with fuzzy' and 'fuzzy computing' and the fundamental question raised by these constructions is where uncertainty resides in language constructions for logic. This paper also shows how the notion of signature often needs to be expanded to levels of signatures, in particular when dealing with type constructors. Such levels allow us to strictly delineate, e.g., primitive operations, type terms, and value level terms. Levels of signature will in this paper be exemplified by the construction of the signature of simply typed lambda calculus. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Eklund, Patrik and Gal{\'{a}}n, M. {\'{A}}ngeles and Helgesson, Robert and Kortelainen, Jari},
doi = {10.1016/j.fss.2013.02.012},
file = {:Users/liang-tingchen/Dropbox/References/Eklund et al. - 2013 - Fuzzy terms.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Algebra,Category theory,Quantale,Term monads},
pages = {211--235},
publisher = {Elsevier},
title = {{Fuzzy terms}},
url = {http://dx.doi.org/10.1016/j.fss.2013.02.012},
volume = {256},
year = {2013}
}
@article{Antoniou2007a,
abstract = {Nonmonotonic rule systems are expected to play an important role in the layered development of the semantic Web. Defeasible reasoning is a direction in nonmonotonic reasoning that is based on the use of rules that may be defeated by other rules. It is a simple, but often more efficient approach than other nonmonotonic rule systems for reasoning with incomplete and inconsistent information. This paper reports on the implementation of a system for defeasible reasoning on the Web. The system 1) is syntactically compatible with RuleML, 2) features strict and defeasible rules, priorities, and two kinds of negation, 3) is based on a translation to logic programming with declarative semantics, 4) is flexible and adaptable to different intuitions within defeasible reasoning, and 5) can reason with rules, RDF, RDF Schema, and (parts of) OWL ontologies},
author = {Antoniou, Grigoris and Bikakis, Antonis},
doi = {10.1109/TKDE.2007.29},
file = {:Users/liang-tingchen/Dropbox/References/Antoniou, Bikakis - 2007 - DR-Prolog A System for Defeasible Reasoning with Rules and Ontologies on the Semantic Web.pdf:pdf},
isbn = {1041-4347},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Nonmonotonic reasoning,Rules,Semantic,Web reasoning},
month = {feb},
number = {2},
pages = {233--245},
title = {{DR-Prolog: A System for Defeasible Reasoning with Rules and Ontologies on the Semantic Web}},
url = {http://ieeexplore.ieee.org/document/4039286/},
volume = {19},
year = {2007}
}
@article{Perera2018,
abstract = {We present a formalisation in Agda of the theory of concurrent transitions, residuation and causal equivalence of traces for the $\pi$-calculus. Our formalisation employs de Bruijn indices and dependently typed syntax, and aligns the ‘proved transitions' proposed by Boudol and Castellani in the context of CCS with the proof terms naturally present in Agda's representation of the labelled transition relation. Our main contributions are proofs of the ‘diamond lemma' for the residuals of concurrent transitions and a formal definition of equivalence of traces up to permutation of transitions.},
archivePrefix = {arXiv},
arxivId = {1604.04575},
author = {PERERA, ROLY and CHENEY, JAMES},
doi = {10.1017/S096012951700010X},
eprint = {1604.04575},
file = {:Users/liang-tingchen/Dropbox/References/PERERA, CHENEY - 2018 - Proof-relevant $\pi$-calculus a constructive account of concurrency and causality.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {09},
pages = {1541--1577},
title = {{Proof-relevant $\pi$-calculus: a constructive account of concurrency and causality}},
url = {https://www.cambridge.org/core/product/identifier/S096012951700010X/type/journal{\_}article},
volume = {28},
year = {2018}
}
@article{Mcbride2010,
abstract = {This paper re-examines the presentation of datatypes in dependently typed languages, addressing in particular the issue of what it means for one datatype to be in various ways more informative than another. Informal human observations like 'lists are natural numbers with extra labels' and 'vectors are lists indexed by length' are expressed in a first class language of ornaments—presentations of fancy new types based on plain old ones. Each ornament adds information, so it comes with a forgetful function from fancy data back to plain, expressible as the fold of its ornamental algebra: lists built from numbers acquire the 'length' algebra. Conversely, each algebra for a datatype induces a way to index it—an algebraic ornament. The length algebra for lists induces the construction of the paradigmatic dependent vector types. Dependent types thus provide not only a new 'axis of diversity'—indexing—for data structures, but also new abstractions to manage and exploit that diversity. In the new programming (2), coinci-dence is replaced by consequence.},
author = {McBride, Conor},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2010 - Ornamental Algebras, Algebraic Ornaments.pdf:pdf},
number = {August},
title = {{Ornamental Algebras, Algebraic Ornaments}},
year = {2010}
}
@article{Morales1996,
author = {Morales, Domingo and Pardo, Leandro and Vajda, Igor},
doi = {10.1109/3468.541329},
file = {:Users/liang-tingchen/Dropbox/References/Morales, Pardo, Vajda - 1996 - Uncertainty of discrete stochastic systems general theory and statistical inference.pdf:pdf},
issn = {10834427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
number = {6},
pages = {681--697},
title = {{Uncertainty of discrete stochastic systems: general theory and statistical inference}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=541329{\%}5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=541329 http://ieeexplore.ieee.org/document/541329/},
volume = {26},
year = {1996}
}
@article{Maietti2009,
abstract = {We present a two-level theory to formalize constructive mathematics as advocated in a previous paper with G. Sambin. One level is given by an intensional type theory, called Minimal type theory. This theory extends a previous version with collections. The other level is given by an extensional set theory that is interpreted in the first one by means of a quotient model. This two-level theory has two main features: it is minimal among the most relevant foundations for constructive mathematics; it is constructive thanks to the way the extensional level is linked to the intensional one which fulfills the "proofs-as-programs" paradigm and acts as a programming language. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0811.2774},
author = {Maietti, Maria Emilia},
doi = {10.1016/j.apal.2009.01.006},
eprint = {0811.2774},
file = {:Users/liang-tingchen/Dropbox/References/Maietti - 2009 - A minimalist two-level foundation for constructive mathematics.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Intuitionistic logic,Set theory,Type theory},
month = {sep},
number = {3},
pages = {319--354},
publisher = {Elsevier B.V.},
title = {{A minimalist two-level foundation for constructive mathematics}},
url = {http://dx.doi.org/10.1016/j.apal.2009.01.006 https://linkinghub.elsevier.com/retrieve/pii/S0168007209000104},
volume = {160},
year = {2009}
}
@book{Manes1986,
address = {New York, NY},
author = {Manes, Ernest G. and Arbib, Michael A.},
doi = {10.1007/978-1-4612-4962-7},
isbn = {978-1-4612-9377-4},
publisher = {Springer New York},
title = {{Algebraic Approaches to Program Semantics}},
url = {http://www.springerlink.com/index/10.1007/978-1-4612-4962-7},
year = {1986}
}
@article{Fiore2004,
archivePrefix = {arXiv},
arxivId = {math/0408298},
author = {Fiore, Thomas M.},
eprint = {0408298},
file = {:Users/liang-tingchen/Dropbox/References/Fiore - 2004 - Pseudo Limits, Biadjoints, and Pseudo Algebras Categorical Foundations of Conformal Field Theory.pdf:pdf},
journal = {ArXiv e-prints},
month = {aug},
primaryClass = {math},
title = {{Pseudo Limits, Biadjoints, and Pseudo Algebras: Categorical Foundations of Conformal Field Theory}},
url = {http://arxiv.org/abs/math/0408298v4},
year = {2004}
}
@inproceedings{DePaiva2016,
abstract = {This paper describes a fibrational categorical semantics for the modal necessity-only fragment of constructive modal type theory, both with and without dependent types. Constructive type theory does not usually discuss logical modalities, and modalities tend to be mostly studied within classical logic, not within type theory. But modalities should be very useful in type theory, as they are very useful in modelling theoretical computing systems. Providing constructive versions of modal logics and their associated Curry-Howard modal type theories is also a very productive program, e.g. helpful when dealing with computational effects, staged computation, and functional reactive types, for example. There seems to be renewed interest in the notion of constructive modal type theory (and in notions of linear type theory), in part because of the interest in homotopy type theory. The modal type theory presented here uses dependent types, in the style of Ritter's categorical models of the Calculus of Constructions. To build up to these, we first discuss the kinds of constructive modal type theory in the literature. Then we provide a non-dependent modal type theory, introduced in previous work, that we generalize to dependent types in the following section. Dependent type theories are usually but not always given categorical semantics in terms of fibrations. We provide semantics in terms of fibrations for both the non-dependent and the dependent type systems discussed and prove them sound and complete, thereby providing evidence that the type theory is meaningful. These fibrational models should be also applicable to the homotopy type theory setting.},
author = {de Paiva, Valeria and Ritter, Eike},
booktitle = {Proceedings of the Tenth Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2015)},
doi = {10.1016/j.entcs.2016.06.010},
file = {:Users/liang-tingchen/Dropbox/References/de Paiva, Ritter - 2016 - Fibrational Modal Type Theory.pdf:pdf},
issn = {15710661},
keywords = {categorical models,fibrations,modal logic},
month = {jul},
pages = {143--161},
publisher = {Elsevier B.V.},
title = {{Fibrational Modal Type Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2016.06.010 https://linkinghub.elsevier.com/retrieve/pii/S1571066116300378},
volume = {323},
year = {2016}
}
@inproceedings{Swamy2016a,
abstract = {We present a new, completely redesigned, version of F∗, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F? is a dependently typed, higher-order, call-by-value language with primitive effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F∗ uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F∗ is a language of pure functions used to write specifications and proof terms-its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F∗ we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F∗ is programmed (but not verified) in F∗, and bootstraps in both OCaml and F{\#}. Our experience confirms F∗'s pay-As-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F∗ is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F∗ than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F∗ in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System Fw and even $\mu$F∗, a sizeable fragment of F∗ itself-these proofs make essential use of F∗'s flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.},
address = {New York, New York, USA},
author = {Swamy, Nikhil and Kohlweiss, Markulf and Zinzindohoue, Jean-Karim and Zanella-B{\'{e}}guelin, Santiago and Hriţcu, Cătălin and Keller, Chantal and Rastogi, Aseem and Delignat-Lavaud, Antoine and Forest, Simon and Bhargavan, Karthikeyan and Fournet, C{\'{e}}dric and Strub, Pierre-Yves},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL 2016},
doi = {10.1145/2837614.2837655},
file = {:Users/liang-tingchen/Dropbox/References//Swamy et al. - 2016 - Dependent types and multi-monadic effects in F.pdf:pdf},
isbn = {9781450335492},
issn = {15232867},
keywords = {Effectful programming,Proof assistants,Verification,advantage and that copies,all or part of,bear this notice and,classroom use is granted,copies are not made,effectful programming,for profit or commercial,or,or distributed,or hard copies of,permission to make digital,proof assistants,the full citation,this work for personal,verification,without fee provided that},
month = {jan},
number = {1},
pages = {256--270},
publisher = {ACM Press},
title = {{Dependent types and multi-monadic effects in F*}},
url = {http://dl.acm.org/citation.cfm?doid=2914770.2837655 http://dl.acm.org/citation.cfm?doid=2837614.2837655},
volume = {51},
year = {2016}
}
@article{Cirstea2007,
abstract = {We present a modular approach to defining logics for a wide variety of state-based systems. The systems are modelled as coalgebras, and we use modal logics to specify their observable properties. We show that the syntax, semantics and proof systems associated with such logics can all be derived in a modular fashion. Moreover, we show that the logics thus obtained inherit soundness, completeness and expressiveness properties from their building blocks. We apply these techniques to derive sound, complete and expressive logics for a wide variety of probabilistic systems, for which no complete axiomatisation has been obtained so far.},
annote = {one-step semantics is equivalent to a natural transformation d : LP -{\textgreater} PT},
author = {C{\^{i}}rstea, Corina and Pattinson, Dirk},
doi = {10.1016/j.tcs.2007.06.002},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea, Pattinson - 2007 - Modular construction of complete coalgebraic logics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebra,completeness,modal logic,probabilistic systems},
month = {dec},
number = {1-3},
pages = {83--108},
title = {{Modular construction of complete coalgebraic logics}},
url = {http://dx.doi.org/10.1016/j.tcs.2007.06.002},
volume = {388},
year = {2007}
}
@article{Urabe2016c,
abstract = {Notions of simulation, among other uses, provide a computationally tractable and sound (but not necessarily complete) proof method for language inclusion. They have been comprehensively studied by Lynch and Vaandrager for nondeterministic and timed systems; for (nondeterministic) Buechi automata the notion of fair simulation has been introduced by Henzinger, Kupferman and Rajamani. We contribute generalization of fair simulation in two different directions: one for nondeterministic tree automata (this has been studied previously by Bomhard); and the other for probabilistic word automata (with a finite state space), both under the Buechi acceptance condition. The former (nondeterministic) definition is formulated in terms of systems of fixed-point equations, hence is readily translated to parity games and then amenable to Jurdzinski's algorithm; the latter (probabilistic) definition bears a strong ranking-function flavor. These two different-looking definitions are derived from one source, namely our coalgebraic modeling of Buechi automata; the proofs of soundness (i.e. that a simulation indeed witnesses language inclusion) are based on these coalgebraic observations, too.},
archivePrefix = {arXiv},
arxivId = {1606.04680},
author = {Urabe, Natsuki and Shimizu, Shunsuke and Hasuo, Ichiro},
eprint = {1606.04680},
file = {:Users/liang-tingchen/Dropbox/References/Urabe, Shimizu, Hasuo - 2016 - Fair simulation for nondeterministic and probabilistic B{\"{u}}chi automata a coalgebraic perspective.pdf:pdf},
journal = {ArXiv preprint},
keywords = {and phrases},
month = {jun},
pages = {1--33},
title = {{Fair simulation for nondeterministic and probabilistic B{\"{u}}chi automata: a coalgebraic perspective}},
url = {http://arxiv.org/abs/1606.04680},
year = {2016}
}
@article{Morihata2021,
abstract = {Parallel reduction is a major component of parallel programming and widely used for summarisation and aggregation. It is not well understood, however, what sorts of non-trivial summarisations can be implemented as parallel reductions. This paper develops a calculus named $\lambda$ AS , a simply typed lambda calculus with algebraic simplification. This calculus provides a foundation for studying a parallelisation of complex reductions by equational reasoning. Its key feature is $\delta$ abstraction. A $\delta$ abstraction is observationally equivalent to the standard $\lambda$ abstraction, but its body is simplified before the arrival of its arguments using algebraic properties such as associativity and commutativity. In addition, the type system of $\lambda$ AS guarantees that simplifications due to $\delta$ abstractions do not lead to serious overheads. The usefulness of $\lambda$ AS is demonstrated on examples of developing complex parallel reductions, including those containing more than one reduction operator, loops with conditional jumps, prefix sum patterns and even tree manipulations.},
author = {MORIHATA, AKIMASA},
doi = {10.1017/S0956796821000058},
file = {:Users/liang-tingchen/Dropbox/References/MORIHATA - 2021 - Lambda calculus with algebraic simplification for reduction parallelisation Extended study.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {apr},
pages = {e7},
title = {{Lambda calculus with algebraic simplification for reduction parallelisation: Extended study}},
url = {https://www.cambridge.org/core/product/identifier/S0956796821000058/type/journal{\_}article},
volume = {31},
year = {2021}
}
@article{Ziliani2017,
abstract = {Unification is a core component of every proof assistant or programming language featuring dependent types. In many cases, it must deal with higher order problems up to conversion. Since unification in such conditions is undecidable, unification algorithms may include several heuristics to solve common problems. However, when the stack of heuristics grows large, the result and complexity of the algorithm can become unpredictable. Our contributions are twofold: (1) We present a full description of a new unification algorithm for the Calculus of Inductive Constructions (the base logic of C OQ ), building it up from a basic calculus to the full Calculus of Inductive Constructions as it is implemented in C OQ , including universe polymorphism, canonical structures (the overloading mechanism baked into C OQ 's unification), and a small set of useful heuristics. (2) We implemented our algorithm, and tested it on several libraries, providing evidence that the selected set of heuristics suffices for large developments.},
author = {ZILIANI, BETA and SOZEAU, MATTHIEU},
doi = {10.1017/S0956796817000028},
file = {:Users/liang-tingchen/Dropbox/References/ZILIANI, SOZEAU - 2017 - A comprehensible guide to a new unifier for CIC including universe polymorphism and overloading.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {feb},
number = {e10},
pages = {63},
publisher = {Cambridge University Press},
title = {{A comprehensible guide to a new unifier for CIC including universe polymorphism and overloading}},
url = {https://www.cambridge.org/core/product/identifier/S0956796817000028/type/journal{\_}article},
volume = {27},
year = {2017}
}
@article{Christiansen2019,
author = {Christiansen, David Thrane and Diatchki, Iavor S and Dockins, Robert and Hendrix, Joe and Ravitch, Tristan},
doi = {10.1145/3341704},
file = {:Users/liang-tingchen/Dropbox/References/Christiansen et al. - 2019 - Dependently typed Haskell in industry (experience report).pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Haskell,dependent types,performance},
month = {jul},
number = {ICFP},
pages = {1--16},
title = {{Dependently typed Haskell in industry (experience report)}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341704},
volume = {3},
year = {2019}
}
@incollection{Bull1984,
address = {Dordrecht},
author = {Bull, Robert and Segerberg, Krister},
booktitle = {Handbook of Philosophical Logic},
doi = {10.1007/978-94-009-6259-0_1},
editor = {Gabbay, D. and Guenthner, F.},
pages = {1--88},
publisher = {Springer, Dordrecht},
series = {Synthese Library (Studies in Epistemology, Logic, Methodology, and Philosophy of Science)},
title = {{Basic Modal Logic}},
url = {http://link.springer.com/10.1007/978-94-009-6259-0{\_}1},
volume = {165},
year = {1984}
}
@article{Johnstone2001a,
author = {Johnstone, Peter T. and Power, A. John and Tsujishita, Toru and Watanabe, Hiroshi and Worrell, James},
doi = {doi:%20DOI:%2010.1016/S0304-3975(00)00124-9},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone et al. - 2001 - On the structure of categories of coalgebras.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {Classifier,Coalgebra,Cofree comonad,Subobject,Topos,Weak pullback,classifier,coalgebra,cofree,comonad,pullback,subobject,topos,weak},
mendeley-tags = {classifier,coalgebra,cofree,comonad,pullback,subobject,topos,weak},
month = {jun},
number = {1-2},
pages = {87--117},
title = {{On the structure of categories of coalgebras}},
type = {Journal article},
volume = {260},
year = {2001}
}
@article{Barthe2016a,
author = {Barthe, Gilles and Gaboardi, Marco and Hsu, Justin and Pierce, Benjamin},
doi = {10.1145/2893582.2893591},
file = {:Users/liang-tingchen/Dropbox/References/Barthe et al. - 2016 - Programming language techniques for differential privacy.pdf:pdf},
issn = {2372-3491},
journal = {ACM SIGLOG News},
number = {1},
pages = {34--53},
title = {{Programming language techniques for differential privacy}},
url = {http://doi.acm.org/10.1145/2893582.2893591},
volume = {3},
year = {2016}
}
@incollection{Winant2014,
author = {Winant, Thomas and Devriese, Dominique and Piessens, Frank and Schrijvers, Tom},
booktitle = {Practical Aspects of Declarative Languages. PADL 2014},
doi = {10.1007/978-3-319-04132-2_2},
editor = {Flatt, Matthew and Guo, Hai-Feng},
file = {:Users/liang-tingchen/Dropbox/References/Winant et al. - 2014 - Partial type signatures for Haskell.pdf:pdf},
isbn = {9783319041315},
issn = {03029743},
keywords = {(partial) type signatures,Haskell,Hindley-Milner type inference,wildcards},
pages = {17--32},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Partial type signatures for Haskell}},
volume = {8324},
year = {2014}
}
@phdthesis{Knapp2018,
author = {Knapp, Cory M.},
file = {:Users/liang-tingchen/Dropbox/References/Knapp - 2018 - Partial Functions and Recursion in Univalent Type Theory.pdf:pdf},
school = {University of Birmingham},
title = {{Partial Functions and Recursion in Univalent Type Theory}},
type = {Doctoral Thesis},
url = {http://etheses.bham.ac.uk/id/eprint/8448},
year = {2018}
}
@article{Grayson2018,
author = {Grayson, Daniel R},
doi = {10.1090/bull/1616},
file = {:Users/liang-tingchen/Dropbox/References/Grayson - 2018 - An introduction to univalent foundations for mathematicians.pdf:pdf},
issn = {0273-0979},
journal = {Bulletin of the American Mathematical Society},
keywords = {Homotopy type theory,identity type,type theory},
month = {mar},
number = {4},
pages = {427--450},
title = {{An introduction to univalent foundations for mathematicians}},
url = {http://www.ams.org/bull/2018-55-04/S0273-0979-2018-01616-9/},
volume = {55},
year = {2018}
}
@article{Descotte2014,
archivePrefix = {arXiv},
arxivId = {1406.5762},
author = {Descotte, M. Emilia and Dubuc, Eduardo J.},
eprint = {1406.5762},
file = {:Users/liang-tingchen/Dropbox/References/Descotte, Dubuc - 2014 - A theory of 2-pro-objects (with expanded proofs).pdf:pdf},
journal = {ArXiv e-prints},
month = {jun},
pages = {1--33},
title = {{A theory of 2-pro-objects (with expanded proofs)}},
url = {http://arxiv.org/abs/1406.5762v1},
year = {2014}
}
@book{Dubuc1970,
author = {Dubuc, Eduardo J.},
doi = {10.1007/BFb0060485},
file = {:Users/liang-tingchen/Dropbox/References/Dubuc - 1970 - Kan extensions in Enriched Category Theory.pdf:pdf},
isbn = {978-3-540-04934-0},
pmid = {13771357},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Kan extensions in Enriched Category Theory}},
url = {http://link.springer.com/10.1007/BFb0060485},
volume = {145},
year = {1970}
}
@article{Farka2018,
abstract = {First-order resolution has been used for type inference for many years, including in Hindley-Milner type inference, type-classes, and constrained data types. Dependent types are a new trend in functional languages. In this paper, we show that proof-relevant first-order resolution can play an important role in automating type inference and term synthesis for dependently typed languages. We propose a calculus that translates type inference and term synthesis problems in a dependently typed language to a logic program and a goal in the proof-relevant first-order Horn clause logic. The computed answer substitution and proof term then provide a solution to the given type inference and term synthesis problem. We prove the decidability and soundness of our method.},
archivePrefix = {arXiv},
arxivId = {arXiv:1804.11250v1},
author = {Farka, Franti{\v{s}}ek Frantisek and Komendantskaya, Ekaterina and Hammond, Kevin},
doi = {10.1017/S1471068418000212},
eprint = {arXiv:1804.11250v1},
file = {:Users/liang-tingchen/Dropbox/References/Farka, Komendantskaya, Hammond - 2018 - Proof-relevant Horn Clauses for Dependent Type Inference and Term Synthesis.pdf:pdf},
issn = {1471-0684},
journal = {Theory and Practice of Logic Programming},
keywords = {Dependent types,Horn clauses,Proof-relevant logic,Proof-relevant resolution,Type Inference},
month = {jul},
number = {3-4},
pages = {484--501},
title = {{Proof-relevant Horn Clauses for Dependent Type Inference and Term Synthesis}},
url = {https://www.cambridge.org/core/product/identifier/S1471068418000212/type/journal{\_}article},
volume = {18},
year = {2018}
}
@article{Jung2017,
abstract = {Rust is a new systems programming language that promises to overcome the seemingly fundamental tradeoff between high-level safety guarantees and low-level control over resource management. Unfortunately, none of Rust's safety claims have been formally proven, and there is good reason to question whether they actually hold. Specifically, Rust employs a strong, ownership-based type system, but then extends the expressive power of this core type system through libraries that internally use unsafe features. In this paper, we give the first formal (and machine-checked) safety proof for a language representing a realistic subset of Rust. Our proof is extensible in the sense that, for each new Rust library that uses unsafe features, we can say what verification condition it must satisfy in order for it to be deemed a safe extension to the language. We have carried out this verification for some of the most important libraries that are used throughout the Rust ecosystem.},
author = {Jung, Ralf and Jourdan, Jacques-Henri and Krebbers, Robbert and Dreyer, Derek},
doi = {10.1145/3158154},
file = {:Users/liang-tingchen/Dropbox/References/Jung et al. - 2017 - RustBelt securing the foundations of the rust programming language.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Rust,concurrency,logical relations,separation logic,type systems},
month = {dec},
number = {POPL},
pages = {1--34},
title = {{RustBelt: securing the foundations of the rust programming language}},
url = {http://dl.acm.org/citation.cfm?doid=3177123.3158154},
volume = {2},
year = {2017}
}
@article{Logic2008,
abstract = {In this paper we give a new proof of the characterization of the closed fragment of the provability logic of Heyting's Arithmetic. We also provide a characterization of the closed fragment of the provability logic of Heyting's Arithmetic plus Markov's Principle and Heyting's Arithmetic plus Primitive Recursive Markov's Principle.},
author = {Visser, Albert},
doi = {10.2178/jsl/1230396766},
file = {:Users/liang-tingchen/Dropbox/References/Visser - 2008 - Closed Fragments of Provability Logics of Constructive Theories.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {sep},
number = {3},
pages = {1081--1096},
title = {{Closed Fragments of Provability Logics of Constructive Theories}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200004369/type/journal{\_}article},
volume = {73},
year = {2008}
}
@phdthesis{Kovacs2017,
author = {Kov{\'{a}}cs, Andr{\'{a}}s},
file = {:Users/liang-tingchen/Dropbox/References/Kov{\'{a}}cs - 2017 - A Machine-Checked Correctness Proof of Normalization by Evaluation for Simply Typed Lambda Calculus.pdf:pdf},
school = {E{\"{o}}tv{\"{o}}s Lor{\'{a}}nd University},
title = {{A Machine-Checked Correctness Proof of Normalization by Evaluation for Simply Typed Lambda Calculus}},
type = {Master},
url = {https://github.com/AndrasKovacs/stlc-nbe/blob/separate-PSh/thesis.pdf},
year = {2017}
}
@inproceedings{Chu2016,
abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1607.00133v1},
author = {Abadi, Martı́n and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security - CCS'16},
doi = {10.1145/2976749.2978318},
eprint = {arXiv:1607.00133v1},
file = {:Users/liang-tingchen/Dropbox/References/Abadi et al. - 2016 - Deep Learning with Differential Privacy.pdf:pdf},
isbn = {9781450341394},
issn = {9781450321389},
pages = {308--318},
publisher = {ACM Press},
title = {{Deep Learning with Differential Privacy}},
url = {http://dl.acm.org/citation.cfm?doid=2976749.2978318},
year = {2016}
}
@book{Bertot2004,
address = {Berlin, Heidelberg},
author = {Bertot, Yves and Cast{\'{e}}ran, Pierre},
doi = {10.1007/978-3-662-07964-5},
isbn = {978-3-642-05880-6},
publisher = {Springer Berlin Heidelberg},
series = {Texts in Theoretical Computer Science An EATCS Series},
title = {{Interactive Theorem Proving and Program Development}},
url = {http://link.springer.com/10.1007/978-3-662-07964-5},
year = {2004}
}
@article{Mulry1994,
abstract = {In this paper we consider two conceptually different categorical approaches to partiality namely partial map classifiers (pmcs) with total maps, and partial cartesian closed categories (pcccs) pC with partial maps, showing how these approaches are intimately related. While a topos setting generally provides a richer setting for defining possible pmcs and classes of partial maps, conditions are derived that determine when pmcs and partial maps can in fact restrict to pC. In this way semantic constructs can be interpreted consistently from both approaches. Various examples involving domains and cpos are examined as is the connection to Kleisli categories. Finally, it is observed that a general categorical framework involving monads arises naturally in this context. ?? 1994.},
author = {Mulry, Philip S.},
doi = {10.1016/0304-3975(94)00124-2},
file = {:Users/liang-tingchen/Dropbox/References/Mulry - 1994 - Partial map classifiers and partial cartesian closed categories.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1},
pages = {109--123},
title = {{Partial map classifiers and partial cartesian closed categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397594001242},
volume = {136},
year = {1994}
}
@article{Kamareddine2016,
abstract = {There are two versions of type assignment in the $\lambda$-calculus: Church-style, in which the type of each variable is fixed, and Curry-style (also called "domain free"), in which it is not. As an example, in Church-style typing, $\lambda$x:A.x is the identity function on type A, and it has type A→A but not B→B for a type B different from A. In Curry-style typing, $\lambda$x.x is a general identity function with type C→C for every type C. In this paper, we will show how to interpret in a Curry-style system every Pure Type System (PTS) in the Church-style without losing any typing information. We will also prove a kind of conservative extension result for this interpretation, a result which implies that for most consistent PTSs of the Church-style, the corresponding Curry-style system is consistent. We will then show how to interpret in a system of the Church-style (a modified PTS, stronger than a PTS) every PTS-like system in the Curry style.},
author = {Kamareddine, Fairouz and Seldin, Jonathan P. and Wells, J.B.},
doi = {10.1016/j.jal.2016.05.008},
file = {:Users/liang-tingchen/Dropbox/References/Kamareddine, Seldin, Wells - 2016 - Bridging Curry and Church's typing style.pdf:pdf},
issn = {15708683},
journal = {Journal of Applied Logic},
keywords = {Church-style typing,Curry-style typing,Domain-free typing,Domain-full typing},
month = {nov},
pages = {42--70},
publisher = {Elsevier B.V.},
title = {{Bridging Curry and Church's typing style}},
url = {http://dx.doi.org/10.1016/j.jal.2016.05.008 https://linkinghub.elsevier.com/retrieve/pii/S1570868316300313},
volume = {18},
year = {2016}
}
@article{New2020,
abstract = {Parametric polymorphism and gradual typing have proven to be a difficult combination, with no language yet produced that satisfies the fundamental theorems of each: parametricity and graduality. Notably, Toro, Labrada, and Tanter (POPL 2019) conjecture that for any gradual extension of System F that uses dynamic type generation, graduality and parametricity are {\l}simply incompatible{\v{z}}. However, we argue that it is not graduality and parametricity that are incompatible per se, but instead that combining the syntax of System F with dynamic type generation as in previous work necessitates type-directed computation, which we show has been a common source of graduality and parametricity violations in previous work. We then show that by modifying the syntax of universal and existential types to make the type name generation explicit, we remove the need for type-directed computation, and get a language that satisfies both graduality and parametricity theorems. The language has a simple runtime semantics, which can be explained by translation to a statically typed language where the dynamic type is interpreted as a dynamically extensible sum type. Far from being in conflict, we show that the parametricity theorem follows as a direct corollary of a relational interpretation of the graduality property.},
author = {New, Max S. and Jamner, Dustin and Ahmed, Amal},
doi = {10.1145/3371114},
file = {:Users/liang-tingchen/Dropbox/References/New, Jamner, Ahmed - 2020 - Graduality and parametricity together again for the first time.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {gradual typing,graduality,logical relation,parametricity,polymorphism},
month = {jan},
number = {POPL},
pages = {1--32},
title = {{Graduality and parametricity: together again for the first time}},
url = {https://dl.acm.org/doi/10.1145/3371114},
volume = {4},
year = {2020}
}
@article{Determann2018,
author = {Determann, Lothar},
doi = {10.2139/ssrn.3123957},
file = {:Users/liang-tingchen/Dropbox/References/Determann - 2018 - No One Owns Data.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
number = {265},
pages = {1--49},
title = {{No One Owns Data}},
url = {https://www.ssrn.com/abstract=3123957},
year = {2018}
}
@inproceedings{Bonsangue2007,
abstract = {Abramsky's logical formulation of domain theory is extended to encompass the domain theoretic model for pi-calculus processes of Stark and of Fiore, Moggi and Sangiorgi. This is done by defining a logical counterpart of categorical constructions including dynamic name allocation and name exponentiation, and showing that they are dual to standard constructs in functor categories. We show that initial algebras of functors defined in terms of these constructs give rise to a logic that is sound, complete, and characterises bisimilarity. The approach is modular, and we apply it to derive a logical formulation of pi-calculus. The resulting logic is a modal calculus with primitives for input, free output and bound output.},
author = {Bonsangue, Marcello M. and Kurz, Alexander},
booktitle = {22nd Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2007.36},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Kurz - 2007 - Pi-calculus in logical Form.pdf:pdf},
isbn = {0-7695-2908-9},
pages = {303--312},
publisher = {IEEE},
title = {{Pi-calculus in logical Form}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4276574},
year = {2007}
}
@article{Majster-Cederbaum1996,
abstract = {Complete partial orders have been used for a long time for defining semantics of programming languages. In the context of concurrency de Bakker and Zucker (1982) proposed a metric setting for handling concurrency, recursion and nontermination, which has proved to be very successful in many applications. Starting with a semantic domain D for 'finite behaviour' we investigate the relation between the ideal completion Idl(D) and the metric completion which are both suitable to model recursion and infinite behaviour. We also consider the properties of semantic operators.},
author = {Majster-Cederbaum, Mila E. and Baier, Christel},
doi = {10.1016/0304-3975(95)00262-6},
file = {:Users/liang-tingchen/Dropbox/References/Majster-Cederbaum, Baier - 1996 - Metric completion versus ideal completion.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1-2},
pages = {145--171},
title = {{Metric completion versus ideal completion}},
volume = {170},
year = {1996}
}
@article{Basin2011,
abstract = {The distributed temporal logic DTL is an expressive logic, well suited for formalizing properties of concurrent, communicating agents. We show how DTL can be used as a metalogic to reason about and relate different security protocol models. This includes reasoning about model simplifications, where models are transformed to have fewer agents or behaviors, and verifying model reductions, where to establish the validity of a property it suffices to consider its satisfaction on only a subset of models. We illustrate how DTL can be used to formalize security models, protocols, and properties, and then present three concrete examples of metareasoning. First, we prove a general theorem about sufficient conditions for data to remain secret during communication. Second, we prove the equivalence of two models for guaranteeing message-origin authentication. Finally, we relate channel-based and intruder-centric models, showing that it is sufficient to consider models in which the intruder completely controls the network. While some of these results belong to the folklore or have been shown, mutatis mutandis, using other formalisms, DTL provides a uniform means to prove them within the same formalism. It also allows us to clarify subtle aspects of these model transformations that are often neglected or cannot be specified in the first place. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Basin, David and Caleiro, Carlos and Ramos, Jaime and Vigan??, Luca},
doi = {10.1016/j.tcs.2011.04.006},
file = {:Users/liang-tingchen/Dropbox/References/Basin et al. - 2011 - Distributed temporal logic for the analysis of security protocol models.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Distributed temporal logic,Security protocol analysis,Security protocol models,Security protocols,Temporal logic},
number = {31},
pages = {4007--4043},
publisher = {Elsevier B.V.},
title = {{Distributed temporal logic for the analysis of security protocol models}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.04.006},
volume = {412},
year = {2011}
}
@incollection{Cauderlier2018,
abstract = {Inspired by a number of different applications of rewriting logic, equational logic, and type theory that we present and further advance in this thesis, we study a unified formalism based on the key aspects of these quite different lines of research. The resulting formalism, that we call the open calculus of constructions, is intended as a step towards our long-term goal of developing a unified language for programming, specification and interactive theorem proving. $\backslash$nWe begin our work by exploring the application of rewriting logic as a semantic framework for concurrency. To this end, we give a unified treatment of different classes of Petri nets, a typical and important representative of a class of formalisms that are used for the modeling and specification of concurrent and distributed systems based on a multiset representation of a distributed state space. Specifically, we continue the line of research initiated by Meseguer and Montanari under the motto "Petri nets are monoids" by giving a rewriting semantics for different Petri nets classes. In particular, we have covered important high-level Petri net models, namely algebraic net specifications and colored Petri nets, and we have proved that the models of our representations are naturally isomorphic to the well-known Best-Devillers process semantics. Apart from their contribution to a conceptual unification in this field, the main practical advantage of our representations in rewriting logic is their executability, which allows us to use a rewriting engine such as Maude for the efficient symbolic execution of system models and for their analysis. $\backslash$nThe next application addressed in this thesis is the use of type theory, more precisely the calculus of inductive constructions, as a logical framework and for metalogical reasoning. Specifically, we have used the COQ proof assistant in a formally rigorous development of a UNITY-style temporal logic, which generalizes the original UNITY approach in important aspects. Since all inference rules of the temporal logic are proved as theorems in the metalogic, the result of the development is a verified temporal logic library, which due to the use of labeled transition systems as a semantic basis, can be employed for a wide range of system models, Petri nets and rewriting logic specifications being particular examples. The development also includes a new application of the proposition-as-types interpretation in the context of compositional reasoning. $\backslash$nThe use of membership equational logic or rewriting logic as a semantic and logical framework for higher-order languages, or more generally languages with binding constructs, obviously requires a first-order treatment of names and relevant operations such as substitutions. To systematically address such applications, we develop CINNI, a new calculus of names and substitutions, that takes names seriously in the sense that it does not abstract from names, and is generic in the sense that it can be instantiated to arbitrary object languages. Our calculus unifies the standard named notation and a notation based on de Bruijn indices by employing a representation that was originally developed by Berkling for the lambda-calculus. It furthermore nicely generalizes the calculus lambda upsilon of explicit substitutions developed by Lescanne, and, as we show, most metatheoretic results can be generalized to the new calculus. We furthermore give a very general confluence result for the composition of CINNI with the equations or rules capturing the dynamics of the object language, and we in particular discuss how our approach can be applied to the representation of the untyped lambda-calculus, Abadi and Cardelli's object calculus, also called the sigma-calculus, and Milner's pi-calculus for communicating and mobile systems. As a real-world application of CINNI we briefly discuss a specification of an active network programming language in the rewriting-logic-based language Maude. $\backslash$nWe more specifically address the use of membership equational logic and rewriting logic as a first-order logical framework by representing an important class of pure type systems. Pure type systems generalize a variety of different type theories, including the calculus of constructions and its well-known subsystems, and can be seen as higher-order logics via the propositions-as-types interpretation. Following a methodology based on Meseguer's general logics in combination with rewriting logic as a concrete logical framework, we have studied representations of pure type systems at different levels of abstractions, ranging from an abstract textbook representation to a more concrete executable representation of an important subclass, which can directly serve as a type inference and type checking algorithm. The latter representation is based on a new notion of uniform pure type systems, which take names seriously thanks to the CINNI calculus and simultaneously offer a possible solution to the known problem with alpha-closure pointed out by Pollack. Using an example, in which we validate proofs developed with the LEGO proof assistant in an extension of the calculus of constructions with universes, we have demonstrated how our approach directly leads to an executable prototype in a rewriting logic language such as Maude. $\backslash$nAs an application of type theory in the context of classical reasoning we study Howe's HOL/Nuprl connection, which addresses the problem of formal interoperability between proof assistents, from the viewpoint of Meseguer's general logics. We supplement Howe's semantic justification by a proof-theoretic correctness argument, a piece of work which has lead to proof-translation as new interesting application (explored in joint work with Naumov) that goes beyond Howe's original HOL/Nuprl connection. From a theoretical perspective we found that the core idea of the HOL/Nuprl connection, namely the beneficial coexistence of an intensional and an extensional logic in the same formal system, does not rely on any of the advanced concepts of Nuprl, but can equally well be used in Martin-L{\"{o}}f's type theory and can further be easily adopted to type theories in the line of calculus of constructions. $\backslash$nThe final and main contribution of this thesis is the development of a formalism that we call the open calculus of constructions (OCC). It is based on the surprisingly powerful interaction between its two key features, namely dependent types, in the spirit of Martin-L{\"{o}}f's type theory and the calculus of constructions, and the computational system of rewriting logic and its underlying membership equational logic, which is based on conditional rewriting modulo equations. The applications of membership equational logic, rewriting logic, and type theory, studied in this thesis have not only inspired the development of this unifying formalism, but they become applications of OCC itself and benefit from its use in an essential way. On the theoretical side, we introduce OCC by presenting a classical set-theoretic semantics and a formal system for which we prove soundness and consistency as a logic. The formal system is used to define derivable judgements together with their operational semantics, and is based on the ideas that we developed earlier in the context of uniform pure type systems. The model-theoretic semantics that we develop in this thesis is a very intuitive semantics with proof-irrelevance for impredicative universes, but unlike existing approaches it is more direct and can be given independently of the formal system. Using an experimental prototype of OCC, that we implemented in Maude following the approach to the specification of type theories mentioned before in combination with reflective techniques, we have developed a large collection of examples, many of which are closely related to the applications discussed earlier in this thesis. These examples do not only convey the pragmatics of OCC, but they simultaneously provide a proof-of-concept for our approach. Among the topics covered by our examples we find executable equational/behavioral specifications, programming with dependent types, symbolic execution of system models, formalization of algebraic and categorical concepts, inductive/coinductive theorem proving, and theorem proving modulo equational theories.},
author = {Cauderlier, Rapha{\"{e}}l},
booktitle = {Interactive Theorem Proving. ITP 2018},
doi = {10.1007/978-3-319-94821-8_9},
editor = {Avigad, Jeremy and Mahboubi, Assia},
file = {:Users/liang-tingchen/Dropbox/References/Cauderlier - 2018 - Tactics and Certificates in Meta Dedukti.pdf:pdf},
isbn = {9783319948218},
pages = {142--159},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Tactics and Certificates in Meta Dedukti}},
url = {http://link.springer.com/10.1007/978-3-319-94821-8{\_}9},
volume = {10895},
year = {2018}
}
@article{VanDenBerg2011,
abstract = {One of the main goals of this paper is to give a construction of realizability models for predicative constructive set theories in a predicative metatheory. We will use the methods of algebraic set theory, in particular the results on exact completion from van den Berg and Moerdijk (2008) [5]. Thus, the principal results of our paper are concerned with the construction of an extension of a category with small maps by a category of assemblies, again equipped with a class of maps, and to show that this extension construction preserves those axioms for a class of maps necessary to produce models of the relevant set theories in the exact completion of this category of assemblies. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {van den Berg, Benno and Moerdijk, Ieke},
doi = {10.1016/j.tcs.2010.12.019},
file = {:Users/liang-tingchen/Dropbox/References/van den Berg, Moerdijk - 2011 - Aspects of predicative algebraic set theory, II Realizability.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Categorical logic,Constructive set theory,Realizability},
month = {apr},
number = {20},
pages = {1916--1940},
publisher = {Elsevier B.V.},
title = {{Aspects of predicative algebraic set theory, II: Realizability}},
url = {http://dx.doi.org/10.1016/j.tcs.2010.12.019 https://linkinghub.elsevier.com/retrieve/pii/S0304397510007103},
volume = {412},
year = {2011}
}
@article{Pitts2015,
abstract = {This paper describes a version of Martin-L{\"{o}}f's dependent type theory extended with names and constructs for freshness and name-abstraction derived from the theory of nominal sets. We aim for a type theory for computing and proving (via a Curry-Howard correspondence) with syntactic structures which captures familiar, but informal, 'nameful' practices when dealing with binders.},
author = {Pitts, Andrew M. and Matthiesen, Justus and Derikx, Jasper},
doi = {10.1016/j.entcs.2015.04.003},
file = {:Users/liang-tingchen/Dropbox/References/Pitts, Matthiesen, Derikx - 2015 - A Dependent Type Theory with Abstractable Names.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {binding,dependent types,names,nominal sets},
month = {apr},
pages = {19--50},
publisher = {Elsevier B.V.},
title = {{A Dependent Type Theory with Abstractable Names}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.04.003 https://linkinghub.elsevier.com/retrieve/pii/S1571066115000079},
volume = {312},
year = {2015}
}
@article{Bonchi2008,
author = {Bonchi, Filippo and Montanari, Ugo},
doi = {10.1016/j.entcs.2009.02.012},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi, Montanari - 2008 - A coalgebraic theory of reactive systems.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coalgebra,labeled transition system,reactive system},
month = {apr},
number = {2008},
pages = {201--215},
publisher = {Elsevier B.V.},
title = {{A coalgebraic theory of reactive systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066109000176},
volume = {209},
year = {2008}
}
@article{Adamek2018,
abstract = {This is a survey on fixed points of endofunctors, including initial algebras and terminal coalgebras. We also consider the rational fixed point, a canonical domain of behavior for finitely presentable systems. In addition to the basic existence theorems for fixed points, several new results are presented. For example, the Smyth–Plotkin theorem that locally continuous endofunctors of DCPO have terminal coalgebras is derived from a new result stating that every locally monotone endofunctor with a fixed point has a terminal coalgebra. We introduce bounded endofunctors on abstract categories and prove that they have terminal coalgebras. We study well-founded coalgebras and prove that for set functors, the largest well-founded coalgebra of every fixed point is the initial algebra. Another new result concerns mixed fixed points: initial algebras and terminal coalgebras of a parametrized accessible functor always form accessible functors.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Moss, Lawrence S.},
doi = {10.1016/j.jlamp.2017.11.003},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Moss - 2018 - Fixed points of functors(2).pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
keywords = {Fixed points of functors,Initial algebra,Rational fixed point,Terminal coalgebra},
month = {feb},
pages = {41--81},
title = {{Fixed points of functors}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2352220816301201},
volume = {95},
year = {2018}
}
@book{James1999,
author = {James, Ioan},
booktitle = {Numerical Methods for Partial Differential Equations},
doi = {10.1007/978-1-4471-3994-2},
file = {:Users/liang-tingchen/Dropbox/References/James - 1999 - Topologies and Uniformities.pdf:pdf},
isbn = {9781846280405},
publisher = {Springer London},
series = {Springer Undergraduate Mathematics Series},
title = {{Topologies and Uniformities}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=OyD4toi-XDIC{\&}oi=fnd{\&}pg=PA2{\&}dq=Game+theory+:+Decisions,+Interactions+and+Evolution{\&}ots=TfgJJReigk{\&}sig=AnVOJ8VTGk60lUCldvLrPPnrJD4},
volume = {79},
year = {1999}
}
@article{Wand1979,
abstract = {We consider the problem of data type extensions. Guttag, Horowitz, and Musser have pointed out that in this situation the naive initial algebra approach requires the data type to save too much information. We formulate a category of implementations of such an extension, and we show that such a category has a final object. The resulting semantics is closer to that of Hoare, since it can be argued that an abstract data type in the sense of Hoare is a final object in the category of representations of that type. We consider as an example the specification of integer arrays, and we show that our specification yields arrays as its abstract data type. The connection with initial algebra semantics is discussed. {\textcopyright} 1979.},
author = {Wand, Mitchell},
doi = {10.1016/0022-0000(79)90011-4},
file = {:Users/liang-tingchen/Dropbox/References/Wand - 1979 - Final algebra semantics and data type extensions.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {aug},
number = {1},
pages = {27--44},
title = {{Final algebra semantics and data type extensions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000079900114},
volume = {19},
year = {1979}
}
@book{Fong2020,
abstract = {This book is an invitation to discover advanced topics in category theory through concrete, real-world examples. It aims to give a tour: a gentle, quick introduction to guide later exploration. The tour takes place over seven sketches, each pairing an evocative application, such as databases, electric circuits, or dynamical systems, with the exploration of a categorical structure, such as adjoint functors, enriched categories, or toposes. No prior knowledge of category theory is assumed. A feedback form for typos, comments, questions, and suggestions is available here: https://docs.google.com/document/d/160G9OFcP5DWT8Stn7TxdVx83DJnnf7d5GML0{\_}FOD5Wg/edit},
archivePrefix = {arXiv},
arxivId = {1803.05316},
author = {Fong, Brendan and Spivak, David I},
doi = {10.13287/j.1001-9332.201712.020},
eprint = {1803.05316},
file = {:Users/liang-tingchen/Dropbox/References/Fong, Spivak - 2020 - Seven Sketches in Compositionality An Invitation to Applied Category Theory.pdf:pdf},
issn = {1001-9332 (Print)},
pmid = {29696903},
publisher = {Cambridge University Press},
title = {{Seven Sketches in Compositionality: An Invitation to Applied Category Theory}},
url = {http://arxiv.org/abs/1803.05316},
year = {2020}
}
@article{Barendregt1992a,
abstract = {Let $\psi$ be a partial recursive function (of one argument) with $\lambda$-defining term F ∈$\Lambda$°. This means There are several proposals for what F ⌜ n ⌝ should be in case $\psi$( n ) is undefined: (1) a term without a normal form (Church); (2) an unsolvable term (Barendregt); (3) an easy term (Visser); (4) a term of order 0 (Statman).},
author = {Barendregt, Henk},
doi = {10.1017/S0956796800000447},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt - 1992 - Theoretical Pearls Representing ‘undefined' in lambda calculus.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {3},
pages = {367--374},
title = {{Theoretical Pearls: Representing ‘undefined' in lambda calculus}},
url = {https://www.cambridge.org/core/product/identifier/S0956796800000447/type/journal{\_}article},
volume = {2},
year = {1992}
}
@article{Lack1999,
author = {Lack, Stephen},
doi = {10.1016/S0022-4049(99)00019-5},
file = {:Users/liang-tingchen/Dropbox/References/Lack - 1999 - On the monadicity of finitary monads.pdf:pdf},
isbn = {6129351453},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {1},
pages = {65--73},
title = {{On the monadicity of finitary monads}},
volume = {140},
year = {1999}
}
@incollection{Butler2017,
abstract = {Inspired by a number of different applications of rewriting logic, equational logic, and type theory that we present and further advance in this thesis, we study a unified formalism based on the key aspects of these quite different lines of research. The resulting formalism, that we call the open calculus of constructions, is intended as a step towards our long-term goal of developing a unified language for programming, specification and interactive theorem proving. $\backslash$nWe begin our work by exploring the application of rewriting logic as a semantic framework for concurrency. To this end, we give a unified treatment of different classes of Petri nets, a typical and important representative of a class of formalisms that are used for the modeling and specification of concurrent and distributed systems based on a multiset representation of a distributed state space. Specifically, we continue the line of research initiated by Meseguer and Montanari under the motto "Petri nets are monoids" by giving a rewriting semantics for different Petri nets classes. In particular, we have covered important high-level Petri net models, namely algebraic net specifications and colored Petri nets, and we have proved that the models of our representations are naturally isomorphic to the well-known Best-Devillers process semantics. Apart from their contribution to a conceptual unification in this field, the main practical advantage of our representations in rewriting logic is their executability, which allows us to use a rewriting engine such as Maude for the efficient symbolic execution of system models and for their analysis. $\backslash$nThe next application addressed in this thesis is the use of type theory, more precisely the calculus of inductive constructions, as a logical framework and for metalogical reasoning. Specifically, we have used the COQ proof assistant in a formally rigorous development of a UNITY-style temporal logic, which generalizes the original UNITY approach in important aspects. Since all inference rules of the temporal logic are proved as theorems in the metalogic, the result of the development is a verified temporal logic library, which due to the use of labeled transition systems as a semantic basis, can be employed for a wide range of system models, Petri nets and rewriting logic specifications being particular examples. The development also includes a new application of the proposition-as-types interpretation in the context of compositional reasoning. $\backslash$nThe use of membership equational logic or rewriting logic as a semantic and logical framework for higher-order languages, or more generally languages with binding constructs, obviously requires a first-order treatment of names and relevant operations such as substitutions. To systematically address such applications, we develop CINNI, a new calculus of names and substitutions, that takes names seriously in the sense that it does not abstract from names, and is generic in the sense that it can be instantiated to arbitrary object languages. Our calculus unifies the standard named notation and a notation based on de Bruijn indices by employing a representation that was originally developed by Berkling for the lambda-calculus. It furthermore nicely generalizes the calculus lambda upsilon of explicit substitutions developed by Lescanne, and, as we show, most metatheoretic results can be generalized to the new calculus. We furthermore give a very general confluence result for the composition of CINNI with the equations or rules capturing the dynamics of the object language, and we in particular discuss how our approach can be applied to the representation of the untyped lambda-calculus, Abadi and Cardelli's object calculus, also called the sigma-calculus, and Milner's pi-calculus for communicating and mobile systems. As a real-world application of CINNI we briefly discuss a specification of an active network programming language in the rewriting-logic-based language Maude. $\backslash$nWe more specifically address the use of membership equational logic and rewriting logic as a first-order logical framework by representing an important class of pure type systems. Pure type systems generalize a variety of different type theories, including the calculus of constructions and its well-known subsystems, and can be seen as higher-order logics via the propositions-as-types interpretation. Following a methodology based on Meseguer's general logics in combination with rewriting logic as a concrete logical framework, we have studied representations of pure type systems at different levels of abstractions, ranging from an abstract textbook representation to a more concrete executable representation of an important subclass, which can directly serve as a type inference and type checking algorithm. The latter representation is based on a new notion of uniform pure type systems, which take names seriously thanks to the CINNI calculus and simultaneously offer a possible solution to the known problem with alpha-closure pointed out by Pollack. Using an example, in which we validate proofs developed with the LEGO proof assistant in an extension of the calculus of constructions with universes, we have demonstrated how our approach directly leads to an executable prototype in a rewriting logic language such as Maude. $\backslash$nAs an application of type theory in the context of classical reasoning we study Howe's HOL/Nuprl connection, which addresses the problem of formal interoperability between proof assistents, from the viewpoint of Meseguer's general logics. We supplement Howe's semantic justification by a proof-theoretic correctness argument, a piece of work which has lead to proof-translation as new interesting application (explored in joint work with Naumov) that goes beyond Howe's original HOL/Nuprl connection. From a theoretical perspective we found that the core idea of the HOL/Nuprl connection, namely the beneficial coexistence of an intensional and an extensional logic in the same formal system, does not rely on any of the advanced concepts of Nuprl, but can equally well be used in Martin-L{\"{o}}f's type theory and can further be easily adopted to type theories in the line of calculus of constructions. $\backslash$nThe final and main contribution of this thesis is the development of a formalism that we call the open calculus of constructions (OCC). It is based on the surprisingly powerful interaction between its two key features, namely dependent types, in the spirit of Martin-L{\"{o}}f's type theory and the calculus of constructions, and the computational system of rewriting logic and its underlying membership equational logic, which is based on conditional rewriting modulo equations. The applications of membership equational logic, rewriting logic, and type theory, studied in this thesis have not only inspired the development of this unifying formalism, but they become applications of OCC itself and benefit from its use in an essential way. On the theoretical side, we introduce OCC by presenting a classical set-theoretic semantics and a formal system for which we prove soundness and consistency as a logic. The formal system is used to define derivable judgements together with their operational semantics, and is based on the ideas that we developed earlier in the context of uniform pure type systems. The model-theoretic semantics that we develop in this thesis is a very intuitive semantics with proof-irrelevance for impredicative universes, but unlike existing approaches it is more direct and can be given independently of the formal system. Using an experimental prototype of OCC, that we implemented in Maude following the approach to the specification of type theories mentioned before in combination with reflective techniques, we have developed a large collection of examples, many of which are closely related to the applications discussed earlier in this thesis. These examples do not only convey the pragmatics of OCC, but they simultaneously provide a proof-of-concept for our approach. Among the topics covered by our examples we find executable equational/behavioral specifications, programming with dependent types, symbolic execution of system models, formalization of algebraic and categorical concepts, inductive/coinductive theorem proving, and theorem proving modulo equational theories.},
author = {Butler, David and Aspinall, David and Gasc{\'{o}}n, Adri{\`{a}}},
booktitle = {Interactive Theorem Proving. ITP 2017},
doi = {10.1007/978-3-319-66107-0_8},
editor = {Ayala-Rinc{\'{o}}n, Mauricio and Mu{\~{n}}oz, C{\'{e}}sar A.},
file = {:Users/liang-tingchen/Dropbox/References/Butler, Aspinall, Gasc{\'{o}}n - 2017 - How to Simulate It in Isabelle Towards Formal Proof for Secure Multi-Party Computation.pdf:pdf},
isbn = {978-3-642-14051-8},
keywords = {formal verification,oblivious transfer,proof},
pages = {114--130},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{How to Simulate It in Isabelle: Towards Formal Proof for Secure Multi-Party Computation}},
url = {http://link.springer.com/10.1007/978-3-319-66107-0{\_}8},
volume = {10499},
year = {2017}
}
@article{Klin2010,
author = {Klin, Bartek},
doi = {10.1016/j.entcs.2010.07.019},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2010 - Structural Operational Semantics and Modal Logic, Revisited.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coalgebra,modal logic,structural operational semantics},
month = {aug},
number = {2},
pages = {155--175},
publisher = {Elsevier B.V.},
title = {{Structural Operational Semantics and Modal Logic, Revisited}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066110000782},
volume = {264},
year = {2010}
}
@article{Komendantskaya2018,
abstract = {A propositional logic program P may be identified with a PfPf-coalgebra on the set of atomic propositions in the program. The corresponding C(PfPf)-coalgebra, where C(PfPf) is the cofree comonad on PfPf, describes derivations by resolution. That correspondence has been developed to model first-order programs in two ways, with lax semantics and saturated semantics, based on locally ordered categories and right Kan extensions respectively. We unify the two approaches, exhibiting them as complementary rather than competing, reflecting the theorem-proving and proof-search aspects of logic programming. While maintaining that unity, we further refine lax semantics to give finitary models of logic programs with existential variables, and to develop a precise semantic relationship between variables in logic programming and worlds in local state.},
archivePrefix = {arXiv},
arxivId = {1608.07708},
author = {Komendantskaya, Ekaterina and Power, John},
doi = {10.1016/j.jlamp.2018.07.004},
eprint = {1608.07708},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Power - 2018 - Logic programming Laxness and saturation.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
month = {dec},
pages = {1--21},
publisher = {Elsevier Inc.},
title = {{Logic programming: Laxness and saturation}},
url = {https://www.sciencedirect.com/science/article/pii/S2352220816301031 https://linkinghub.elsevier.com/retrieve/pii/S2352220816301031},
volume = {101},
year = {2018}
}
@article{lmcs:4814,
abstract = {In this paper, we analyze and compare three of the many algebraic structures that have been used for modeling dependent type theories: categories with families, split type-categories, and representable maps of presheaves. We study these in univalent type theory, where the comparisons between them can be given more elementarily than in set-theoretic foundations. Specifically, we construct maps between the various types of structures, and show that assuming the Univalence axiom, some of the comparisons are equivalences. We then analyze how these structures transfer along (weak and strong) equivalences of categories, and, in particular, show how they descend from a category (not assumed univalent/saturated) to its Rezk completion. To this end, we introduce relative universes, generalizing the preceding notions, and study the transfer of such relative universes along suitable structure. We work throughout in (intensional) dependent type theory; some results, but not all, assume the univalence axiom. All the material of this paper has been formalized in Coq, over the UniMath library. 18C50, 03B15, 03B70},
archivePrefix = {arXiv},
arxivId = {1705.04310},
author = {Ahrens, Benedikt and Lumsdaine, Peter LeFanu and Voevodsky, Vladimir},
doi = {10.23638/LMCS-14(3:18)2018},
eprint = {1705.04310},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Lumsdaine, Voevodsky - 2018 - Categorical structures for type theory in univalent foundations.pdf:pdf},
issn = {23318422},
journal = {Logical Methods in Computer Science},
keywords = {03B15,03B70,18C50,Categorical Semantics,Computer Science - Logic in Computer Science,F.3.2,F.4.1,Mathematics - Category Theory,Mathematics - Logic,Type Theory,Univalence Axiom},
month = {sep},
number = {3},
pages = {1--18},
title = {{Categorical structures for type theory in univalent foundations}},
url = {https://lmcs.episciences.org/4814},
volume = {14},
year = {2018}
}
@incollection{Linton1969,
author = {Linton, F. E. J.},
booktitle = {Seminar on Triples and Categorical Homology Theory},
doi = {10.1007/BFb0083082},
editor = {Eckmann, B.},
file = {:Users/liang-tingchen/Dropbox/References/Linton - 1969 - Coequalizers in categories of algebras.pdf:pdf},
pages = {75--90},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Coequalizers in categories of algebras}},
year = {1969}
}
@article{Bezhanishvili1998a,
abstract = {This paper deals with the varieties of monadic Heyting algebras, algebraic models of intuitionistic modal logic MIPC. We investigate semisimple, locally finite, finitely approximated and splitting varieties of monadic Heyting algebras as well as varieties with the disjunction and the existence properties. The investigation of monadic Heyting algebras clarifies the correspondence between intuitionistic modal logics over MIPC and superintuitionistic predicate logics and provides us with the solutions of several problems raised by Ono [35].},
author = {Bezhanishvili, Guram},
doi = {10.1023/A:1005073905902},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili - 1998 - Varieties of Monadic Heyting Algebras. Part I.pdf:pdf},
journal = {Studia Logica},
number = {3},
pages = {367--402},
title = {{Varieties of Monadic Heyting Algebras. Part I}},
url = {http://link.springer.com/article/10.1023{\%}2FA{\%}3A1005073905902},
volume = {61},
year = {1998}
}
@article{Reiter1980,
abstract = {The need to make default assumptions is frequently encountered in reasoning about incompletely specified worlds. Inferences sanctioned by default are best viewed as beliefs which may well be modified or rejected by subsequent observations. It is this property which leads to the non-monotonicity of any logic of defaults. In this paper we propose a logic for default reasoning. We then specialize our treatment to a very large class of commonly occuring defaults. For this class we develop a complete proof theory and show how to interface it with a top down resolution theorem prover. Finally, we provide criteria under which the revision of derived beliefs must be effected. {\textcopyright} 1980.},
author = {Reiter, R.},
doi = {10.1016/0004-3702(80)90014-4},
file = {:Users/liang-tingchen/Dropbox/References/Reiter - 1980 - A logic for default reasoning.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
month = {apr},
number = {1-2},
pages = {81--132},
title = {{A logic for default reasoning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0004370280900144},
volume = {13},
year = {1980}
}
@book{Curry1958,
author = {Curry, Haskell B. and Feys, Robert},
publisher = {Amsterdam: North Holland},
title = {{Combinatory Logic}},
year = {1958}
}
@article{Compagnoni2003,
abstract = {Bounded operator abstraction is a language construct relevant to object-oriented programming languages and to ML2000, the successor to Standard ML. In this paper, we introduce ℱ≤$\omega$, a variant of F{\textless}:$\omega$ with this feature and with Cardelli and Wegner's kernel Fun rule for quantifiers. We define a typed operational semantics with subtyping and prove that it is equivalent with ℱ≤$\omega$, using logical relations to prove soundness. The typed operational semantics provides a powerful and uniform technique to study metatheoretic properties of ℱ≤$\omega$, such as Church-Rosser, subject reduction, the admissibility of structural rules, and the equivalence with the algorithmic presentation of the system that performs weak-head reductions. Furthermore, we can show decidability of subtyping using the typed operational semantics and its equivalence with the usual presentation. Hence, this paper demonstrates for the first time that logical relations can be used to show decidability of subtyping. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Compagnoni, Adriana and Goguen, Healfdene},
doi = {10.1016/S0890-5401(03)00062-2},
file = {:Users/liang-tingchen/Dropbox/References/Compagnoni, Goguen - 2003 - Typed operational semantics for higher-order subtyping.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Dependent kinds,Subtyping,Type theory,Typed operational semantics,$\lambda$-Calculus},
month = {aug},
number = {2},
pages = {242--297},
title = {{Typed operational semantics for higher-order subtyping}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540103000622},
volume = {184},
year = {2003}
}
@article{Kamide2002a,
abstract = {We introduce Kripke semantics for modal substructural logics, and provethe completeness theorems with respect to the semantics. Thecompleteness theorems are proved using an extended Ishihara's method ofcanonical model construction (Ishihara, 2000). The framework presentedcan deal with a broad range of modal substructural logics, including afragment of modal intuitionistic linear logic, and modal versions ofCorsi's logics, Visser's logic, M{\'{e}}ndez's logics and relevant logics.},
author = {Kamide, Norihiro},
doi = {10.1023/A:1019915908844},
file = {:Users/liang-tingchen/Dropbox/References/Kamide - 2002 - Kripke Semantics for Modal Substructural Logics.pdf:pdf},
journal = {Journal of Logic, Language and Information},
keywords = {completeness theorem,kripke semantics,linear logic,modal substructural logic,rele-},
pages = {453--470},
title = {{Kripke Semantics for Modal Substructural Logics}},
url = {http://www.springerlink.com/content/w08015027524153q/},
volume = {4},
year = {2002}
}
@article{Jang2022,
abstract = {We describe the foundation of the metaprogramming language, M{\oe}bius, which supports the generation of polymorphic code and, more importantly, the analysis of polymorphic code via pattern matching.},
author = {Jang, Junyoung and G{\'{e}}lineau, Samuel and Monnier, Stefan and Pientka, Brigitte},
doi = {10.1145/3498700},
file = {:Users/liang-tingchen/Dropbox/References/Jang et al. - 2022 - M{\oe}bius metaprogramming using contextual types the stage where system f can pattern match on itself.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--27},
title = {{M{\oe}bius: metaprogramming using contextual types: the stage where system f can pattern match on itself}},
url = {https://dl.acm.org/doi/10.1145/3498700},
volume = {6},
year = {2022}
}
@article{Honsell2007,
abstract = {In this paper, we introduce a General Logical Framework, called GLF, for defining Logical Frameworks, based on dependent types, in the style of the well known Edinburgh Logical Framework LF. The framework GLF features a generalized form of lambda abstraction where $\beta$-reductions fire provided the argument satisfies a logical predicate and may produce an n-ary substitution. The type system keeps track of when reductions have yet to fire. The framework GLF subsumes, by simple instantiation, LF as well as a large class of generalized constrained-based lambda calculi, ranging from well known restricted lambda calculi, such as Plotkin's call-by-value lambda calculus, to lambda calculi with patterns. But it suggests also a wide spectrum of new calculi which have intriguing potential as Logical Frameworks. We investigate the metatheoretical properties of the calculus underpinning GLF and illustrate its expressive power. In particular, we focus on two interesting instantiations of GLF. The first is the Pattern Logical Framework (PLF), where applications fire via pattern-matching in the style of Cirstea, Kirchner, and Liquori. The second is the Closed Logical Framework (CLF) which features, besides standard $\beta$-reduction, also a reduction which fires only if the argument is a closed term. For both these instantiations of GLF we discuss standard metaproperties, such as subject reduction, confluence and strong normalization. The GLF framework is particularly suitable, as a metalanguage, for encoding rewriting logics and logical systems, where rules require proof terms to have special syntactic constraints, e.g. logics with rules of proof, in addition to rules of derivations, such as, e.g., modal logic, and call-by-value lambda calculus. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Honsell, Furio and Lenisa, Marina and Liquori, Luigi},
doi = {10.1016/j.entcs.2007.02.014},
file = {:Users/liang-tingchen/Dropbox/References/Honsell, Lenisa, Liquori - 2007 - A Framework for Defining Logical Frameworks.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Dependent-type systems,Lambda calculus,Logical Framework,Logics,Pattern matching},
month = {apr},
number = {1},
pages = {399--436},
publisher = {Elsevier B.V.},
title = {{A Framework for Defining Logical Frameworks}},
url = {http://dx.doi.org/10.1016/j.entcs.2007.02.014 https://linkinghub.elsevier.com/retrieve/pii/S1571066107000862},
volume = {172},
year = {2007}
}
@incollection{Cleaveland1993,
address = {Berlin},
author = {Cleaveland, Ranee and Klein, Marion and Steffen, Bernhard},
booktitle = {Computer Aided Verification. CAV 1992},
doi = {10.1007/3-540-56496-9_32},
editor = {von Bochmann, G. and Probst, D.K.},
pages = {410--422},
publisher = {Springer},
title = {{Faster model checking for the modal Mu-Calculus}},
url = {http://link.springer.com/10.1007/3-540-56496-9{\_}32},
year = {1993}
}
@inproceedings{ahrens_et_al:LIPIcs:2019:10512,
abstract = {We develop bicategory theory in univalent foundations. Guided by the notion of univalence for (1-)categories studied by Ahrens, Kapulkin, and Shulman, we define and study univalent bicategories. To construct examples of those, we develop the notion of “displayed bicategories”, an analog of displayed 1-categories introduced by Ahrens and Lumsdaine. Displayed bicategories allow us to construct univalent bicategories in a modular fashion. To demonstrate the applicability of this notion, we prove several bicategories are univalent. Among these are the bicategory of univalent categories with families and the bicategory of pseudofunctors between univalent bicategories. Our work is formalized in the UniMath library of univalent mathematics.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Bicategories in Univalent Foundations - Ahrens, Benedikt; Frumin, Dan; Maggesi, Marco; van der Weide, Niels)

Keywords: bicategory theory, univalent mathematics, dependent type theory, Coq},
archivePrefix = {arXiv},
arxivId = {1903.01152},
author = {Ahrens, Benedikt and Frumin, Dan and Maggesi, Marco and van der Weide, Niels},
booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
doi = {10.4230/LIPIcs.FSCD.2019.5},
editor = {Geuvers, Herman},
eprint = {1903.01152},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2019 - Bicategories in Univalent Foundations(2).pdf:pdf;:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2019 - Bicategories in Univalent Foundations.pdf:pdf},
isbn = {978-3-95977-107-8},
issn = {1868-8969},
keywords = {Bicategory theory,Coq,Dependent type theory,Univalent mathematics},
number = {5},
pages = {5:1----5:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Bicategories in Univalent Foundations}},
url = {http://drops.dagstuhl.de/opus/volltexte/2019/10512},
volume = {131},
year = {2019}
}
@article{Herrlich1979,
author = {Herrlich, Horst and Salicrup, G. and Vazquez, R.},
doi = {10.4153/CJM-1979-097-7},
file = {:Users/liang-tingchen/Dropbox/References/Herrlich, Salicrup, Vazquez - 1979 - Dispersed factorization structures.pdf:pdf},
issn = {1496-4279},
journal = {Canadian Journal of Mathematics},
month = {oct},
number = {5},
pages = {1059--1071},
publisher = {The Canadian Mathematical Society},
title = {{Dispersed factorization structures}},
url = {http://www.cms.math.ca/10.4153/CJM-1979-097-7},
volume = {31},
year = {1979}
}
@incollection{Filinski2001,
abstract = {We show how a simple semantic characterization of normalization by evaluation for the $\lambda$ $\beta$ $\mu$-calculus can be extended to a similar construction for normalization of terms in the computational $\lambda$-calculus. Specifically, we show that a suitable residualizing interpretation of base types, constants, and computational effects allows us to extract a syntactic normal form from a term's denotation. The required interpretation can itself be constructed as the meaning of a suitable functional program in an ML-like language, leading directly to a practical normalization algorithm. The results extend easily to product and sum types, and can be seen as a formal basis for call-by-value type-directed partial evaluation. {\textcopyright} Springer-Verlag Berlin Heidelberg 2001.},
author = {Filinski, Andrzej},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2001},
doi = {10.1007/3-540-45413-6_15},
editor = {Abramsky, Samson},
file = {:Users/liang-tingchen/Dropbox/References/Filinski - 2001 - Normalization by Evaluation for the Computational Lambda-Calculus.pdf:pdf},
isbn = {3540419608},
issn = {16113349},
pages = {151--165},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Normalization by Evaluation for the Computational Lambda-Calculus}},
url = {http://link.springer.com/10.1007/3-540-45413-6{\_}15},
volume = {2044},
year = {2001}
}
@phdthesis{Longley1995,
author = {Longley, John R .},
file = {:Users/liang-tingchen/Dropbox/References/Longley - 1995 - Realizability Toposes and Language Semantics(2).pdf:pdf},
school = {University of Edinburgh},
title = {{Realizability Toposes and Language Semantics}},
year = {1995}
}
@book{Makkai1989,
author = {Makkai, Michael and Par{\'{e}}, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Makkai, Par{\'{e}} - 1989 - Accessible Categories The Foundations of Categorical Model Theory.pdf:pdf},
isbn = {082185111X},
pages = {176},
publisher = {American Mathematical Society},
series = {Contemporary Mathematics},
title = {{Accessible Categories: The Foundations of Categorical Model Theory}},
year = {1989}
}
@inproceedings{Reed2010,
abstract = {We want assurances that sensitive information will not be disclosed when aggregate data derived from a database is published. Differential privacy offers a strong statistical guarantee that the effect of the presence of any individual in a database will be negligible, even when an adversary has auxiliary knowledge. Much of the prior work in this area consists of proving algorithms to be differentially private one at a time; we propose to streamline this process with a functional language whose type system automatically guarantees differential privacy, allowing the programmer to write complex privacy-safe query programs in a flexible and compositional way. The key novelty is the way our type system captures function sensitivity, a measure of how much a function can magnify the distance between similar inputs: well-typed programs not only can't go wrong, they can't go too far on nearby inputs. Moreover, by introducing a monad for random computations, we can show that the established definition of differential privacy falls out naturally as a special case of this soundness principle. We develop examples including known differentially private algorithms, privacy-aware variants of standard functional programming idioms, and compositionality principles for differential privacy.},
address = {New York, New York, USA},
author = {Reed, Jason and Pierce, Benjamin C.},
booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming - ICFP '10},
doi = {10.1145/1863543.1863568},
file = {:Users/liang-tingchen/Dropbox/References/Reed, Pierce - 2010 - Distance makes the types grow stronger.pdf:pdf},
isbn = {9781605587943},
issn = {03621340},
month = {sep},
number = {9},
pages = {157},
publisher = {ACM Press},
title = {{Distance makes the types grow stronger}},
url = {http://repository.upenn.edu/cgi/viewcontent.cgi?article=1710{\&}context=cis{\_}papers http://portal.acm.org/citation.cfm?doid=1932681.1863568 http://portal.acm.org/citation.cfm?doid=1863543.1863568},
volume = {45},
year = {2010}
}
@inproceedings{Matsikoudis2012,
author = {Matsikoudis, Eleftherios and Lee, Edward A.},
booktitle = {Proceedings of the 11th International Workshop on Coalgebraic Methods in Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Matsikoudis, Lee - 2012 - From transitions to executions.pdf:pdf},
title = {{From transitions to executions}},
volume = {0720882},
year = {2012}
}
@article{Kurz2001,
author = {Kurz, Alexander},
doi = {10.1016/S0304-3975(00)00125-0},
file = {:Users/liang-tingchen/Dropbox/References/Kurz - 2001 - Specifying coalgebras with modal logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebras,modal logic,object-oriented programming,speci{\"{y}}cation,veri{\"{y}}cation},
month = {jun},
number = {1-2},
pages = {119--138},
title = {{Specifying coalgebras with modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397500001250},
volume = {260},
year = {2001}
}
@article{McSherry2010,
abstract = {We report on the design and implementation of the Privacy Integrated Queries (PINQ) platform for privacy-preserving data analysis. PINQ provides analysts with a programming interface to unscrubbed data through a SQL-like language. At the same time, the design of PINQ's analysis language and its careful implementation provide formal guarantees of differential privacy for any and all uses of the platform. PINQ's unconditional structural guarantees require no trust placed in the expertise or diligence of the analysts, substantially broadening the scope for design and deployment of privacy-preserving data analysis, especially by non-experts.},
author = {McSherry, Frank},
doi = {10.1145/1810891.1810916},
file = {:Users/liang-tingchen/Dropbox/References/McSherry - 2010 - Privacy integrated queries.pdf:pdf},
isbn = {9781605585512},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {anonymization,confidentiality,differential privacy,linq},
month = {sep},
number = {9},
pages = {89},
title = {{Privacy integrated queries}},
url = {http://portal.acm.org/citation.cfm?doid=1810891.1810916},
volume = {53},
year = {2010}
}
@inproceedings{muroya_et_al:LIPIcs:2017:7688,
abstract = {Girard's Geometry of Interaction (GoI), a semantics designed for linear logic proofs, has been also successfully applied to programming language semantics. One way is to use abstract machines that pass a token on a fixed graph along a path indicated by the GoI. These token-passing abstract machines are space efficient, because they handle duplicated computation by repeating the same moves of a token on the fixed graph. Although they can be adapted to obtain sound models with regard to the equational theories of various evaluation strategies for the lambda calculus, it can be at the expense of significant time costs. In this paper we show a token-passing abstract machine that can implement evaluation strategies for the lambda calculus, with certified time efficiency. Our abstract machine, called the Dynamic GoI Machine (DGoIM), rewrites the graph to avoid replicating computation, using the token to find the redexes. The flexibility of interleaving token transitions and graph rewriting allows the DGoIM to balance the trade-off of space and time costs. This paper shows that the DGoIM can implement call-by-need evaluation for the lambda calculus by using a strategy of interleaving token passing with as much graph rewriting as possible. Our quantitative analysis confirms that the DGoIM with this strategy of interleaving the two kinds of possible operations on graphs can be classified as "efficient" following Accattoli's taxonomy of abstract machines.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (The Dynamic Geometry of Interaction Machine: A Call-by-Need Graph Rewriter - Muroya, Koko; Ghica, Dan R)

Keywords: Geometry of Interaction, cost analysis, call-by-need reduction},
archivePrefix = {arXiv},
arxivId = {1703.10027},
author = {Muroya, Koko and Ghica, Dan R.},
booktitle = {26th EACSL Annual Conference on Computer Science Logic (CSL 2017)},
doi = {10.4230/LIPIcs.CSL.2017.32},
editor = {Goranko, Valentin and Dam, Mads},
eprint = {1703.10027},
file = {:Users/liang-tingchen/Dropbox/References//Muroya, Ghica - 2017 - The Dynamic Geometry of Interaction Machine A Call-by-Need Graph Rewriter.pdf:pdf},
isbn = {978-3-95977-045-3},
issn = {1868-8969},
keywords = {{2017,32,4230,Germany{\}},ISBN =	{\{}978-3-95977-045-3{\}},ISSN =	{\{}1868-8969{\}},URL =		{\{}http://drops.dagstuhl.de/opus/volltexte/20,URN =		{\{}urn:nbn:de:0030-drops-76886{\}},address =	{\{}Dagstuhl,and phrases geometry of,annote =	{\{}Keywords: Geometry of Interaction,author =	{\{}Koko Muroya and Dan R. Ghica{\}},booktitle =	{\{}26th EACSL Annual Conference on Compu,call-by-need reduction,call-by-need reduction{\}},co@InProceedings{\{}muroya{\_}et{\_}al:LIPIcs:2017:7688,cost analysis,csl,digital object identifier 10,doi =		{\{}10.4230/LIPIcs.CSL.2017.32{\}},editor =	{\{}Valentin Goranko and Mads Dam{\}},interaction,lipics,pages =	{\{}32:1--32:15{\}},publisher =	{\{}Schloss Dagstuhl--Leibniz-Zentrum fue,series =	{\{}Leibniz International Proceedings in Inf,title =	{\{}{\{}The Dynamic Geometry of Interaction Mach,volume =	{\{}82{\}},year =	{\{}2017{\}},{\}}st analysis}}}}}}}},
number = {32},
pages = {32:1----32:15},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{The Dynamic Geometry of Interaction Machine: A Call-by-Need Graph Rewriter}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/7688},
volume = {82},
year = {2017}
}
@article{Kupke2011,
abstract = {Coalgebras can be seen as a natural abstraction of Kripke frames. In the same sense, coalgebraic logics are generalised modal logics. In this paper, we give an overview of the basic tools, techniques and results that connect coalgebras and modal logic. We argue that coalgebras unify the semantics of a large range of different modal logics (such as probabilistic, graded, relational, conditional) and discuss unifying approaches to reasoning at this level of generality. We review languages defined in terms of the so-called cover modality, languages induced by predicate liftings as well as their common categorical abstraction, and present (abstract) results on completeness, expressiveness and complexity in these settings, both for basic languages as well as a number of extensions, such as hybrid languages and fixpoints.},
author = {Kupke, Clemens and Pattinson, Dirk},
doi = {10.1016/j.tcs.2011.04.023},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Pattinson - 2011 - Coalgebraic semantics of modal logics An overview.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebra,modal logic},
month = {sep},
number = {38},
pages = {5070--5094},
publisher = {Elsevier B.V.},
title = {{Coalgebraic semantics of modal logics: An overview}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.04.023 http://linkinghub.elsevier.com/retrieve/pii/S0304397511003215},
volume = {412},
year = {2011}
}
@article{Gonthier2011,
abstract = {Most interactive theorem provers provide support for some form of user-customizable proof automation. In a number of popular systems, such as Coq and Isabelle, this automation is achieved primarily through tactics, which are programmed in a separate language from that of the prover's base logic. While tactics are clearly useful in practice, they can be difficult to maintain and compose because, unlike lemmas, their behavior cannot be specified within the expressive type system of the prover itself. We propose a novel approach to proof automation in Coq that allows the user to specify the behavior of custom automated routines in terms of Coq's own type system. Our approach involves a sophisticated application of Coq's canonical structures, which generalize Haskell type classes and facilitate a flexible style of dependentlytyped logic programming. Specifically, just as Haskell type classes are used to infer the canonical implementation of an overloaded term at a given type, canonical structures can be used to infer the canonical proof of an overloaded lemma for a given instantiation of its parameters. We present a series of design patterns for canonical structure programming that enable one to carefully and predictably coax Coq's type inference engine into triggering the execution of user-supplied algorithms during unification, and we illustrate these patterns through several realistic examples drawn from Hoare Type Theory. We assume no prior knowledge of Coq and describe the relevant aspects of Coq type inference from first principles. Copyright {\textcopyright} 2011 ACM.},
author = {Gonthier, Georges and Ziliani, Beta and Nanevski, Aleksandar and Dreyer, Derek},
doi = {10.1145/2034574.2034798},
file = {:Users/liang-tingchen/Dropbox/References/Gonthier et al. - 2011 - How to make ad hoc proof automation less ad hoc.pdf:pdf},
isbn = {9781450308656},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Canonical structures,Coq,Custom proof automation,Hoare Type Theory,Interactive theorem proving,Tactics,Type classes},
month = {sep},
number = {9},
pages = {163--175},
title = {{How to make ad hoc proof automation less ad hoc}},
url = {https://dl.acm.org/doi/10.1145/2034574.2034798},
volume = {46},
year = {2011}
}
@phdthesis{Battenfeld2008,
author = {Battenfeld, Ingo},
file = {:Users/liang-tingchen/Dropbox/References/Battenfeld - 2008 - Topological domain theory.pdf:pdf},
keywords = {Computational Effects,Computer Science,Denotational Semantics,Domain Theory,Topology},
pages = {174},
school = {University of Edinburgh},
title = {{Topological domain theory}},
url = {http://hdl.handle.net/1842/2214},
year = {2008}
}
@phdthesis{Zanasi2015,
archivePrefix = {arXiv},
arxivId = {1403.7048},
author = {Zanasi, Fabio},
eprint = {1403.7048},
file = {:Users/liang-tingchen/Dropbox/References/Zanasi - 2015 - Interacting Hopf Algebras.pdf:pdf},
keywords = {distributive law,frobenius algebra,hopf algebra,linear algebra,prop,string diagram},
school = {Universit{\'{e}} de Lyon},
title = {{Interacting Hopf Algebras}},
year = {2015}
}
@article{Dwork2014,
abstract = {The Algorithmic Foundations of Differential Privacy},
author = {Dwork, Cynthia and Roth, Aaron},
doi = {10.1561/0400000042},
file = {:Users/liang-tingchen/Dropbox/References/Dwork, Roth - 2014 - The Algorithmic Foundations of Differential Privacy.pdf:pdf},
isbn = {9781601988188},
issn = {1551-305X},
journal = {Foundations and Trends{\textregistered} in Theoretical Computer Science},
number = {3-4},
pages = {211--407},
title = {{The Algorithmic Foundations of Differential Privacy}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
volume = {9},
year = {2014}
}
@inproceedings{Brady2010a,
abstract = {Partial evaluation aims to improve the efficiency of a program by specialising it with respect to some known inputs. In this paper, we show that partial evaluation can be an effective and, unusually, easy to use technique for the efficient implementation of embedded domain-specific languages. We achieve this by exploiting dependent types and by following some simple rules in the definition of the interpreter for the domain-specific language. We present experimental evidence that partial evaluation of programs in domain-specific languages can yield efficient residual programs whose performance is competitive with their Java and C equivalents and which are also, through the use of dependent types, verifiably resource-safe. Using our technique, it follows that a verifiably correct and resource-safe program can also be an efficient program. {\textcopyright} 2010 ACM.},
address = {New York, New York, USA},
author = {Brady, Edwin C and Hammond, Kevin},
booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming - ICFP '10},
doi = {10.1145/1863543.1863587},
file = {:Users/liang-tingchen/Dropbox/References/Brady, Hammond - 2010 - Scrapping your inefficient engine.pdf:pdf},
isbn = {9781605587943},
keywords = {dependent types,partial evaluation},
pages = {297},
publisher = {ACM Press},
title = {{Scrapping your inefficient engine}},
url = {http://doi.acm.org/10.1145/1932681.1863587 http://portal.acm.org/citation.cfm?doid=1863543.1863587},
volume = {45},
year = {2010}
}
@phdthesis{Bethke1988,
author = {Bethke, Ingemarie},
file = {:Users/liang-tingchen/Dropbox/References/Bethke - 1988 - Notes on Partial Combinatory Algebras.pdf:pdf},
school = {University of Amster­dam},
title = {{Notes on Partial Combinatory Algebras}},
type = {Doctoral Thesis},
year = {1988}
}
@techreport{Robinson1986a,
author = {Robinson, Edmund P.},
file = {:Users/liang-tingchen/Dropbox/References/Robinson - 1986 - Power-domains, modalities and the Vietoris monad.pdf:pdf},
institution = {University of Cambridge},
issn = {1476-2986},
month = {oct},
publisher = {Computer Laboratory, University of Cambridge},
title = {{Power-domains, modalities and the Vietoris monad}},
type = {Book},
volume = {98},
year = {1986}
}
@article{Adamek2014a,
abstract = {Coproducts of monads on Set have arisen in both the study of computational effects and universal algebra. We describe coproducts of consistent monads on Set by an initial algebra formula, and prove also the converse: if the coproduct exists, so do the required initial algebras. That formula was, in the case of ideal monads, also used by Ghani and Uustalu. We deduce that coproduct embeddings of consistent monads are injective; and that a coproduct of injective monad morphisms is injective. Two consistent monads have a coproduct iff either they have arbitrarily large common fixpoints, or one is an exception monad, possibly modified to preserve the empty set. Hence a consistent monad has a coproduct with every monad iff it is an exception monad, possibly modified to preserve the empty set. We also show other fixpoint results, including that a functor (not constant on nonempty sets) is finitary iff every sufficiently large cardinal is a fixpoint.},
archivePrefix = {arXiv},
arxivId = {1409.3804},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Bowler, Nathan and Levy, Paul Blain and Milius, Stefan},
eprint = {1409.3804},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2014 - Coproducts of Monads on Set.pdf:pdf},
journal = {ArXiv e-prints},
month = {sep},
title = {{Coproducts of Monads on Set}},
url = {http://arxiv.org/abs/1409.3804},
year = {2014}
}
@article{Nguyen2006,
abstract = {We give a framework for developing the least model semantics, fixpoint semantics, and SLD-resolution calculi for logic programs in multimodal logics whose frame restrictions consist of the conditions of seriality (i.e. ∀ x ∃ y Ri(x, y)) and some classical first-order Horn clauses. Our approach is direct and no special restriction on occurrences of □iand {\{}white diamond suit{\}}iis required. We apply our framework for a large class of basic serial multimodal logics, which are parameterized by an arbitrary combination of generalized versions of axioms T, B, 4, 5 (in the form, e.g. 4 : □i$\phi${\{}symbol{\}} → □j□k$\phi${\{}symbol{\}}) and I : □i$\phi${\{}symbol{\}} → □j$\phi${\{}symbol{\}}. Another part of the work is devoted to programming in multimodal logics intended for reasoning about multidegree belief, for use in distributed systems of belief, or for reasoning about epistemic states of agents in multiagent systems. For that we also use the framework, and although these latter logics belong to the mentioned class of basic serial multimodal logics, the special SLD-resolution calculi proposed for them are more efficient. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Nguyen, Linh Anh},
doi = {10.1016/j.tcs.2006.03.026},
file = {:Users/liang-tingchen/Dropbox/References/Nguyen - 2006 - Multimodal logic programming.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Kripke models,Logic programming,Logics of belief,MProlog,Modal logic},
month = {aug},
number = {1-3},
pages = {247--288},
title = {{Multimodal logic programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506002830},
volume = {360},
year = {2006}
}
@article{Edelkamp2018,
abstract = {QuickXsort is a highly efficient in-place sequential sorting scheme that mixes Hoare's Quicksort algorithm with X, where X can be chosen from a wider range of other known sorting algorithms, like Heapsort, Insertionsort and Mergesort. Its major advantage is that QuickXsort can be in-place even if X is not. In this work we provide general transfer theorems expressing the number of comparisons of QuickXsort in terms of the number of comparisons of X. More specifically, if pivots are chosen as medians of (not too fast) growing size samples, the average number of comparisons of QuickXsort and X differ only by {\$}o(n){\$}-terms. For median-of-{\$}k{\$} pivot selection for some constant {\$}k{\$}, the difference is a linear term whose coefficient we compute precisely. For instance, median-of-three QuickMergesort uses at most {\$}n \backslashlg n - 0.8358n + O(\backslashlog n){\$} comparisons. Furthermore, we examine the possibility of sorting base cases with some other algorithm using even less comparisons. By doing so the average-case number of comparisons can be reduced down to {\$}n \backslashlg n- 1.4106n + o(n){\$} for a remaining gap of only {\$}0.0321n{\$} comparisons to the known lower bound (while using only {\$}O(\backslashlog n){\$} additional space and {\$}O(n \backslashlog n){\$} time overall). Implementations of these sorting strategies show that the algorithms challenge well-established library implementations like Musser's Introsort.},
archivePrefix = {arXiv},
arxivId = {1811.01259},
author = {Edelkamp, Stefan and Wei{\ss}, Armin and Wild, Sebastian},
eprint = {1811.01259},
file = {:Users/liang-tingchen/Dropbox/References/Edelkamp, Wei{\ss}, Wild - 2018 - QuickXsort - A Fast Sorting Scheme in Theory and Practice.pdf:pdf},
month = {nov},
title = {{QuickXsort - A Fast Sorting Scheme in Theory and Practice}},
url = {http://arxiv.org/abs/1811.01259},
year = {2018}
}
@unpublished{Sterling2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1809.08646v1},
author = {Sterling, Jonathan and Spitters, Bas},
eprint = {arXiv:1809.08646v1},
file = {:Users/liang-tingchen/Dropbox/References/Sterling, Spitters - 2018 - Normalization by gluing for free $\lambda$-theories.pdf:pdf},
month = {sep},
pages = {1--21},
title = {{Normalization by gluing for free $\lambda$-theories}},
year = {2018}
}
@article{Turing1937,
abstract = {The "computable" numbers may be described briefly as the real numbers whose expressions as a decimal are calculable by finite means. Although the subject of this paper is ostensibly the computable numbers. it is almost equally easy to define and investigate computable functions of an integral variable or a real or computable variable, computable predicates, and so forth. The fundamental problems involved are, however, the same in each case, and I have chosen the computable numbers for explicit treatment as involving the least cumbrous technique. I hope shortly to give an account of the relations of the computable numbers, functions, and so forth to one another. This will include a development of the theory of functions of a real variable expressed in terms of com-putable numbers. According to my definition, a number is computable if its decimal can be written down by a machine. In 9, 10 I give some arguments with the intention of showing that the computable numbers include all numbers which could naturally be regarded as computable. In particular, I show that certain large classes of numbers are computable. They include, for instance, the real parts of all algebraic numbers, the real parts of the zeros of the Bessel functions, the numbers IT, e, etc. The computable numbers do not, however, include all definable numbers, and an example is given of a definable number which is not computable. Although the class of computable numbers is so great, and in many Avays similar to the class of real numbers, it is nevertheless enumerable. In 81 examine certain arguments which would seem to prove the contrary. By the correct application of one of these arguments, conclusions are reached which are superficially similar to those of Gbdelf. These results f Godel, " Uber formal unentscheidbare Satze der Principia Mathematica und ver- • vvandter Systeme, I " . Monatsheftc Math. Phys., 38 (1931), 173-198.},
author = {Turing, A. M.},
doi = {10.1112/plms/s2-42.1.230},
file = {:Users/liang-tingchen/Dropbox/References/Turing - 1937 - On Computable Numbers, with an Application to the Entscheidungsproblem.pdf:pdf},
issn = {00246115},
journal = {Proceedings of the London Mathematical Society},
number = {1},
pages = {230--265},
title = {{On Computable Numbers, with an Application to the Entscheidungsproblem}},
url = {http://draperg.cis.byuh.edu/archive/winter2014/cs320/Turing{\_}Paper{\_}1936.pdf http://doi.wiley.com/10.1112/plms/s2-42.1.230},
volume = {s2-42},
year = {1937}
}
@unpublished{Gumm1999,
author = {Gumm, H. Peter},
file = {:Users/liang-tingchen/Dropbox/References/Gumm - 1999 - Elements of the general theory of coalgebras.pdf:pdf},
keywords = {Coalgebra,coalgebra},
mendeley-tags = {coalgebra},
title = {{Elements of the general theory of coalgebras}},
type = {Unpublished work},
url = {http://www.mathematik.uni-marburg.de/{~}gumm/Papers/Luatcs.ps},
year = {1999}
}
@incollection{Dybjer1996,
author = {Dybjer, Peter},
booktitle = {Types for Proofs and Programs. TYPES 1995},
doi = {10.1007/3-540-61780-9_66},
editor = {Berardi, Stefano and Coppo, Mario},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer - 1996 - Internal type theory.pdf:pdf},
pages = {120--134},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Internal type theory}},
url = {http://www.springerlink.com/content/y7185498v632w087/ http://link.springer.com/10.1007/3-540-61780-9{\_}66},
volume = {1158},
year = {1996}
}
@article{Hansen2004,
author = {Hansen, Helle Hvid and Kupke, Clemens},
doi = {10.1016/j.entcs.2004.02.028},
file = {:Users/liang-tingchen/Dropbox/References/Hansen, Kupke - 2004 - A coalgebraic perspective on monotone modal logic.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {bisimulation,coalgebra,frame,modal logic},
month = {dec},
pages = {121--143},
title = {{A coalgebraic perspective on monotone modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104051722},
volume = {106},
year = {2004}
}
@incollection{Hughes1995,
author = {Hughes, John},
booktitle = {Advanced Functional Programming},
editor = {Meijer, J. Jeuring and E.},
file = {:Users/liang-tingchen/Dropbox/References/Hughes - 1995 - The design of a pretty-printing library.pdf:pdf},
pages = {53--96},
publisher = {Springer Verlag},
series = {Lecture Notes in Computer Science},
title = {{The design of a pretty-printing library}},
url = {http://www.cse.chalmers.se/{~}rjmh/Papers/pretty.html},
year = {1995}
}
@article{Crolard2001,
abstract = {This paper is the first part of a work whose purpose is to investigate duality in some related frameworks (cartesian closed categories, lambda-calculi, intuitionistic and classical logics) from syntactic, semantical and computational viewpoints. We start with category theory and we show that any bicartesian closed category with coexponents is degenerated (i.e. there is at most one arrow between two objects). The remainder of the paper is devoted to logical issues. We examine the propositional calculus underlying the type system of bicartesian closed categories with coexponents and we show that this calculus corresponds to subtractive logic: a conservative extension of intuitionistic logic with a new connector (subtraction) dual to implication. Eventually, we consider first-order subtractive logic and we present an embedding of classical logic into subtractive logic. {\textcopyright} 2001 Published by Elsevier Science B.V.},
author = {Crolard, Tristan},
doi = {10.1016/S0304-3975(99)00124-3},
file = {:Users/liang-tingchen/Dropbox/References/Crolard - 2001 - Subtractive logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {1-2},
pages = {151--185},
title = {{Subtractive logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397599001243},
volume = {254},
year = {2001}
}
@article{Kiss2019,
author = {Kiss, Csongor and Field, Tony and Eisenbach, Susan and {Peyton Jones}, Simon},
doi = {10.1145/3341706},
file = {:Users/liang-tingchen/Dropbox/References/Kiss et al. - 2019 - Higher-order type-level programming in Haskell.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Higher-order functions,Type families,Type-level programming},
month = {jul},
number = {ICFP},
pages = {1--26},
title = {{Higher-order type-level programming in Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341706},
volume = {3},
year = {2019}
}
@incollection{Beck1969,
author = {Beck, Jon},
booktitle = {Seminar on Triples and Categorical Homology Theory},
doi = {10.1007/BFb0083084},
editor = {Eckmann, B.},
file = {:Users/liang-tingchen/Dropbox/References/Beck - 1969 - Distributive Laws.pdf:pdf},
pages = {119--140},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Distributive Laws}},
year = {1969}
}
@inproceedings{Gratzer2020,
abstract = {We introduce MTT, a dependent type theory which supports multiple modalities. MTT is parametrized by a mode theory which specifies a collection of modes, modalities, and transformations between them. We show that different choices of mode theory allow us to use the same type theory to compute and reason in many modal situations, including guarded recursion, axiomatic cohesion, and parametric quantification. We reproduce examples from prior work in guarded recursion and axiomatic cohesion--demonstrating that MTT constitutes a simple and usable syntax whose instantiations intuitively correspond to previous handcrafted modal type theories. In some cases, instantiating MTT to a particular situation unearths a previously unknown type theory that improves upon prior systems. Finally, we investigate the metatheory of MTT. We prove the consistency of MTT and establish canonicity through an extension of recent type-theoretic gluing techniques. These results hold irrespective of the choice of mode theory, and thus apply to a wide variety of modal situations.},
address = {New York, NY, USA},
author = {Gratzer, Daniel and Kavvos, G. Alex and Nuyts, Andreas and Birkedal, Lars},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394736},
file = {:Users/liang-tingchen/Dropbox/References/Gratzer et al. - 2020 - Multimodal Dependent Type Theory.pdf:pdf},
isbn = {9781450371049},
keywords = {Modal types K@dependent types,categorical semantics,gluing,guarded recursion},
month = {jul},
pages = {492--506},
publisher = {ACM},
title = {{Multimodal Dependent Type Theory}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394736},
year = {2020}
}
@book{Butz1998,
abstract = {Notes handed out to students attending the course on Category Theory at the Department of Computer Science in Aarhus, Spring 1998. These notes were supposed to give more detailed information about the relationship between regular categories and regular logic than is contained in Jaap van Oosten's script on category theory (BRICS Lectures Series LS-95-1). Regular logic is there called coherent logic.},
author = {Butz, Carsten},
file = {:Users/liang-tingchen/Dropbox/References/Butz - 1998 - Regular Categories and Regular Logic.pdf:pdf},
issn = {1395-2048},
number = {October},
pages = {46},
series = {BRICS Lecture Series},
title = {{Regular Categories and Regular Logic}},
year = {1998}
}
@inproceedings{Cuff2016,
abstract = {Differential privacy is a precise mathematical constraint meant to ensure privacy of individual pieces of information in a database even while queries are being answered about the aggregate. Intuitively, one must come to terms with what differential privacy does and does not guarantee. For example, the definition prevents a strong adversary who knows all but one entry in the database from further inferring about the last one. This strong adversary assumption can be overlooked, resulting in misinterpretation of the privacy guarantee of differential privacy. Herein we give an equivalent definition of privacy using mutual information that makes plain some of the subtleties of differential privacy. The mutual-information differential privacy is in fact sandwiched between {\$}\backslashepsilon{\$}-differential privacy and {\$}(\backslashepsilon,\backslashdelta){\$}-differential privacy in terms of its strength. In contrast to previous works using unconditional mutual information, differential privacy is fundamentally related to conditional mutual information, accompanied by a maximization over the database distribution. The conceptual advantage of using mutual information, aside from yielding a simpler and more intuitive definition of differential privacy, is that its properties are well understood. Several properties of differential privacy are easily verified for the mutual information alternative, such as composition theorems.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1608.03677},
author = {Cuff, Paul and Yu, Lanqing},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security - CCS'16},
doi = {10.1145/2976749.2978308},
eprint = {1608.03677},
file = {:Users/liang-tingchen/Dropbox/References/Cuff, Yu - 2016 - Differential Privacy as a Mutual Information Constraint.pdf:pdf},
isbn = {9781450341394},
issn = {15437221},
keywords = {differential privacy,information theory},
pages = {43--54},
publisher = {ACM Press},
title = {{Differential Privacy as a Mutual Information Constraint}},
url = {http://arxiv.org/abs/1608.03677{\%}0Ahttp://dx.doi.org/10.1145/2976749.2978308 http://dl.acm.org/citation.cfm?doid=2976749.2978308},
year = {2016}
}
@incollection{Berger1998,
abstract = {We extend normalization by evaluation (first presented in [4]) from the pure typed $\lambda$-calculus to general higher type term rewrite systems. This work also gives a theoretical explanation of the normalization algorithm implemented in the Minlog system},
author = {Berger, Ulrich and Eberl, Matthias and Schwichtenberg, Helmut},
booktitle = {Prospects for Hardware Foundations},
doi = {10.1007/3-540-49254-2_4},
editor = {M{\"{o}}ller, Bernhard and {John V. Tucker}},
file = {:Users/liang-tingchen/Dropbox/References/Berger, Eberl, Schwichtenberg - 1998 - Normalization by Evaluation.pdf:pdf},
pages = {117--137},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Normalization by Evaluation}},
url = {http://link.springer.com/10.1007/3-540-49254-2{\_}4},
volume = {1546},
year = {1998}
}
@inproceedings{Serrano2018,
abstract = {Datatype-generic programming is a widely used technique to define functions that work regularly over a class of datatypes. Examples include deriving serialization of data, equality or even functoriality. The state-of-the-art of generic programming still lacks handling GADTs, multiple type variables, and some other features. This paper exploits modern GHC extensions, including TypeInType , to handle arbitrary number of type variables, constraints, and existentials. We also provide an Agda model of our construction that does not require Russel's paradox, proving the construction is consistent.},
address = {New York, NY, USA},
author = {Serrano, Alejandro and Miraldo, Victor Cacciari},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Haskell},
doi = {10.1145/3242744.3242745},
file = {:Users/liang-tingchen/Dropbox/References/Serrano, Miraldo - 2018 - Generic programming of all kinds.pdf:pdf},
isbn = {9781450358354},
issn = {15232867},
keywords = {Generic programming,Haskell},
month = {sep},
number = {7},
pages = {41--54},
publisher = {ACM},
title = {{Generic programming of all kinds}},
url = {https://dl.acm.org/doi/10.1145/3242744.3242745},
volume = {53},
year = {2018}
}
@article{Ulmer1968,
author = {Ulmer, Friedrich},
doi = {10.1016/0021-8693(68)90036-7},
file = {:Users/liang-tingchen/Dropbox/References/Ulmer - 1968 - Properties of dense and relative adjoint functors.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
month = {jan},
number = {1},
pages = {77--95},
title = {{Properties of dense and relative adjoint functors}},
url = {http://dx.doi.org/10.1016/0021-8693(68)90036-7 http://linkinghub.elsevier.com/retrieve/pii/0021869368900367},
volume = {8},
year = {1968}
}
@article{ABEL2016,
abstract = {In this paper, we study strong normalization of a core language based on System {\$}{\{}\backslashmathsf{\{}F{\}}{\_}\backslashomega{\}}{\$} which supports programming with finite and infinite structures. Finite data such as finite lists and trees is defined via constructors and manipulated via pattern matching, while infinite data such as streams and infinite trees is defined by observations and synthesized via copattern matching. Taking a type-based approach to strong normalization, we track size information about finite and infinite data in the type. We exploit the duality of pattern and copatterns to give a unifying semantic framework which allows us to elegantly and uniformly support both well-founded induction and coinduction by rewriting. The strong normalization proof is structured around Girard's reducibility candidates. As such, our system allows for non-determinism and does not rely on coverage. Since System {\$}{\{}\backslashmathsf{\{}F{\}}{\_}\backslashomega{\}}{\$} is general enough that it can be the target of compilation for the Calculus of Constructions, this work is a significant step towards representing observation-based infinite data in proof assistants such as Coq and Agda.},
author = {Abel, Andreas M. and Pientka, Brigitte},
doi = {10.1017/S0956796816000022},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Pientka - 2016 - Well-founded recursion with copatterns and sized types.pdf:pdf},
isbn = {9781450323260},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
pages = {e2},
title = {{Well-founded recursion with copatterns and sized types}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796816000022},
volume = {26},
year = {2016}
}
@misc{Admek2004,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
booktitle = {Studia Logica},
doi = {10.1007/s11225-005-7033-6},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2004 - On quasivarieties and varieties as categories.pdf:pdf},
issn = {0039-3215},
keywords = {exact generator,pseudoequivalence,quasivariety,regular generator,variety},
number = {1-2},
pages = {7--33},
title = {{On quasivarieties and varieties as categories}},
volume = {78},
year = {2004}
}
@incollection{Nordstrom2000,
author = {Nordstr{\"{o}}m, Bengt and Petersson, Kent and Smith, Jan M.},
booktitle = {Handbook of Logic in Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Nordstr{\"{o}}m, Petersson, Smith - 2000 - Martin-L{\"{o}}f Type Theory.pdf:pdf},
isbn = {978-0-19-853781-6},
number = {October},
publisher = {Oxford University Press},
title = {{Martin-L{\"{o}}f Type Theory}},
volume = {5},
year = {2000}
}
@article{Urbat2016,
abstract = {Eilenberg-type correspondences, relating varieties of languages (e.g. of finite words, infinite words, or trees) to pseudovarieties of finite algebras, form the backbone of algebraic language theory. Numerous such correspondences are known in the literature. We demonstrate that they all arise from the same recipe: one models languages and the algebras recognizing them by monads on an algebraic category, and applies a Stone-type duality. Our main contribution is a generic variety theorem that covers e.g. Wilke's and Pin's work on {\$}\backslashinfty{\$}-languages, the variety theorem for cost functions of Daviaud, Kuperberg, and Pin, and unifies the two previous categorical approaches of Boja$\backslash$'nczyk and of Ad$\backslash$'amek et al. In addition it gives a number of new results, such as an extension of the local variety theorem of Gehrke, Grigorieff, and Pin from finite to infinite words.},
archivePrefix = {arXiv},
arxivId = {1602.05831},
author = {Urbat, Henning and Ad{\'{a}}mek, Jiř{\'{i}} and Chen, Liang-Ting and Milius, Stefan},
eprint = {1602.05831},
file = {:Users/liang-tingchen/Dropbox/References/Urbat et al. - 2016 - One Eilenberg theorem to rule them all.pdf:pdf},
journal = {ArXiv preprint},
title = {{One Eilenberg theorem to rule them all}},
url = {http://arxiv.org/abs/1602.05831},
year = {2016}
}
@article{Hedges2014,
abstract = {This paper extends Escard{\'{o}} and Oliva's selection monad to the selection monad transformer, a general monadic framework for expressing backtracking search algorithms in Haskell. The use of the closely related continuation monad transformer for similar purposes is also discussed, including an implementation of a DPLL-like SAT solver with no explicit recursion. Continuing a line of work exploring connections between selection functions and game theory, we use the selection monad transformer with the nondeterminism monad to obtain an intuitive notion of backward induction for a certain class of nondeterministic games.},
archivePrefix = {arXiv},
arxivId = {1406.2058},
author = {Hedges, Jules},
doi = {10.4204/EPTCS.153.3},
eprint = {1406.2058},
file = {:Users/liang-tingchen/Dropbox/References/Hedges - 2014 - Monad Transformers for Backtracking Search.pdf:pdf},
isbn = {978-1-4244-4712-1},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {jun},
number = {4},
pages = {31--50},
publisher = {IEEE},
title = {{Monad Transformers for Backtracking Search}},
url = {http://arxiv.org/abs/1406.2058v1},
volume = {153},
year = {2014}
}
@article{Milius2005,
author = {Milius, Stefan},
doi = {10.1016/j.ic.2004.05.003},
file = {:Users/liang-tingchen/Dropbox/References/Milius - 2005 - Completely iterative algebras and completely iterative monads.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {coalgebra,completely iterative algebra,completely iterative theory,monad},
month = {jan},
number = {1},
pages = {1--41},
title = {{Completely iterative algebras and completely iterative monads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540104001488},
volume = {196},
year = {2005}
}
@article{Doberkat2011,
author = {Doberkat, Ernst-Erich and Schubert, Christoph},
doi = {10.1017/S0960129510000526},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat, Schubert - 2011 - Coalgebraic logic over general measurable spaces–--a survey.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {02},
pages = {175--234},
title = {{Coalgebraic logic over general measurable spaces–--a survey}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Coalgebraic+Logic+Over+General+Measurable+Spaces+?+A+Survey{\#}0 http://www.journals.cambridge.org/abstract{\_}S0960129510000526},
volume = {21},
year = {2011}
}
@incollection{Bonizzoni2009,
author = {Bonizzoni, Paola and {Della Vedova}, Gianluca and Dondi, Riccardo},
booktitle = {Fundamentals of Computation Theory},
doi = {10.1007/978-3-642-03409-1_4},
editor = {Kuty{\l}owski, Miros{\l}aw and Charatonik, Witold and G{\c{e}}bala, Maciej},
file = {:Users/liang-tingchen/Dropbox/References/Bonizzoni, Della Vedova, Dondi - 2009 - The {\$}k{\$}-Anonymity Problem Is Hard.pdf:pdf},
pages = {26--37},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The {\$}k{\$}-Anonymity Problem Is Hard}},
url = {http://link.springer.com/10.1007/978-3-642-03409-1{\_}4},
volume = {5699},
year = {2009}
}
@article{Fellegi1969,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. A mathematical model is developed to provide a theoretical frame-work for a computer-oriented solution to the problem of recognizing those records in two files which represent identical persons, objects or events (said to be matched). A comparison is to be made between the recorded characteristics and values in two records (one from each file) and a decision made as to whether or not the members of the comparison-pair represent the same person or event, or whether there is insufficient evidence to justify either of these decisions at stipulated levels of error. These three decisions are referred to as link (A1), a non-link (A3), and a possible link (A2). The first two decisions are called positive dispositions. The two types of error are defined as the error of the decision A, when the members of the comparison pair are in fact unmatched, and the error of the decision A, when the members of the comparison pair are, in fact matched. The probabilities of these errors are defined as = E u(y)P(A,I y) rer and X m(r)P(AaIr) yTr respectively where u(y), m(y) are the probabilities of realizing y (a comparison vector whose components are the coded agreements and disagreements on each characteristic) for unmatched and matched record pairs respectively. The summation is over the whole comparison space r of possible realizations. A linkage rule assigns probabilities P(A, Iy), and P(A2 1y), and P(A3 'y) to each possible realization of y e P. An optimal linkage rule L (u, X, r) is defined for each value of (,u, X) as the rule that minimizes P(A2) at those error levels. In other words, for fixed levels of error, the rule minimizes the probability of failing to make positive dispositions. A theorem describing the construction and properties of the optimal linkage rule and two corollaries to the theorem which make it a practical working tool are given.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.2649v3},
author = {Fellegi, Ivan P. and Sunter, Alan B.},
doi = {10.2307/2286061},
eprint = {arXiv:1011.2649v3},
file = {:Users/liang-tingchen/Dropbox/References/Fellegi, Sunter - 1969 - A Theory for Record Linkage.pdf:pdf},
isbn = {01621459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
month = {dec},
number = {328},
pages = {1183},
title = {{A Theory for Record Linkage}},
url = {http://www.jstor.org/stable/2286061?origin=crossref},
volume = {64},
year = {1969}
}
@article{Isbell1963,
author = {Isbell, John R.},
file = {:Users/liang-tingchen/Dropbox/References/Isbell - 1963 - Two set-theoretical theorems in categories.pdf:pdf},
journal = {Fund. Math.},
pages = {43--49},
title = {{Two set-theoretical theorems in categories}},
volume = {53},
year = {1963}
}
@article{Kozen2013,
author = {Kozen, Dexter and Larsen, Kim G. and Mardare, Radu and Panangaden, Prakash},
doi = {10.1109/LICS.2013.38},
file = {:Users/liang-tingchen/Dropbox/References/Kozen et al. - 2013 - Stone Duality for Markov Processes.pdf:pdf},
isbn = {978-1-4799-0413-6},
journal = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
month = {jun},
pages = {321--330},
publisher = {Ieee},
title = {{Stone Duality for Markov Processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6571564},
year = {2013}
}
@article{Alpern1987,
abstract = {A formal characterization for safety properties and liveness properties is given in terms of the structure of the Buchi automaton that specifies the property. The characterizations permit a property to be decomposed into a safety property and a liveness property whose conjunction is the original. The characterizations also give insight into techniques required to prove a large class of safety and liveness properties.},
author = {Alpern, Bowen and Schneider, Fred B.},
doi = {10.1007/BF01782772},
file = {:Users/liang-tingchen/Dropbox/References/Alpern, Schneider - 1987 - Recognizing safety and liveness.pdf:pdf},
issn = {0178-2770},
journal = {Distributed Computing},
month = {sep},
number = {3},
pages = {117--126},
title = {{Recognizing safety and liveness}},
url = {http://link.springer.com/10.1007/BF01782772},
volume = {2},
year = {1987}
}
@book{Tennent1991a,
author = {Tennent, R. D.},
isbn = {0138055998},
month = {jul},
publisher = {Prentice Hall},
title = {{Semantics of Programming Languages}},
type = {Book},
year = {1991}
}
@article{Lack,
archivePrefix = {arXiv},
arxivId = {arXiv:0802.1946v2},
author = {Lack, Stephen},
doi = {10.1007/s10485-008-9167-y},
eprint = {arXiv:0802.1946v2},
file = {:Users/liang-tingchen/Dropbox/References/Lack - 2008 - Note on the Construction of Free Monoids.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
month = {oct},
number = {1},
pages = {17--29},
title = {{Note on the Construction of Free Monoids}},
url = {http://link.springer.com/10.1007/s10485-008-9167-y},
volume = {18},
year = {2008}
}
@techreport{Kupke2003,
abstract = {We argue that the category of Stone spaces forms an interesting base category for coalgebras, in particular, if one considers the Vietoris functor as an analogue to the power set functor on the category of sets. We prove that the so-called descriptive general frames, which play a fundamental role in the semantics of modal logics, can be seen as Stone coalgebras in a natural way. This yields a duality between modal algebras and coalgebras for the Vietoris functor. Building on this idea, we introduce the notion of a Vietoris polynomial functor over the category of Stone spaces. For each such functor T we provide an adjunction between T-sorted Boolean algebras with operators and the Stone coalgebras for T. We also identify the subcategory of algebras on which the adjunction restricts to an equivalence and show that the final T-coalgebra is the dual of the initial T-BAO.},
annote = {
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Kupke, Clemens and Kurz, Alexander and Venema, Yde},
booktitle = {Theoretical Computer Science},
doi = {10.1016/j.tcs.2004.07.023},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Kurz, Venema - 2003 - Stone coalgebras.pdf:pdf},
issn = {0304-3975},
keywords = {In this paper we argue that the category of Stone,Kripke polynomial functors,can be seen as Stone coalgebras in a natural way.,coalgebra,descriptive general,frames,functors,if one considers the Vietoris functor as an analog,in particular,kripke,kripke polynomial functors,modal logic,polynomial,stone spaces,this shows that Coalg(T){\^{}}op is a full reflective s,vietoris topology,we introduce the notion of a Vietoris polynomial f,which play a fundamental role in the semantics of},
mendeley-tags = {In this paper we argue that the category of Stone,can be seen as Stone coalgebras in a natural way.,functors,if one considers the Vietoris functor as an analog,in particular,kripke,polynomial,this shows that Coalg(T){\^{}}op is a full reflective s,we introduce the notion of a Vietoris polynomial f,which play a fundamental role in the semantics of},
month = {oct},
number = {1--2},
pages = {109--134},
title = {{Stone coalgebras}},
type = {Journal article},
url = {http://dare.uva.nl/en/record/114520 http://www.sciencedirect.com/science/article/pii/S0304397504004451},
volume = {327},
year = {2003}
}
@article{Rothe2003,
author = {Rothe, Jan and Ma{\v{s}}ulovi{\'{c}}, Dragan},
doi = {10.1016/S1571-0661(04)80646-7},
file = {:Users/liang-tingchen/Dropbox/References/Rothe, Ma{\v{s}}ulovi{\'{c}} - 2003 - Modal Logics for Observation Equivalences.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jul},
number = {1},
pages = {303--320},
title = {{Modal Logics for Observation Equivalences}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104806467},
volume = {82},
year = {2003}
}
@article{Kozen1983,
abstract = {In this paper we define and study a propositional ??-calculus L??, which consists essentially of propositional modal logic with a least fixpoint operator. L?? is syntactically simpler yet strictly more expressive than Propositional Dynamic Logic (PDL). For a restricted version we give an exponential-time decision procedure, small model property, and complete deductive system, theory subsuming the corresponding results for PDL. ?? 1983.},
author = {Kozen, Dexter},
doi = {10.1016/0304-3975(82)90125-6},
file = {:Users/liang-tingchen/Dropbox/References/Kozen - 1983 - Results on the propositional $\mu$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {3},
pages = {333--354},
title = {{Results on the propositional $\mu$-calculus}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397582901256},
volume = {27},
year = {1983}
}
@inproceedings{Devriese2013,
abstract = {We present a novel set of meta-programming primitives for use in a dependently-typed functional language. The types of our meta-programs provide strong and precise guarantees about their termination, correctness and completeness. Our system supports type-safe construction and analysis of terms, types and typing contexts. Unlike alternative approaches, they are written in the same style as normal programs and use the language's standard functional computational model. We formalise the new meta-programming primitives, implement them as an extension of Agda, and provide evidence of usefulness by means of two compelling applications in the fields of datatype-generic programming and proof tactics.},
address = {New York, New York, USA},
author = {Devriese, Dominique and Piessens, Frank},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500575},
file = {:Users/liang-tingchen/Dropbox/References/Devriese, Piessens - 2013 - Typed syntactic meta-programming.pdf:pdf},
isbn = {9781450323260},
issn = {0362-1340},
keywords = {datatype-generic,dependent types,meta-programming,programming,tactics},
month = {nov},
number = {9},
pages = {73},
publisher = {ACM Press},
title = {{Typed syntactic meta-programming}},
url = {http://dl.acm.org/citation.cfm?doid=2500365.2500575},
volume = {48},
year = {2013}
}
@article{Ghiorzi2020,
abstract = {We introduce the theory of enrichment over an internal monoidal category as a common generalization of both the standard theories of enriched and internal categories. The aim of the paper is to justify and contextualize the new notion by comparing it to other known generalizations of enrichment: namely, those for indexed categories and for generalized multicategories. It turns out that both of these notions are closely related to internal enrichment and, as a corollary, to each other.},
archivePrefix = {arXiv},
arxivId = {2006.07997},
author = {Ghiorzi, Enrico},
eprint = {2006.07997},
file = {:Users/liang-tingchen/Dropbox/References/Ghiorzi - 2020 - Internal enriched categories.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {Mathematics - Category Theory},
month = {jun},
pages = {1--47},
title = {{Internal enriched categories}},
url = {http://arxiv.org/abs/2006.07997},
year = {2020}
}
@article{Dalen1999,
author = {van Dalen, Dirk},
doi = {10.1023/A:1026411905257},
file = {:Users/liang-tingchen/Dropbox/References/Dalen - 1999 - From Brouwerian Counter Examples to the Creating Subject.pdf:pdf},
journal = {Studia Logica},
number = {2},
pages = {305----314},
title = {{From Brouwerian Counter Examples to the Creating Subject}},
url = {https://doi.org/10.1023/A:1026411905257},
volume = {62},
year = {1999}
}
@article{Gomes1985,
abstract = {The purpose of this article is to introduce the notion of “recursive realizability.”},
author = {Kleene, S. C.},
doi = {10.2307/2269016},
file = {:Users/liang-tingchen/Dropbox/References/Kleene - 1945 - On the interpretation of intuitionistic number theory.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {dec},
number = {4},
pages = {109--124},
title = {{On the interpretation of intuitionistic number theory}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200061363/type/journal{\_}article},
volume = {10},
year = {1945}
}
@incollection{Kelly1974,
author = {Kelly, Gregory Maxwell and Street, Ross},
booktitle = {Category Seminar: Proceedings Sydney Category Theory Seminar 1972/1973},
doi = {10.1007/BFb0063101},
editor = {Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Street - 1974 - Review of the elements of 2-categories.pdf:pdf},
isbn = {978-3-540-06966-9},
pages = {75--103},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Review of the elements of 2-categories}},
year = {1974}
}
@article{Hutton1998,
abstract = {This paper is a tutorial on defining recursive descent parsers in Haskell. In the spirit of one-stop shopping, the paper combines material from three areas into a single source. The three areas are functional parsers (Burge, 1975; Wadler, 1985; Hutton, 1992; Fokker, 1995), the use of monads to structure functional programs (Wadler, 1990, 1992a, 1992b), and the use of special syntax for monadic programs in Haskell (Jones, 1995; Peterson et al., 1996). More specifically, the paper shows how to define monadic parsers using do notation in Haskell. Of course, recursive descent parsers defined by hand lack the efficiency of bottom-up parsers generated by machine (Aho et al., 1986; Mogensen, 1993; Gill and Marlow, 1995). However, for many research applications, a simple recursive descent parser is perfectly sufficient. Moreover, while parser generators typically offer a fixed set of combinators for describing grammars, the method described here is completely extensible: parsers are first-class values, and we have the full power of Haskell available to define new combinators for special applications. The method is also an excellent illustration of the elegance of functional programming.},
author = {Hutton, Graham and Meijer, Erik},
file = {:Users/liang-tingchen/Dropbox/References/Hutton, Meijer - 1998 - Monadic Parsing in Haskell.pdf:pdf},
journal = {Journal of Functional Programming},
number = {04},
pages = {437--444},
publisher = {Cambridge University Press},
title = {{Monadic Parsing in Haskell}},
url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online{\&}aid=44175},
volume = {8},
year = {1998}
}
@phdthesis{OConnor2009,
author = {O'Connor, Russell},
file = {:Users/liang-tingchen/Dropbox/References/O'Connor - 2009 - Incompleteness {\&} completeness formalizing logic and analysis in type theory.pdf:pdf},
isbn = {9789090244556},
pages = {151},
school = {Radboud Universiteit Nijmegen},
title = {{Incompleteness {\&} completeness : formalizing logic and analysis in type theory}},
year = {2009}
}
@article{Rosicky1990,
author = {Rosick{\'{y}}, Jiř{\'{i}} and Trnkov{\'{a}}, V{\v{e}}ra and Ad{\'{a}}mek, Jiř{\'{i}}},
doi = {10.1007/BF01182450},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}}, Trnkov{\'{a}}, Ad{\'{a}}mek - 1990 - Unexpected properties of locally presentable categories.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {jun},
number = {2},
pages = {153--170},
title = {{Unexpected properties of locally presentable categories}},
url = {http://www.springerlink.com/index/10.1007/BF01182450},
volume = {27},
year = {1990}
}
@article{Kakutani2019,
abstract = {In the stream of studies on intuitionistic modal logic, we can find mainly three kinds of natural deduction systems. For logical aspects, adding axiom schemata is a simple and popular way to construct a system. The Curry-Howard correspondence, however, gives us a connection between logic and computer science. From the viewpoint of programming languages, two more important systems, called a dual-context system and a Fitch-style system, have been proposed. While dual-context systems for S4 are heavily used in the field of staged computation, a dual-context system for K is also studied more recently. In our previous studies, categorical semantics for Fitch-style modal logic is proposed and usefulness of levels is noticed. This paper observes an interesting fact that the box modality of the dual-context system is in fact a left adjoint of that of the Fitch-style system. In order to show the statement, we embed both the two systems, which are refined with levels, into the adjoint calculus that equips an adjunction a priori. Moreover, the adjunction is refined with polarity and the adjoint calculus is extended to polarized logic.},
author = {Kakutani, Yoshihiko and Murase, Yuito and Nishiwaki, Yuichi},
doi = {10.2197/ipsjjip.27.77},
file = {:Users/liang-tingchen/Dropbox/References/Kakutani, Murase, Nishiwaki - 2019 - Dual-context Modal Logic as Left Adjoint of Fitch-style Modal Logic.pdf:pdf},
issn = {1882-6652},
journal = {Journal of Information Processing},
keywords = {Adjunction,Lambda-calculus,Modal logic,Staged computation},
pages = {77--86},
title = {{Dual-context Modal Logic as Left Adjoint of Fitch-style Modal Logic}},
url = {https://www.jstage.jst.go.jp/article/ipsjjip/27/0/27{\_}77/{\_}article},
volume = {27},
year = {2019}
}
@book{Flu2008,
editor = {Flum, Jörg and Grädel, Erich and Wilke, Thomas},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 2008 - Logic and Automata History and Perspectives.pdf:pdf},
pages = {736},
publisher = {Amsterdam University Press},
series = {Texts in Logic and Games},
title = {{Logic and Automata: History and Perspectives}},
year = {2008}
}
@inproceedings{Dagand2013,
abstract = {Ornaments aim at taming the multiplication of special-purpose datatype in dependently-typed theory. In its original form, the definition of ornaments is tied to a particular universe of datatypes. Being a type theoretic object, constructions on ornaments are typically explained through an operational narrative. This overbearing concreteness calls for an abstract model of ornaments. In this paper, we give a categorical model of ornaments. As a necessary first step, we abstract the universe of datatypes using the theory of polynomial functors. We are then able to characterize ornaments as cartesian morphisms between polynomial functors. We thus gain access to powerful mathematical tools that shall help us understand and develop ornaments. We shall also illustrate the adequacy of our model. Firstly, we rephrase the standard ornamental constructions into our framework. Thanks to its conciseness, this process gives us a deeper understanding of the structures at play. Secondly, we develop new ornamental constructions, by translating categorical structures into type theoretic artifacts.},
author = {Dagand, Pierre-Evariste and McBride, Conor},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.60},
file = {:Users/liang-tingchen/Dropbox/References/Dagand, McBride - 2013 - A Categorical Treatment of Ornaments.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
keywords = {Type theory,category theory,inductive families},
month = {jun},
pages = {530--539},
publisher = {IEEE},
title = {{A Categorical Treatment of Ornaments}},
url = {http://ieeexplore.ieee.org/document/6571586/},
year = {2013}
}
@inproceedings{Lindley2014,
abstract = {Plotkin and Power's algebraic effects combined with Plotkin and Pretnar's effect handlers provide a foundation for modular programming with effects. We present a generalisation of algebraic effects and effect handlers to support other kinds of effectful computations corresponding to McBride and Paterson's idioms and Hughes' arrows.},
address = {New York, New York, USA},
author = {Lindley, Sam},
booktitle = {Proceedings of the 10th ACM SIGPLAN Workshop on Generic programming - WGP '14},
doi = {10.1145/2633628.2633636},
file = {:Users/liang-tingchen/Dropbox/References/Lindley - 2014 - Algebraic effects and effect handlers for idioms and arrows.pdf:pdf},
isbn = {9781450330428},
keywords = {algebraic effects,applicative functors,arrows,call-by-push-value,effect handlers,efficient implementa-,idioms,in both cases providing,monads,more space and time,tions than monadic alternatives},
pages = {47--58},
publisher = {ACM Press},
title = {{Algebraic effects and effect handlers for idioms and arrows}},
url = {http://doi.acm.org/10.1145/2633628.2633636 http://dl.acm.org/citation.cfm?doid=2633628.2633636},
year = {2014}
}
@article{Dybjer1994,
abstract = {A general formulation of inductive and recursive definitions in Martin-L{\"{o}}f's type theory is presented. It extends Backhouse's 'Do-It-Yourself Type Theory' to include inductive definitions of families of sets and definitions of functions by recursion on the way elements of such sets are generated. The formulation is in natural deduction and is intended to be a natural generalisation to type theory of Martin-L{\"{o}}f's theory of iterated inductive definitions in predicate logic. Formal criteria are given for correct formation and introduction rules of a new set former capturing definition by strictly positive, iterated, generalised induction. Moreover, there is an inversion principle for deriving elimination and equality rules from the formation and introduction rules. Finally, there is an alternative schematic presentation of definition by recursion. The resulting theory is a flexible and powerful language for programming and constructive mathematics. We hint at the wealth of possible applications by showing several basic examples: predicate logic, generalised induction, and a formalisation of the untyped lambda calculus. {\textcopyright} 1994 BCS.},
author = {Dybjer, Peter},
doi = {10.1007/BF01211308},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer - 1994 - Inductive families.pdf:pdf},
issn = {0934-5043},
journal = {Formal Aspects of Computing},
keywords = {Inductive definitions,Intuitionistic type theory,Natural deduction},
month = {jul},
number = {4},
pages = {440--465},
title = {{Inductive families}},
url = {http://link.springer.com/10.1007/BF01211308},
volume = {6},
year = {1994}
}
@article{Street1972,
author = {Street, Ross},
doi = {10.1016/0022-4049(72)90019-9},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1972 - The formal theory of monads.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jul},
number = {2},
pages = {149--168},
title = {{The formal theory of monads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404972900199},
volume = {2},
year = {1972}
}
@incollection{Urbat2017,
author = {Urbat, Henning and Ad{\'{a}}mek, Jiř{\'{i}} and Chen, Liang-Ting and Milius, Stefan},
booktitle = {42nd International Symposium on Mathematical Foundations of Computer Science ({\{}MFCS 2017{\}})},
doi = {10.4230/LIPIcs.MFCS.2017.43},
editor = {Larsen, Kim G. and Bodlaender, Hans L. and Raskin, Jean-Francois},
file = {:Users/liang-tingchen/Dropbox/References/Urbat et al. - 2017 - Eilenberg Theorems for Free.pdf:pdf},
keywords = {2017,4230,43,and phrases eilenberg,digital object identifier 10,duality,lipics,mfcs,monad,pseudovariety,s theorem,variety of languages},
pages = {43:1--43:15},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Eilenberg Theorems for Free}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/8103/},
volume = {83},
year = {2017}
}
@inproceedings{Delaware2013a,
address = {New York, New York, USA},
author = {Delaware, Benjamin and {d. S. Oliveira}, Bruno C. and Schrijvers, Tom},
booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '13},
doi = {10.1145/2429069.2429094},
file = {:Users/liang-tingchen/Dropbox/References/Delaware, d. S. Oliveira, Schrijvers - 2013 - Meta-theory {\`{a}} la carte.pdf:pdf},
isbn = {9781450318327},
keywords = {extensible church,modular mechanized meta-theory},
pages = {207},
publisher = {ACM Press},
title = {{Meta-theory {\`{a}} la carte}},
url = {http://dl.acm.org/citation.cfm?doid=2429069.2429094},
year = {2013}
}
@article{Power1990,
abstract = {Pasting is the fundamental operation within a 2-category. However, until recently, it had never been proved that the operation of pasting is well defined. In fact, a 2-categorical pasting theorem had not even been properly formulated. Herein, we state and prove such a result. This brings together two strands of the current work of the Sydney Category Theory school: taking the general theory of n-categories, and applying its ideas to the particular case of 2-categories, with heavy use of the techniques of Graph Theory. This provides a more solid foundation for the development of 2-categories.},
author = {Power, A. John},
doi = {10.1016/0021-8693(90)90229-H},
file = {:Users/liang-tingchen/Dropbox/References/Power - 1990 - A 2-categorical pasting theorem.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
number = {2},
pages = {439--445},
title = {{A 2-categorical pasting theorem}},
volume = {129},
year = {1990}
}
@article{Nieves2011,
abstract = {In the literature, there are several approaches which try to perform common sense reasoning. Among them, the approaches which have probably received the most attention the last two decades are the approaches based on logic programming semantics with negation as failure and argumentation theory. Even though both approaches have their own features, it seems that they share some common behaviours which can be studied by considering the close relationship between logic programming semantics and extension-based argumentation semantics. In this paper, we will present a general recursive schema for defining new logic programming semantics. This schema takes as input any basic logic programming semantics, such as the stable model semantics, and gives as output a new logic programming semantics which satisfies some desired properties such as relevance and the existence of the intended models for every normal program. We will see that these new logic programming semantics can define candidate extension-based argumentation semantics. These new argumentation semantics will overcome some of the weakness of the extension-based argumentation semantics based on admissible sets. In fact, we will see that some of these new argumentation semantics have similar behaviour to the extension-based argumentation semantics built in terms of strongly connected components.},
author = {Nieves, Juan Carlos and Osorio, Mauricio and Zepeda, Claudia},
doi = {10.3233/FI-2011-388},
file = {:Users/liang-tingchen/Dropbox/References/Nieves, Osorio, Zepeda - 2011 - A schema for generating relevant logic programming semantics and its applications in argumentation theor.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
keywords = {Non-monotonic reasoning,extension-based argumentation semantics and logic,logic programming},
number = {2-4},
pages = {295--319},
title = {{A schema for generating relevant logic programming semantics and its applications in argumentation theory}},
volume = {106},
year = {2011}
}
@techreport{Stanley2003,
abstract = {Americans need to step back from the daily drum of privacy stories and absorb the big picture: the United States is at risk of turning into a full-fledged surveillance society. The fact is, Orwell's vision of "Big Brother" is now, for the first time, technologically possible.},
author = {Stanley, J. and Steinhardt, Barry},
file = {:Users/liang-tingchen/Dropbox/References/Stanley, Steinhardt - 2003 - Bigger Monster, Weaker Chains The Growth of an American Surveillance Society.pdf:pdf},
institution = {American Civil Liberties Union},
pages = {53--79},
title = {{Bigger Monster, Weaker Chains: The Growth of an American Surveillance Society}},
url = {http://libertyparkusafd.org/lp/Hale/Special Reports{\%}5CPatriot Act{\%}5CBigger Monster -- Weaker Chains -- the Growth of an American Surveillance Society.pdf},
year = {2003}
}
@article{Gumm2001a,
abstract = {Functors preserving weak pullbacks provide the basis for a rich structure theory of coalgebras. We give an easy to use criterion to check whether a functor preserves weak pullbacks. We apply the characterization to the functor F which associates a set X with the set F(X) of all filters on X. It turns out that this functor preserves weak pullbacks, yet does not preserve weak generalized pullbacks. Since topological spaces can be considered as F-coalgebras, in fact they constitute a covariety, we find that the intersection of subcoalgebras need not be a coalgebra, and 1-generated F-coalgebras need not exist.},
author = {Gumm, H. Peter},
doi = {10.1007/s00012-001-8156-x},
file = {:Users/liang-tingchen/Dropbox/References/Gumm - 2001 - Functors for Coalgebras.pdf:pdf},
journal = {Algebra universalis},
number = {2-3},
pages = {135--147},
title = {{Functors for Coalgebras}},
volume = {45},
year = {2001}
}
@article{Porst2008,
author = {Porst, Hans-E.},
doi = {10.2989/QM.2008.31.2.2.474},
file = {:Users/liang-tingchen/Dropbox/References/Porst - 2008 - On Categories of Monoids, Comonoids, and Bimonoids.pdf:pdf},
issn = {1607-3606},
journal = {Quaestiones Mathematicae},
keywords = {bimonoids,comonoids,free and cofree construc-,monoidally closed categories,monoids,tions},
month = {jun},
number = {2},
pages = {127--139},
title = {{On Categories of Monoids, Comonoids, and Bimonoids}},
url = {http://www.informaworld.com/openurl?genre=article{\&}doi=10.2989/QM.2008.31.2.2.474{\&}magic=crossref{\%}7C{\%}7CD404A21C5BB053405B1A640AFFD44AE3},
volume = {31},
year = {2008}
}
@inproceedings{Altenkirch2016d,
abstract = {In homotopy type theory (HoTT), all constructions are necessarily stable under homotopy equivalence. This has shortcomings: for example, it is believed that it is impossible to define a type of semi-simplicial types. More generally, it is difficult and often impossible to handle towers of coherences. To address this, we propose a 2-level theory which features both strict and weak equality. This can essentially be represented as two type theories: an "outer" one, containing a strict equality type former, and an "inner" one, which is some version of HoTT. Our type theory is inspired by Voevodsky's suggestion of a homotopy type system (HTS) which currently refers to a range of ideas. A core insight of our proposal is that we do not need any form of equality reflection in order to achieve what HTS was suggested for. Instead, having unique identity proofs in the outer type theory is sufficient, and it also has the meta-theoretical advantage of not breaking decidability of type checking. The inner theory can be an easily justifiable extensions of HoTT, allowing the construction of "infinite structures" which are considered impossible in plain HoTT. Alternatively, we can set the inner theory to be exactly the current standard formulation of HoTT, in which case our system can be thought of as a type-theoretic framework for working with "schematic" definitions in HoTT. As demonstrations, we define semi-simplicial types and formalise constructions of Reedy fibrant diagrams.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Extending Homotopy Type Theory with Strict Equality - Altenkirch, Thorsten; Capriotti, Paolo; Kraus, Nicolai)

Keywords: homotopy type theory, coherences, strict equality, homotopy type system},
archivePrefix = {arXiv},
arxivId = {1604.03799},
author = {Altenkirch, Thorsten and Capriotti, Paolo and Kraus, Nicolai},
booktitle = {25th EACSL Annual Conference on Computer Science Logic (CSL 2016)},
doi = {10.4230/LIPIcs.CSL.2016.21},
editor = {Talbot, Jean-Marc and Regnier, Laurent},
eprint = {1604.03799},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Capriotti, Kraus - 2016 - Extending Homotopy Type Theory with Strict Equality.pdf:pdf},
isbn = {978-3-95977-022-4},
issn = {1868-8969},
keywords = {Coherences,Homotopy type system,Homotopy type theory,Strict equality},
number = {21},
pages = {21:1----21:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Extending Homotopy Type Theory with Strict Equality}},
url = {http://drops.dagstuhl.de/opus/volltexte/2016/6561},
volume = {62},
year = {2016}
}
@inproceedings{Gundry2010,
abstract = {In the theory of programming languages, type inference is the process of inferring the type of an expression automatically, often making use of information from the context in which the expression appears. Such mechanisms turn out to be extremely useful in the practice of interac- tive theorem proving, whereby users interact with a computational proof assistant to construct formal axiomatic derivations of mathematical the- orems. This article explains some of the mechanisms for type inference used by the Mathematical Components project, which is working towards a verification of the Feit-Thompson theorem.},
address = {New York, New York, USA},
author = {Gundry, Adam and McBride, Conor and McKinna, James},
booktitle = {Proceedings of the third ACM SIGPLAN workshop on Mathematically structured functional programming - MSFP '10},
doi = {10.1145/1863597.1863608},
file = {:Users/liang-tingchen/Dropbox/References/Gundry, McBride, McKinna - 2010 - Type inference in context.pdf:pdf},
isbn = {9781450302555},
keywords = {algorithm w,hindley-milner,type inference,unification},
pages = {43},
publisher = {ACM Press},
title = {{Type inference in context}},
url = {http://portal.acm.org/citation.cfm?doid=1863597.1863608},
year = {2010}
}
@article{Kraus2015,
abstract = {In a type-theoretic fibration category in the sense of Shulman (representing a dependent type theory with at least 1, ∑, ∐, and identity types), we define the type of coherently constant functions A ∥ ∥ B. This involves an infinite tower of coherence conditions, and we therefore need the category to have Reedy limits of diagrams over !op. Our main result is that, if the category further has propositional truncations and satisfies function extensionality, the type of coherently constant function is equivalent to the type kAk ! B. If B is an n-type for a given finite n, the tower of coherence conditions becomes finite and the requirement of nontrivial Reedy limits vanishes. The whole construction can then be carried out in (standard syntactical) homotopy type theory and generalises the universal property of the truncation. This provides a way to define functions ∥Ak ∥ →B if B is not known to be propositional, and it streamlines the common approach of finding a propositional type Q with A → Q and Q → B.},
author = {Kraus, Nicolai},
doi = {10.4230/LIPIcs.TYPES.2014.111},
file = {:Users/liang-tingchen/Dropbox/References/Kraus - 2015 - The general universal property of the propositional truncation.pdf:pdf},
isbn = {9783939897880},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Coherence conditions,Propositional truncation,Reedy limits,Universal property,Well-behaved constancy},
number = {Types},
pages = {111--145},
title = {{The general universal property of the propositional truncation}},
volume = {39},
year = {2015}
}
@inproceedings{Gordon2014,
abstract = {Probabilistic programming means two strongly connected models as well as the study of their mathematical properties, solutions of the relevant optimization problems and their applications. The two models are: maximizing (or minimizing) a probability under constraints and programming under probabilistic constraints. There are a number of variants and special cases of these models and we present them in Section 1. In Section 2 we summarize those mathematical theories which can be used to prove the convexity of large classes of our problems and we also show how they can be applied in this context. In Section 3 we present solution algorithms of our stochastic programming problems. Since we are handling probabilities of sets in higher dimensional spaces, it is necessary to use bounding and other approximation algorithms to find these probabilities with satisfactory precision. This is the subject of Section 5. In Section 4 we present two-stage and multi-stage problems which are combined with probabilistic constraints. Some duality and stability theorems are presented in Section 6. Finally, in Section 7, we present applications of our model constructions. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1312.4328},
author = {Gordon, Andrew D. and Henzinger, Thomas A. and Nori, Aditya V. and Rajamani, Sriram K.},
booktitle = {Proceedings of the on Future of Software Engineering},
doi = {10.1145/2593882.2593900},
eprint = {1312.4328},
file = {:Users/liang-tingchen/Dropbox/References/Gordon et al. - 2014 - Probabilistic programming.pdf:pdf},
isbn = {9781450328654},
issn = {09270507},
pages = {167--181},
publisher = {ACM Press},
series = {FOSE 2014},
title = {{Probabilistic programming}},
url = {http://doi.acm.org/10.1145/2593882.2593900},
volume = {10},
year = {2014}
}
@article{Pattinson2001,
author = {Pattinson, Dirk},
doi = {10.1016/S1571-0661(04)80913-7},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson - 2001 - Modal Languages for Coalgebras in a Topological Setting.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {may},
number = {1},
pages = {271--284},
title = {{Modal Languages for Coalgebras in a Topological Setting}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104809137 http://www.sciencedirect.com/science/article/pii/S1571066104809137},
volume = {44},
year = {2001}
}
@article{Gischer1988,
abstract = {Pomsets have been introduced as a model of concurrency. Since a pomset is a string in which the total order has been relaxed to be a partial order, in this paper we view them as a generalization of strings, and investigate their algebraic properties. In particular, we investigate the axiomatic properties of pomsets, sets of pomsets and ideals of pomsets, under such operations as concatenation, parallel composition, union and their associated closure operations. We find that the equational theory of sets, pomsets under concatenation, parallel composition and union is finitely axiomatizable, whereas the theory of languages under the analogous operations is not. A similar result is obtained for ideals of pomsets, which incorporate the notion of subsumption which is also known as augmentation. Finally, we show that the addition of any closure operation (parallel or serial) leads to nonfinite axiomatizability of the resulting equational theory. {\textcopyright} 1988.},
author = {Gischer, Jay L.},
doi = {10.1016/0304-3975(88)90124-7},
file = {:Users/liang-tingchen/Dropbox/References/Gischer - 1988 - The equational theory of pomsets.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {nov},
number = {2-3},
pages = {199--224},
title = {{The equational theory of pomsets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397588901247},
volume = {61},
year = {1988}
}
@article{Lambek1968a,
author = {Lambek, Joachim},
doi = {10.1007/BF01110627},
file = {:Users/liang-tingchen/Dropbox/References/Lambek - 1968 - A fixpoint theorem for complete categories.pdf:pdf},
journal = {Mathematische Zeitschrift},
month = {apr},
number = {2},
pages = {151--161},
title = {{A fixpoint theorem for complete categories}},
type = {Journal article},
url = {http://dx.doi.org/10.1007/BF01110627},
volume = {103},
year = {1968}
}
@phdthesis{Viglizzo2005,
author = {Viglizzo, Ignacio Dario},
file = {:Users/liang-tingchen/Dropbox/References/Viglizzo - 2005 - Coalgebras on Measurable Spaces.pdf:pdf},
keywords = {Mathematics,coalgebra,final coalgebra,measurable spaces,probabilities,type space},
number = {August},
publisher = {faculty of the Graduate School in partial fulfillment of the requirements for the degree Doctor of Philosophy in the Department of Mathematics, Indiana University},
school = {Indiana University},
title = {{Coalgebras on Measurable Spaces}},
url = {http://hdl.handle.net/2022/7065},
year = {2005}
}
@article{Pelletier1993,
author = {Pelletier, J. Wick and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1007/BF01196099},
file = {:Users/liang-tingchen/Dropbox/References/Pelletier, Rosick{\'{y}} - 1993 - On the equational theory of C-algebras.pdf:pdf},
issn = {00025240},
journal = {Algebra Universalis},
pages = {275--284},
title = {{On the equational theory of C*-algebras}},
volume = {30},
year = {1993}
}
@article{Carayol2017,
author = {Carayol, Arnaud and {\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1016/j.jlamp.2016.09.004},
file = {:Users/liang-tingchen/Dropbox/References/Carayol, {\'{E}}sik - 2017 - An analysis of the equational properties of the well-founded fixed point.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
number = {1},
pages = {308--318},
publisher = {Elsevier Inc.},
title = {{An analysis of the equational properties of the well-founded fixed point}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2352220816301110},
volume = {86},
year = {2017}
}
@article{Ciancia2008,
abstract = {The problem of defining fully abstract operational models of name passing calculi has been given some elegant solutions, such as coalgebras over presheaf categories or over nominal sets. These formalisms fail to model garbage collection of unused names, hence they do not have nice properties with respects to finite state algorithms. The category of named sets, on the other hand, was designed for the purpose of supporting efficient algorithms to handle the semantics of name passing calculi. However the theory was developed in a rather ad-hoc fashion (e.g. the existence of a final coalgebra was only proved in the finite case). In this work we introduce a name abstraction functor for named sets and show that it provides a simple and effective notion of garbage collection of unused names. Along the way, we survey a number of needed results on the category of permutation algebras, an algebra-theoretic definition of nominal sets. In particular we give a formalization of the adjunction between abstraction and concretion, an example illustrating a nominal syntax alike handling of De Bruijn indexes, and an explicit functor to model the early semantics of the $\pi$-calculus in nominal sets. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Ciancia, Vincenzo and Montanari, Ugo},
doi = {10.1016/j.entcs.2008.05.019},
file = {:Users/liang-tingchen/Dropbox/References/Ciancia, Montanari - 2008 - A Name Abstraction Functor for Named Sets.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {De Bruijn indexes,binding,garbage collection,named sets,nominal sets},
month = {jun},
number = {5},
pages = {49--70},
publisher = {Elsevier B.V.},
title = {{A Name Abstraction Functor for Named Sets}},
url = {http://dx.doi.org/10.1016/j.entcs.2008.05.019 https://linkinghub.elsevier.com/retrieve/pii/S1571066108003332},
volume = {203},
year = {2008}
}
@phdthesis{Frey2014,
abstract = {This is the author's PhD thesis. It is a contribution to categorical logic, in particular to the theory of realizability toposes. While the tools of categorical logic have proven very successful in analyzing and organizing proof theoretic realizability interpretations, it was remarked by experts (notably Peter Johnstone) that the field of realizability toposes itself was not clearly delineated, and lacked a powerful theory analogous to that of Grothendieck toposes. The present work sets out to remedy this situation to a certain extent. We argue that realizability toposes are best understood using Grothendieck fibrations, and develop a framework of fibrational cocompletions, which allows to view certain constructions from realizability in precise analogy to constructions of presheaf and sheaf toposes. Using these techniques, and a class of posetal fibrations that we call uniform preorders, we are able to give an extensional characterization of partial combinatory algebras and of the realizability toposes that are constructed from these algebras. Striving to develop the analogy to Grothendieck toposes further, we outline how to apply our techniques on arbitrary base toposes, and give a decomposition theorem for constant objects functors induced by triposes, analogous to the known decompositions of geometric morphisms. Finally, we sketch an approach of how to find a unified framework for Grothendieck toposes and realizability toposes, based on the observation that uniform preorders can be identified with preorders internal to a category of sheaves.},
archivePrefix = {arXiv},
arxivId = {1403.3672},
author = {Frey, Jonas},
eprint = {1403.3672},
file = {:Users/liang-tingchen/Dropbox/References/Frey - 2014 - A fibrational study of realizability toposes.pdf:pdf},
number = {March},
publisher = {Doctoral dissertation},
school = {Universit{\'{e}} Paris Diderot – Paris 7},
title = {{A fibrational study of realizability toposes}},
url = {http://arxiv.org/abs/1403.3672},
year = {2014}
}
@inproceedings{Danielsson2012,
abstract = {The operational semantics of a partial, functional language is often given as a relation rather than as a function. The latter approach is arguably more natural: if the language is functional, why not take advantage of this when defining the semantics},
address = {New York, New York, USA},
author = {Danielsson, Nils Anders},
booktitle = {Proceedings of the 17th ACM SIGPLAN international conference on Functional programming - ICFP '12},
doi = {10.1145/2364527.2364546},
file = {:Users/liang-tingchen/Dropbox/References/Danielsson - 2012 - Operational semantics using the partiality monad.pdf:pdf},
isbn = {9781450310543},
issn = {15232867},
keywords = {dependent types,mixed induction and coinduction},
pages = {127},
publisher = {ACM Press},
title = {{Operational semantics using the partiality monad}},
url = {http://dl.acm.org/citation.cfm?doid=2364527.2364546},
year = {2012}
}
@article{Almeida1990,
author = {Almeida, Jorge},
doi = {10.1007/BF01190713},
file = {:Users/liang-tingchen/Dropbox/References/Almeida - 1990 - On pseudovarieties, varieties of languages, filters of congruences, pseudoidentities and related topics.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {sep},
number = {3},
pages = {333--350},
title = {{On pseudovarieties, varieties of languages, filters of congruences, pseudoidentities and related topics}},
url = {http://link.springer.com/10.1007/BF01190713},
volume = {27},
year = {1990}
}
@inproceedings{munro_et_al:LIPIcs:2018:9526,
abstract = {We present two stable mergesort variants, "peeksort" and "powersort", that exploit existing runs and find nearly-optimal merging orders with practically negligible overhead. Previous methods either require substantial effort for determining the merging order (Takaoka 2009; Barbay {\&} Navarro 2013) or do not have a constant-factor optimal worst-case guarantee (Peters 2001; Auger, Nicaud {\&} Pivoteau 2015; Buss {\&} Knop 2018). We demonstrate that our methods are competitive in terms of running time with state-of-the-art implementations of stable sorting methods.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Nearly-Optimal Mergesorts: Fast, Practical Sorting Methods That Optimally Adapt to Existing Runs - Munro, J Ian; Wild, Sebastian)

Keywords: adaptive sorting, nearly-optimal binary search trees, Timsort},
archivePrefix = {arXiv},
arxivId = {1805.04154},
author = {Munro, J Ian and Wild, Sebastian},
booktitle = {26th Annual European Symposium on Algorithms (ESA 2018)},
doi = {10.4230/LIPIcs.ESA.2018.63},
editor = {Azar, Yossi and Bast, Hannah and Herman, Grzegorz},
eprint = {1805.04154},
file = {:Users/liang-tingchen/Dropbox/References//Munro, Wild - 2018 - Nearly-Optimal Mergesorts Fast, Practical Sorting Methods That Optimally Adapt to Existing Runs.pdf:pdf},
isbn = {978-3-95977-081-1},
issn = {1868-8969},
keywords = {04154,1805,2018,4230,63,and phrases adaptive sorting,digital object identifier 10,esa,extended version with appendices,lipics,nearly-optimal binary search trees,related version arxiv,timsort},
month = {aug},
number = {5},
pages = {63:1----63:16},
pmid = {11503116},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Nearly-Optimal Mergesorts: Fast, Practical Sorting Methods That Optimally Adapt to Existing Runs}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9526},
volume = {112},
year = {2018}
}
@incollection{Plotkin2002,
abstract = {We model notions of computation using algebraic operations and equations. We show that these generate several of the monads of primary interest that have been used to model computational effects, with the striking omission of the continuations monad. We focus on semantics for global and local state, showing that taking operations and equations as primitive yields a mathematical relationship that reflects their computational relationship.},
author = {Plotkin, Gordon D. and Power, John},
booktitle = {Proceedings of the 5th International Conference on Foundations of Software Science and Computation Structures},
doi = {10.1007/3-540-45931-6_24},
editor = {Nielsen, Mogens and Engberg, Uffe},
isbn = {978-3-540-45931-6},
pages = {342--356},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Notions of Computation Determine Monads}},
url = {http://link.springer.com/chapter/10.1007/3-540-45931-6{\_}24 http://link.springer.com/10.1007/3-540-45931-6{\_}24},
year = {2002}
}
@article{Urban2008,
author = {Urban, Christian},
doi = {10.1007/s10817-008-9097-2},
file = {:Users/liang-tingchen/Dropbox/References/Urban - 2008 - Nominal techniques in IsabelleHOL.pdf:pdf},
isbn = {1081700890},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {lambda-calculus,nominal logic work,theorem provers},
month = {mar},
number = {4},
pages = {327--356},
title = {{Nominal techniques in Isabelle/HOL}},
url = {http://link.springer.com/10.1007/s10817-008-9097-2},
volume = {40},
year = {2008}
}
@misc{Kock1995,
author = {Kock, Anders},
booktitle = {Journal of Pure and Applied Algebra},
doi = {10.1016/0022-4049(94)00111-U},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 1995 - Monads for which structures are adjoint to units.pdf:pdf},
issn = {00224049},
number = {1},
pages = {41--59},
title = {{Monads for which structures are adjoint to units}},
volume = {104},
year = {1995}
}
@incollection{Belnap1977,
address = {Dordrecht},
author = {Belnap, Nuel D.},
booktitle = {Modern Uses of Multiple-Valued Logic},
doi = {10.1007/978-94-010-1161-7_2},
file = {:Users/liang-tingchen/Dropbox/References/Belnap - 1977 - A Useful Four-Valued Logic.pdf:pdf},
pages = {5--37},
publisher = {Springer Netherlands},
series = {Episteme},
title = {{A Useful Four-Valued Logic}},
url = {http://www.springerlink.com/index/10.1007/978-94-010-1161-7{\_}2},
volume = {2},
year = {1977}
}
@inproceedings{DeMarchi2005,
abstract = {There are several approaches to the problem of giving a categorical semantics to Martin-L{\"{o}}f type theory with dependent sums and products and extensional equality types. The most established one relies on the notion of a type-category (or category with attributes) with $\Sigma$ and $\Pi$ types. We extend such a semantics by introducing coinductive types both on the syntactic level and in a type-category. Soundness of the semantics is preserved. As an example of such a category, we prove that the type-category built over a locally cartesian closed category C admits coinductive types whenever C has final coalgebras for all polynomial functors.},
address = {Swansea},
author = {{De Marchi}, Federico},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/11548133_8},
editor = {Fiadeiro, Jos{\'{e}} Luiz and Harman, Neil and Roggenbach, Markus and Rutten, Jan},
file = {:Users/liang-tingchen/Dropbox/References/De Marchi - 2005 - On the Semantics of Coinductive Types in Martin-L{\"{o}}f Type Theory.pdf:pdf},
pages = {114--126},
publisher = {Springer Berlin Heidelberg},
title = {{On the Semantics of Coinductive Types in Martin-L{\"{o}}f Type Theory}},
year = {2005}
}
@article{Adamek1996,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
doi = {10.1006/jabr.1996.0345},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 1996 - How to Sketch Quasivarieties.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
month = {nov},
number = {3},
pages = {643--659},
title = {{How to Sketch Quasivarieties}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0021869396903452},
volume = {185},
year = {1996}
}
@incollection{Savary-Belanger2013,
author = {Savary-Belanger, Olivier and Monnier, Stefan and Pientka, Brigitte},
booktitle = {Journal of Formalized Reasoning},
doi = {10.1007/978-3-319-03545-1_16},
file = {:Users/liang-tingchen/Dropbox/References/Savary-Belanger, Monnier, Pientka - 2013 - Programming Type-Safe Transformations Using Higher-Order Abstract Syntax.pdf:pdf},
issn = {1972-5787},
keywords = {abstract syntax,abstract syntax tree,algorithm,compiler,computer science,higher order abstract syntax,homoiconicity,machine code,programming language,syntax,theoretical computer science,type safety},
number = {1},
pages = {243--258},
title = {{Programming Type-Safe Transformations Using Higher-Order Abstract Syntax}},
url = {http://link.springer.com/10.1007/978-3-319-03545-1{\_}16},
volume = {8},
year = {2013}
}
@article{Schroder2010b,
abstract = {Modal fixpoint logics traditionally play a central role in computer science, in particular in artificial intelligence and concurrency. The mu-calculus and its relatives are among the most expressive logics of this type. However, popular fixpoint logics tend to trade expressivity for simplicity and readability, and in fact often live within the single variable fragment of the mu-calculus. The family of such flat fixpoint logics includes, e.g., LTL, CTL, and the logic of common knowledge. Extending this notion to the generic semantic framework of coalgebraic logic enables covering a wide range of logics beyond the standard mu-calculus including, e.g., flat fragments of the graded mu-calculus and the alternating-time mu-calculus (such as alternating-time temporal logic ATL), as well as probabilistic and monotone fixpoint logics. We give a generic proof of completeness of the Kozen-Park axiomatization for such flat coalgebraic fixpoint logics.},
archivePrefix = {arXiv},
arxivId = {1004.2717},
author = {Schr{\"{o}}der, Lutz and Venema, Yde},
doi = {10.1007/978-3-642-15375-4_36},
eprint = {1004.2717},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Venema - 2010 - Completeness of Flat Coalgebraic Fixpoint Logics.pdf:pdf},
title = {{Completeness of Flat Coalgebraic Fixpoint Logics}},
url = {http://arxiv.org/abs/1004.2717{\%}0Ahttp://dx.doi.org/10.1007/978-3-642-15375-4{\_}36},
year = {2010}
}
@incollection{Clarkson2014,
abstract = {Two new logics for verification of hyperproperties are proposed. Hyperproperties characterize security policies, such as noninterference, as a property of sets of computation paths. Standard temporal logics such as LTL, CTL, and CTL* can refer only to a single path at a time, hence cannot express many hyperproperties of interest. The logics proposed here, HyperLTL and HyperCTL*, add explicit and simultaneous quantification over multiple paths to LTL and to CTL*. This kind of quantification enables expression of hyperproperties. A model checking algorithm for the proposed logics is given. For a fragment of HyperLTL, a prototype model checker has been implemented.},
archivePrefix = {arXiv},
arxivId = {1401.4492},
author = {Clarkson, Michael R. and Finkbeiner, Bernd and Koleini, Masoud and Micinski, Kristopher K. and Rabe, Markus N. and S{\'{a}}nchez, C{\'{e}}sar},
booktitle = {Proceedings of the 3rd International Conference on Principles of Security and Trust},
doi = {10.1007/978-3-642-54792-8_15},
editor = {Abadi, Mart{\'{i}}n and Kremer, Steve},
eprint = {1401.4492},
file = {:Users/liang-tingchen/Dropbox/References/Clarkson et al. - 2014 - Temporal logics for hyperproperties.pdf:pdf},
isbn = {9783642547911},
issn = {16113349},
pages = {265--284},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Temporal logics for hyperproperties}},
url = {http://link.springer.com/10.1007/978-3-642-54792-8{\_}15},
volume = {8414},
year = {2014}
}
@inproceedings{Meng2008,
abstract = {If, as a well-known aphorism states, modelling is for reasoning, this paper is an attempt to define and apply a formal semantics to UML sequence diagrams in order to enable rigourous reasoning about them. Actually, model transformation plays a fundamental role in the process of software development, in general, and in model driven engineering in particular. Being a de facto standard in this area, UML is no exception, even if the number and diversity of diagrams expressing UML models makes it difficult to base its semantics on a single framework. This paper builds on previous attempts to base UML semantics in a coalgebraic setting and illustrates the application of the proposed framework to reason about composition and re factoring of sequence diagrams.},
author = {Meng, Sun and Barbosa, Lu{\'{i}}s S.},
booktitle = {2008 The Eighth International Conference on Quality Software},
doi = {10.1109/QSIC.2008.13},
file = {:Users/liang-tingchen/Dropbox/References/Meng, Barbosa - 2008 - A coalgebraic semantic framework for reasoning about UML sequence diagrams.pdf:pdf},
isbn = {978-0-7695-3312-4},
issn = {15506002},
month = {aug},
pages = {17--26},
publisher = {IEEE},
title = {{A coalgebraic semantic framework for reasoning about UML sequence diagrams}},
url = {http://ieeexplore.ieee.org/document/4601524/},
year = {2008}
}
@article{Wood2019,
abstract = {Differential privacy is a formal mathematical framework for quantifying and managing privacy risks. It provides provable privacy protection against a wide range of potential attacks, including those currently unforeseen. Differential privacy is primarily studied in the context of the collection, analysis, and release of aggregate statistics. These range from simple statistical estimations, such as averages, to machine learning. Tools for differentially private analysis are now in early stages of implementation and use across a variety of academic, industry, and government settings. Interest in the concept is growing among potential users of the tools, as well as within legal and policy communities, as it holds promise as a potential approach to satisfying legal requirements for privacy protection when handling personal information. In particular, differential privacy may be seen as a technical solution for analyzing and sharing data while protecting the privacy of individuals in accordance with existing legal or policy requirements for de-identification or disclosure limitation. This primer seeks to introduce the concept of differential privacy and its privacy implications to non-technical audiences. It provides a simplified and informal, but mathematically accurate, description of differential privacy. Using intuitive illustrations and limited mathematical formalism, it discusses the definition of differential privacy, how differential privacy addresses privacy risks, how differentially private analyses are constructed, and how such analyses can be used in practice. A series of illustrations is used to show how practitioners and policymakers can conceptualize the guarantees provided by differential privacy. These illustrations are also used to explain related concepts, such as composition (the accumulation of risk across multiple analyses), privacy loss parameters, and privacy budgets. This primer aims to provide a foundation that can guide future decisions when analyzing and sharing statistical data about individuals, informing individuals about the privacy protection they will be afforded, and designing policies and regulations for robust privacy protection.},
author = {Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and Honaker, James and Nissim, Kobbi and O'Brien, David and Steinke, Thomas and Vadhan, Salil},
doi = {10.2139/ssrn.3338027},
file = {:Users/liang-tingchen/Dropbox/References/Wood et al. - 2018 - Differential Privacy A Primer for a Non-Technical Audience.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
pages = {209--276},
title = {{Differential Privacy: A Primer for a Non-Technical Audience}},
url = {https://www.ssrn.com/abstract=3338027},
year = {2018}
}
@inproceedings{Macqueen,
address = {New York, New York, USA},
author = {MacQueen, David B.},
booktitle = {Proceedings of the 13th ACM SIGACT-SIGPLAN symposium on Principles of programming languages - POPL '86},
doi = {10.1145/512644.512670},
file = {:Users/liang-tingchen/Dropbox/References/MacQueen - 1986 - Using dependent types to express modular structure.pdf:pdf},
pages = {277--286},
publisher = {ACM Press},
title = {{Using dependent types to express modular structure}},
url = {http://portal.acm.org/citation.cfm?doid=512644.512670},
year = {1986}
}
@incollection{Klima2010,
author = {Kl{\'{i}}ma, Ondřej and Pol{\'{a}}k, Libor},
booktitle = {Proceedings of the 14th International Conference on Developments in Language Theory},
doi = {10.1007/978-3-642-14455-4_26},
editor = {Gao, Yuan and Lu, Hanlin and Seki, Shinnosuke and Yu, Sheng},
file = {:Users/liang-tingchen/Dropbox/References/Kl{\'{i}}ma, Pol{\'{a}}k - 2010 - On Sch{\"{u}}tzenberger products of semirings.pdf:pdf},
keywords = {idempotent,of languages,polynomial operators on classes},
number = {201},
pages = {279--290},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Note in Computer Science},
title = {{On Sch{\"{u}}tzenberger products of semirings}},
url = {http://link.springer.com/10.1007/978-3-642-14455-4{\_}26},
year = {2010}
}
@article{Perils1982a,
abstract = {Assoc for Computing Machinery, New York},
author = {Perlis, Alan J.},
doi = {10.1145/947955.1083808},
file = {:Users/liang-tingchen/Dropbox/References/Perlis - 1982 - Special Feature Epigrams on programming.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {sep},
number = {9},
pages = {7--13},
title = {{Special Feature: Epigrams on programming}},
url = {http://portal.acm.org/citation.cfm?doid=947955.1083808},
volume = {17},
year = {1982}
}
@article{Gilbert2019,
abstract = {Definitional equality-or conversion-for a type theory with a decidable type checking is the simplest tool to prove that two objects are the same, letting the system decide just using computation. Therefore, the more things are equal by conversion, the simpler it is to use a language based on type theory. Proof-irrelevance, stating that any two proofs of the same proposition are equal, is a possible way to extend conversion to make a type theory more powerful. However, this new power comes at a price if we integrate it naively, either by making type checking undecidable or by realizing new axioms-such as uniqueness of identity proofs (UIP)-that are incompatible with other extensions, such as univalence. In this paper, taking inspiration from homotopy type theory, we propose a general way to extend a type theory with definitional proof irrelevance, in a way that keeps type checking decidable and is compatible with univalence. We provide a new criterion to decide whether a proposition can be eliminated over a type (correcting and improving the so-called singleton elimination of Coq) by using techniques coming from recent development on dependent pattern matching without UIP. We show the generality of our approach by providing implementations for both Coq and Agda, both of which are planned to be integrated in future versions of those proof assistants.},
author = {Gilbert, Ga{\"{e}}tan and Cockx, Jesper and Sozeau, Matthieu and Tabareau, Nicolas},
doi = {10.1145/3290316},
file = {:Users/liang-tingchen/Dropbox/References/Gilbert et al. - 2019 - Definitional proof-irrelevance without K.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--28},
title = {{Definitional proof-irrelevance without K}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290316},
volume = {3},
year = {2019}
}
@phdthesis{Zeilberger2009a,
abstract = {An old and celebrated analogy says that writing programs is like proving the- orems. This analogy has been productive in both directions, but in particular has demonstrated remarkable utility in driving progress in programming languages, for example leading towards a better understanding of concepts such as abstract data types and polymorphism. One of the best known instances of the analogy actu- ally rises to the level of an isomorphism: between Gentzen's natural deduction and Church's lambda calculus. However, as has been recognized for a while, lambda calculus fails to capture some of the important features of modern programming languages. Notably, it does not have an inherent notion of evaluation order, needed to make sense of programs with side effects. Instead, the historical descendents of lambda calculus (languages like Lisp, ML, Haskell, etc.) impose evaluation order in an ad hoc way. This thesis aims to give a fresh take on the proofs-as-programs analogy—one which better accounts for features of modern programming languages—by starting from a different logical foundation. Inspired by Andreoli's focusing proofs for lin- ear logic, we explain how to axiomatize certain canonical forms of logical reasoning through a notion of pattern. Propositions come with an intrinsic polarity, based on whether they are defined by patterns of proof, or by patterns of refutation. Ap- plying the analogy, we then obtain a programming language with built-in support for pattern-matching, in which evaluation order is explicitly reflected at the level of types—and hence can be controlled locally, rather than being an ad hoc, global policy decision. As we show, different forms of continuation-passing style (one of the his- torical tools for analyzing evaluation order) can be described in terms of different po- larizations. This language provides an elegant, uniform account of both untyped and intrinsically-typed computation (incorporating ideas from infinitary proof theory), and additionally, can be provided an extrinsic type system to express and statically enforce more refined properties of programs. We conclude by using this framework to explore the theory of typing and subtyping for intersection and union types in the presence of effects, giving a simplified explanation of some of the unusual artifacts of existing systems.},
author = {Zeilberger, Noam},
file = {:Users/liang-tingchen/Dropbox/References/Zeilberger - 2009 - The logical basis of evaluation order and pattern-matching(2).pdf:pdf},
school = {Carnegie Mellon University},
title = {{The logical basis of evaluation order and pattern-matching}},
type = {Doctoral thesis},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=OYLogNNTZIgC{\&}oi=fnd{\&}pg=PR3{\&}dq=The+Logical+Basis+of+Evaluation+Order+and+Pattern-Matching{\&}ots=E9l6{\_}6RTA2{\&}sig=gcpqbsd-ep3Ce0E0q7wgL2uPCac},
year = {2009}
}
@article{Uustalu2008,
abstract = {We argue that symmetric (semi)monoidal comonads provide a means to structure context-dependent notions of computation such as notions of dataflow computation (computation on streams) and of tree relabelling as in attribute evaluation. We propose a generic semantics for extensions of simply typed lambda calculus with context-dependent operations analogous to the Moggi-style semantics for effectful languages based on strong monads. This continues the work in the early 90s by Brookes, Geva and Van Stone on the use of computational comonads in intensional semantics. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Uustalu, Tarmo and Vene, Varmo},
doi = {10.1016/j.entcs.2008.05.029},
file = {:Users/liang-tingchen/Dropbox/References/Uustalu, Vene - 2008 - Comonadic notions of computation.pdf:pdf},
isbn = {15710661},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coKleisli semantics,context-dependent computation,dataflow computation,symmetric monoidal comonads,tree transformations},
number = {5},
pages = {263--284},
publisher = {Elsevier B.V.},
title = {{Comonadic notions of computation}},
url = {http://dx.doi.org/10.1016/j.entcs.2008.05.029},
volume = {203},
year = {2008}
}
@inproceedings{King1995,
address = {New York, New York, USA},
author = {King, David J. and Launchbury, John},
booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '95},
doi = {10.1145/199448.199530},
file = {:Users/liang-tingchen/Dropbox/References/King, Launchbury - 1995 - Structuring depth-first search algorithms in Haskell.pdf:pdf},
isbn = {0897916921},
pages = {344--354},
publisher = {ACM Press},
title = {{Structuring depth-first search algorithms in Haskell}},
url = {http://portal.acm.org/citation.cfm?doid=199448.199530},
year = {1995}
}
@book{Jones1997,
author = {Jones, Neil D.},
booktitle = {Electronic Notes in Theoretical Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Jones - 1997 - Computability and Complexity From a Programming Perspective.pdf:pdf},
isbn = {0-262-10064-9},
pages = {467},
publisher = {The MIT Press},
series = {Foundations of Computing},
title = {{Computability and Complexity: From a Programming Perspective}},
year = {1997}
}
@article{Attard2015,
abstract = {We conduct a systematic survey with the aim of assessing open government data initiatives, that is; any attempt, by a government or otherwise, to open data that is produced by a governmental entity. We describe the open government data life-cycle and we focus our discussion on publishing and consuming processes required within open government data initiatives. We cover current approaches undertaken for such initiatives, and classify them. A number of evaluations found within related literature are discussed, and from them we extract challenges and issues that hinder open government initiatives from reaching their full potential. In a bid to overcome these challenges, we also extract guidelines for publishing data and provide an integrated overview. This will enable stakeholders to start with a firm foot in a new open government data initiative. We also identify the impacts on the stakeholders involved in such initiatives.},
author = {Attard, Judie and Orlandi, Fabrizio and Scerri, Simon and Auer, S{\"{o}}ren},
doi = {10.1016/j.giq.2015.07.006},
file = {:Users/liang-tingchen/Dropbox/References/Attard et al. - 2015 - A systematic review of open government data initiatives.pdf:pdf},
isbn = {0740-624X},
issn = {0740624X},
journal = {Government Information Quarterly},
keywords = {Consuming,Data portals,Government data,OGD life-cycle,Open data,Openness,Publishing},
month = {oct},
number = {4},
pages = {399--418},
publisher = {Elsevier Inc.},
title = {{A systematic review of open government data initiatives}},
url = {http://dx.doi.org/10.1016/j.giq.2015.07.006 http://linkinghub.elsevier.com/retrieve/pii/S0740624X1500091X},
volume = {32},
year = {2015}
}
@article{Mandelkern1989,
author = {Mandelkern, Mark},
doi = {10.2307/2689939},
file = {:Users/liang-tingchen/Dropbox/References/Mandelkern - 1989 - Brouwerian Counterexamples.pdf:pdf},
issn = {0025570X},
journal = {Mathematics Magazine},
month = {feb},
number = {1},
pages = {3},
title = {{Brouwerian Counterexamples}},
url = {http://www.jstor.org/stable/10.2307/2689939?origin=crossref},
volume = {62},
year = {1989}
}
@inproceedings{Darnas1982,
address = {New York, New York, USA},
author = {Damas, Luis and Milner, Robin},
booktitle = {Proceedings of the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '82},
doi = {10.1145/582153.582176},
file = {:Users/liang-tingchen/Dropbox/References/Damas, Milner - 1982 - Principal type-schemes for functional programs.pdf:pdf},
isbn = {0897910656},
pages = {207--212},
publisher = {ACM Press},
title = {{Principal type-schemes for functional programs}},
url = {http://portal.acm.org/citation.cfm?doid=582153.582176},
year = {1982}
}
@article{Grandis2004,
author = {Grandis, Marco and Par{\'{e}}, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Grandis, Par{\'{e}} - 2004 - Adjoint for double categories.pdf:pdf},
journal = {Cahiers de topologie et g{\'{e}}om{\'{e}}trie diff{\'{e}}rentielle cat{\'{e}}goriques},
number = {3},
pages = {193--240},
title = {{Adjoint for double categories}},
url = {http://www.numdam.org/item?id=CTGDC{\_}2004{\_}{\_}45{\_}3{\_}193{\_}0},
volume = {45},
year = {2004}
}
@inproceedings{Guatto2018,
abstract = {Nakano's later modality allows types to express that the output of a function does not immediately depend on its input, and thus that computing its fixpoint is safe. This idea, guarded recursion, has proved useful in various contexts, from functional programming with infinite data structures to formulations of step-indexing internal to type theory. Categorical models have revealed that the later modality corresponds in essence to a simple reindexing of the discrete time scale. Unfortunately, existing guarded type theories suffer from significant limitations for programming purposes. These limitations stem from the fact that the later modality is not expressive enough to capture precise input-output dependencies of functions. As a consequence, guarded type theories reject many productive definitions. Combining insights from guarded type theories and synchronous programming languages, we propose a new modality for guarded recursion. This modality can apply any well-behaved reindexing of the time scale to a type. We call such reindexings time warps. Several modalities from the literature, including later, correspond to fixed time warps, and thus arise as special cases of ours.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {1805.11021},
author = {Guatto, Adrien},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3209108.3209148},
eprint = {1805.11021},
file = {:Users/liang-tingchen/Dropbox/References/Guatto - 2018 - A Generalized Modality for Recursion.pdf:pdf},
isbn = {9781450355834},
issn = {10436871},
keywords = {Category Theory,Functional Programming,Guarded Recursion,Streams,Synchronous Programming,Type Systems},
month = {jul},
pages = {482--491},
publisher = {ACM},
title = {{A Generalized Modality for Recursion}},
url = {https://dl.acm.org/doi/10.1145/3209108.3209148},
year = {2018}
}
@incollection{Cox2014,
author = {Cox, Lawrence H},
booktitle = {Privacy in Statistical Databases},
doi = {10.1007/978-3-319-11257-2_1},
editor = {Domingo-Ferrer, Josep},
file = {:Users/liang-tingchen/Dropbox/References/Cox - 2014 - Enabling Statistical Analysis of Suppressed Tabular Data.pdf:pdf},
isbn = {978-3-319-11256-5},
issn = {16113349},
keywords = {algebraic circuit,cell suppression,divergence},
pages = {1--10},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Enabling Statistical Analysis of Suppressed Tabular Data}},
url = {http://dblp.uni-trier.de/db/conf/psd/psd2014.html{\#}Cox14 http://link.springer.com/10.1007/978-3-319-11257-2{\_}1},
volume = {8744},
year = {2014}
}
@incollection{Abramsky1994a,
author = {Abramsky, Samson and Jung, Achim},
booktitle = {Handbook of Logic in Computer Science},
editor = {Abramsky, Samson and Gabby, Dov M. and Maibaum, Thomas S. E.},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky, Jung - 1994 - Domain theory.pdf:pdf},
isbn = {978-0198537625},
pages = {1--168},
publisher = {Oxford University Press},
title = {{Domain theory}},
type = {Book part (with own title)},
url = {http://www.cs.bham.ac.uk/{~}axj/pub/papers/handy1.pdf},
volume = {3},
year = {1994}
}
@incollection{Bezhanishvili2012a,
author = {Bezhanishvili, Nick and Kupke, Clemens and Panangaden, Prakash},
booktitle = {Workshop on Logic, Language, Information and Computation},
doi = {10.1007/978-3-540-73445-1_5},
editor = {Ong, Luke and de Queiroz, Ruy},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili, Kupke, Panangaden - 2012 - Minimization via duality.pdf:pdf},
pages = {191--205},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Minimization via duality}},
year = {2012}
}
@inproceedings{Clinger1991,
abstract = {This paper describes a modified form of Kohlbecker's algorithm for reliably hygienic (capture-free) macro expansion in block-structured languages, where macros are source-Tosource transformations specified using a high-level pattern language. Unlike previous algorithms, the modified algorithm runs in linear instead of quadratic time, copies few constants, does not assume that syntactic keywords (e.g. if) are reserved words, and allows 10CSJ(scoped) macros to refer to lexical variables in a referentially transparent manner. Syntactic closures have been advanced as an alternative to hygienic macro expansion. The problem with syntactic closures is that they are inherently low-level and therefore difficult to use correctly, especially when syntactic keywords are not reserved. It is impossible to construct a patternbased, automatically hygienic macro system on top of syntactic closures because the pattern interpreter must be able to determine the syntactic role of an identifier (in order to close it in the correct syntactic environment) before macro expansion has made that role apparent. Kohlbecker's algorithm maybe viewed as a book-keeping technique for deferring such decisions until macro expansion is locally complete. Building on that insight, this paper unifies and extends the competing paradigms of hygienic macro expansion and syntactic closures to obtain an algorithm that combines the benefits of both. Several prototypes of a complete macro system for Scheme have been based on the algorithm presented here.},
address = {New York, New York, USA},
author = {Clinger, William},
booktitle = {Proceedings of the 18th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '91},
doi = {10.1145/99583.99607},
file = {:Users/liang-tingchen/Dropbox/References/Clinger - 1991 - Macros that work.pdf:pdf},
isbn = {0897914198},
issn = {07308566},
keywords = {and allows 10csj,are reserved words,e,g,if,macros to refer,scoped,to lexical variables},
pages = {155--162},
publisher = {ACM Press},
title = {{Macros that work}},
url = {http://portal.acm.org/citation.cfm?doid=99583.99607},
year = {1991}
}
@article{Carboni1984a,
author = {Carboni, Aurelio and Kasangian, Stefano and Street, Ross},
doi = {10.1016/0022-4049(84)90061-6},
file = {:Users/liang-tingchen/Dropbox/References/Carboni, Kasangian, Street - 1984 - Bicategories of spans and relations.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {sep},
number = {3},
pages = {259--267},
title = {{Bicategories of spans and relations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404984900616},
volume = {33},
year = {1984}
}
@article{Krishnaswami2013,
author = {Krishnaswami, Neelakantan R.},
doi = {10.1145/2544174.2500588},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {nov},
number = {9},
pages = {221--232},
title = {{Higher-order functional reactive programming without spacetime leaks}},
url = {http://dl.acm.org/citation.cfm?doid=2544174.2500588},
volume = {48},
year = {2013}
}
@article{SLack2004,
abstract = {We introduce adhesive categories, which are categories with structure ensuring that pushouts along monomorphisms are well- behaved, as well as quasiadhesive categories which restrict attention to regular monomorphisms. Many examples of graphical structures used in computer science are shown to be examples of adhesive and quasi- adhesive categories. Double-pushout graph rewriting generalizes well to rewriting on arbitrary adhesive and quasiadhesive categories. Mathematics},
author = {Uustalu, Tarmo},
doi = {10.1051/ita:2003022},
file = {:Users/liang-tingchen/Dropbox/References/Uustalu - 2003 - Generalizing Substitution.pdf:pdf},
issn = {0988-3754},
journal = {Theoretical Informatics and Applications},
keywords = {adhesive categories,and phrases,category theory,extensive categories,quasiadhesive categories},
month = {oct},
number = {4},
pages = {315--336},
title = {{Generalizing Substitution}},
url = {http://www.rairo-ita.org/10.1051/ita:2003022},
volume = {37},
year = {2003}
}
@article{Bousfield1977,
author = {Bousfield, A.K.},
doi = {10.1016/0022-4049(77)90067-6},
file = {:Users/liang-tingchen/Dropbox/References/Bousfield - 1977 - Constructions of factorization systems in categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jan},
number = {2-3},
pages = {207--220},
title = {{Constructions of factorization systems in categories}},
url = {http://dx.doi.org/10.1016/0022-4049(77)90067-6},
volume = {9},
year = {1977}
}
@article{Jacobs2015,
abstract = {This paper takes a fresh look at the topic of trace semantics in the theory of coalgebras. In the last few years, two approaches, somewhat incomparable at first sight, captured successfully in a coalgebraic setting trace semantics for various types of transition systems. The first development of coalgebraic trace semantics used final coalgebras in Kleisli categories and required some non-trivial assumptions, which do not always hold, even in cases where one can reasonably speak of traces (like for weighted automata). The second development stemmed from the observation that trace semantics can also arise by performing a determinization construction and used final coalgebras in Eilenberg-Moore categories. In this paper, we develop a systematic study in which the two approaches can be studied and compared. Notably, we show that the two different views on trace semantics are equivalent, in the examples where both approaches are applicable.},
author = {Jacobs, Bart and Silva, Alexandra and Sokolova, Ana},
doi = {10.1016/j.jcss.2014.12.005},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Silva, Sokolova - 2015 - Trace semantics via determinization.pdf:pdf},
isbn = {9783642327834},
issn = {10902724},
journal = {Journal of Computer and System Sciences},
keywords = {Coalgebra,Eilenberg-Moore category,Kleisli category,Trace semantics},
number = {5},
pages = {859--879},
publisher = {Elsevier Inc.},
title = {{Trace semantics via determinization}},
url = {http://dx.doi.org/10.1016/j.jcss.2014.12.005},
volume = {81},
year = {2015}
}
@inproceedings{timany_et_al:LIPIcs:2018:9199,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Cumulative Inductive Types In Coq - Timany, Amin; Sozeau, Matthieu)

Keywords: Coq, Proof Assistants, Inductive Types, Universes, Cumulativity},
author = {Timany, Amin and Sozeau, Matthieu},
booktitle = {3rd International Conference on Formal Structures for Computation and Deduction (FSCD 2018)},
doi = {10.4230/LIPIcs.FSCD.2018.29},
editor = {Kirchner, H{\'{e}}l{\`{e}}ne},
file = {:Users/liang-tingchen/Dropbox/References//Timany, Sozeau - 2018 - Cumulative Inductive Types In Coq.pdf:pdf},
isbn = {978-3-95977-077-4},
issn = {1868-8969},
keywords = {Coq,Cumulativity,Inductive Types,Proof Assistants,Universes},
number = {29},
pages = {29:1----29:16},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Cumulative Inductive Types In Coq}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9199},
volume = {108},
year = {2018}
}
@incollection{Meijer1991,
author = {Meijer, Erik and Fokkinga, Maarten and Paterson, Ross},
booktitle = {Functional Programming Languages and Computer Architecture. FPCA 1991},
doi = {10.1007/3540543961_7},
editor = {Hughes, John},
file = {:Users/liang-tingchen/Dropbox/References/Meijer, Fokkinga, Paterson - 1991 - Functional programming with bananas, lenses, envelopes and barbed wire.pdf:pdf},
pages = {124--144},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Functional programming with bananas, lenses, envelopes and barbed wire}},
url = {http://link.springer.com/10.1007/3540543961{\_}7},
volume = {523},
year = {1991}
}
@article{Garner2009a,
abstract = {We describe a non-extensional variant of Martin-L{\"{o}}f type theory, which we call two-dimensional type theory , and equip it with a sound and complete semantics valued in 2-categories.},
author = {GARNER, RICHARD},
doi = {10.1017/S0960129509007646},
file = {:Users/liang-tingchen/Dropbox/References/GARNER - 2009 - Two-dimensional models of type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {aug},
number = {4},
pages = {687--736},
title = {{Two-dimensional models of type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129509007646/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Bird1999b,
abstract = {Nested datatypes generalise regular datatypes in much the same way that context-free languages generalise regular ones. Although the categorical semantics of nested types turns out to be similar to the regular case, the fold functions are more limited because they can only describe natural transformations. Practical considerations therefore dictate the introduction of a generalised fold function in which this limitation can be overcome. In the paper we show how to construct generalised folds systematically for each nested datatype, and show that they possess a uniqueness property analogous to that of ordinary folds. As a consequence, generalised folds satisfy fusion properties similar to those developed for regular datatypes. Such properties form the core of an effective calculational theory of inductive datatypes.},
author = {Bird, Richard and Paterson, Ross},
doi = {10.1007/s001650050047},
file = {:Users/liang-tingchen/Dropbox/References/Bird, Paterson - 1999 - Generalised folds for nested datatypes.pdf:pdf},
issn = {0934-5043},
journal = {Formal Aspects of Computing},
keywords = {Functional programming,Program construction},
month = {sep},
number = {2},
pages = {200--222},
title = {{Generalised folds for nested datatypes}},
url = {https://dl.acm.org/doi/10.1007/s001650050047},
volume = {11},
year = {1999}
}
@article{Pym1995,
author = {Pym, David J},
doi = {10.1007/BF01063152},
file = {:Users/liang-tingchen/Dropbox/References/Pym - 1995 - A note on the proof theory the $\lambda$II-calculus.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
number = {2},
pages = {199--230},
title = {{A note on the proof theory the $\lambda$II-calculus}},
url = {http://link.springer.com/10.1007/BF01063152},
volume = {54},
year = {1995}
}
@article{Nelson1983,
author = {Nelson, Evelyn},
doi = {10.1016/0304-3975(83)90014-2},
file = {:Users/liang-tingchen/Dropbox/References/Nelson - 1983 - Iterative algebras.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {67--94},
title = {{Iterative algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397583900142},
volume = {25},
year = {1983}
}
@incollection{Czajka2014,
abstract = {We give a coinductive proof of confluence, up to equivalence of root-active subterms, of infinitary lambda-calculus. We also show confluence of B{\"{o}}hm reduction (with respect to root-active terms) in infinitary lambda-calculus. In contrast to previous proofs, our proof makes heavy use of coinduction and does not employ the notion of descendants. {\textcopyright} 2014 Springer International Publishing Switzerland.},
archivePrefix = {arXiv},
arxivId = {1808.05481},
author = {Czajka, {\L}ukasz},
booktitle = {Rewriting and Typed Lambda Calculi. RTA 2014},
doi = {10.1007/978-3-319-08918-8_12},
editor = {Dowek, Gilles},
eprint = {1808.05481},
file = {:Users/liang-tingchen/Dropbox/References/Czajka - 2014 - A Coinductive Confluence Proof for Infinitary Lambda-Calculus.pdf:pdf},
isbn = {9783319089171},
issn = {16113349},
pages = {164--178},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Coinductive Confluence Proof for Infinitary Lambda-Calculus}},
url = {http://link.springer.com/10.1007/978-3-319-08918-8{\_}12},
volume = {8560},
year = {2014}
}
@article{Straubing1981,
author = {Straubing, Howard},
doi = {10.1016/0304-3975(81)90036-0},
file = {:Users/liang-tingchen/Dropbox/References/Straubing - 1981 - A generalization of the Sch{\"{u}}tzenberger product of finite monoids.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {2},
pages = {137--150},
title = {{A generalization of the Sch{\"{u}}tzenberger product of finite monoids}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397581900360},
volume = {13},
year = {1981}
}
@article{Desharnais2002,
author = {Desharnais, Jos{\'{e}}e and Edalat, Abbas and Panangaden, Prakash},
doi = {10.1006/inco.2001.2962},
file = {:Users/liang-tingchen/Dropbox/References/Desharnais, Edalat, Panangaden - 2002 - Bisimulation for Labelled Markov Processes.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {dec},
number = {2},
pages = {163--193},
title = {{Bisimulation for Labelled Markov Processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540101929621},
volume = {179},
year = {2002}
}
@book{Yager,
abstract = {In this review paper we survey the ways in which various micropipet techniques have been used to study the mechanochemical and interactive features of lipid bilayer vesicles and monolayer-coated gas bubbles. Special emphasis will be made on characterizing the barrier properties of grafted PEG layers and how a hierarchical approach that uses a short barrier and extended ligand allows us to start to mimic nature's own solution to the problem of ubiquitous repulsion and specific attraction. The information gained from such studies not only characterizes the membrane and other lipid surfaces and their intersurface interactions from a fundamental materials science perspective, but also provides essential materials property data that are required for the successful design and deployment of lipid-based carriers and other capsules in applications involving this so-called 'stealthy' surface. (C) 2000 Elsrvier Science B.V. All rights reserved},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-540-44792-4},
editor = {Yager, Roland R. and Liu, Liping},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 2008 - Classic Works of the Dempster-Shafer Theory of Belief Functions.pdf:pdf},
isbn = {978-3-540-25381-5},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Fuzziness and Soft Computing},
title = {{Classic Works of the Dempster-Shafer Theory of Belief Functions}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=sZNvI3mRE1sC{\&}oi=fnd{\&}pg=PA1{\&}dq=Hybrid+Intelligent+Systems+for+Pattern+Recognition+Using+Soft+Computing{\&}ots=Da9DPPw{\_}Xn{\&}sig=U-vNOtczJJBWEM-N3okKn1k6WNI http://link.springer.com/10.1007/97},
volume = {219},
year = {2008}
}
@inproceedings{Parent2017a,
abstract = {The ideal worlds of a possible worlds semantics may satisfy both a primary obligation and an associated secondary obligation, for example the obligation to keep a promise and the obligation to apologise for not keeping it. This is known as the pragmatic oddity introduced by Prakken and Sergot. We argue that an adequate treatment of the pragmatic oddity within a norm-based semantics can be obtained, by not allowing primary and secondary obligations to aggregate, because they are obligations of a different kind. On the basis of this conceptual analysis, we introduce two logics, depending on the stance taken on the representation of normative conflicts, and we present sound and complete proof systems for these logics. We then give a formal analysis, discuss extensions, and highlight various topics for further research. Normative reasoning, norm-based deontic logic, deontic logic, para-dox ACM Reference format: Xavier Parent and Leendert van der Torre. 2017. The pragmatic oddity in norm-based deontic logics.},
address = {New York, New York, USA},
author = {Parent, Xavier and van der Torre, Leendert},
booktitle = {Proceedings of the 16th edition of the International Conference on Articial Intelligence and Law - ICAIL '17},
doi = {10.1145/3086512.3086529},
file = {:Users/liang-tingchen/Dropbox/References/Parent, van der Torre - 2017 - The pragmatic oddity in norm-based deontic logics.pdf:pdf},
isbn = {9781450348911},
keywords = {@BULLET Applied computing → Law,CCS CONCEPTS @BULLET Theory of computation → Logic,KEYWORDS},
pages = {169--178},
publisher = {ACM Press},
title = {{The pragmatic oddity in norm-based deontic logics}},
url = {https://doi.org/10.1145/3086512.3086529 http://dl.acm.org/citation.cfm?doid=3086512.3086529},
year = {2017}
}
@article{Angiuli2021,
abstract = {In their usual form, representation independence metatheorems provide an external guarantee that two implementations of an abstract interface are interchangeable when they are related by an operation-preserving correspondence. If our programming language is dependently-typed, however, we would like to appeal to such invariance results within the language itself, in order to obtain correctness theorems for complex implementations by transferring them from simpler, related implementations. Recent work in proof assistants has shown that Voevodsky's univalence principle allows transferring theorems between isomorphic types, but many instances of representation independence in programming involve non-isomorphic representations.},
author = {Angiuli, Carlo and Cavallo, Evan and M{\"{o}}rtberg, Anders and Zeuner, Max},
doi = {10.1145/3434293},
file = {:Users/liang-tingchen/Dropbox/References/Angiuli et al. - 2021 - Internalizing representation independence with univalence.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Cubical Type Theory,Higher Inductive Types,Proof Assistants,Representation Independence,Univalence},
month = {jan},
number = {POPL},
pages = {1--30},
title = {{Internalizing representation independence with univalence}},
url = {https://dl.acm.org/doi/10.1145/3434293},
volume = {5},
year = {2021}
}
@article{Okasaki1997,
author = {OKASAKI, CHRIS},
doi = {10.1017/S0956796897002876},
file = {:Users/liang-tingchen/Dropbox/References/OKASAKI - 1997 - Three algorithms on Braun trees.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {nov},
number = {6},
pages = {S0956796897002876},
publisher = {Swansea University Libraries},
title = {{Three algorithms on Braun trees}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796897002876},
volume = {7},
year = {1997}
}
@incollection{Litak2012,
author = {Litak, Tadeusz and Pattinson, Dirk and Sano, Katsuhiko and Schr{\"{o}}der, Lutz},
booktitle = {Proc. 39th International Colloquium on Automata, Languages and Programming, ICALP 2012},
doi = {10.1007/978-3-642-31585-5_29},
editor = {Wattenhofer, Kurt Mehlhorn and Andrew Pitts and Roger},
file = {:Users/liang-tingchen/Dropbox/References/Litak et al. - 2012 - Coalgebraic predicate logic.pdf:pdf},
pages = {299--311},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Coalgebraic predicate logic}},
year = {2012}
}
@inproceedings{Altenkirch2016b,
abstract = {We present an internal formalisation of a type heory with dependent types in Type Theory using a special case of higher inductive types from Homotopy Type Theory which we call quotient inductive types (QITs). Our formalisation of type theory avoids referring to preterms or a typability relation but defines directly well typed objects by an inductive definition. We use the elimination principle to define the set-theoretic and logical predicate interpretation. The work has been formalized using the Agda system extended with QITs using postulates.},
address = {New York, NY, USA},
author = {Altenkirch, Thorsten and Kaposi, Ambrus},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837638},
file = {:Users/liang-tingchen/Dropbox/References//Altenkirch, Kaposi - 2016 - Type Theory in Type Theory Using Quotient Inductive Types.pdf:pdf},
isbn = {9781450335492},
issn = {0362-1340},
keywords = {Agda,Higher Inductive Types,Homotopy Type Theory,Logical Relations,Metaprogramming},
month = {apr},
pages = {18--29},
publisher = {Association for Computing Machinery},
series = {POPL '16},
title = {{Type Theory in Type Theory Using Quotient Inductive Types}},
url = {https://doi.org/10.1145/2837614.2837638 https://dl.acm.org/doi/10.1145/2914770.2837638},
year = {2016}
}
@incollection{Goris2007,
abstract = {In this paper we answer the question what implicit proof assertions in the provability logic GL can be realized by explicit proof terms. In particular we show that the fragment of GL which can be realized by generalized proof terms of GLA is exactly S4 ∩ GL and equals the fragment that can be realized by proof-terms of LP. In the final sections of this paper we establish the disjunction property for GLA and give an axiomatization for GL ∩ S4. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Goris, Evan},
booktitle = {Logical Foundations of Computer Science. LFCS 2007},
doi = {10.1007/978-3-540-72734-7_17},
editor = {Artemov, Sergei N. and Nerode, Anil},
file = {:Users/liang-tingchen/Dropbox/References/Goris - 2007 - Explicit Proofs in Formal Provability Logic.pdf:pdf},
isbn = {3540727329},
issn = {16113349},
pages = {241--253},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Explicit Proofs in Formal Provability Logic}},
url = {http://link.springer.com/10.1007/978-3-540-72734-7{\_}17},
volume = {4514},
year = {2007}
}
@article{Zhang2008,
abstract = {In order to describe approximate equivalence among processes, the notions of ??-bisimilarity and behavioural pseudometric have been introduced by Ying and van Breugel respectively. Van Breugel provides a distance function induced by ??-bisimilarity, and conjectures that his behavioural pseudometric coincides with this function. This paper is inspired by this conjecture. We give a negative answer for van Breugel's conjecture first. Moreover, we show that the distance function induced by ??-bisimilarity is a pseudometric on states, and provide a fixed point characterization of this pseudometric. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Zhang, Jinjin and Zhu, Zhaohui},
doi = {10.1016/j.entcs.2008.11.022},
file = {:Users/liang-tingchen/Dropbox/References/Zhang, Zhu - 2008 - A behavioural pseudometric based on $\lambda$–bisimilarity.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {??-bisimilarity,Process algebra,behavioural pseudometric,fixed point characterization},
month = {dec},
number = {3},
pages = {115--127},
publisher = {Elsevier B.V.},
title = {{A behavioural pseudometric based on $\lambda$–bisimilarity}},
url = {http://dx.doi.org/10.1016/j.entcs.2008.11.022 http://linkinghub.elsevier.com/retrieve/pii/S1571066108004593},
volume = {220},
year = {2008}
}
@article{Jacobs1993,
abstract = {A comprehension category is defined as a functor P:E→B→ satisfying (a) a cod {\{}ring operator{\}} P is a fibration, and (b) f is cartesian in E implies that Pf is a pullback in B. This notion captures many structures which are used to describe type dependency (like display-map categories (Taylor (1986), Hyland and Pitts (1989) and Lamarche (1988)), categories with attributes (Cartmell (1978) and Moggi (1991)), D-categories (Ehrhard (1988)) and comprehensive fibrations (Pavlovi{\'{c}} (1990)). It also captures comprehension as occurring in topos theory and as described by Lawvere's (1970)) hyperdoctrines. This paper is meant as an introduction to these comprehension categories. A comprehension category will be called closed if it has appropriate dependent products and sums. A few examples of closed comprehension categories will be described here; more of them may be found in Jacobs (1991); applications occur in Jacobs (1991) and Jacobs et al. (1991). {\textcopyright} 1993.},
author = {Jacobs, Bart},
doi = {10.1016/0304-3975(93)90169-T},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 1993 - Comprehension categories and the semantics of type dependency.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jan},
number = {2},
pages = {169--207},
title = {{Comprehension categories and the semantics of type dependency}},
url = {https://linkinghub.elsevier.com/retrieve/pii/030439759390169T},
volume = {107},
year = {1993}
}
@article{Antoniou1998,
abstract = {Default logic is one of the most prominent approaches to nonmonotonic reasoning, and allows one to make plausible conjectures when faced with incomplete information about the problem at hand. Default rules prevail in many application domains such as},
author = {ANTONIOU, GRIGORIS},
doi = {10.1017/S0269888998002136},
file = {:Users/liang-tingchen/Dropbox/References/ANTONIOU - 1998 - A tutorial on default reasoning.pdf:pdf},
issn = {02698889},
journal = {The Knowledge Engineering Review},
month = {oct},
number = {3},
pages = {S0269888998002136},
title = {{A tutorial on default reasoning}},
url = {http://www.journals.cambridge.org/abstract{\_}S0269888998002136},
volume = {13},
year = {1998}
}
@article{Abel2007,
abstract = {We present an algorithm for computing normal terms and types in Martin-L{\"{o}}f type theory with one universe and eta-conversion. We prove that two terms or types are equal in the theory iff the normal forms are identical (as de Bruijn terms). It thus follows that our algorithm can be used for deciding equality in Martin-L{\"{o}}f type theory. The algorithm uses the technique of normalization by evaluation; normal forms are computed by first evaluating terms and types in a suitable model. The normal forms are then extracted from the semantic elements. We prove its completeness by a PER model and its soundness by a Kripke logical relation. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Abel, Andreas and Aehlig, Klaus and Dybjer, Peter},
doi = {10.1016/j.entcs.2007.02.025},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Aehlig, Dybjer - 2007 - Normalization by Evaluation for Martin-L{\"{o}}f Type Theory with One Universe.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Dependent Types,Domain Semantics,Normalization by Evaluation,Type Theory,Universe},
month = {apr},
number = {SPEC. ISS.},
pages = {17--39},
publisher = {Elsevier B.V.},
title = {{Normalization by Evaluation for Martin-L{\"{o}}f Type Theory with One Universe}},
url = {http://dx.doi.org/10.1016/j.entcs.2007.02.025 https://linkinghub.elsevier.com/retrieve/pii/S1571066107000977},
volume = {173},
year = {2007}
}
@inproceedings{Seely1987,
author = {Seely, Robert A. G.},
booktitle = {Second Annual IEEE Symposium on Logic in Computer Science (LICS 1987)},
editor = {Gries, David},
file = {:Users/liang-tingchen/Dropbox/References/Seely - 1987 - Modelling computations a 2-categorical framework.pdf:pdf},
publisher = {IEEE},
title = {{Modelling computations: a 2-categorical framework}},
year = {1987}
}
@incollection{Bekki2014,
abstract = {This volume presents an exploration of a wide variety of new formal methods from computer science, biology and economics that have been applied to problems in semantics and pragmatics in recent years. Many of the contributions included focus on data from East Asian languages, particularly Japanese and Korean. The collection reflects on a range of new empirical issues that have arisen, including issues related to preference, evidentiality, and attention. Separated into several sections, the book presents discussions on: information structure, speech acts and decisions, philosophical themes in semantics, and new formal approaches to semantic and pragmatic theory. Its overarching theme is the relation between different kinds of content, from a variety of perspectives. The discussions presented are both theoretically innovative and empirically motivated.},
author = {Bekki, Daisuke and Masuko, Moe},
booktitle = {Formal Approaches to Semantics and Pragmatics},
doi = {10.1007/978-94-017-8813-7_3},
editor = {McCready, Eric and Yabushita, Katsuhiko and Yoshimoto, Kei},
file = {:Users/liang-tingchen/Dropbox/References/Bekki, Masuko - 2014 - Meta-Lambda Calculus and Linguistic Monads.pdf:pdf},
isbn = {978-94-017-8812-0},
keywords = {continuations,meta-lambda calculus,monads,non-determinism,ostension,type theoretic semantics},
number = {Mlc},
pages = {31--64},
publisher = {Springer, Dordrecht},
series = {Studies in Linguistics and Philosophy},
title = {{Meta-Lambda Calculus and Linguistic Monads}},
url = {http://link.springer.com/10.1007/978-94-017-8813-7{\_}3},
year = {2014}
}
@incollection{Bonsangue2006,
abstract = {We take the point of view that, if transition systems are coalgebras for a functor T, then an adequate logic for these transition systems should arise from the ‘Stone dual' L of T. We show that such a functor always gives rise to an ‘abstract' adequate logic for T-coalgebras and investigate under which circumstances it gives rise to a ‘concrete' such logic, that is, a logic with an inductively defined syntax and proof system. We obtain a result that allows us to prove adequateness of logics uniformly for a large number of different types of transition systems and give some examples of its usefulness.},
annote = {check secton 5},
author = {Bonsangue, Marcello M. and Kurz, Alexander},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/11690634_12},
editor = {Aceto, Luca and Ing{\'{o}}lfsd{\'{o}}ttir, Anna},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Kurz - 2006 - Presenting functors by operations and equations.pdf:pdf},
isbn = {978-3-540-33045-5},
pages = {172--186},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Presenting functors by operations and equations}},
url = {http://www.springerlink.com/index/10.1007/11690634},
volume = {3921},
year = {2006}
}
@article{Maclane1985,
author = {Maclane, Saunders and Par{\'{e}}, Robert},
doi = {10.1016/0022-4049(85)90087-8},
file = {:Users/liang-tingchen/Dropbox/References/Maclane, Par{\'{e}} - 1985 - Coherence for bicategories and indexed categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {C},
pages = {59--80},
title = {{Coherence for bicategories and indexed categories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0022404985900878},
volume = {37},
year = {1985}
}
@incollection{Kurz2015,
author = {Kurz, Alexander and Milius, Stefan and Pattinson, Dirk and Schr{\"{o}}der, Lutz},
booktitle = {Software, Services, and Systems},
doi = {10.1007/978-3-319-15545-6},
editor = {{De Nicola}, Rocco and Hennicker, Rolf},
file = {:Users/liang-tingchen/Dropbox/References/Kurz et al. - 2015 - Simplified coalgebraic trace equivalence.pdf:pdf},
isbn = {978-3-319-15544-9},
pages = {75--90},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Simplified coalgebraic trace equivalence}},
url = {http://link.springer.com/10.1007/978-3-319-15545-6},
year = {2015}
}
@inproceedings{Lammel2005,
abstract = {The 'Scrap your boilerplate' approach to generic programming allows the programmer to write generic functions that can traverse arbitrary data structures, and yet have type-specific cases. However, the original approach required all the type-specific cases to be supplied at once, when the recursive knot of generic function definition is tied. Hence, generic functions were closed. In contrast, Haskell's type classes support open, or extensible, functions that can be extended with new type-specific cases as new data types are defined. In this paper, we extend the 'Scrap your boilerplate' approach to support this open style. On the way, we demonstrate the desirability of abstraction over type classes, and the usefulness of recursive dictionarie.},
address = {New York, New York, USA},
author = {L{\"{a}}mmel, Ralf and Jones, Simon Peyton},
booktitle = {Proceedings of the tenth ACM SIGPLAN international conference on Functional programming - ICFP '05},
doi = {10.1145/1086365.1086391},
file = {:Users/liang-tingchen/Dropbox/References/L{\"{a}}mmel, Peyton-Jones - 2005 - Scrap your boilerplate with class extensible generic functions.pdf:pdf},
isbn = {1595930647},
issn = {03621340},
keywords = {Extensibility,Generic Programming,Programming Languages,Programming Techniques,Reusable Software,Software Engineering,Type Classes,Type-case,language Constructs and Features,recursive dictionaries},
number = {October 2004},
pages = {204},
publisher = {ACM Press},
title = {{Scrap your boilerplate with class}},
url = {http://portal.acm.org/citation.cfm?doid=1086365.1086391},
year = {2005}
}
@inproceedings{Escardo2017,
abstract = {We begin by revisiting partiality in univalent type theory via the notion of dominance. We then perform first steps in constructive computability theory, discussing the consequences of working with computability as property or structure, without assuming countable choice or Markov's principle. A guiding question is what, if any, notion of partial function allows the proposition "all partial functions on natural numbers are Turing computable" to be consistent.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Partial Elements and Recursion via Dominances in Univalent Type Theory - Escard{\'{o}}, Mart{\'{i}}n H; Knapp, Cory M)

Keywords: univalent type theory, homotopy type theory, partial function, dominance, recursion theory, computability theory},
author = {Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel and Knapp, Cory M},
booktitle = {26th EACSL Annual Conference on Computer Science Logic (CSL 2017)},
doi = {10.4230/LIPIcs.CSL.2017.21},
editor = {Goranko, Valentin and Dam, Mads},
file = {:Users/liang-tingchen/Dropbox/References/Escard{\'{o}}, Knapp - 2017 - Partial Elements and Recursion via Dominances in Univalent Type Theory.pdf:pdf},
isbn = {978-3-95977-045-3},
issn = {1868-8969},
number = {21},
pages = {21:1----21:16},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Partial Elements and Recursion via Dominances in Univalent Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/7682},
volume = {82},
year = {2017}
}
@article{Tarjan1985,
abstract = {A powerful technique in the complexity analysis of data structures is amortization, or averaging over time. Amortized running time is a realistic but robust complexity measure for which we can obtain surprisingly tight upper and lower bounds on a variety of algorithms. By following the principle of designing algorithms whose amortized complexity is low, we obtain “self-adjusting” data structures that are simple, flexible and efficient. This paper surveys recent work by several researchers on amortized complexity.},
author = {Tarjan, Robert Endre},
doi = {10.1137/0606031},
file = {:Users/liang-tingchen/Dropbox/References/Tarjan - 1985 - Amortized Computational Complexity.pdf:pdf},
issn = {0196-5212},
journal = {SIAM Journal on Algebraic Discrete Methods},
month = {apr},
number = {2},
pages = {306--318},
title = {{Amortized Computational Complexity}},
url = {http://epubs.siam.org/doi/10.1137/0606031 https://epubs.siam.org/doi/10.1137/0606031},
volume = {6},
year = {1985}
}
@book{Nielson2007,
address = {London},
author = {Nielson, Hanne Riis and Nielson, Flemming},
doi = {10.1007/978-1-84628-692-6},
file = {:Users/liang-tingchen/Dropbox/References/Nielson, Nielson - 2007 - Semantics with Applications An Appetizer.pdf:pdf},
isbn = {978-1-84628-691-9},
publisher = {Springer London},
series = {Undergraduate Topics in Computer Science},
title = {{Semantics with Applications: An Appetizer}},
url = {http://link.springer.com/10.1007/978-1-84628-692-6},
year = {2007}
}
@article{Adamek2000,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Koubek, V{\'{a}}clav and Velebil, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Koubek, Velebil - 2000 - A duality between infinitary varieties and algebraic theories.pdf:pdf},
issn = {0010-2628},
journal = {Commentationes Mathematicae Universitatis Carolinae},
number = {3},
pages = {529--541},
title = {{A duality between infinitary varieties and algebraic theories}},
url = {https://eudml.org/doc/248619},
volume = {41},
year = {2000}
}
@incollection{Hildebrandt2016,
author = {Kokkinofta, Eleni and Philippou, Anna},
booktitle = {Web Services, Formal Methods, and Behavioral Types. WS-FM 2014, WS-FM 2015},
doi = {10.1007/978-3-319-33612-1_8},
editor = {T., Hildebrandt and A., Ravara and J., van der Werf and M., Weidlich},
file = {:Users/liang-tingchen/Dropbox/References/Kokkinofta, Philippou - 2016 - Type Checking Purpose-Based Privacy Policies in the {\$}pi{\$} -Calculus.pdf:pdf},
isbn = {9783319336114},
issn = {16113349},
pages = {122--142},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Type Checking Purpose-Based Privacy Policies in the {\$}\backslashpi{\$} -Calculus}},
url = {http://link.springer.com/10.1007/978-3-319-33612-1{\_}8},
volume = {9421},
year = {2016}
}
@article{Godel1931,
author = {G{\"{o}}del, Kurt},
doi = {10.1007/BF01700692},
file = {:Users/liang-tingchen/Dropbox/References/G{\"{o}}del - 1931 - {\"{U}}ber formal unentscheidbare S{\"{a}}tze der Principia Mathematica und verwandter Systeme I.pdf:pdf},
issn = {0026-9255},
journal = {Monatshefte f{\"{u}}r Mathematik und Physik},
month = {dec},
number = {1},
pages = {173--198},
title = {{{\"{U}}ber formal unentscheidbare S{\"{a}}tze der Principia Mathematica und verwandter Systeme I}},
url = {http://link.springer.com/10.1007/BF01700692},
volume = {38-38},
year = {1931}
}
@incollection{Henzinger1991,
author = {Henzinger, Thomas A and Manna, Zohar and Pnueli, Amir},
booktitle = {Real-Time: Theory in Practice},
doi = {10.1007/BFb0031995},
file = {:Users/liang-tingchen/Dropbox/References/Henzinger, Manna, Pnueli - 1992 - Timed transition systems.pdf:pdf},
isbn = {978-3-540-55564-3},
keywords = {1this research was supported,by the defense advanced,by the national science,ccr-89-13641,concurrency,founda-,ibm graduate fellowship,in part by an,real time,research projects agency under,tion grants ccr-89-11512 and,transition systems},
pages = {226--251},
title = {{Timed transition systems}},
url = {http://link.springer.com/10.1007/BFb0031995},
volume = {3096},
year = {1992}
}
@article{Sterling2021,
abstract = {Extending Mart{\'{i}}n Escard{\'{o}}'s effectful forcing technique, we give a new proof of a well-known result: Brouwer's monotone bar theorem holds for any bar that can be realized by a functional of type (ℕ→ℕ)→ℕ in G{\"{o}}del's System T . Effectful forcing is an elementary alternative to standard sheaf-theoretic forcing arguments, using ideas from programming languages, including computational effects, monads, the algebra interpretation of call-by-name $\lambda$-calculus, and logical relations.},
author = {Sterling, Jonathan},
doi = {10.1017/S0956796821000095},
file = {:Users/liang-tingchen/Dropbox/References/Sterling - 2021 - Higher order functions and Brouwer's thesis.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
keywords = {Computer Science - Logic in Computer Science,Mathematics - Logic},
month = {may},
pages = {e11},
title = {{Higher order functions and Brouwer's thesis}},
url = {https://www.cambridge.org/core/product/identifier/S0956796821000095/type/journal{\_}article},
volume = {31},
year = {2021}
}
@article{SCHULTZ2017,
abstract = {In this paper, we develop an algebraic approach to data integration by combining techniques from functional programming, category theory, and database theory. In our formalism, database schemas and instances are algebraic (multi-sorted equational) theories of a certain form. Schemas denote categories, and instances denote their initial (term) algebras. The instances on a schema S form a category, S – Inst , and a morphism of schemas F : S → T induces three adjoint data migration functors: $\Sigma$ F : S – Inst → T – Inst , defined by substitution along F , which has a right adjoint $\Delta$ F : T – Inst → S – Inst , which in turn has a right adjoint $\Pi$ F : S – Inst → T – Inst . We present a query language based on for/where/return syntax where each query denotes a sequence of data migration functors; a pushout-based design pattern for performing data integration using our formalism; and describe the implementation of our formalism in a tool we call AQL (Algebraic Query Language).},
author = {SCHULTZ, PATRICK and WISNESKY, RYAN},
doi = {10.1017/S0956796817000168},
file = {:Users/liang-tingchen/Dropbox/References/SCHULTZ, WISNESKY - 2017 - Algebraic data integration.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {nov},
pages = {e24},
title = {{Algebraic data integration}},
url = {https://www.cambridge.org/core/product/identifier/S0956796817000168/type/journal{\_}article},
volume = {27},
year = {2017}
}
@book{Eilenberg1976,
address = {New York},
author = {Eilenberg, Samuel},
publisher = {Academic Press},
title = {{Automata, Languages, and Machines}},
volume = {2},
year = {1976}
}
@inproceedings{Swamy2013,
abstract = {Modern programming languages, ranging from Haskell and ML, to JavaScript, C{\{}{\#}{\}} and Java, all make extensive use of higher-order state. This paper advocates a new verification methodology for higher-order stateful programs, based on a new monad of predicate transformers called the Dijkstra monad. Using the Dijkstra monad has a number of benefits. First, the monad naturally yields a weakest pre-condition calculus. Second, the computed specifications are structurally simpler in several ways, e.g., single-state post-conditions are sufficient (rather than the more complex two-state post-conditions). Finally, the monad can easily be varied to handle features like exceptions and heap invariants, while retaining the same type inference algorithm. We implement the Dijkstra monad and its type inference algorithm for the F* programming language. Our most extensive case study evaluates the Dijkstra monad and its F* implementation by using it to verify JavaScript programs. Specifically, we describe a tool chain that translates programs in a subset of JavaScript decorated with assertions and loop invariants to F*. Once in F*, our type inference algorithm computes verification conditions and automatically discharges their proofs using an SMT solver. We use our tools to prove that a core model of the JavaScript runtime in F* respects various invariants and that a suite of JavaScript source programs are free of runtime errors.},
address = {New York, New York, USA},
author = {Swamy, Nikhil and Weinberger, Joel and Schlesinger, Cole and Chen, Juan and Livshits, Benjamin},
booktitle = {Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation - PLDI '13},
doi = {10.1145/2491956.2491978},
file = {:Users/liang-tingchen/Dropbox/References/Swamy et al. - 2013 - Verifying higher-order programs with the dijkstra monad.pdf:pdf},
isbn = {9781450320146},
issn = {03621340},
keywords = {hoare monad,predicate transformer,refinement types},
pages = {387},
publisher = {ACM Press},
title = {{Verifying higher-order programs with the dijkstra monad}},
url = {http://dl.acm.org/citation.cfm?doid=2491956.2491978},
year = {2013}
}
@techreport{Bonchi2012,
abstract = {We introduce $\backslash$$\backslash$emphbisimulation up to congruence as a technique for proving language equivalence of non-deterministic finite automata. Exploiting this technique, we devise an optimisation of the classical algorithm by Hopcroft and Karp$\backslash$$\backslash${\~{}}$\backslash$$\backslash$citeHopcroftKarp that, instead of computing the whole determinised automata, explores only a small portion of it. Although the optimised algorithm remains exponential in worst case (the problem is PSPACE-complete), experimental results show improvements of several orders of magnitude over the standard algorithm.},
author = {Bonchi, Filippo and Pous, Damien},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi, Pous - 2012 - Checking NFA equivalence with bisimulations up to congruence.pdf:pdf},
keywords = {Language Equivalence,Non-deterministic Finite Au,automata,bisimulation,coinduction,congruence,equivalence,finite,language,non-deterministic,techniques,up-to},
mendeley-tags = {automata,bisimulation,coinduction,congruence,equivalence,finite,language,non-deterministic,techniques,up-to},
title = {{Checking NFA equivalence with bisimulations up to congruence}},
type = {Technical report},
url = {http://hal.archives-ouvertes.fr/hal-00639716},
year = {2012}
}
@article{Bartels2004,
author = {Bartels, Falk and Sokolova, Ana and de Vink, Erik P.},
doi = {10.1016/j.tcs.2004.07.019},
file = {:Users/liang-tingchen/Dropbox/References/Bartels, Sokolova, de Vink - 2004 - A hierarchy of probabilistic system types.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {bisimulation,coalgebra,cocongruence,preservation and reflection of,probabilistic bisimulation,probabilistic transition systems},
month = {oct},
number = {1-2},
pages = {3--22},
title = {{A hierarchy of probabilistic system types}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504004414},
volume = {327},
year = {2004}
}
@article{Wilkinson2012a,
author = {Wilkinson, Toby},
doi = {10.1016/j.entcs.2012.08.021},
file = {:Users/liang-tingchen/Dropbox/References/Wilkinson - 2012 - A characterisation of expressivity for coalgebraic bisimulation and simulation.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {bisimulation,coalgebra,enriched logical connection,preordered set,simulation},
month = {sep},
pages = {323--336},
publisher = {Elsevier B.V.},
title = {{A characterisation of expressivity for coalgebraic bisimulation and simulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066112000515},
volume = {286},
year = {2012}
}
@phdthesis{VanGool2014,
author = {van Gool, Samuel Jacob},
file = {:Users/liang-tingchen/Dropbox/References/van Gool - 2014 - On Sheaves and Duality.pdf:pdf},
isbn = {9781291759853},
number = {april},
school = {Radboud Universiteit Nijmegen},
title = {{On Sheaves and Duality}},
year = {2014}
}
@article{Ellerman2017,
author = {Ellerman, David},
doi = {10.1093/jigpal/jzx022},
file = {:Users/liang-tingchen/Dropbox/References/Ellerman - 2017 - Logical information theory new logical foundations for information theory.pdf:pdf},
issn = {1367-0751},
journal = {Logic Journal of the IGPL},
keywords = {logical entropy,partition logic,shannon entropy},
month = {oct},
number = {5},
pages = {806--835},
title = {{Logical information theory: new logical foundations for information theory}},
url = {http://academic.oup.com/jigpal/article/25/5/806/4070969/Logical-information-theory-new-logical-foundations},
volume = {25},
year = {2017}
}
@article{Gumm2007,
abstract = {We define an out-degree for F-coalgebras and show that the coalgebras of outdegree at most $\kappa$ form a covariety. As a subcategory of all F-coalgebras, this class has a terminal object, which for many problems can stand in for the terminal F-coalgebra, which need not exist in general. As examples, we derive structure theoretic results about minimal coalgebras, showing that, for instance minimization of coalgebras is functorial, that products of finitely many minimal coalgebras exist and are given by their largest common subcoalgebra, that minimal subcoalgebras have no inner endomorphisms and show how minimal subcoalgebras can be constructed from Moore-automata. Since the elements of minimal subcoalgebras must correspond uniquely to the formulae of any logic characterizing observational equivalence, we give in the last section a straightforward and self-contained account of the coalgebraic logic of D. Pattinson and L. Schr{\"{o}}der, which we believe is simpler and more direct than the original exposition.},
author = {Gumm, H. Peter},
doi = {10.1007/s10485-007-9116-1},
file = {:Users/liang-tingchen/Dropbox/References/Gumm - 2007 - On minimal coalgebras.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
month = {dec},
number = {3},
pages = {313--332},
publisher = {Springer},
title = {{On minimal coalgebras}},
type = {Journal article},
url = {http://www.springerlink.com/index/10.1007/s10485-007-9116-1},
volume = {16},
year = {2007}
}
@article{Abramsky1994,
abstract = {The main purpose of this short paper is to serve as an introduction to the following paper,$\backslash$ On the-calculus and Linear Logic", by Gianluigi Bellin and Philip Scott. The circumstances from which it arises are as follows. In June 1991 I gave a lecture on$\backslash$ Proofs as Processes" ... $\backslash$n},
author = {Abramsky, Samson},
doi = {10.1016/0304-3975(94)00103-0},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 1994 - Proofs as processes.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1},
pages = {5--9},
title = {{Proofs as processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397594001030},
volume = {135},
year = {1994}
}
@article{Pierce2000a,
abstract = {We study two partial type inference methods for a language combining subtyping and impredica- tive polymorphism. Both methods are local in the sense that missing annotations are recovered using only information from adjacent nodes in the syntax tree, without long-},
author = {Pierce, Benjamin C. and Turner, David N.},
doi = {10.1145/345099.345100},
file = {:Users/liang-tingchen/Dropbox/References/Pierce, Turner - 2000 - Local type inference.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
keywords = {D.3.1 [Programming Languages]: Formal Definitions,Languages,Polymorphism,Subtyping,Theory,Type inference},
month = {jan},
number = {1},
pages = {1--44},
title = {{Local type inference}},
url = {http://portal.acm.org/citation.cfm?doid=345099.345100},
volume = {22},
year = {2000}
}
@article{Rosebrugh2004,
author = {Rosebrugh, Robert and Wood, R. J.},
file = {:Users/liang-tingchen/Dropbox/References/Rosebrugh, Wood - 2004 - Split structures.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Complete distributivity,Idempotent splitting completion,K-Z doctrine},
number = {12},
pages = {172--183},
title = {{Split structures}},
volume = {13},
year = {2004}
}
@article{Kozen1998,
abstract = {Set constraints are inclusion relations between expressions denoting sets of ground terms over a ranked alphabet. They are the main ingredient in set-based program analysis. In this paper we describe a constraint logic programming language CLP(SC) over set constraints in the style of J. Jaffar and J.-L. Lassez (1987roc. Symp. Principles of Programming Languages 1987,'' pp. 1111119). The language subsumes ordinary logic programs over an Herbrand domain. We give an efficient unification algorithm and opera-tional, declarative, and fixpoint semantics. We show how the language can be applied in set-based program analysis by deriving explicitly the monadic approximation of the collecting semantics of N.},
author = {Kozen, Dexter},
doi = {10.1006/inco.1997.2694},
file = {:Users/liang-tingchen/Dropbox/References/Kozen - 1998 - Set Constraints and Logic Programming.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {1},
pages = {2--25},
title = {{Set Constraints and Logic Programming}},
url = {https://ac.els-cdn.com/S0890540197926948/1-s2.0-S0890540197926948-main.pdf?{\_}tid=8778931d-78fd-4f6e-a254-8b9c364e8d5d{\&}acdnat=1529015336{\_}3d7e8e23467704d651ff258f2e9bfce3 http://linkinghub.elsevier.com/retrieve/pii/S0890540197926948},
volume = {142},
year = {1998}
}
@inproceedings{farka:OASIcs:2018:9884,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Proof-Relevant Resolution for Elaboration of Programming Languages - Farka, Frantisek)

Keywords: resolution, elaboration, proof-relevant, dependent types, type classes},
author = {Farka, Franti{\v{s}}ek Frantisek},
booktitle = {Technical Communications of the 34th International Conference on Logic Programming (ICLP 2018)},
doi = {10.4230/OASIcs.ICLP.2018.18},
editor = {Palu', Alessandro Dal and Tarau, Paul and Saeedloei, Neda and Fodor, Paul},
file = {:Users/liang-tingchen/Dropbox/References//Farka - 2018 - Proof-Relevant Resolution for Elaboration of Programming Languages.pdf:pdf},
isbn = {978-3-95977-090-3},
issn = {2190-6807},
keywords = {18,2018,4230,acknowledgements this thesis abstract,and phrases resolution,dependent types,digital object identifier 10,elaboration,iclp,is based on published,joint work with ekaterina,ko-,mendatskaya and kevin hammond,oasics,proof-relevant,type classes},
number = {18},
pages = {18:1----18:9},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {OpenAccess Series in Informatics (OASIcs)},
title = {{Proof-Relevant Resolution for Elaboration of Programming Languages}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9884},
volume = {64},
year = {2018}
}
@article{Cockx2016,
abstract = {Dependently typed languages such as Agda, Coq and Idris use a syntactic first-order unification algorithm to check definitions by dependent pattern matching. However, these algorithms don't adequately consider the types of the terms being unified, leading to various unintended results. As a consequence, they require ad hoc restrictions to preserve soundness, but this makes them very hard to prove correct, modify, or extend. This paper proposes a framework for reasoning formally about unification in a dependently typed setting. In this framework, unification rules compute not just a unifier but also a corresponding correctness proof in the form of an equivalence between two sets of equations. By rephrasing the standard unification rules in a proof-relevant manner, they are guaranteed to preserve soundness of the theory. In addition, it enables us to safely add new rules that can exploit the dependencies between the types of equations. Using our framework, we reimplemented the unification algorithm used by Agda. As a result, we were able to replace previous ad hoc restrictions with formally verified unification rules, fixing a number of bugs in the process. We are convinced this will also enable the addition of new and interesting unification rules in the future, without compromising soundness along the way.},
author = {Cockx, Jesper and Devriese, Dominique and Piessens, Frank},
doi = {10.1145/3022670.2951917},
file = {:Users/liang-tingchen/Dropbox/References/Cockx, Devriese, Piessens - 2016 - Unifiers as equivalences proof-relevant unification of dependently typed data.pdf:pdf},
isbn = {9781450342193},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {dependent types,inductive,type theory,unification},
month = {sep},
number = {9},
pages = {270--283},
title = {{Unifiers as equivalences: proof-relevant unification of dependently typed data}},
url = {http://dl.acm.org/citation.cfm?doid=3022670.2951917},
volume = {51},
year = {2016}
}
@article{Goncharov2014a,
archivePrefix = {arXiv},
arxivId = {1401.5277},
author = {Goncharov, Sergey and Milius, Stefan and Silva, Alexandra},
eprint = {1401.5277},
file = {:Users/liang-tingchen/Dropbox/References/Goncharov, Milius, Silva - 2014 - Towards a Coalgebraic Chomsky Hierarchy.pdf:pdf},
journal = {ArXiv e-prints},
month = {jan},
pages = {1--48},
title = {{Towards a Coalgebraic Chomsky Hierarchy}},
url = {http://arxiv.org/abs/1401.5277v3},
year = {2014}
}
@inproceedings{Tews2004,
abstract = {Relation lifting [6] extends an endofunctor F : C???C to a functor Rel(F) : Rel(C)???Rel(C), where Rel(C) is a suitable category of relations over C. The relation lifting for the functor F can be used to define the notion of bisimulation for coalgebras X???F(X). The related notion of predicate lifting can be used to define invariants for F-coalgebras. Predicate and relation lifting can be directly defined for a rich class of polynomial functors [5,6,19]. In this paper I investigate the case where the functor F is defined as the initial semantics of a (single sorted) parametric algebraic specification.},
author = {Tews, Hendrik},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/j.entcs.2004.02.040},
file = {:Users/liang-tingchen/Dropbox/References/Tews - 2004 - Predicate and relation lifting for parametric algebraic specifications.pdf:pdf},
issn = {15710661},
keywords = {Algebraic specification,Bisimulation,Coalgebra,Endofunctor,Polynomial functor,Relation lifting},
pages = {335--353},
title = {{Predicate and relation lifting for parametric algebraic specifications}},
volume = {107},
year = {2004}
}
@article{Bottu2017,
abstract = {Quantified class constraints have been proposed many years agoto raise the expressive power of type classes from Horn clausestofirst-order logic. Yet, while it has been much asked for overthe years, the feature was never implemented or studied in depth.Instead, several workarounds have been proposed, all of which areultimately stopgap measures.This paper revisits the idea of quantified class constraints andelaborates it into a practical language design. We show the meritof quantified class constraints in terms of more expressive modelingand in terms of terminating type class resolution. In addition, weprovide a declarative specifi cation of the type system as well as atype inference algorithm that elaborates into System F. Moreover,we discuss termination conditions of our system and also provide aprototype implementation.},
author = {Bottu, Gert-Jan and Karachalias, Georgios and Schrijvers, Tom and Oliveira, Bruno C. d. S. and Wadler, Philip},
doi = {10.1145/3156695.3122967},
file = {:Users/liang-tingchen/Dropbox/References/Bottu et al. - 2017 - Quantified class constraints.pdf:pdf},
isbn = {9781450351829},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {2017,acm reference format,and philip wadler,bruno c,d,georgios karachalias,gert-jan bottu,haskell,in proceedings of 10th,oliveira,quantified class constraints,s,tom schrijvers,type classes,type inference},
month = {sep},
number = {10},
pages = {148--161},
pmid = {905426},
title = {{Quantified class constraints}},
url = {http://dl.acm.org/citation.cfm?doid=3156695.3122967},
volume = {52},
year = {2017}
}
@inproceedings{Smith1984,
address = {New York, New York, USA},
author = {Smith, Brian Cantwell},
booktitle = {Proceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages - POPL '84},
doi = {10.1145/800017.800513},
file = {:Users/liang-tingchen/Dropbox/References/Smith - 1984 - Reflection and semantics in LISP.pdf:pdf},
isbn = {0897911253},
pages = {23--35},
publisher = {ACM Press},
title = {{Reflection and semantics in LISP}},
url = {http://portal.acm.org/citation.cfm?doid=800017.800513},
year = {1984}
}
@article{Shulman2008,
abstract = {Questions of set-theoretic size play an essential role in category theory, especially the distinction between sets and proper classes (or small sets and large sets). There are many different ways to formalize this, and which choice is made can have noticeable effects on what categorical constructions are permissible. In this expository paper we summarize and compare a number of such "set-theoretic foundations for category theory," and describe their implications for the everyday use of category theory. We assume the reader has some basic knowledge of category theory, but little or no prior experience with formal logic or set theory.},
archivePrefix = {arXiv},
arxivId = {0810.1279},
author = {Shulman, Michael A.},
eprint = {0810.1279},
file = {:Users/liang-tingchen/Dropbox/References/Shulman - 2008 - Set theory for category theory.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {1--39},
title = {{Set theory for category theory}},
url = {http://arxiv.org/abs/0810.1279},
year = {2008}
}
@article{Aczel2003,
abstract = {Infinite trees form a free completely iterative theory over any given signature - this fact, proved by Elgot, Bloom and Tindell, turns out to be a special case of a much more general categorical result exhibited in the present paper. We prove that whenever an endofunctor H of a category has final coalgebras for all functors H({\_})+X, then those coalgebras, TX, form a monad. This monad is completely iterative, i.e., every guarded system of recursive equations has a unique solution. And it is a free completely iterative monad on H. The special case of polynomial endofunctors of the category Set is the above mentioned theory, or monad, of infinite trees. This procedure can be generalized to monoidal categories satisfying a mild side condition: if, for an object H, the endofunctor H ⊗{\_}+I has a final coalgebra, T, then T is a monoid. This specializes to the above case for the monoidal category of all endofunctors. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Aczel, Peter and Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1016/S0304-3975(02)00728-4},
file = {:Users/liang-tingchen/Dropbox/References/Aczel et al. - 2003 - Infinite trees and completely iterative theories A coalgebraic view.pdf:pdf},
isbn = {0960129502},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Coalgebra,Completely iterative theory,Monad,Monoidal category,Solution Theorem},
number = {1-3},
pages = {1--45},
title = {{Infinite trees and completely iterative theories: A coalgebraic view}},
volume = {300},
year = {2003}
}
@book{Kelly1974c,
address = {Berlin, Heidelberg},
author = {Kelly, Gregory Maxwell},
doi = {10.1007/BFb0063096},
editor = {Kelly, Gregory M.},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1974 - Category Seminar.pdf:pdf},
isbn = {978-3-540-06966-9},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Category Seminar}},
url = {http://link.springer.com/10.1007/BFb0063096},
volume = {420},
year = {1974}
}
@article{Barr1993a,
author = {Barr, Michael},
doi = {2010.1016/0304-3975(93)90076-6},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1993 - Terminal coalgebras in well-founded set theory.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical Computer Science},
month = {jun},
number = {2},
pages = {299--315},
title = {{Terminal coalgebras in well-founded set theory}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/B6V1G-45FCX9D-4W/2/c51af619ea441e3c98c74f106eca87c6},
volume = {114},
year = {1993}
}
@incollection{Samarati2001,
abstract = {Access control is the process of mediating every request to resources and data maintained by a system and determining whether the request should be granted or denied. The access control decision is enforced by a mechanism implementing regulations established by a security policy. Different access control policies can be applied, corresponding to different criteria for defining what should, and what should not, be allowed, and, in some sense, to different definitions of what ensuring security means. In this chapter we investigate the basic concepts behind access control design and enforcement, and point out different security requirements that may need to be taken into consideration. We discuss several access control policies, and models formalizing them, that have been proposed in the literature or that are currently under investigation.},
author = {Samarati, Pierangela and de Vimercati, Sabrina Capitani},
booktitle = {Foundations of Security Analysis and Design},
doi = {10.1007/3-540-45608-2_3},
file = {:Users/liang-tingchen/Dropbox/References/Samarati, de Vimercati - 2001 - Access control policies, models, and mechanisms.pdf:pdf},
isbn = {3540428968},
keywords = {Computer Science,authorization},
pages = {137--196},
title = {{Access control: policies, models, and mechanisms}},
url = {http://dx.doi.org/10.1007/3-540-45608-2{\_}3 http://link.springer.com/10.1007/3-540-45608-2{\_}3},
volume = {2171},
year = {2001}
}
@article{Author2019,
author = {Algehed, Maximilian and Bernardy, Jean-Philippe},
doi = {10.1145/3341693},
file = {:Users/liang-tingchen/Dropbox/References/Algehed, Bernardy - 2019 - Simple noninterference from parametricity.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Noninterference,Parametricity,Security,Types},
month = {jul},
number = {ICFP},
pages = {1--22},
title = {{Simple noninterference from parametricity}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341693},
volume = {3},
year = {2019}
}
@inproceedings{Allen1990,
abstract = {The authors lay the foundations for reasoning about proofs whose steps include both invocations of programs to build subproofs (tactics) and references to representations of proofs themselves (reflected proofs). The main result is the definition of a single type of proof which can mention itself, using a novel technique which finds a fixed point of a mapping between metalanguage and object language. This single type contrasts with hierarchies of types used in other approaches to accomplish the same classification. It is shown that these proofs are valid, and that every proof can be reduced to a proof involving only primitive inference rules. The extension of the results to proofs from which programs (such as tactics) can be derived and to proofs that can refer to a library of definitions and previously proven theorems is shown. It is believed that the mechanism of reflection is fundamental in building proof development systems, and its power is illustrated with applications to automating reasoning and describing modes of computation.},
author = {Allen, S.F. and Constable, R.L. and Howe, D.J. and Aitken, W.E.},
booktitle = {[1990] Proceedings. Fifth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1990.113737},
file = {:Users/liang-tingchen/Dropbox/References/Allen et al. - 1990 - The semantics of reflected proof.pdf:pdf},
isbn = {0-8186-2073-0},
pages = {95--105},
publisher = {IEEE Comput. Soc. Press},
title = {{The semantics of reflected proof}},
url = {http://ieeexplore.ieee.org/document/113737/},
year = {1990}
}
@article{Kelly1980a,
author = {Kelly, Gregory Maxwell and Laplaza, M.L.},
doi = {10.1016/0022-4049(80)90101-2},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Laplaza - 1980 - Coherence for compact closed categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
pages = {193--213},
title = {{Coherence for compact closed categories}},
volume = {19},
year = {1980}
}
@inproceedings{Baldan2015,
address = {Dagstuhl, Germany},
annote = {Keywords: trace metric, monad lifting, pseudometric, coalgebra},
author = {Baldan, Paolo and Bonchi, Filippo and Kerstan, Henning and K{\"{o}}nig, Barbara},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science (CALCO 2015)},
doi = {http://dx.doi.org/10.4230/LIPIcs.CALCO.2015.35},
editor = {Moss, Lawrence S and Sobocinski, Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Baldan et al. - 2015 - Towards Trace Metrics via Functor Lifting.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
pages = {35--49},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Towards Trace Metrics via Functor Lifting}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5525},
volume = {35},
year = {2015}
}
@article{Hennessy2002,
abstract = {This paper describes the construction of two set-theoretic denotational models for the $\pi$-calculus. The models are obtained as initial solutions to domain equations in a functor category. By associating with each syntactic construct of the $\pi$-calculus a natural transformation over these models we obtain two interpretations for the language. We also show that these models are fully abstract with respect to natural behavioural preorders over terms in the language. By this we mean that two terms are related behaviourally if and only if their interpretations in the model are related. The behavioural preorders are the standard versions of may and must testing adapted to the $\pi$-calculus. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Hennessy, Matthew},
doi = {10.1016/S0304-3975(00)00331-5},
file = {:Users/liang-tingchen/Dropbox/References/Hennessy - 2002 - A fully abstract denotational semantics for the $\pi$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {may},
number = {1-2},
pages = {53--89},
title = {{A fully abstract denotational semantics for the $\pi$-calculus}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397500003315},
volume = {278},
year = {2002}
}
@incollection{Bernardo2012a,
abstract = {One of the most studied extensions of testing theory to nondeterministic and probabilistic processes yields unrealistic probabilities estimations that give rise to two anomalies. First, probabilistic testing equivalence does not imply probabilistic trace equivalence. Second, probabilistic testing equivalence differentiates processes that perform the same sequence of actions with the same probability but make internal choices in different moments and thus, when applied to processes without probabilities, does not coincide with classical testing equivalence. In this paper, new versions of probabilistic trace and testing equivalences are presented for nondeterministic and probabilistic processes that resolve the two anomalies. Instead of focussing only on suprema and infima of the set of success probabilities of resolutions of interaction systems, our testing equivalence matches all the resolutions on the basis of the success probabilities of their identically labeled computations. A simple spectrum is provided to relate the new relations with existing ones. It is also shown that, with our approach, the standard probabilistic testing equivalences for generative and reactive probabilistic processes can be retrieved.},
annote = {10.1007/978-3-642-28729-9{\_}13},
author = {Bernardo, Marco and {De Nicola}, Rocco and Loreti, Michele},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-642-28729-9_13},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Bernardo, De Nicola, Loreti - 2012 - Revisiting Trace and Testing Equivalences for Nondeterministic and Probabilistic Processes.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {195--209},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Revisiting Trace and Testing Equivalences for Nondeterministic and Probabilistic Processes}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}13},
volume = {7213},
year = {2012}
}
@article{Pare1974,
abstract = {Given a cartesian closed category E with subobject classifier t:l-{\textgreater}$\Omega$, it is shown that the functor $\Omega${\^{}}( ) : E{\^{}}op-{\textgreater}E is tripleable. Standard results from the theory of triples are then used to show that E has I-colimits if and only if it has I{\^{}}op-limits. This gives a new proof of Mikkelsen's theorem which states that E has all finite colimits.},
author = {Par{\'{e}}, Robert},
doi = {10.1090/S0002-9904-1974-13497-X},
file = {:Users/liang-tingchen/Dropbox/References/Par{\'{e}} - 1974 - Colimits in Topoi.pdf:pdf},
issn = {0002-9904},
journal = {Bulletin of the American Mathematical Society},
keywords = {Colimits,Elementary topos,Limits,Triple},
month = {may},
number = {3},
pages = {556--562},
title = {{Colimits in Topoi}},
url = {http://www.ams.org/journal-getitem?pii=S0002-9904-1974-13497-X},
volume = {80},
year = {1974}
}
@inproceedings{Hinze2000,
address = {New York, New York, USA},
author = {Hinze, Ralf},
booktitle = {Proceedings of the fifth ACM SIGPLAN international conference on Functional programming - ICFP '00},
doi = {10.1145/351240.351258},
file = {:Users/liang-tingchen/Dropbox/References/Hinze - 2000 - Deriving backtracking monad transformers.pdf:pdf},
isbn = {1581132026},
pages = {186--197},
publisher = {ACM Press},
title = {{Deriving backtracking monad transformers}},
url = {http://portal.acm.org/citation.cfm?doid=351240.351258},
year = {2000}
}
@article{Navarro-Arribas2012,
abstract = {In this paper, we review the role of information fusion in data privacy. To that end, we introduce data privacy, and describe how information and data fusion are used in some fields of data privacy. Our study is focused on the use of aggregation for privacy protections, and record linkage techniques. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
author = {Navarro-Arribas, Guillermo and Torra, Vicen{\c{c}}},
doi = {10.1016/j.inffus.2012.01.001},
file = {:Users/liang-tingchen/Dropbox/References/Navarro-Arribas, Torra - 2012 - Information fusion in data privacy A survey.pdf:pdf},
isbn = {1566-2535},
issn = {15662535},
journal = {Information Fusion},
keywords = {Data privacy,Information fusion,Microaggregation,Record linkage},
month = {oct},
number = {4},
pages = {235--244},
publisher = {Elsevier B.V.},
title = {{Information fusion in data privacy: A survey}},
url = {http://dx.doi.org/10.1016/j.inffus.2012.01.001 http://linkinghub.elsevier.com/retrieve/pii/S1566253512000024},
volume = {13},
year = {2012}
}
@article{Solovay1976,
author = {Solovay, Robert M.},
doi = {10.1007/BF02757006},
file = {:Users/liang-tingchen/Dropbox/References/Solovay - 1976 - Provability interpretations of modal logic.pdf:pdf},
issn = {0021-2172},
journal = {Israel Journal of Mathematics},
month = {sep},
number = {3-4},
pages = {287--304},
title = {{Provability interpretations of modal logic}},
url = {http://link.springer.com/10.1007/BF02757006},
volume = {25},
year = {1976}
}
@inproceedings{Kohlbecker1986,
address = {New York, New York, USA},
author = {Kohlbecker, Eugene and Friedman, Daniel P. and Felleisen, Matthias and Duba, Bruce},
booktitle = {Proceedings of the 1986 ACM conference on LISP and functional programming - LFP '86},
doi = {10.1145/319838.319859},
file = {:Users/liang-tingchen/Dropbox/References/Kohlbecker et al. - 1986 - Hygienic macro expansion.pdf:pdf},
isbn = {0897912004},
pages = {151--161},
publisher = {ACM Press},
title = {{Hygienic macro expansion}},
url = {http://dl.acm.org/citation.cfm?id=319859 http://portal.acm.org/citation.cfm?doid=319838.319859},
year = {1986}
}
@incollection{Hofmann2009,
abstract = {[PS]},
author = {Hofmann, Martin},
booktitle = {Semantics and Logics of Computation},
doi = {10.1017/CBO9780511526619.004},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann - 1997 - Syntax and Semantics of Dependent Types.pdf:pdf},
isbn = {9780511526619},
month = {jan},
pages = {79--130},
publisher = {Cambridge University Press},
title = {{Syntax and Semantics of Dependent Types}},
url = {https://www.cambridge.org/core/product/identifier/CBO9780511526619A022/type/book{\_}part},
year = {1997}
}
@inproceedings{Traytel2012,
author = {Traytel, Dmitry and Popescu, Andrei and Blanchette, Jasmin C.},
booktitle = {Proceedings of the 2012 27th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2012},
doi = {10.1109/LICS.2012.75},
file = {:Users/liang-tingchen/Dropbox/References/Traytel, Popescu, Blanchette - 2012 - Foundational, compositional (co)datatypes for higher-order logic Category theory applied to theore.pdf:pdf},
isbn = {9780769547695},
keywords = {(co)datatypes,Category theory,cardinals,higher-order logic,interactive theorem proving},
pages = {596--605},
title = {{Foundational, compositional (co)datatypes for higher-order logic: Category theory applied to theorem proving}},
year = {2012}
}
@article{Reiterman1982,
author = {Reiterman, Jan},
doi = {10.1007/BF02483902},
file = {:Users/liang-tingchen/Dropbox/References/Reiterman - 1982 - The Birkhoff theorem for finite algebras.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {dec},
number = {1},
pages = {1--10},
title = {{The Birkhoff theorem for finite algebras}},
url = {http://link.springer.com/10.1007/BF02483902},
volume = {14},
year = {1982}
}
@article{Scott1976,
abstract = {The meaning of many kinds of expressions in programming languages can be taken as elements of certain spaces of “partial” objects. In this report these spaces are modeled in one universal domain {\$}{\{}\backslashbf P{\}} \backslashomega {\$}, the set of all subsets of the integers. This domain renders the connection of this semantic theory with the ordinary theory of number theoretic (especially general recursive) functions clear and straightforward.},
author = {Scott, Dana S.},
doi = {10.1137/0205037},
file = {:Users/liang-tingchen/Dropbox/References/Scott - 1976 - Data Types as Lattices.pdf:pdf},
isbn = {0097-5397},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
month = {sep},
number = {3},
pages = {522--587},
title = {{Data Types as Lattices}},
url = {http://epubs.siam.org/doi/10.1137/0205037},
volume = {5},
year = {1976}
}
@inproceedings{Dwork2009,
abstract = {We consider private data analysis in the setting in which a trusted and trustworthy curator, having obtained a large data set containing private information, releases to the public a "sanitization" of the data set that simultaneously protects the privacy of the individual contributors of data and offers utility to the data analyst. The sanitization may be in the form of an arbitrary data structure, accompanied by a computational procedure for determining approximate answers to queries on the original data set, or it may be a "synthetic data set" consisting of data items drawn from the same universe as items in the original data set; queries are carried out as if the synthetic data set were the actual input. In either case the process is non-interactive; once the sanitization has been released the original data and the curator play no further role. For the task of sanitizing with a synthetic dataset output, we map the boundary between computational feasibility and infeasibility with respect to a variety of utility measures. For the (potentially easier) task of sanitizing with unrestricted output format, we show a tight qualitative and quantitative connection between hardness of sanitizing and the existence of traitor tracing schemes.},
address = {New York, New York, USA},
author = {Dwork, Cynthia and Naor, Moni and Reingold, Omer and Rothblum, Guy N and Vadhan, Salil},
booktitle = {Proceedings of the 41st annual ACM symposium on Symposium on theory of computing - STOC '09},
doi = {10.1145/1536414.1536467},
file = {:Users/liang-tingchen/Dropbox/References/Dwork et al. - 2009 - On the complexity of differentially private data release.pdf:pdf},
isbn = {9781605585062},
issn = {07378017},
keywords = {cryptography,differential privacy,exponential mechanism,privacy,traitor tracing},
pages = {381},
publisher = {ACM Press},
title = {{On the complexity of differentially private data release}},
url = {http://doi.acm.org/10.1145/1536414.1536467{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1536414.1536467 http://portal.acm.org/citation.cfm?doid=1536414.1536467},
year = {2009}
}
@article{Lambek1970,
author = {Lambek, Joachim},
doi = {http://10.4153/CMB-1970-065-6},
file = {:Users/liang-tingchen/Dropbox/References/Lambek - 1970 - Subequalizers.pdf:pdf},
journal = {Canadian Mathematical Bulletin},
number = {3},
pages = {337--349},
title = {{Subequalizers}},
volume = {13},
year = {1970}
}
@article{Donnelly2007,
abstract = {We formalize in the logical framework ATS/LF a proof based on Tait's method that establishes the simply-typed lambda-calculus being strongly normalizing. In this formalization, we employ higher-order abstract syntax to encode lambda-terms and an inductive datatype to encode the reducibility predicate in Tait's method. The resulting proof is particularly simple and clean when compared to previously formalized ones. Also, we mention briefly how a proof based on Girard's method can be formalized in a similar fashion that establishes System F being strongly normalizing. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Donnelly, Kevin and Xi, Hongwei},
doi = {10.1016/j.entcs.2007.01.021},
file = {:Users/liang-tingchen/Dropbox/References/Donnelly, Xi - 2007 - A Formalization of Strong Normalization for Simply-Typed Lambda-Calculus and System F.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {ATS/LF,HOAS,Logical frameworks,Logical relations,Normalization,Reducibility candidates,Tait's method},
month = {jun},
number = {5},
pages = {109--125},
publisher = {Elsevier B.V.},
title = {{A Formalization of Strong Normalization for Simply-Typed Lambda-Calculus and System F}},
url = {http://dx.doi.org/10.1016/j.entcs.2007.01.021 https://linkinghub.elsevier.com/retrieve/pii/S1571066107002356},
volume = {174},
year = {2007}
}
@article{Igarashi1999,
abstract = {Several recent studies have introduced lightweight versions of Java: reduced languages in which complex features like threads and reflection are dropped to enable rigorous arguments about key properties such as type safety. We carry this process a step further, omitting almost all features of the full language (including interfaces and even assignment) to obtain a small calculus, Featherweight Java, for which rigorous proofs are not only possible but easy. Featherweight Java bears a similar relation to full Java as the lambda-calculus does to languages such as ML and Haskell. It offers a similar computational "feel," providing classes, methods, fields, inheritance, and dynamic typecasts, with a semantics closely following Java's. A proof of type safety for Featherweight Java thus illustrates many of the interesting features of a safety proof for the full language, while remaining pleasingly compact. The syntax, type rules, and operational semantics of Featherweight Java fit on one page, making it easier to understand the consequences of extensions and variations. As an illustration of its utility in this regard, we extend Featherweight Java with generic classes in the style of GJ (Bracha, Odersky, Stoutamire, and Wadler) and sketch a proof of type safety. The extended system formalizes for the first time some of the key features of GJ. {\textcopyright} 1999 ACM.},
author = {Igarashi, Atshushi and Pierce, Benjamin and Wadler, Philip},
doi = {10.1145/320385.320395},
file = {:Users/liang-tingchen/Dropbox/References/Igarashi, Pierce, Wadler - 1999 - Featherwieght Java.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {Language design and implementation,Theoretical foundations},
month = {oct},
number = {10},
pages = {132--146},
title = {{Featherwieght Java}},
url = {http://portal.acm.org/citation.cfm?doid=320385.320395},
volume = {34},
year = {1999}
}
@incollection{Magalhaes2014,
author = {Magalh{\~{a}}es, Jos{\'{e}} Pedro and L{\"{o}}h, Andres},
booktitle = {Practical Aspects of Declarative Languages. PADL 2014},
doi = {10.1007/978-3-319-04132-2_15},
editor = {Flatt, Matthew and Guo, Hai-Feng},
file = {:Users/liang-tingchen/Dropbox/References/Magalh{\~{a}}es, L{\"{o}}h - 2014 - Generic Generic Programming.pdf:pdf},
isbn = {978-3-319-04132-2},
pages = {216--231},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Generic Generic Programming}},
url = {http://link.springer.com/10.1007/978-3-319-04132-2{\_}15},
volume = {8324},
year = {2014}
}
@article{Jacobs2004,
abstract = {Traditionally, traces are the sequences of labels associated with paths in transition systems X → P(A × X). Here we describe traces more generally, for coalgebras of the form X → P(F(X)), where F is a polynomial functor. The main result states that F's final coalgebra Z ≅→ F(Z) gives rise to a weakly final coalgebra with state space P(Z), in a suitable category of coalgebras. Weak finality means that there is a coalgebra map X → P(Z), but there is no uniqueness. We show that there is a canonical choice among these maps X → P(Z), namely the largest one, describing the traces in a suitably abstract formulation. A crucial technical ingredient in our construction is a general distributive law FP ⇒ PF, obtained via relation lifting.},
author = {Jacobs, Bart},
doi = {10.1016/j.entcs.2004.02.031},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2004 - Trace semantics for coalgebras.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Coalgebra,Distributive law,Final coalgebra,Polynomial functor,Trace semantics},
month = {dec},
pages = {167--184},
title = {{Trace semantics for coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104051746},
volume = {106},
year = {2004}
}
@inproceedings{Zyskind2015b,
abstract = {—The recent increase in reported incidents of surveil-lance and security breaches compromising users' privacy call into question the current model, in which third-parties collect and con-trol massive amounts of personal data. Bitcoin has demonstrated in the financial space that trusted, auditable computing is possible using a decentralized network of peers accompanied by a public ledger. In this paper, we describe a decentralized personal data management system that ensures users own and control their data. We implement a protocol that turns a blockchain into an automated access-control manager that does not require trust in a third party. Unlike Bitcoin, transactions in our system are not strictly financial – they are used to carry instructions, such as storing, querying and sharing data. Finally, we discuss possible future extensions to blockchains that could harness them into a well-rounded solution for trusted computing problems in society.},
author = {Zyskind, Guy and Nathan, Oz and Pentland, Alex Sandy},
booktitle = {2015 IEEE Security and Privacy Workshops},
doi = {10.1109/SPW.2015.27},
file = {:Users/liang-tingchen/Dropbox/References/Zyskind, Nathan, Pentland - 2015 - Decentralizing privacy Using blockchain to protect personal data.pdf:pdf},
keywords = {Bitcoin,Blockchain,Personal data,Privacy},
month = {may},
pages = {180--184},
publisher = {IEEE},
title = {{Decentralizing privacy: Using blockchain to protect personal data}},
url = {http://ieeexplore.ieee.org/document/7163223/},
year = {2015}
}
@incollection{Pitts1995,
author = {Pitts, Andrew M.},
booktitle = {Handbook of Logic in Computer Science},
editor = {Abramsky, Samson and Gabbay, D. M. and Maibaum, Thomas S.E.},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 1995 - Categorical Logic.pdf:pdf},
publisher = {Oxford University Press},
title = {{Categorical Logic}},
year = {1995}
}
@article{Palamidessi2012,
abstract = {Differential privacy is a modern approach in privacy-preserving data analysis to control the amount of information that can be inferred about an individual by querying a database. The most common techniques are based on the introduction of probabilistic noise, often defined as a Laplacian parametric on the sensitivity of the query. In order to maximize the utility of the query, it is crucial to estimate the sensitivity as precisely as possible. In this paper we consider relational algebra, the classical language for queries in relational databases, and we propose a method for computing a bound on the sensitivity of queries in an intuitive and compositional way. We use constraint-based techniques to accumulate the information on the possible values for attributes provided by the various components of the query, thus making it possible to compute tight bounds on the sensitivity.},
archivePrefix = {arXiv},
arxivId = {1207.0872},
author = {Palamidessi, Catuscia and Stronati, Marco},
doi = {10.4204/EPTCS.85.7},
eprint = {1207.0872},
file = {:Users/liang-tingchen/Dropbox/References/Palamidessi, Stronati - 2012 - Differential Privacy for Relational Algebra Improving the Sensitivity Bounds via Constraint Systems.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {jul},
number = {Qapl},
pages = {92--105},
title = {{Differential Privacy for Relational Algebra: Improving the Sensitivity Bounds via Constraint Systems}},
url = {http://arxiv.org/abs/1207.0872v1},
volume = {85},
year = {2012}
}
@book{Adamek1994,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.2277/0521422612},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}} - 1994 - Locally Presentable and Accessible Categories.pdf:pdf},
isbn = {9780521422611},
pages = {332},
publisher = {Cambridge University Press},
series = {London Mathematical Society Lecture Note Series},
title = {{Locally Presentable and Accessible Categories}},
url = {http://dx.doi.org/10.2277/0521422612},
year = {1994}
}
@book{Almeida1995,
author = {Almeida, Jorge},
pages = {532},
publisher = {World Scientific},
series = {Series in Algebra},
title = {{Finite Semigroups and Universal Algebra}},
year = {1995}
}
@inproceedings{Flatt2002,
abstract = {Many macro systems, especially for Lisp and Scheme, allow macro transformers to perform general computation. Moreover, the language for implementing compile-time macro transformers is usually the same as the language for implementing run-time functions. As a side effect of this sharing, implementations tend to allow the mingling of compile-time values and run-time values, as well as values from separate compilations. Such mingling breaks programming tools that must parse code without executing it. Macro implementors avoid harmful mingling by obeying certain macro-definition protocols and by inserting phase-distinguishing annotations into the code. However, the annotations are fragile, the protocols are not enforced, and programmers can only reason about the result in terms of the compiler's implementation. MzScheme---the language of the PLT Scheme tool suite---addresses the problem through a macro system that separates compilation without sacrificing the expressiveness of macros.},
address = {New York, New York, USA},
author = {Flatt, Matthew},
booktitle = {Proceedings of the seventh ACM SIGPLAN international conference on Functional programming - ICFP '02},
doi = {10.1145/581478.581486},
file = {:Users/liang-tingchen/Dropbox/References/Flatt - 2002 - Composable and compilable macros.pdf:pdf},
isbn = {1581134878},
issn = {0362-1340},
keywords = {Language tower,Macros,Modules},
month = {sep},
number = {9},
pages = {72--83},
publisher = {ACM Press},
title = {{Composable and compilable macros:}},
url = {https://dl.acm.org/doi/10.1145/583852.581486 http://portal.acm.org/citation.cfm?doid=581478.581486},
volume = {37},
year = {2002}
}
@article{Bohm1985,
abstract = {The notion of iteratively defined functions from and to heterogeneous term algebras is introduced as the solution of a finite set of equations of a special shape. Such a notion has remarkable consequences: (1) Choosing the second-order typed lamdda-calculus ($\Lambda$ for short) as a programming language enables one to represent algebra elements and iterative functions by automatic uniform synthesis paradigms, using neither conditional nor recursive constructs. (2) A completeness theorem for $\Lambda$-terms with type of degree at most two and a companion corollary for $\Lambda$-programs have been proved. (3) A new congruence relation for the last-mentioned $\Lambda$-terms which is stronger than $\Lambda$-convertibility is introduced and proved to have the meaning of a $\Lambda$-program equivalence. Moreover, an extension of the paradigms to the synthesis of functions of higher complexity is considered and exemplified. All the concepts are explained and motivated by examples over integers, list- and tree-structures. {\textcopyright} 1985.},
author = {B{\"{o}}hm, Corrado and Berarducci, Alessandro},
doi = {10.1016/0304-3975(85)90135-5},
file = {:Users/liang-tingchen/Dropbox/References/B{\"{o}}hm, Berarducci - 1985 - Automatic synthesis of typed $\Lambda$-programs on term algebras.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {C},
pages = {135--154},
title = {{Automatic synthesis of typed $\Lambda$-programs on term algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397585901355},
volume = {39},
year = {1985}
}
@article{Chen2013a,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.1505v1},
author = {Chen, Jiahua},
doi = {10.1007/s10959-011-0375-2},
eprint = {arXiv:1108.1505v1},
file = {:Users/liang-tingchen/Dropbox/References/Chen - 2013 - A Partial Order on Uncertainty and Information.pdf:pdf},
issn = {0894-9840},
journal = {Journal of Theoretical Probability},
keywords = {Cauchy distribution,Conditional variance,Dispersion order,Gini's mean difference,Likelihood ratio order,Log-concavity,Normal distribution,Shannon information,Stochastic order,Total positivity},
month = {jun},
number = {2},
pages = {349--359},
title = {{A Partial Order on Uncertainty and Information}},
url = {http://link.springer.com/10.1007/s10959-011-0375-2},
volume = {26},
year = {2013}
}
@phdthesis{Tzevelekos2008,
author = {Tzevelekos, Nikos},
file = {:Users/liang-tingchen/Dropbox/References/Tzevelekos - 2008 - Nominal Game Semantics.pdf:pdf},
school = {University of Oxford},
title = {{Nominal Game Semantics}},
year = {2008}
}
@article{Gehrke2005,
abstract = {In this paper we consider distributive modal logic, a setting in which we may add modalities, such as classical types of modalities as well as weak forms of negation, to the fragment of classical propositional logic given by conjunction, disjunction, true, and false. For these logics we define both algebraic semantics, in the form of distributive modal algebras, and relational semantics, in the form of ordered Kripke structures. The main contributions of this paper lie in extending the notion of Sahlqvist axioms to our generalized setting and proving both a correspondence and a canonicity result for distributive modal logics axiomatized by Sahlqvist axioms. Our proof of the correspondence result relies on a reduction to the classical case, but our canonicity proof departs from the traditional style and uses the newly extended algebraic theory of canonical extensions.},
author = {Gehrke, Mai and Nagahashi, Hideo and Venema, Yde},
doi = {10.1016/j.apal.2004.04.007},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke, Nagahashi, Venema - 2005 - A Sahlqvist theorem for distributive modal logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Canonical extensions,Canonical logic,Canonical varieties,Correspondence theory,Distributive modal algebras,Distributive modal logic,Duality,Lattice expansions},
month = {jan},
number = {1-3},
pages = {65--102},
publisher = {Elsevier},
title = {{A Sahlqvist theorem for distributive modal logic}},
url = {http://www.sciencedirect.com/science/article/pii/S0168007204000880},
volume = {131},
year = {2005}
}
@inproceedings{Delaware2013,
address = {New York, New York, USA},
author = {Delaware, Benjamin and Keuchel, Steven and Schrijvers, Tom and Oliveira, Bruno C.d.S.},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500587},
file = {:Users/liang-tingchen/Dropbox/References/Delaware et al. - 2013 - Modular monadic meta-theory.pdf:pdf},
isbn = {9781450323260},
pages = {319},
publisher = {ACM Press},
title = {{Modular monadic meta-theory}},
url = {http://dl.acm.org/citation.cfm?doid=2500365.2500587},
year = {2013}
}
@book{Krzysztof2015,
abstract = {The concept of “definition” refers both to a propositional structure, namely a type of convertible relation between the definiens and the definiendum, and a speech act that can have various definitional purposes. On the one hand, definitions can have different subject matter. For instance, it is possible to define a concept (essential definitions), themeaning of its linguistic expression (etymolog- ical definition), its possible extension (definition by enumeration), an illustration of its possible denotations (definition by example), or the operation that can be used to classify the entities falling under it (operational definition). On the other hand, definitions are the propositional content of acts aimed at producing specific effects. Definitions can impose a new meaning, or remind or inform the interlocutors of criteria of classification. However, from an argumentative perspective the acts of stipulating, reminding or informing of, or committing to a definition are not as dangerous as the implicit acts of omitting a definition and implicitly defining and redefining a concept. Sometimes crucial concepts, especially the ones concerning problematic ethical or political issues, are ill described or are left (intentionally or unintentionally) undefined. This gap can become the ground of extremely effective strategies based on tacit (re)definitions.These uses of definition can shed light on the definitional activity of the lawmakers. Statutory definitions become in this sense a limitation of the interpreters' freedomof redefining strategically a concept. For this reason, the choice of leaving a concept undefined or underdefined can be regarded as},
address = {Cham},
doi = {10.1007/978-3-319-19575-9},
editor = {Araszkiewicz, Micha{\l} and P{\l}eszka, Krzysztof},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 2015 - Logic in the Theory and Practice of Lawmaking.pdf:pdf},
isbn = {978-3-319-19574-2},
issn = {15431649},
publisher = {Springer, Cham},
series = {Legisprudence Library (Legisprudence Library Studies on the Theory and Practice of Legislation)},
title = {{Logic in the Theory and Practice of Lawmaking}},
url = {http://link.springer.com/10.1007/978-3-319-19575-9},
volume = {2},
year = {2015}
}
@article{Severi2017,
abstract = {In this paper, we introduce a strong form of eta reduction called etabang that we use to construct a confluent and normalising infinitary lambda calculus, of which the normal forms correspond to Barendregt's infinite eta B{\"{o}}hm trees. This new infinitary perspective on the set of infinite eta B{\"{o}}hm trees allows us to prove that the set of infinite eta B{\"{o}}hm trees is a model of the lambda calculus. The model is of interest because it has the same local structure as Scott's D ∞ -models, i.e. two finite lambda terms are equal in the infinite eta B{\"{o}}hm model if and only if they have the same interpretation in Scott's D ∞ -models.},
author = {SEVERI, PAULA and {DE VRIES}, FER-JAN},
doi = {10.1017/S096012951500033X},
file = {:Users/liang-tingchen/Dropbox/References/SEVERI, DE VRIES - 2017 - The infinitary lambda calculus of the infinite eta B{\"{o}}hm trees.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {5},
pages = {681--733},
title = {{The infinitary lambda calculus of the infinite eta B{\"{o}}hm trees}},
url = {https://www.cambridge.org/core/product/identifier/S096012951500033X/type/journal{\_}article},
volume = {27},
year = {2017}
}
@incollection{Litak2014,
address = {Dordrecht},
author = {Litak, Tadeusz},
booktitle = {Leo Esakia on Duality in Modal and Intuitionistic Logics},
doi = {10.1007/978-94-017-8860-1},
editor = {Bezhanishvili, Guram},
file = {:Users/liang-tingchen/Dropbox/References/Litak - 2014 - Constructive Modalities with Provability Smack.pdf:pdf},
isbn = {978-94-017-8859-5},
pages = {43--62},
publisher = {Springer Netherlands},
series = {Outstanding Contributions to Logic},
title = {{Constructive Modalities with Provability Smack}},
url = {http://link.springer.com/10.1007/978-94-017-8860-1},
volume = {4},
year = {2014}
}
@article{Klin2009,
author = {Klin, Bartek},
doi = {10.1016/j.entcs.2006.11.018},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2007 - Bialgebraic methods in structural operational semantics.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {algebra,bialgebra,category theory,coalgebra,structural operational semantics},
month = {may},
number = {1},
pages = {33--43},
title = {{Bialgebraic methods in structural operational semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066107001600},
volume = {175},
year = {2007}
}
@article{Hansen2009,
author = {Hansen, Helle Hvid and Kupke, Clemens and Pacuit, Eric},
doi = {10.2168/LMCS-5(2:2)2009},
editor = {Mossakowski, Till},
file = {:Users/liang-tingchen/Dropbox/References/Hansen, Kupke, Pacuit - 2009 - Neighbourhood Structures Bisimilarity and Basic Model Theory.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,behavioural,bisimulation,equivalence,invariance,neighbourhood semantics,non-normal modal logic},
month = {apr},
number = {2},
pages = {1--38},
title = {{Neighbourhood Structures: Bisimilarity and Basic Model Theory}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=381},
volume = {5},
year = {2009}
}
@incollection{Martinez2019,
abstract = {We present the semantics and proof system for an object-oriented language with active objects, asynchronous method calls,$\backslash$n and futures. The language, based on Creol, distinguishes itself in that unlike active object models, it permits more than$\backslash$n one thread of control within an object, though, unlike Java, only one thread can be active within an object at a given time$\backslash$n and rescheduling occurs only at specific release points. Consequently, reestablishing an object's monitor invariant is possible$\backslash$n at specific well-defined points in the code. The resulting proof system shows that this approach to concurrency is simpler$\backslash$n for reasoning than, say, Java's multithreaded concurrency model. From a methodological perspective, we identify constructs$\backslash$n which admit a simple proof system and those which require, for example, interference freedom tests.},
author = {Mart{\'{i}}nez, Guido and Ahman, Danel and Dumitrescu, Victor and Giannarakis, Nick and Hawblitzel, Chris and Hriţcu, Cătălin and Narasimhamurthy, Monal and Paraskevopoulou, Zoe and Pit-Claudel, Cl{\'{e}}ment and Protzenko, Jonathan and Ramananandro, Tahina and Rastogi, Aseem and Swamy, Nikhil},
booktitle = {Programming Languages and Systems. ESOP 2019},
doi = {10.1007/978-3-030-17184-1_2},
editor = {Caires, Lu{\'{i}}s},
file = {:Users/liang-tingchen/Dropbox/References/Mart{\'{i}}nez et al. - 2019 - Meta-{\$}Fstar{\$} Proof Automation with SMT, Tactics, and Metaprograms.pdf:pdf},
isbn = {978-3-540-64302-9},
pages = {30--59},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science,},
title = {{Meta-{\$}F{\^{}}\backslashstar{\$}: Proof Automation with SMT, Tactics, and Metaprograms}},
url = {http://link.springer.com/10.1007/978-3-030-17184-1{\_}2},
volume = {11423},
year = {2019}
}
@article{Su1991,
abstract = {The authors investigate the inference problems due to functional$\backslash$ndependencies (FD) and multivalued dependencies (MVD) in a multilevel$\backslash$nrelational database (MDB) with attribute and record classification$\backslash$nschemes, respectively. The set of functional dependencies to be taken$\backslash$ninto account in order to prevent FD-compromises is determined. It is$\backslash$nproven that incurring minimum information loss to prevent compromises is$\backslash$nan NP-complete problem. An exact algorithm to adjust the attribute$\backslash$nlevels so that no compromise due to functional dependencies occurs is$\backslash$ngiven. Some necessary and sufficient conditions for MVD-compromises are$\backslash$npresented. The set of MVDs to be taken into account for controlling$\backslash$ninferences is determined. An algorithm to prevent MVD-compromises in a$\backslash$nrelation with conflict-free MVDs is given},
author = {Su, T.-A. and Ozsoyoglu, Gultekin},
doi = {10.1109/69.109108},
file = {:Users/liang-tingchen/Dropbox/References/Su, Ozsoyoglu - 1991 - Controlling FD and MVD inferences in multilevel relational database systems.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Compromise,NP-complete,data classification,database security,functional dependency,inference control,information loss,multilevel relational database,multivalued dependency},
number = {4},
pages = {474--485},
title = {{Controlling FD and MVD inferences in multilevel relational database systems}},
url = {http://ieeexplore.ieee.org/document/109108/},
volume = {3},
year = {1991}
}
@article{Gumm2009,
author = {Gumm, H. Peter},
file = {:Users/liang-tingchen/Dropbox/References/Gumm - 2009 - Universal coalgebras and their logics.pdf:pdf},
journal = {AJSE-Mathematics},
pages = {105--130},
title = {{Universal coalgebras and their logics}},
volume = {1},
year = {2009}
}
@incollection{Pavlovic2006,
abstract = {We propose a methodology based on testing as a framework to capture the interactions of a machine represented in a denotational model and the data it manipulates. Using a connection that models machines on the one hand, and the data they manipulate on the other, testing is used to capture the interactions of each with the objects on the other side: just as the data that are input into a machine can be viewed as tests that the machine can be subjected to, the machine can be viewed as a test that can be used to distinguish data. This approach is based on generalizing from duality theories that now are common in semantics to logical connections, which are simply contravariant adjunctions. In the process, it accomplishes much more than simply moving from one side of a duality to the other; it faithfully represents the interactions that embody what is happening as the computation proceeds. Our basic philosophy is that tests can be used as a basis for modeling interactions, as well as processes and the data on which they operate. In more abstract terms, tests can be viewed as formulas of process logics, and testing semantics connects processes and process logics, and assigns computational meanings to both.},
address = {Berlin, Heidelberg},
author = {Pavlovi{\'{c}}, Dusko and Mislove, Michael W. and Worrell, James and Johnson, Michael and Vene, Varmo},
booktitle = {Algebraic Methodology and Software Technology},
doi = {10.1007/11784180_24},
editor = {Johnson, Michael and Vene, Varmo},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} et al. - 2006 - Testing semantics connecting processes and process logics.pdf:pdf},
isbn = {978-3-540-35633-2},
pages = {308--322},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Testing semantics: connecting processes and process logics}},
url = {http://www.springerlink.com/content/h2378vq8547j4625/ http://dx.doi.org/10.1007/11784180{\_}24},
volume = {4019},
year = {2006}
}
@inproceedings{Devriese2011,
abstract = {We present instance arguments: an alternative to type classes and related features in the dependently typed, purely functional programming language/proof assistant Agda. They are a new, general type of function arguments, resolved from call-site scope in a type-directed way. The mechanism is inspired by both Scala's implicits and Agda's existing implicit arguments, but differs from both in important ways. Our mechanism is designed and implemented for Agda, but our design choices can be applied to other programming languages as well. Like Scala's implicits, we do not provide a separate structure for type classes and their instances, but instead rely on Agda's standard dependently typed records, so that standard language mechanisms provide features that are missing or expensive in other proposals. Like Scala, we support the equivalent of local instances. Unlike Scala, functions taking our new arguments are first-class citizens and can be abstracted over and manipulated in standard ways. Compared to other proposals, we avoid the pitfall of introducing a separate type-level computational model through the instance search mechanism. All values in scope are automatically candidates for instance resolution. A final novelty of our approach is that existing Agda libraries using records gain the benefits of type classes without any modification. We discuss our implementation in Agda (to be part of Agda 2.2.12) and we use monads as an example to show how it allows existing concepts in the Agda standard library to be used in a similar way as corresponding Haskell code using type classes. We also demonstrate and discuss equivalents and alternatives to some advanced type class-related patterns from the literature and some new patterns specific to our system.},
address = {New York, New York, USA},
author = {Devriese, Dominique and Piessens, Frank},
booktitle = {Proceeding of the 16th ACM SIGPLAN international conference on Functional programming - ICFP '11},
doi = {10.1145/2034773.2034796},
file = {:Users/liang-tingchen/Dropbox/References/Devriese, Piessens - 2011 - On the bright side of type classes.pdf:pdf},
isbn = {9781450308656},
issn = {03621340},
keywords = {ad hoc poly-,agda,instance arguments,type classes},
month = {sep},
number = {9},
pages = {143},
publisher = {ACM Press},
title = {{On the bright side of type classes}},
url = {http://dl.acm.org/citation.cfm?doid=2034574.2034796 http://dl.acm.org/citation.cfm?doid=2034773.2034796},
volume = {46},
year = {2011}
}
@article{Kristensen2021,
abstract = {Guarded recursion is a powerful modal approach to recursion that can be seen as an abstract form of step-indexing. It is currently used extensively in separation logic to model programming languages with advanced features by solving domain equations also with negative occurrences. In its multi-clocked version, guarded recursion can also be used to program with and reason about coinductive types, encoding the productivity condition required for recursive definitions in types. This paper presents the first denotational model of a type theory combining multi-clocked guarded recursion with the features of Cubical Type Theory. Using the combination of Higher Inductive Types (HITs) and guarded recursion allows for simple programming and reasoning about coinductive types that are traditionally hard to represent in type theory, such as the type of finitely branching labelled transition systems. For example, our results imply that bisimilarity for these imply path equality, and so proofs can be transported along bisimilarity proofs.},
archivePrefix = {arXiv},
arxivId = {2102.01969v2},
author = {Kristensen, Magnus Baunsgaard and M{\o}gelberg, Rasmus Ejlers and Vezzosi, Andrea},
eprint = {2102.01969v2},
file = {:Users/liang-tingchen/Dropbox/References//Kristensen, M{\o}gelberg, Vezzosi - 2021 - Greatest HITs Higher inductive types in coinductives via induction under clocks.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Kristensen, M{\o}gelberg, Vezzosi - 2021 - Greatest HITs Higher inductive types in coinductives via induction under clocks.pdf:pdf},
journal = {ArXiv preprint},
month = {feb},
title = {{Greatest HITs: Higher inductive types in coinductives via induction under clocks}},
url = {http://arxiv.org/abs/2102.01969},
year = {2021}
}
@article{Santos2019,
abstract = {In this work, we continue our consideration of the constructions presented in the paper Krivine's Classical Realizability from a Categorical Perspective by Thomas Streicher. Therein, the author points towards the interpretation of the classical realizability of Krivine as an instance of the categorical approach started by Hyland. The present paper continues with the study of the basic algebraic set-up underlying the categorical aspects of the theory. Motivated by the search of a full adjunction, we introduce a new closure operator on the subsets of the stacks of an abstract Krivine structure that yields an adjunction between the corresponding application and implication operations. We show that all the constructions from ordered combinatory algebras to triposes presented in our previous work can be implemented, mutatis mutandis , in the new situation and that all the associated triposes are equivalent. We finish by proving that the whole theory can be developed using the ordered combinatory algebras with full adjunction or strong abstract Krivine structures as the basic set-up.},
author = {SANTOS, WALTER FERRER and GUILLERMO, MAURICIO and MALHERBE, OCTAVIO},
doi = {10.1017/S0960129518000075},
file = {:Users/liang-tingchen/Dropbox/References/SANTOS, GUILLERMO, MALHERBE - 2019 - Realizability in ordered combinatory algebras with adjunction.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {3},
pages = {430--464},
title = {{Realizability in ordered combinatory algebras with adjunction}},
url = {https://www.cambridge.org/core/product/identifier/S0960129518000075/type/journal{\_}article},
volume = {29},
year = {2019}
}
@article{Pastro2009,
abstract = {This paper determines what structure is needed for internal homs in a monoidal category C to be liftable to the category CG of Eilenberg-Moore coalgebras for a monoidal comonad G on C. We apply this to lift *-autonomy with the view to recasting the definition of quantum groupoid. ?? 2008 Elsevier Inc. All rights reserved.},
author = {Pastro, Craig and Street, Ross},
doi = {10.1016/j.jalgebra.2008.05.004},
file = {:Users/liang-tingchen/Dropbox/References/Pastro, Street - 2009 - Closed categories, star-autonomy, and monoidal comonads.pdf:pdf},
isbn = {0021-8693},
issn = {00218693},
journal = {Journal of Algebra},
keywords = {*-autonomy,Antipode,Bialgebroid,Closed category,Internal hom,Monad,Quantum groupoid},
month = {jun},
number = {11},
pages = {3494--3520},
publisher = {Elsevier Inc.},
title = {{Closed categories, star-autonomy, and monoidal comonads}},
url = {http://dx.doi.org/10.1016/j.jalgebra.2008.05.004 http://linkinghub.elsevier.com/retrieve/pii/S0021869308002524},
volume = {321},
year = {2009}
}
@incollection{Dybjer2002,
abstract = {We give an introduction to normalization by evaluation and type-directed partial evaluation. We first present normalization by evaluation for a combinatory version of G{\"{o}}del System T. Then we show normalization by evaluation for typed lambda calculus with $\beta$ and $\eta$ conversion. Finally, we introduce the notion of binding time, and explain the method of type-directed partial evaluation for a small PCF-style functional programming language. We give algorithms for both call-by-name and call-by-value versions of this language. {\textcopyright} Springer-Verlag Berlin Heidelberg 2002.},
author = {Dybjer, Peter and Filinski, Andrzej},
booktitle = {Applied Semantics. APPSEM 2000},
doi = {10.1007/3-540-45699-6_4},
editor = {Barthe, Gilles and Dybjer, Peter and Pinto, Lu{\'{i}}s and Saraiva, Jo{\~{a}}o},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer, Filinski - 2002 - Normalization and partial evaluation.pdf:pdf},
isbn = {3540440445},
issn = {16113349},
pages = {137--192},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Normalization and partial evaluation}},
volume = {2395},
year = {2002}
}
@article{Hyland2006,
author = {Hyland, Martin and Plotkin, Gordon D. and Power, A. John},
doi = {10.1016/j.tcs.2006.03.013},
file = {:Users/liang-tingchen/Dropbox/References/Hyland, Plotkin, Power - 2006 - Combining effects Sum and tensor.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {computational effect,lawvere theory,modularity,monad},
month = {jul},
number = {1-3},
pages = {70--99},
title = {{Combining effects: Sum and tensor}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506002659},
volume = {357},
year = {2006}
}
@inproceedings{Dankar2012,
address = {New York, New York, USA},
author = {Dankar, Fida Kamal and {El Emam}, Khaled},
booktitle = {Proceedings of the 2012 Joint EDBT/ICDT Workshops on - EDBT-ICDT '12},
doi = {10.1145/2320765.2320816},
file = {:Users/liang-tingchen/Dropbox/References/Dankar, El Emam - 2012 - The application of differential privacy to health data.pdf:pdf},
isbn = {9781450311434},
keywords = {anonymity,de-identification,differential privacy,microdata},
pages = {158},
publisher = {ACM Press},
title = {{The application of differential privacy to health data}},
url = {http://dl.acm.org/citation.cfm?doid=2320765.2320816},
year = {2012}
}
@inproceedings{Kiselyov2013,
abstract = {We design and implement a library that solves the long-standing problem of combining effects without imposing restrictions on their interactions (such as static ordering). Effects arise from interactions between a client and an effect handler (interpreter); interactions may vary throughout the program and dynamically adapt to exe-cution conditions. Existing code that relies on monad transform-ers may be used with our library with minor changes, gaining effi-ciency over long monad stacks. In addition, our library has greater expressiveness, allowing for practical idioms that are inefficient, cumbersome, or outright impossible with monad transformers. Our alternative to a monad transformer stack is a single monad, for the coroutine-like communication of a client with its handler. Its type reflects possible requests, i.e., possible effects of a com-putation. To support arbitrary effects and their combinations, re-quests are values of an extensible union type, which allows adding and, notably, subtracting summands. Extending and, upon han-dling, shrinking of the union of possible requests is reflected in its type, yielding a type-and-effect system for Haskell. The library is lightweight, generalizing the extensible exception handling to other effects and accurately tracking them in types.},
address = {New York, New York, USA},
author = {Kiselyov, Oleg and Sabry, Amr and Swords, Cameron},
booktitle = {Proceedings of the 2013 ACM SIGPLAN symposium on Haskell - Haskell '13},
doi = {10.1145/2503778.2503791},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov, Sabry, Swords - 2013 - Extensible effects.pdf:pdf},
isbn = {9781450323833},
issn = {15232867},
keywords = {coroutine,effect handler,effect interaction,monad,monad transformer,open union,type and effect system},
pages = {59},
publisher = {ACM Press},
title = {{Extensible effects}},
url = {http://dl.acm.org/citation.cfm?doid=2503778.2503791},
year = {2013}
}
@article{Miller1991,
abstract = {Miller, D., G. Nadathur, F. Pfenning and A. Scedrov, Uniform proofs as a foundation for logic programming, Annals of Pure and Applied Logic 51 (1991) 125-157. A proof-theoretic characterization of logical languages that form suitable bases for Prolog-like programming languages is provided. This characterization is based on the principle that the declarative meaning of a logic program, provided by provability in a logical system, should coincide with its operational meaning, provided by interpreting logical connectives as simple and fixed search instructions. The operational semantics is formalized by the identification of a class of cut-free sequent proofs called uniform proofs. A uniform proof is one that can be found by a goal-directed search that respects the interpretation of the logical connectives as search instructions. The concept of a uniform proof is used to define the notion of an abstract logic programming language, and it is shown that first-order and higher-order Horn clauses with classical provability are examples of such a language. Horn clauses are then generalized to hereditary Harrop formulas and it is shown that first-order and higher-order versions of this new class of formulas are also abstract logic programming languages if the inference rules are those of either intuitionistic or minimal logic. The programming language significance of the various generalizations to first-order Horn clauses is briefly discussed. {\textcopyright} 1991.},
author = {Miller, Dale and Nadathur, Gopalan and Pfenning, Frank and Scedrov, Andre},
doi = {10.1016/0168-0072(91)90068-W},
file = {:Users/liang-tingchen/Dropbox/References/Miller et al. - 1991 - Uniform proofs as a foundation for logic programming.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {mar},
number = {1-2},
pages = {125--157},
title = {{Uniform proofs as a foundation for logic programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/016800729190068W},
volume = {51},
year = {1991}
}
@article{Ghani2015,
abstract = {There is a huge number of problems, from various areas, being solved by reducing them to SAT. However, for most applications, translations into SAT are performed by specialized, problem-specific tools. In this paper we describe a novel approach for uniform solving of a wide class of problems by reducing them to SAT. The approach uses a new specification language that combines imperative and declarative programming paradigms. A problem is specified by a test (expressed in an imperative form) that a given set of values indeed makes a solution to the problem. In the solving phase, parameters of the problem are represented by (finite) vectors of propositional formulae and the specification is symbolically executed. An assertion that given values make a solution is transformed to an instance of the SAT problem and passed to a SAT solver. If the formula is satisfiable, its model is transformed back to variables describing the problem, i.e., to a solution of the problem. We also describe a system URSA that implements the described approach. The experiments show that the system is competitive to state-of-the related modelling systems.},
archivePrefix = {arXiv},
arxivId = {1502.05561},
author = {Ghani, Neil and Malatesta, Lorenzo and Forsberg, Fredrik Nordvall},
eprint = {1502.05561},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Malatesta, Forsberg - 2015 - Positive inductive-recursive definitions.pdf:pdf},
journal = {ArXiv e-prints},
pages = {50},
title = {{Positive inductive-recursive definitions}},
url = {http://arxiv.org/abs/1012.1255},
year = {2015}
}
@article{Bauer2014,
author = {Bauer, Andrej and Plotkin, Gordon D. and Scott, Dana S.},
doi = {10.1016/j.tcs.2014.02.042},
file = {:Users/liang-tingchen/Dropbox/References/Bauer, Plotkin, Scott - 2014 - Cartesian closed categories of separable Scott domains.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {aug},
pages = {17--29},
publisher = {Elsevier B.V.},
title = {{Cartesian closed categories of separable Scott domains}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397514001686},
volume = {546},
year = {2014}
}
@article{Fitting2005,
abstract = {A new semantics is presented for the logic of proofs (LP), (Technical Report MSI 95-29, Cornell University (1995), Bull. Symbolic Logic 7 (2001) 1) based on the intuition that it is a logic of explicit knowledge. This semantics is used to give new proofs of several basic results concerning LP. In particular, the realization of S4 into LP is established in a way that carefully examines and explicates the role of the + operator. Finally connections are made with the conventional approach, via soundness and completeness results. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
author = {Fitting, Melvin},
doi = {10.1016/j.apal.2004.04.009},
file = {:Users/liang-tingchen/Dropbox/References/Fitting - 2005 - The logic of proofs, semantically.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {feb},
number = {1},
pages = {1--25},
title = {{The logic of proofs, semantically}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007204000909},
volume = {132},
year = {2005}
}
@article{Gunter1992,
abstract = {This paper introduces an operator M called the mixed powerdomain which generalizes the convex (Plotkin) powerdomain. The construction is based on the idea of representing partial information about a set of data items using a pair of sets, one representing partial information in the manner of the upper (Smyth) powerdomain and the other in the manner of the lower (Hoare) powerdomain where the components of such pairs are required to satisfy a consistency condition. This provides a richer family of meaningful partial descriptions than are available in the convex powerdomain and also makes it possible to include the empty set in a satisfactory way. The new construct is given a rigorous mathematical treatment like that which has been applied to the known powerdomains. It is proved that M is a continuous functor on bifinite domains which is left adjoint to the forgetful functor from a category of continuous structures called mix algebras. For a domain D with a coherent Scott topology, elements of MD can be represented as pairs (U, V) where U ⊆ D is a compact upper set, V ⊆ D is a closed set and the downward closure of U {\{}frown{\}} V is equal to V. A Stone dual characterization of M is also provided. {\textcopyright} 1992.},
author = {Gunter, Carl A.},
doi = {10.1016/0304-3975(92)90017-A},
file = {:Users/liang-tingchen/Dropbox/References//Gunter - 1992 - The mixed powerdomain.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {sep},
number = {2},
pages = {311--334},
title = {{The mixed powerdomain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/030439759290017A},
volume = {103},
year = {1992}
}
@article{Power1999,
abstract = {We present a coalgebraic approach to trace equivalence semantics based on lifting behaviour endofunctors for deterministic action to Kleisli categories of monads for non-deterministic choice. In Set, this gives a category with ordinary transition systems as objects and with morphisms characterised in terms of a linear notion of bisimulation. The final object in this category is the canonical abstract model for trace equivalence and can be obtained by extending the final coalgebra of the deterministic action behaviour to the Kleisli category of the non-empty powerset monad. The corresponding final coalgebra semantics is fully abstract with respect to trace equivalence. Discussions with Julian Rathke and with Gordon Plotkin, Alex Simpson and Martin Wehr are gratefully acknowledged. {\textcopyright} 1999 Published by Elsevier Science B. V.},
author = {Power, John and Turi, Daniele},
doi = {10.1016/S1571-0661(05)80319-6},
file = {:Users/liang-tingchen/Dropbox/References/Power, Turi - 1999 - A coalgebraic foundation for linear time semantics.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {1},
pages = {259--274},
publisher = {Elsevier B.V.},
title = {{A coalgebraic foundation for linear time semantics}},
url = {http://dx.doi.org/10.1016/S1571-0661(05)80319-6 http://linkinghub.elsevier.com/retrieve/pii/S1571066105803196},
volume = {29},
year = {1999}
}
@inproceedings{Eisenberg2018,
abstract = {For many years, GHC has implemented an extension to Haskell that allows type variables to be bound in type signatures and patterns, and to scope over terms. This extension was never properly specified. We rectify that oversight here. With the formal specification in hand, the otherwise-labyrinthine path toward a design for binding type variables in patterns becomes blindingly clear. We thus extend ScopedTypeVariables to bind type variables explicitly, obviating the Proxy workaround to the dustbin of history.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1806.03476},
author = {Eisenberg, Richard A. and Breitner, Joachim and {Peyton Jones}, Simon},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Symposium on Haskell - Haskell 2018},
doi = {10.1145/3242744.3242753},
eprint = {1806.03476},
file = {:Users/liang-tingchen/Dropbox/References/Eisenberg, Breitner, Peyton Jones - 2018 - Type variables in patterns.pdf:pdf},
isbn = {9781450358354},
issn = {0362-1340},
keywords = {Haskell,Patterns,Polymorphism,Type variables},
number = {Section 5},
pages = {94--105},
publisher = {ACM Press},
title = {{Type variables in patterns}},
url = {http://dl.acm.org/citation.cfm?doid=3242744.3242753},
year = {2018}
}
@inproceedings{Reynolds1995,
address = {New York, New York, USA},
author = {Reynolds, John C.},
booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '95},
doi = {10.1145/199448.199452},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds - 1995 - Using functor categories to generate intermediate code.pdf:pdf},
isbn = {0897916921},
pages = {25--36},
publisher = {ACM Press},
title = {{Using functor categories to generate intermediate code}},
url = {http://portal.acm.org/citation.cfm?doid=199448.199452},
year = {1995}
}
@article{Bauer2018,
abstract = {Andromeda is an LCF-style proof assistant where the user builds derivable judgments by writing code in a meta-level programming language AML. The only trusted component of Andromeda is a minimalist nucleus (an implementation of the inference rules of an object-level type theory), which controls construction and decomposition of type-theoretic judgments. Since the nucleus does not perform complex tasks like equality checking beyond syntactic equality, this responsibility is delegated to the user, who implements one or more equality checking procedures in the meta-language. The AML interpreter requests witnesses of equality from user code using the mechanism of algebraic operations and handlers. Dynamic checks in the nucleus guarantee that no invalid object-level derivations can be constructed. {\%}even if the AML code (or interpreter) is untrusted. To demonstrate the flexibility of this system structure, we implemented a nucleus consisting of dependent type theory with equality reflection. Equality reflection provides a very high level of expressiveness, as it allows the user to add new judgmental equalities, but it also destroys desirable meta-theoretic properties of type theory (such as decidability and strong normalization). The power of effects and handlers in AML is demonstrated by a standard library that provides default algorithms for equality checking, computation of normal forms, and implicit argument filling. Users can extend these new algorithms by providing local "hints" or by completely replacing these algorithms for particular developments. We demonstrate the resulting system by showing how to axiomatize and compute with natural numbers, by axiomatizing the untyped {\$}\backslashlambda{\$}-calculus, and by implementing a simple automated system for managing a universe of types.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Design and Implementation of the Andromeda Proof Assistant - Bauer, Andrej; Gilbert, Ga{\"{e}}tan; Haselwarter, Philipp G.; Pretnar, Matija; Stone, Christopher A.)

From Duplicate 1 (Design and Implementation of the Andromeda Proof Assistant - Bauer, Andrej; Gilbert, Ga{\"{e}}tan; Haselwarter, Philipp G; Pretnar, Matija; Stone, Christopher A)

Keywords: type theory, proof assistant, equality reflection, computational effects},
author = {Bauer, Andrej and Gilbert, Ga{\"{e}}tan and Haselwarter, Philipp G. and Pretnar, Matija and Stone, Christopher A.},
doi = {10.4230/LIPIcs.TYPES.2016.5},
editor = {Ghilezan, Silvia and Geuvers, Herman and Iveti{\'{c}}, Jelena},
file = {:Users/liang-tingchen/Dropbox/References//Bauer et al. - 2018 - Design and implementation of the andromeda proof assistant.pdf:pdf},
isbn = {9783959770651},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Computational effects,Equality reflection,Proof assistant,Type theory},
number = {5},
pages = {1--5},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Design and implementation of the andromeda proof assistant}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9857},
volume = {97},
year = {2018}
}
@phdthesis{Murray2010a,
abstract = {The object-capability model is an increasingly popular architecture$\backslash$nfor building secure software systems. This model promotes the construction$\backslash$nof reusable patterns for enforcing security properties within object-capability$\backslash$nsystems. In this thesis, we apply the process algebra CSP, and its$\backslash$nautomatic refinement-checker FDR, to analyse object-capability patterns$\backslash$nand prove whether they uphold the security properties they are designed$\backslash$nto enforce. We show how CSP can accurately model object capability$\backslash$nsystems and patterns, and express their wide variety of features.$\backslash$nWe show that complex safety properties of object-capability patterns$\backslash$ncan be reasoned about by encoding them as CSP refinement checks for$\backslash$nFDR. This enables one to detect vulnerabilities automatically in$\backslash$npatterns due to concurrent and recursive invocation. We show that$\backslash$nCSP's theory of data-independence can be applied to allow one to$\backslash$ngeneralise the results obtained from analysing small fixed-sized$\backslash$nsystems, to systems of arbitrary size. We show how to reason about$\backslash$nthe information flow properties of object capability patterns. We$\backslash$nargue that in order to do so sensibly, one must make the assumption$\backslash$nthat objects can directly in uence each other only through their$\backslash$novert interactions together. We show how traditional noninterference$\backslash$nproperties can be adapted to take this assumption into account, and$\backslash$nhow they can then be tested with FDR. We consider how to reason about$\backslash$nliveness properties of object-capability patterns under necessary$\backslash$nfairness assumptions. We prove that such properties cannot always$\backslash$nbe expressed as CSP refinement checks for FDR, making them impossible$\backslash$nfor FDR to test precisely, but how FDR can be applied to reason about$\backslash$nthem by testing sufficient conditions for them instead. To reason$\backslash$nabout authority, we develop a framework for expressing general non-causation$\backslash$nproperties and show how it can capture various kinds of authority,$\backslash$nas well as the notions of defensive correctness and defensive con-$\backslash$nsistency. We show that, for deterministic systems, non-causation$\backslash$nof safety effects can be expressed as refinement checks in CSP models$\backslash$nthat FDR can support. However, for nondeterministic systems, we prove$\backslash$nthat even certain simple non-causation properties cannot be precisely$\backslash$ncaptured this way.},
author = {Murray, Toby},
file = {:Users/liang-tingchen/Dropbox/References/Murray - 2010 - Analysing the Security Properties of Object-Capability Patterns.pdf:pdf},
school = {University of Oxford},
title = {{Analysing the Security Properties of Object-Capability Patterns}},
year = {2010}
}
@article{Mich2005,
abstract = {A fully abstract and universal domain model for modal transition systems and refinement is shown to be a maximal-points space model for the bisimulation quotient of labelled transition systems over a finite set of events. In this domain model we prove that this quotient is a Stone space whose compact, zero-dimensional, and ultra-metrizable Hausdorff topology measures the degree of bisimilarity such that image-finite labelled transition systems are dense. Using this compactness we show that the set of labelled transition systems that refine a modal transition system, its ''set of implementations'', is compact and derive a compactness theorem for Hennessy-Milner logic on such implementation sets. These results extend to systems that also have partially specified state propositions, unify existing denotational, operational, and metric semantics on partial processes, render robust consistency measures for modal transition systems, and yield an abstract interpretation of compact sets of labelled transition systems as Scott-closed sets of modal transition systems.},
author = {Huth, Michael},
doi = {10.2168/LMCS-1(1:1)2005},
editor = {Escard{\'{o}}, Mart{\'{i}}n},
file = {:Users/liang-tingchen/Dropbox/References/Huth - 2005 - Labelled transition systems as a Stone space.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
language = {en},
month = {jan},
number = {1},
publisher = {Institut f{\"{u}}r Theoretische Informatik, TU Braunschweig / Department of Theoretical Computer Science, Technical University Braunschweig, Germany},
title = {{Labelled transition systems as a Stone space}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=15{\&}layout=abstract},
volume = {1},
year = {2005}
}
@article{GrzegorzJarzembski1994,
author = {{Grzegorz Jarzembski}},
file = {:Users/liang-tingchen/Dropbox/References/Grzegorz Jarzembski - 1994 - A new proof or Reiterman's theorem.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {3},
pages = {239--247},
title = {{A new proof or Reiterman's theorem}},
url = {https://eudml.org/doc/91546},
volume = {35},
year = {1994}
}
@inproceedings{Conchon2007,
abstract = {Abstract The problem of disjoint sets, also known as union - find , consists in maintaining a partition of a finite set within a data structure . This structure provides two operations: a function find returning the class of an element and a function union merging two classes. ...},
address = {New York, New York, USA},
author = {Conchon, Sylvain and Filli{\^{a}}tre, Jean-Christophe},
booktitle = {Proceedings of the 2007 workshop on Workshop on ML - ML '07},
doi = {10.1145/1292535.1292541},
file = {:Users/liang-tingchen/Dropbox/References/Conchon, Filli{\^{a}}tre - 2007 - A persistent union-find data structure.pdf:pdf},
isbn = {9781595936769},
keywords = {0,1,a new partition where,algorithms,constitutes a,each element in,formal verification,n,persistence,union-find,verification},
pages = {37},
publisher = {ACM Press},
title = {{A persistent union-find data structure}},
url = {http://portal.acm.org/citation.cfm?doid=1292535.1292541},
year = {2007}
}
@article{BOTTA2017,
abstract = {We present the starting elements of a mathematical theory of policy advice and avoidability. More specifically, we formalize a cluster of notions related to policy advice, such as policy , viability , reachability , and propose a novel approach for assisting decision making, based on the concept of avoidability . We formalize avoidability as a relation between current and future states, investigate under which conditions this relation is decidable and propose a generic procedure for assessing avoidability. The formalization is constructive and makes extensive use of the correspondence between dependent types and logical propositions, decidable judgments are obtained through computations. Thus, we aim for a computational theory, and emphasize the role that computer science can play in global system science.},
author = {BOTTA, NICOLA and JANSSON, PATRIK and IONESCU, CEZAR},
doi = {10.1017/S0956796817000156},
file = {:Users/liang-tingchen/Dropbox/References/BOTTA, JANSSON, IONESCU - 2017 - Contributions to a computational theory of policy advice and avoidability.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {oct},
number = {676547},
pages = {e23},
title = {{Contributions to a computational theory of policy advice and avoidability}},
url = {https://www.cambridge.org/core/product/identifier/S0956796817000156/type/journal{\_}article},
volume = {27},
year = {2017}
}
@article{Atkey2013,
author = {Atkey, Robert and McBride, Conor},
doi = {10.1145/2544174.2500597},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, McBride - 2013 - Productive coprogramming with guarded recursion.pdf:pdf},
isbn = {9781450323260},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {coalgebras,corecursion,guarded recursion,total func-},
month = {nov},
number = {9},
pages = {197--208},
title = {{Productive coprogramming with guarded recursion}},
url = {http://dl.acm.org/citation.cfm?doid=2544174.2500597},
volume = {48},
year = {2013}
}
@article{Abel2009a,
abstract = {In the simply typed $\lambda$-calculus, a hereditary substitution replaces a free variable in a normal form r by another normal form s of type a , removing freshly created redexes on the fly. It can be defined by lexicographic induction on a and r , thus giving rise to a structurally recursive normalizer for the simply typed $\lambda$-calculus. We implement hereditary substitutions in a functional programming language with sized heterogeneous inductive types {\$}\backslashFhat{\$} , arriving at an interpreter whose termination can be tracked by the type system of its host programming language.},
author = {Abel, Andreas M.},
doi = {10.1017/S0956796809007266},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2009 - Implementing a normalizer using sized heterogeneous types.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {3-4},
pages = {287--310},
title = {{Implementing a normalizer using sized heterogeneous types}},
url = {https://www.cambridge.org/core/product/identifier/S0956796809007266/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Vietoris1922a,
author = {Vietoris, Leopold},
doi = {10.1007/BF01696886},
issn = {0026-9255},
journal = {Monatshefte f{\"{u}}r Mathematik und Physik},
month = {dec},
number = {1},
pages = {258--280},
title = {{Bereiche zweiter Ordnung}},
type = {Journal article},
url = {http://www.springerlink.com/index/10.1007/BF01696886},
volume = {32},
year = {1922}
}
@inproceedings{Heunen2017,
abstract = {Higher-order probabilistic programming languages allow programmers to write sophisticated models in machine learning and statistics in a succinct and structured way, but step outside the standard measure-theoretic formalization of probability theory. Programs may use both higher-order functions and continuous distributions, or even define a probability distribution on functions. But standard probability theory does not handle higher-order functions well: the category of measurable spaces is not cartesian closed. Here we introduce quasi-Borel spaces. We show that these spaces: form a new formalization of probability theory replacing measurable spaces; form a cartesian closed category and so support higher-order functions; form a well-pointed category and so support good proof principles for equational reasoning; and support continuous probability distributions. We demonstrate the use of quasi-Borel spaces for higher-order functions and probability by: showing that a well-known construction of probability theory involving random functions gains a cleaner expression; and generalizing de Finetti's theorem, that is a crucial theorem in probability theory, to quasi-Borel spaces.},
archivePrefix = {arXiv},
arxivId = {1701.02547},
author = {Heunen, Chris and Kammar, Ohad and Staton, Sam and Yang, Hongseok},
booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2017.8005137},
eprint = {1701.02547},
file = {:Users/liang-tingchen/Dropbox/References/Heunen et al. - 2017 - A convenient category for higher-order probability theory.pdf:pdf},
isbn = {978-1-5090-3018-7},
issn = {10436871},
month = {jun},
pages = {1--12},
publisher = {IEEE},
title = {{A convenient category for higher-order probability theory}},
url = {http://ieeexplore.ieee.org/document/8005137/},
year = {2017}
}
@incollection{Kavvos2017b,
author = {Kavvos, G. Alex},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2017},
doi = {10.1007/978-3-662-54458-7_32},
editor = {Esparza, Javier and Murawski, Andrzej S.},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2017 - On the Semantics of Intensionality.pdf:pdf},
isbn = {9783662544587},
pages = {550--566},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On the Semantics of Intensionality}},
url = {http://link.springer.com/10.1007/978-3-662-54458-7{\_}32},
volume = {10203},
year = {2017}
}
@book{Munkres1999,
author = {Munkres, James},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Munkres - 1999 - Topology.pdf:pdf},
isbn = {9780131816299},
pages = {537},
publisher = {Pearson},
title = {{Topology}},
year = {1999}
}
@article{Guitart1980,
author = {Guitart, Ren{\'{e}}},
file = {:Users/liang-tingchen/Dropbox/References/Guitart - 1980 - Tenseurs et machines.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {1},
pages = {5--62},
title = {{Tenseurs et machines}},
url = {http://www.numdam.org/item/CTGDC{\_}1980{\_}{\_}21{\_}1{\_}5{\_}0},
volume = {21},
year = {1980}
}
@article{Kobayashi1997,
abstract = {In 1989, Eugenio Moggi proposed a categorical framework for program semantics based on the notion of a strong monad. He showed that various kinds of computation can be modeled in his framework. On the other hand, strong monads are not suited for the categorical semantics of traditional modal logics. According to these observations, Moggi thought that the Curry-Howard correspondence would not hold between programs and constructive proofs in modal logics. However, contrary to his view, we can show that proofs in a certain kind of modal logics are actually considered as programs. In this paper, first we shall introduce the notion of an ℒ-strong monad which is a generalization of strong monads. Using this new notion, we can generalize Moggi's semantics-preserving soundness and completeness with respect to his equational logic. Next we shall show that ℒ-strong monads give a sound and complete semantics of a constructive version of S4 modal logic. Finally, we present a method to extract a monad-based imperative functional program from a proof in the modal logic. Interestingly, this method can also be understood in terms of ℒ-strong monads.},
author = {Kobayashi, Satoshi},
doi = {10.1016/S0304-3975(96)00169-7},
file = {:Users/liang-tingchen/Dropbox/References/Kobayashi - 1997 - Monad as modality.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {1},
pages = {29--74},
title = {{Monad as modality}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397596001697},
volume = {175},
year = {1997}
}
@article{Gabbay2002,
abstract = {In this paper we improve the results of [2] by proving the product f.m.p. for the product of minimal n-modal and minimal n-temporal logic. For this case we modify the finite depth method introduced in [1]. The main result is applied to identify new fragments of classical first-order logic and of the equational theory of relation algebras, that are decidable and have the finite model property.},
author = {Gabbay, Dov and Shehtman, Valentin},
doi = {10.1023/A:1021304426509},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Shehtman - 2002 - Products of Modal Logics. Part 3 Products of Modal and Temporal Logics.pdf:pdf},
journal = {Studia Logica},
keywords = {classical first-order logic,decidability,finite depth method,finite model property,product finite model property,product of modal logics,relation algebra,temporal logic},
number = {2},
pages = {157--183},
publisher = {Kluwer Academic Publishers},
title = {{Products of Modal Logics. Part 3: Products of Modal and Temporal Logics}},
volume = {72},
year = {2002}
}
@incollection{Hasuo2006,
address = {Berlin, Heidelberg},
author = {Hasuo, Ichiro},
booktitle = {CONCUR 2006--Concurrency Theory},
doi = {10.1007/11817949_27},
editor = {Baier, Christel and Hermanns, Holger},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo - 2006 - Generic forward and backward simulations.pdf:pdf},
isbn = {978-3-540-37376-6},
pages = {406--420},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generic forward and backward simulations}},
url = {http://link.springer.com/10.1007/11817949{\_}27},
volume = {4137},
year = {2006}
}
@incollection{Ghica2014,
abstract = {Bounded linear types have proved to be useful for automated resource analysis and control in functional programming languages. In this paper we introduce a bounded linear typing discipline on a general notion of resource which can be modeled in a semiring. For this type system we provide both a general type-inference procedure, parameter-ized by the decision procedure of the semiring equational theory, and a (coherent) categorical semantics. This could be a useful type-theoretic and denotational framework for resource-sensitive compilation, and it represents a generalization of several existing type systems. As a non-trivial instance, motivated by hardware compilation, we present a complex new application to calculating and controlling timing of execution in a (recursion-free) higher-order functional programming language with local store.},
author = {Ghica, Dan R. and Smith, Alex I.},
booktitle = {Programming Languages and Systems. ESOP 2014},
doi = {10.1007/978-3-642-54833-8_18},
editor = {Shao, Zhong},
file = {:Users/liang-tingchen/Dropbox/References/Ghica, Smith - 2014 - Bounded Linear Types in a Resource Semiring.pdf:pdf},
isbn = {9783642548321},
issn = {16113349},
pages = {331--350},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Bounded Linear Types in a Resource Semiring}},
url = {http://link.springer.com/10.1007/978-3-642-54833-8{\_}18},
volume = {8410},
year = {2014}
}
@article{Baez2017,
abstract = {Reaction networks, or equivalently Petri nets, are a general framework for describing processes in which entities of various kinds interact and turn into other entities. In chemistry, where the reactions are assigned ‘rate constants', any reaction network gives rise to a nonlinear dynamical system called its ‘rate equation'. Here we generalize these ideas to ‘open' reaction networks, which allow entities to flow in and out at certain designated inputs and outputs. We treat open reaction networks as morphisms in a category. Composing two such morphisms connects the outputs of the first to the inputs of the second. We construct a functor sending any open reaction network to its corresponding ‘open dynamical system'. This provides a compositional framework for studying the dynamics of reaction networks. We then turn to statics: that is, steady state solutions of open dynamical systems. We construct a ‘black-boxing' functor that sends any open dynamical system to the relation that it imposes between input and output variables in steady states. This extends our earlier work on black-boxing for Markov processes.},
archivePrefix = {arXiv},
arxivId = {1704.02051},
author = {Baez, John C. and Pollard, Blake S.},
doi = {10.1142/S0129055X17500283},
eprint = {1704.02051},
file = {:Users/liang-tingchen/Dropbox/References/Baez, Pollard - 2017 - A compositional framework for reaction networks.pdf:pdf},
issn = {0129-055X},
journal = {Reviews in Mathematical Physics},
keywords = {Petri net,category,chemical reaction network,dynamical system,open system,rate equation},
month = {oct},
number = {09},
pages = {1750028},
title = {{A compositional framework for reaction networks}},
url = {https://www.worldscientific.com/doi/abs/10.1142/S0129055X17500283},
volume = {29},
year = {2017}
}
@inproceedings{Enqvist2015,
archivePrefix = {arXiv},
arxivId = {1501.07215},
author = {Enqvist, Sebastian and Seifan, Fatemeh and Venema, Yde},
booktitle = {Proceedings of the 2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2015.41},
eprint = {1501.07215},
file = {:Users/liang-tingchen/Dropbox/References/Enqvist, Seifan, Venema - 2015 - Monadic Second-Order Logic and Bisimulation Invariance for Coalgebras.pdf:pdf},
isbn = {978-1-4799-8875-4},
issn = {10436871},
keywords = {-coalgebra,Automata,Bisimulation invariance,Coalgebra,Modal mu-calculus,Monadic second-order logic,automata,bisimulation invariance,modal mu-calculus,monadic second-order logic},
month = {jul},
pages = {353--365},
publisher = {IEEE},
title = {{Monadic Second-Order Logic and Bisimulation Invariance for Coalgebras}},
url = {http://ieeexplore.ieee.org/document/7174895/ http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7174895},
volume = {2015-July},
year = {2015}
}
@article{Celani1997a,
author = {Celani, Sergio A. and Jansana, Ramon},
file = {:Users/liang-tingchen/Dropbox/References/Celani, Jansana - 1997 - A new semantics for positive modal logic.pdf:pdf},
journal = {Notre Dame Journal of Formal Logic},
number = {1},
pages = {1--18},
publisher = {University of Notre Dame},
title = {{A new semantics for positive modal logic}},
type = {Journal article},
volume = {38},
year = {1997}
}
@inproceedings{Murray2010,
abstract = {We consider the problem of detecting covert channels within security-enforcing$\backslash$nobject-capability patterns. Traditional formalisms for reasoning$\backslash$nabout the security properties of object-capability patterns require$\backslash$none to be aware, a priori , of all possible mechanisms for covert$\backslash$ninformation flow that might be present within a pattern, in order$\backslash$nto detect covert channels within it. We show how the CSP process$\backslash$nalgebra, and its model-checker FDR, can be applied to overcome this$\backslash$nlimitation.},
author = {Murray, Toby and Lowe, Gavin},
booktitle = {Formal Aspects in Security and Trust. FAST 2009},
doi = {10.1007/978-3-642-12459-4_7},
editor = {Degano, Pierpaolo and Guttman, Joshua D.},
file = {:Users/liang-tingchen/Dropbox/References/Murray, Lowe - 2010 - Analysing the information flow properties of object-capability patterns.pdf:pdf},
isbn = {3642124585},
issn = {03029743},
pages = {81--95},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Analysing the information flow properties of object-capability patterns}},
url = {http://link.springer.com/10.1007/978-3-642-12459-4{\_}7},
volume = {5983},
year = {2010}
}
@article{Sergot1996,
abstract = {Abstract. We investigate under what conditions contrary -to- duty (CTD) structures lacking temporal and action elements can be given a coherent reading. We argue, contrary to some recent proposals, that CTD is not an instance of defeasibte reasoning, and that methods of ...},
author = {Prakken, Henry and Sergot, Marek},
doi = {10.1007/BF00370671},
file = {:Users/liang-tingchen/Dropbox/References/Prakken, Sergot - 1996 - Contrary-to-duty obligations.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {contrary-to-duty obligations,deontic conditionals,deontic logic,formalisation of norms,obligations,reparational},
month = {jul},
number = {1},
pages = {91--115},
title = {{Contrary-to-duty obligations}},
url = {http://www.springerlink.com/index/x074h02854022533.pdf{\%}0Apapers3://publication/uuid/374DA5B1-315E-4AA4-831D-F03D38EE933C http://link.springer.com/10.1007/BF00370671},
volume = {57},
year = {1996}
}
@inproceedings{Christiansen2013,
abstract = {Type providers [16], pioneered in the F{\#} programming language, are a practical and powerful means of gaining the benefits of a modern static type system when working with data schemas that are defined outside of the programming language, such as relational databases. F{\#} type providers are implemented using a form of compile-time code generation, which requires the compiler to expose an internal API and can undermine type safety. We show that with dependent types it is possible to define a type provider mechanism that does not rely on code generation. Using this mechanism, a type provider becomes a kind of generic program that is instantiated for a particular external schema, which can be represented using an ordinary datatype. Because these dependent type providers use the ordinary abstraction mechanisms of the type system, they preserve its safety properties. We evaluate the practicality of this technique and explore future extensions.},
address = {New York, New York, USA},
author = {Christiansen, David Raymond},
booktitle = {Proceedings of the 9th ACM SIGPLAN workshop on Generic programming - WGP '13},
doi = {10.1145/2502488.2502495},
file = {:Users/liang-tingchen/Dropbox/References/Christiansen - 2013 - Dependent type providers.pdf:pdf},
isbn = {9781450323895},
keywords = {Dependent types,Generic programming,Metaprogramming,Type providers},
pages = {25},
publisher = {ACM Press},
title = {{Dependent type providers}},
url = {http://dl.acm.org/citation.cfm?doid=2502488.2502495},
year = {2013}
}
@incollection{Levy2006,
author = {Levy, Paul Blain},
booktitle = {Automata, Languages and Programming. ICALP 2006},
doi = {10.1007/11787006_38},
editor = {Bugliesi, Michele and Preneel, Bart and Sassone, Vladimiro and Wegener, Ingo},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2006 - Jumbo $\lambda$-Calculus.pdf:pdf},
pages = {444--455},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Jumbo $\lambda$-Calculus}},
url = {http://link.springer.com/10.1007/11787006{\_}38},
volume = {4052},
year = {2006}
}
@article{Garner2014a,
author = {Garner, Richard},
doi = {10.1016/j.jpaa.2014.02.018},
file = {:Users/liang-tingchen/Dropbox/References/Garner - 2014 - Lawvere theories, finitary monads and Cauchy-completion.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {11},
pages = {1973--1988},
publisher = {Elsevier B.V.},
title = {{Lawvere theories, finitary monads and Cauchy-completion}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002240491400036X},
volume = {218},
year = {2014}
}
@article{Brotherston2011,
abstract = {This article formalizes and compares two different styles of reasoning with inductively defined predicates, each style being encapsulated by a corresponding sequent calculus proof system.The first system, LKID, supports traditional proof by induction, with induction rules formulated as rules for introducing inductively defined predicates on the left of sequents.We show LKID to be cut-free complete with respect to a natural class of Henkin models; the eliminability of cut follows as a corollary. The second system, LKID $\omega$, uses infinite (non-well-founded) proofs to represent arguments by infinite descent. In this system, the left-introduction rules for inductively defined predicates are simple case-split rules, and an infinitary, global condition on proof trees is required in order to ensure soundness.We show LKID$\omega$ to be cut-free complete with respect to standard models, and again infer the eliminability of cut. The infinitary system LKID $\omega$ is unsuitable for formal reasoning. However, it has a natural restriction to proofs given by regular trees, i.e. to those proofs representable by finite graphs, which is so suited. We demonstrate that this restricted 'cyclic' proof system, CLKID$\omega$, subsumes LKID, and conjecture that CLKID$\omega$ and LKID are in fact equivalent, i.e. that proof by induction is equivalent to regular proof by infinite descent. {\textcopyright} 2010 The Author.},
author = {Brotherston, James and Simpson, Alex},
doi = {10.1093/logcom/exq052},
file = {:Users/liang-tingchen/Dropbox/References/Brotherston, Simpson - 2011 - Sequent calculi for induction and infinite descent.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Sequent calculus,cut-elimination,cyclic proof,inductive definitions,infinite descent},
month = {dec},
number = {6},
pages = {1177--1216},
title = {{Sequent calculi for induction and infinite descent}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exq052},
volume = {21},
year = {2011}
}
@article{COQUAND1997a,
author = {Coquand, Thierry and Dybjer, Peter},
doi = {10.1017/S0960129596002150},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Dybjer - 1997 - Intuitionistic model constructions and normalization proofs(2).pdf:pdf},
isbn = {0960129596},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {1},
title = {{Intuitionistic model constructions and normalization proofs}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129596002150},
volume = {7},
year = {1997}
}
@inproceedings{Hansson1990,
author = {Hansson, H. and Jonsson, B.},
booktitle = {Real-Time Systems, RTSS 90},
doi = {10.1109/REAL.1990.128759},
file = {:Users/liang-tingchen/Dropbox/References/Hansson, Jonsson - 1990 - A calculus for communicating systems with time and probabilities.pdf:pdf},
isbn = {0-8186-2112-5},
pages = {278--287},
publisher = {IEEE},
title = {{A calculus for communicating systems with time and probabilities}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=128759},
year = {1990}
}
@inproceedings{Coecke2010,
author = {Coecke, Bob and Lal, Raymond},
booktitle = {Proceedings of the 7th International QPL Workshop Quantum Physics and Logic},
file = {:Users/liang-tingchen/Dropbox/References/Coecke, Lal - 2010 - Causal categories a backbone for a quantum-relativistic universe of interacting processes.pdf:pdf},
pages = {17----26},
title = {{Causal categories: a backbone for a quantum-relativistic universe of interacting processes}},
url = {papers3://publication/uuid/3515A5CB-0685-4B9C-A3CF-56358A155A39},
year = {2010}
}
@article{Scalas2018,
author = {Scalas, Alceste and Yoshida, Nobuko},
doi = {10.1016/j.jlamp.2018.01.001},
file = {:Users/liang-tingchen/Dropbox/References/Scalas, Yoshida - 2018 - Multiparty session types, beyond duality.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
pages = {55--84},
publisher = {Elsevier Inc.},
title = {{Multiparty session types, beyond duality}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2352220817301487},
volume = {97},
year = {2018}
}
@phdthesis{Turi1996a,
author = {Turi, Daniele},
file = {:Users/liang-tingchen/Dropbox/References/Turi - 1996 - Functional Operational Semantics and its Denotational Dual.pdf:pdf},
month = {jun},
school = {Free University},
title = {{Functional Operational Semantics and its Denotational Dual}},
type = {Thesis (PhD)},
url = {http://hdl.handle.net/1871/11304},
year = {1996}
}
@article{PITTS2000,
abstract = {Studies of the mathematical properties of impredicative polymorphic types have for the most part focused on the polymorphic lambda calculus of Girard–Reynolds, which is a calculus of total polymorphic functions. This paper considers polymorphic types from a functional programming perspective, where the partialness arising from the presence of fixpoint recursion complicates the nature of potentially infinite (‘lazy') data types. An approach to Reynolds' notion of relational parametricity is developed that works directly on the syntax of a programming language, using a novel closure operator to relate operational behaviour to parametricity properties of types. Working with an extension of Plotkin's PCF with ∀-types, lazy lists and existential types, we show by example how the resulting logical relation can be used to prove properties of polymorphic types up to operational equivalence.},
author = {Pitts, Andrew M.},
doi = {10.1017/S0960129500003066},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2000 - Parametric polymorphism and operational equivalence.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {3},
pages = {321--359},
title = {{Parametric polymorphism and operational equivalence}},
url = {https://www.cambridge.org/core/product/identifier/S0960129500003066/type/journal{\_}article},
volume = {10},
year = {2000}
}
@article{Moss1997,
author = {Moss, Lawrence S.},
doi = {10.1093/jigpal/5.2.231},
file = {:Users/liang-tingchen/Dropbox/References/Moss - 1997 - On the Foundations of Corecursion.pdf:pdf},
issn = {1367-0751},
journal = {Logic Journal of IGPL},
keywords = {coalgebra,corecursion,operator on sets},
month = {mar},
number = {2},
pages = {231--257},
title = {{On the Foundations of Corecursion}},
url = {http://jigpal.oupjournals.org/cgi/doi/10.1093/jigpal/5.2.231},
volume = {5},
year = {1997}
}
@article{Coquand1988,
abstract = {Thierry Coquand No contact information provided yet. Bibliometrics: publication history Publication years1985-2010 Publication count56 Citation Count501 Available for download0 Downloads (6 Weeks)0 Downloads (12 Months)0 View colleagues of Thierry Coquand Gerard Huet No contact information provided yet. Bibliometrics: publication history Publication years1972-2009 Publication count26 Citation Count404 Available for download4 Downloads (6 Weeks)17 Downloads (12 Months)135 View colleagues of Gerard Huet},
author = {Coquand, Thierry and Huet, G{\'{e}}rard},
doi = {10.1016/0890-5401(88)90005-3},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Huet - 1988 - The calculus of constructions.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {feb},
number = {2-3},
pages = {95--120},
title = {{The calculus of constructions}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0890540188900053},
volume = {76},
year = {1988}
}
@article{Fiore2011,
abstract = {We extend the basic concepts of Street's formal theory of monads from the setting of 2-categories to that of double categories. In particular, we introduce the double category Mnd(C) of monads in a double category C and define what it means for a double category to admit the construction of free monads. Our main theorem shows that, under some mild conditions, a double category that is a framed bicategory admits the construction of free monads if its horizontal 2-category does. We apply this result to obtain double adjunctions which extend the adjunction between graphs and categories and the adjunction between polynomial endofunctors and polynomial monads. ?? 2010 Elsevier B.V..},
archivePrefix = {arXiv},
arxivId = {1006.0797},
author = {Fiore, Thomas M. and Gambino, Nicola and Kock, Joachim},
doi = {10.1016/j.jpaa.2010.08.003},
eprint = {1006.0797},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Gambino, Kock - 2011 - Monads in double categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jun},
number = {6},
pages = {1174--1197},
publisher = {Elsevier B.V.},
title = {{Monads in double categories}},
url = {http://dx.doi.org/10.1016/j.jpaa.2010.08.003 http://linkinghub.elsevier.com/retrieve/pii/S002240491000174X},
volume = {215},
year = {2011}
}
@article{Birkedal2011,
author = {Birkedal, Lars and Reus, Bernhard and Schwinghammer, Jan and St{\o}vring, Kristian and Thamsborg, Jacob and Yang, Hongseok},
doi = {10.1145/1925844.1926401},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal et al. - 2011 - Step-indexed kripke models over recursive worlds.pdf:pdf},
isbn = {9781450304900},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {capability calculus,els,frame rules,indirection theory,kripke models,step-indexed mod-,ultrametric spaces},
month = {jan},
number = {1},
pages = {119},
title = {{Step-indexed kripke models over recursive worlds}},
url = {http://portal.acm.org/citation.cfm?doid=1925844.1926401},
volume = {46},
year = {2011}
}
@article{Centazzo2004,
author = {Centazzo, C and Rosick{\'{y}}, Jiř{\'{i}} and Vitale, Enrico M.},
file = {:Users/liang-tingchen/Dropbox/References/Centazzo, Rosick{\'{y}}, Vitale - 2004 - A characterization of locally D-presentable categories.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
keywords = {limit doctrine},
number = {2},
pages = {141--146},
title = {{A characterization of locally D-presentable categories}},
url = {http://eudml.org/doc/91679},
volume = {45},
year = {2004}
}
@article{ELLERMAN2013,
author = {ELLERMAN, DAVID},
doi = {10.1142/S1793351X13400059},
file = {:Users/liang-tingchen/Dropbox/References/ELLERMAN - 2013 - AN INTRODUCTION TO LOGICAL ENTROPY AND ITS RELATION TO SHANNON ENTROPY.pdf:pdf},
issn = {1793-351X},
journal = {International Journal of Semantic Computing},
keywords = {logical entropy,partition logic,shannon entropy},
month = {jun},
number = {02},
pages = {121--145},
title = {{AN INTRODUCTION TO LOGICAL ENTROPY AND ITS RELATION TO SHANNON ENTROPY}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S1793351X13400059},
volume = {07},
year = {2013}
}
@article{Ahrensm2015,
abstract = {We develop category theory within Univalent Foundations, which is a foundational system for mathematics based on a homotopical interpretation of dependent type theory. In this system, we propose a definition of ‘category' for which equality and equivalence of categories agree. Such categories satisfy a version of the univalence axiom, saying that the type of isomorphisms between any two objects is equivalent to the identity type between these objects; we call them ‘saturated' or ‘univalent' categories. Moreover, we show that any category is weakly equivalent to a univalent one in a universal way. In homotopical and higher-categorical semantics, this construction corresponds to a truncated version of the Rezk completion for Segal spaces, and also to the stack completion of a prestack.},
author = {AHRENS, BENEDIKT and KAPULKIN, KRZYSZTOF and SHULMAN, MICHAEL},
doi = {10.1017/S0960129514000486},
file = {:Users/liang-tingchen/Dropbox/References/AHRENS, KAPULKIN, SHULMAN - 2015 - Univalent categories and the Rezk completion.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {05},
pages = {1010--1039},
title = {{Univalent categories and the Rezk completion}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129514000486},
volume = {25},
year = {2015}
}
@article{Kiss2018,
abstract = {Functional programmers have an established tradition of using traversals as a design pattern to work with recursive data structures. The technique is so prolific that a whole host of libraries have been designed to help in the task of automatically providing traversals by analysing the generic structure of data types. More recently, lenses have entered the functional scene and have proved themselves to be a simple and versatile mechanism for working with product types. They make it easy to focus on the salient parts of a data structure in a composable and reusable manner.},
archivePrefix = {arXiv},
arxivId = {1805.06798},
author = {Kiss, Csongor and Pickering, Matthew and Wu, Nicolas},
doi = {10.1145/3236780},
eprint = {1805.06798},
file = {:Users/liang-tingchen/Dropbox/References/Kiss, Pickering, Wu - 2018 - Generic deriving of generic traversals.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Extensibility,Generic Programming,Lenses,Traversals},
month = {jul},
number = {ICFP},
pages = {1--30},
title = {{Generic deriving of generic traversals}},
url = {https://dl.acm.org/doi/10.1145/3236780},
volume = {2},
year = {2018}
}
@article{Hashiguchi2004,
author = {Hashiguchi, Kosaburo and Sakakibara, Naoto and Jimbo, Shuji},
doi = {10.1016/j.tcs.2003.09.005},
file = {:Users/liang-tingchen/Dropbox/References/Hashiguchi, Sakakibara, Jimbo - 2004 - Equivalence of regular binoid expressions and regular expressions denoting binoid languages over.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Free binoid,Regular (monoid) expression,Regular binoid expression,Regular language},
month = {jan},
number = {2-3},
pages = {251--266},
title = {{Equivalence of regular binoid expressions and regular expressions denoting binoid languages over free binoids}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397503004985},
volume = {312},
year = {2004}
}
@article{Goldreich1991,
abstract = {In this paper the generality and wide applicability of Zero-knowledge$\backslash$nproofs, a notion introduced by Goldwasser, Micali, and Rackoff is$\backslash$ndemonstrated. These are probabilistic and interactive proofs that,$\backslash$nfor the members of a language, efficiently demonstrate membership$\backslash$nin the language without conveying any additional knowledge. All previously$\backslash$nknown zero-knowledge proofs were only for number-theoretic languages$\backslash$nin NP fl CONP.$\backslash$n$\backslash$nUnder the assumption that secure encryption functions exist or by$\backslash$nusing “physical means for hiding information, ‘‘ it is shown that$\backslash$nall languages in NP have zero-knowledge proofs. Loosely speaking,$\backslash$nit is possible to demonstrate that a CNF formula is satisfiable without$\backslash$nrevealing any other property of the formula, in particular, without$\backslash$nyielding neither a satis@ing assignment nor properties such as whether$\backslash$nthere is a satisfying assignment in which xl = X3 etc.$\backslash$n$\backslash$nIt is also demonstrated that zero-knowledge proofs exist “outside$\backslash$nthe domain of cryptography and number theory. ” Using no assumptions.$\backslash$nit is shown that both graph isomorphism and graph nonisomorphism$\backslash$nhave zero-knowledge interactive proofs. The mere existence of an$\backslash$ninteractive proof for graph nonisomorphism is interesting, since$\backslash$ngraph nonisomorphism is not known to be in NP and hence no efficient$\backslash$nproofs were known before for demonstrating that two graphs are not$\backslash$nisomorphic.},
author = {Goldreich, Oded and Micali, Silvio and Wigderson, Avi},
doi = {10.1145/116825.116852},
editor = {Fischer-H{\"{u}}bner, Simone and Hopper, Nicholas},
file = {:Users/liang-tingchen/Dropbox/References/Goldreich, Micali, Wigderson - 1991 - Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof syst.pdf:pdf},
isbn = {0004-5411},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Journal of the ACM},
month = {jul},
number = {3},
pages = {690--728},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems}},
url = {http://freehaven.net/anonbib/papers/pets2011/p1-perito.pdf http://link.springer.com/10.1007/978-3-642-22263-4{\_}1 http://portal.acm.org/citation.cfm?doid=116825.116852},
volume = {38},
year = {1991}
}
@article{Altenkirch2009a,
abstract = {Traditionally, decidability of conversion for typed $\lambda$-calculi is established by showing that small-step reduction is confluent and strongly normalising. Here we investigate an alternative approach employing a recursively defined normalisation function which we show to be terminating and which reflects and preserves conversion. We apply our approach to the simply typed $\lambda$-calculus with explicit substitutions and $\beta$$\eta$-equality, a system which is not strongly normalising. We also show how the construction can be extended to system T with the usual $\beta$-rules for the recursion combinator. Our approach is practical, since it does verify an actual implementation of normalisation which, unlike normalisation by evaluation, is first order. An important feature of our approach is that we are using logical relations to establish equational soundness (identity of normal forms reflects the equational theory), instead of the usual syntactic reasoning using the Church–Rosser property of a term rewriting system.},
author = {Altenkirch, Thorsten and Chapman, James},
doi = {10.1017/S0956796809007278},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Chapman - 2009 - Big-step normalisation.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {3-4},
pages = {311--333},
title = {{Big-step normalisation}},
url = {https://www.cambridge.org/core/product/identifier/S0956796809007278/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Schurmann2008,
abstract = {Tait's method (a.k.a. proof by logical relations) is a powerful proof technique frequently used for showing foundational properties of languages based on typed lambda-calculi. Historically, these proofs have been extremely difficult to formalize in proof assistants with weak meta-logics, such as Twelf, and yet they are often straightforward in proof assistants with stronger meta-logics. In this paper, we propose structural logical relations as a technique for conducting these proofs in systems with limited meta-logical strength by explicitly representing and reasoning about an auxiliary logic. In support of our claims, we give a Twelf-checked proof of the completeness of an algorithm for checking equality of simply typed lambda-terms.},
author = {Sch{\"{u}}rmann, Carsten and Sarnat, Jeffrey},
doi = {10.1109/LICS.2008.44},
file = {:Users/liang-tingchen/Dropbox/References/Sch{\"{u}}rmann, Sarnat - 2008 - Structural logical relations.pdf:pdf},
isbn = {9780769531830},
issn = {10436871},
journal = {Proceedings - Symposium on Logic in Computer Science},
pages = {69--80},
title = {{Structural logical relations}},
year = {2008}
}
@article{Oosten2002,
abstract = {The purpose of this short paper is to sketch the development of a few basic topics in the history of realizability. The number of topics is quite limited and reflects very much my own personal taste, prejudices and area of competence.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {{VAN OOSTEN}, JAAP},
doi = {10.1017/S0960129502003626},
eprint = {1512.00567},
file = {:Users/liang-tingchen/Dropbox/References/VAN OOSTEN - 2002 - Realizability a historical essay.pdf:pdf},
isbn = {1469-8072},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {03},
pages = {239--263},
title = {{Realizability: a historical essay}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129502003626},
volume = {12},
year = {2002}
}
@article{Adamek2021,
abstract = {Profinite equations are an indispensable tool for the algebraic classification of formal languages. Reiterman's theorem states that they precisely specify pseudovarieties, i.e., classes of finite algebras closed under finite products, subalgebras and quotients. In this article, Reiterman's theorem is generalized to finite Eilenberg-Moore algebras for a monad T on a category D: we prove that a class of finite T -algebras is a pseudovariety iff it is presentable by profinite equations. As a key technical tool, we introduce the concept of a profinite monad T {\^{}} associated to the monad T , which gives a categorical view of the construction of the space of profinite terms.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Chen, Liang-Ting and Milius, Stefan and Urbat, Henning},
doi = {10.1145/3464691},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2021 - Reiterman's Theorem on Finite Algebras for a Monad.pdf:pdf},
issn = {1529-3785},
journal = {ACM Transactions on Computational Logic},
month = {oct},
number = {4},
pages = {1--48},
title = {{Reiterman's Theorem on Finite Algebras for a Monad}},
url = {https://dl.acm.org/doi/10.1145/3464691},
volume = {22},
year = {2021}
}
@article{Day1979,
author = {Day, Brian J.},
doi = {10.1017/S0004972700009096},
file = {:Users/liang-tingchen/Dropbox/References/Day - 1979 - On profiniteness of compact totally disconnected algebras.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
number = {01},
pages = {71},
title = {{On profiniteness of compact totally disconnected algebras}},
volume = {20},
year = {1979}
}
@book{Kohlas2003,
address = {London},
author = {Kohlas, J{\"{u}}rg},
doi = {10.1007/978-1-4471-0009-6},
isbn = {978-1-85233-689-9},
pages = {265},
publisher = {Springer-Verlag London},
series = {Discrete Mathematics and Theoretical Computer Science},
title = {{Information Algebras}},
url = {http://link.springer.com/10.1007/978-1-4471-0009-6},
year = {2003}
}
@article{Bertino2009,
author = {Bertino, E. and Brodie, C. and Calo, S. B. and Cranor, L. F. and Karat, C. and Karat, J. and Li, N. and Lin, D. and Lobo, J. and Ni, Q. and Rao, P. R. and Wang, X.},
doi = {10.1147/JRD.2009.5429045},
file = {:Users/liang-tingchen/Dropbox/References/Bertino et al. - 2009 - Analysis of privacy and security policies.pdf:pdf},
isbn = {978-3-319-25743-3},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
keywords = {location privacy,online social networks,security and privacy exposure,user profiling},
month = {mar},
number = {2},
pages = {3:1--3:18},
title = {{Analysis of privacy and security policies}},
url = {http://ieeexplore.ieee.org/document/5429045/},
volume = {53},
year = {2009}
}
@phdthesis{Rosolini1986,
author = {Rosolini, Giuseppe},
booktitle = {PhD thesis},
file = {:Users/liang-tingchen/Dropbox/References/Rosolini - 1986 - Continuity and Effectiveness in Topoi.pdf:pdf},
number = {March},
school = {University of Oxford},
title = {{Continuity and Effectiveness in Topoi}},
type = {Doctoral Thesis},
year = {1986}
}
@article{Adamek1974,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 1974 - Free algebras and automata realizations in the language of categories.pdf:pdf},
journal = {Commentationes Mathematicae Universitatis Carolinae},
number = {4},
pages = {589--602},
title = {{Free algebras and automata realizations in the language of categories}},
url = {http://dml.cz/dmlcz/105583},
volume = {15},
year = {1974}
}
@article{Dong2015,
abstract = {The task of {\{}$\backslash$em data fusion{\}} is to identify the true values of data items (eg, the true date of birth for {\{}$\backslash$em Tom Cruise{\}}) among multiple observed values drawn from different sources (eg, Web sites) of varying (and unknown) reliability. A recent survey$\backslash$cite{\{}LDL+12{\}} has provided a detailed comparison of various fusion methods on Deep Web data. In this paper, we study the applicability and limitations of different fusion techniques on a more challenging problem: {\{}$\backslash$em knowledge fusion{\}}. Knowledge fusion identifies true subject-predicate-object triples extracted by multiple information extractors from multiple information sources. These extractors perform the tasks of entity linkage and schema alignment, thus introducing an additional source of noise that is quite different from that traditionally considered in the data fusion literature, which only focuses on factual errors in the original sources. We adapt state-of-the-art data fusion techniques and apply them to a knowledge base with 1.6B unique knowledge triples extracted by 12 extractors from over 1B Web pages, which is three orders of magnitude larger than the data sets used in previous data fusion papers. We show great promise of the data fusion approaches in solving the knowledge fusion problem, and suggest interesting research directions through a detailed error analysis of the methods.},
archivePrefix = {arXiv},
arxivId = {1503.00302},
author = {Dong, Xin Luna and Gabrilovich, Evgeniy and Heitz, Geremy and Horn, Wilko and Murphy, Kevin and Sun, Shaohua and Zhang, Wei},
doi = {10.14778/2732951.2732962},
eprint = {1503.00302},
file = {:Users/liang-tingchen/Dropbox/References/Dong et al. - 2014 - From data fusion to knowledge fusion.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {jun},
number = {10},
pages = {881--892},
title = {{From data fusion to knowledge fusion}},
url = {http://arxiv.org/abs/1503.00302 http://dl.acm.org/citation.cfm?doid=2732951.2732962},
volume = {7},
year = {2014}
}
@incollection{Kawata2019,
abstract = {We study a dependently typed extension of a multi-stage programming language {\`{a}} la MetaOCaml, which supports quasi-quotation and cross-stage persistence for manipulation of code fragments as first-class values and an evaluation construct for execution of programs dynamically generated by this code manipulation. Dependent types are expected to bring to multi-stage programming enforcement of strong invariant—beyond simple type safety—on the behavior of dynamically generated code. An extension is, however, not trivial because such a type system would have to take stages of types—roughly speaking, the number of surrounding quotations—into account. To rigorously study properties of such an extension, we develop $\lambda$MD, which is an extension of Hanada and Igarashi's typed calculus (formula presented) with dependent types, and prove its properties including preservation, confluence, strong normalization for full reduction, and progress for staged reduction. Motivated by code generators that generate code whose type depends on a value from outside of the quotations, we argue the significance of cross-stage persistence in dependently typed multi-stage programming and certain type equivalences that are not directly derived from reduction rules.},
archivePrefix = {arXiv},
arxivId = {1908.02035},
author = {Kawata, Akira and Igarashi, Atsushi},
booktitle = {Programming Languages and Systems. APLAS 2019},
doi = {10.1007/978-3-030-34175-6_4},
editor = {Lin, Anthony Widjaja},
eprint = {1908.02035},
file = {:Users/liang-tingchen/Dropbox/References/Kawata, Igarashi - 2019 - A Dependently Typed Multi-stage Calculus.pdf:pdf},
isbn = {9783030341749},
issn = {16113349},
keywords = {Cross-stage persistence,Dependent types,Multi-stage programming},
pages = {53--72},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Dependently Typed Multi-stage Calculus}},
url = {http://link.springer.com/10.1007/978-3-030-34175-6{\_}4},
volume = {11893},
year = {2019}
}
@article{Palmigiano2004,
author = {Palmigiano, Alessandra},
doi = {10.1016/j.tcs.2004.07.026},
file = {:Users/liang-tingchen/Dropbox/References/Palmigiano - 2004 - A coalgebraic view on positive modal logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {positive modal algebra,positive modal logic,priestley space,vietoris functor},
month = {oct},
number = {1-2},
pages = {175--195},
title = {{A coalgebraic view on positive modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504004487},
volume = {327},
year = {2004}
}
@inproceedings{Getoor1999,
abstract = {A large portion of real-world data is stored in commercial relational database systems. In contrast, most statistical learning methods work only with "flat" data representations. Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database. This paper builds on the recent work on probabilistic relational models (PRMs), and describes how to learn them from databases. PRMs allow the properties of an...},
address = {Stockholm, Sweden},
author = {Friedman, N. and Getoor, L. and Koller, Daphne and Pfeffer, A.},
booktitle = {Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence ({\{}IJCAI{\}}-99)},
file = {:Users/liang-tingchen/Dropbox/References/Friedman et al. - 1999 - Learning Probabilistic Relational Models.pdf:pdf},
pages = {1300----1309},
publisher = {Morgan Kaufman},
title = {{Learning Probabilistic Relational Models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.4737{\&}rep=rep1{\&}type=pdf},
year = {1999}
}
@inproceedings{Agrawal2012,
author = {Agrawal, Manindra and Akshay, Sundararaman and Genest, Blaise and Thiagarajan, P. S.},
booktitle = {Logic in Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Agrawal et al. - 2012 - Approximate Verification of the Symbolic Dynamics of Markov Chains.pdf:pdf},
title = {{Approximate Verification of the Symbolic Dynamics of Markov Chains}},
year = {2012}
}
@article{Landin1966,
abstract = {A family of unimplemented computing languages is described that is intended to span differences of application area by a unified framework. This framework dictates the rules about the uses of user-coined names, and the conventions about characterizing functional relationships. Within this framework the design of a specific language splits into two independent parts. One is the choice of written appearances of programs (or more generally, their physical representation). The other is the choice of the abstract entities (such as numbers, character-strings, list of them, functional relations among them) that can be referred to in the language.$\backslash$nThe system is biased towards “expressions” rather than “statements.” It includes a nonprocedural (purely functional) subsystem that aims to expand the class of users' needs that can be met by a single print-instruction, without sacrificing the important properties that make conventional right-hand-side expressions easy to construct and understand.},
author = {Landin, P. J.},
doi = {10.1145/365230.365257},
file = {:Users/liang-tingchen/Dropbox/References/Landin - 1966 - The next 700 programming languages.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {mar},
number = {3},
pages = {157--166},
title = {{The next 700 programming languages}},
url = {http://portal.acm.org/citation.cfm?doid=365230.365257},
volume = {9},
year = {1966}
}
@article{Paraskevopoulou2019,
author = {Paraskevopoulou, Zoe and Appel, Andrew W.},
doi = {10.1145/3341687},
file = {:Users/liang-tingchen/Dropbox/References/Paraskevopoulou, Appel - 2019 - Closure conversion is safe for space.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {closure conversion,compiler correctness,continuation-passing style,cost models,garbage collection,logical relations},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Closure conversion is safe for space}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341687},
volume = {3},
year = {2019}
}
@inproceedings{dejong_et_al:LIPIcs.FSCD.2021.8,
abstract = {We investigate predicative aspects of order theory in constructive univalent foundations. By predicative and constructive, we respectively mean that we do not assume Voevodsky's propositional resizing axioms or excluded middle. Our work complements existing work on predicative mathematics by exploring what cannot be done predicatively in univalent foundations. Our first main result is that nontrivial (directed or bounded) complete posets are necessarily large. That is, if such a nontrivial poset is small, then weak propositional resizing holds. It is possible to derive full propositional resizing if we strengthen nontriviality to positivity. The distinction between nontriviality and positivity is analogous to the distinction between nonemptiness and inhabitedness. We prove our results for a general class of posets, which includes directed complete posets, bounded complete posets and sup-lattices, using a technical notion of a $\delta$V-complete poset. We also show that nontrivial locally small $\delta$V-complete posets necessarily lack decidable equality. Specifically, we derive weak excluded middle from assuming a nontrivial locally small $\delta$V-complete poset with decidable equality. Moreover, if we assume positivity instead of nontriviality, then we can derive full excluded middle. Secondly, we show that each of Zorn's lemma, Tarski's greatest fixed point theorem and Pataraia's lemma implies propositional resizing. Hence, these principles are inherently impredicative and a predicative development of order theory must therefore do without them. Finally, we clarify, in our predicative setting, the relation between the traditional definition of sup-lattice that requires suprema for all subsets and our definition that asks for suprema of all small families.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Predicative Aspects of Order Theory in Univalent Foundations - de Jong, Tom; Escard{\'{o}}, Mart$\backslash$'$\backslash$in H{\"{o}}tzel)

Keywords: order theory, constructivity, predicativity, univalent foundations},
archivePrefix = {arXiv},
arxivId = {2102.08812},
author = {de Jong, Tom and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel},
booktitle = {6th International Conference on Formal Structures for Computation and Deduction (FSCD 2021)},
doi = {10.4230/LIPIcs.FSCD.2021.8},
editor = {Kobayashi, Naoki},
eprint = {2102.08812},
file = {:Users/liang-tingchen/Dropbox/References/de Jong, Escard{\'{o}} - 2021 - Predicative Aspects of Order Theory in Univalent Foundations.pdf:pdf},
isbn = {978-3-95977-191-7},
issn = {1868-8969},
keywords = {Constructivity,Order theory,Predicativity,Univalent foundations},
number = {8},
pages = {8:1----8:18},
publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Predicative Aspects of Order Theory in Univalent Foundations}},
url = {https://drops.dagstuhl.de/opus/volltexte/2021/14246},
volume = {195},
year = {2021}
}
@article{Cancila2004,
author = {Cancila, Daniela and Honsell, Furio and Lenisa, Marina},
doi = {10.1016/j.entcs.2004.08.019},
file = {:Users/liang-tingchen/Dropbox/References/Cancila, Honsell, Lenisa - 2004 - Properties of Set Functors.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {categories of sets,constant functor,identity functor,partially defined endofunctors},
month = {nov},
pages = {61--80},
title = {{Properties of Set Functors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104051436},
volume = {104},
year = {2004}
}
@article{Adamek2008a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Bloom, Stephen L. and Milius, Stefan},
doi = {10.1093/logcom/exn035},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Bloom, Milius - 2008 - On algebras with iteration.pdf:pdf},
issn = {0955792X},
journal = {Journal of Logic and Computation},
number = {6},
pages = {1047--1085},
title = {{On algebras with iteration}},
volume = {18},
year = {2008}
}
@article{Mcbride2008,
abstract = {In this paper, we introduce Applicative functors—an abstract characterisation of an ap- plicative style of effectful programming, weaker than Monads and hence more widespread. Indeed, it is the ubiquity of this programming pattern that drew us to the abstraction. We retrace our steps in this paper, introducing the applicative pattern by diverse exam- ples, then abstracting it to define the Applicative type class and introducing a bracket notation which interprets the normal application syntax in the idiom of an Applicative functor. Further, we develop the properties of applicative functors and the generic opera- tions they support.We close by identifying the categorical structure of applicative functors and examining their relationship both with Monads and with Arrows.},
author = {McBride, Conor and Paterson, Ross},
doi = {10.1017/S0956796807006326},
file = {:Users/liang-tingchen/Dropbox/References/McBride, Paterson - 2008 - Applicative programming with effects.pdf:pdf},
isbn = {0956-7968},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
number = {01},
pages = {1--13},
title = {{Applicative programming with effects}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796807006326},
volume = {18},
year = {2008}
}
@article{Stucki2020,
author = {Stucki, Nicolas and Biboudis, Aggelos and Odersky, Martin},
doi = {10.1145/3393934.3278139},
file = {:Users/liang-tingchen/Dropbox/References/Stucki, Biboudis, Odersky - 2020 - A practical unification of multi-stage programming and macros.pdf:pdf},
isbn = {9781450360456},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {2018,a,acm reference format,aggelos biboudis,and martin odersky,in,macros,multi-stage programming,multi-stage programming and macros,nicolas stucki,practical uni cation of,scala},
month = {apr},
number = {9},
pages = {14--27},
title = {{A practical unification of multi-stage programming and macros}},
url = {https://dl.acm.org/doi/10.1145/3393934.3278139},
volume = {53},
year = {2020}
}
@article{Bernardy2012,
abstract = {Reynolds' abstraction theorem (Reynolds, J. C. (1983) Types, abstraction and parametric polymorphism, Inf. Process. 83 (1), 513–523) shows how a typing judgement in System F can be translated into a relational statement (in second-order predicate logic) about inhabitants of the type. We obtain a similar result for pure type systems (PTSs): for any PTS used as a programming language, there is a PTS that can be used as a logic for parametricity. Types in the source PTS are translated to relations (expressed as types) in the target. Similarly, values of a given type are translated to proofs that the values satisfy the relational interpretation. We extend the result to inductive families. We also show that the assumption that every term satisfies the parametricity condition generated by its type is consistent with the generated logic.},
author = {Bernardy, Jean-philippe and Jansson, Patrik and Paterson, Ross},
doi = {10.1017/S0956796812000056},
file = {:Users/liang-tingchen/Dropbox/References/Bernardy, Jansson, Paterson - 2012 - Proofs for free.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {107--152},
title = {{Proofs for free}},
url = {https://www.cambridge.org/core/product/identifier/S0956796812000056/type/journal{\_}article},
volume = {22},
year = {2012}
}
@article{Erkok2005,
abstract = {Monads have become a popular tool for dealing with computational effects in Haskell for two significant reasons: equational reasoning is retained even in the presence of effects; and program modularity is enhaced by hiding "plumbing" issues inside the monadic infrastructure. Unfortunately, not all the facilities provided by the underlying language are readily available for monadic computations. Inparticular, while recursive monadic computations can be defined directly using Haskell's built-in recursion capabilities, there is no natural way to express recursion over the values of monadic actions. Using examples, we illustrate why this is a problem, and we propose and extension to Haskell's do-notation to remedy the situation. It turns out that the structure of monadic value-recursion depends on the structure of the underlying monad. We propose an axiomatization of the recursion operation and provide a catalogue of definitions that satisfy our criteria. The proofs of the claims we make throughout the report, along with other technical development, is presented in the appendices.},
author = {Erk{\"{o}}k, Levent and Launchbury, John},
doi = {10.1145/357766.351257},
file = {:Users/liang-tingchen/Dropbox/References/Erk{\"{o}}k, Launchbury - 2000 - Recursive monadic bindings.pdf:pdf},
isbn = {1581132026},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {sep},
number = {9},
pages = {174--185},
title = {{Recursive monadic bindings}},
url = {http://portal.acm.org/citation.cfm?doid=357766.351257},
volume = {35},
year = {2000}
}
@article{Mokhov2019,
abstract = {Applicative functors and monads have conquered the world of functional programming by providing general and powerful ways of describing effectful computations using pure functions. Applicative functors provide a way to compose independent effects that cannot depend on values produced by earlier computations, and all of which are declared statically. Monads extend the applicative interface by making it possible to compose dependent effects, where the value computed by one effect determines all subsequent effects, dynamically.},
author = {Mokhov, Andrey and Lukyanov, Georgy and Marlow, Simon and Dimino, Jeremie},
doi = {10.1145/3341694},
file = {:Users/liang-tingchen/Dropbox/References/Mokhov et al. - 2019 - Selective applicative functors(2).pdf:pdf;:Users/liang-tingchen/Dropbox/References/Mokhov et al. - 2019 - Selective applicative functors.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {applicative functors,effects,monads,selective functors},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Selective applicative functors}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341694 https://dl.acm.org/doi/10.1145/3341694},
volume = {3},
year = {2019}
}
@inproceedings{Kataoka2015b,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Towards Concept Analysis in Categories: Limit Inferior as Algebra, Limit Superior as Coalgebra - Kataoka, Toshiki; Pavlovic, Dusko)

Keywords: concept analysis, semantic indexing, category, completion, algebra},
author = {Kataoka, Toshiki and Pavlovi{\'{c}}, Dusko},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.130},
editor = {Moss, Lawrence S and Sobocinski, Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Kataoka, Pavlovi{\'{c}} - 2015 - Towards Concept Analysis in Categories Limit Inferior as Algebra, Limit Superior as Coalgebra.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
keywords = {130,2015,4230,a,a sup- and inf-complete,algebra,and phrases concept analysis,calco,category,category a with a,completion,digital object identifier 10,it is an open,lipics,problem whether there exists,semantic indexing,sup- and inf-dense embedding},
pages = {130--155},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Towards Concept Analysis in Categories: Limit Inferior as Algebra, Limit Superior as Coalgebra}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5531},
volume = {35},
year = {2015}
}
@article{Abel2008b,
abstract = {Normalization for the simply-typed $\lambda$-calculus is proven in Twelf, an implementation of the Edinburgh Logical Framework. Since due to proof-theoretical restrictions Twelf Tait's computability method does not seem to be directly usable, a syntactical proof is adapted and formalized instead. In this case study, some boundaries of Twelf current capabilities are touched and discussed. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Abel, Andreas},
doi = {10.1016/j.entcs.2007.11.009},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2008 - Normalization for the Simply-Typed Lambda-Calculus in Twelf.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Edinburgh Logical Framework,HOAS,Mechanized Proof,Normalization,Twelf},
month = {feb},
pages = {3--16},
publisher = {Elsevier B.V.},
title = {{Normalization for the Simply-Typed Lambda-Calculus in Twelf}},
url = {http://dx.doi.org/10.1016/j.entcs.2007.11.009 https://linkinghub.elsevier.com/retrieve/pii/S1571066108000753},
volume = {199},
year = {2008}
}
@incollection{Hanada2014,
author = {Hanada, Yuichiro and Igarashi, Atsushi},
booktitle = {Functional and Logic Programming. FLOPS 2014},
doi = {10.1007/978-3-319-07151-0_7},
editor = {Codish, Michael and Sumii, Eijiro},
file = {:Users/liang-tingchen/Dropbox/References/Hanada, Igarashi - 2014 - On Cross-Stage Persistence in Multi-Stage Programming.pdf:pdf},
pages = {103--118},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{On Cross-Stage Persistence in Multi-Stage Programming}},
url = {http://link.springer.com/10.1007/978-3-319-07151-0{\_}7},
volume = {8475},
year = {2014}
}
@incollection{Palmigiano2007,
abstract = {This paper is a study into some properties and applications of Moss' coalgebraic or ‘cover' modality ∇ . First we present two axiomatizations of this operator, and we prove these axiomatizations to be sound and complete with respect to basic modal and positive modal logic, respectively. More precisely, we introduce the notions of a modal ∇ -algebra and of a positive modal ∇ -algebra. We establish a categorical isomorphism between the category of modal ∇ -algebra and that of modal algebras, and similarly for positive modal ∇ -algebras and positive modal algebras. We then turn to a presentation, in terms of relation lifting, of the Vietoris hyperspace in topology. The key ingredient is an F-lifting construction, for an arbitrary set functor F, on the category Chu of two-valued Chu spaces and Chu transforms, based on relation lifting. As a case study, we show how to realize the Vietoris construction on Stone spaces as a special instance of this Chu construction for the (finite) power set functor. Finally, we establish a tight connection with the axiomatization of the modal ∇ -algebras.},
address = {Bergen, Norway},
author = {Palmigiano, Alessandra and Venema, Yde},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-540-73859-6_27},
editor = {Mossakowski, Till and Montanari, Ugo and Haveraaen, Magne},
file = {:Users/liang-tingchen/Dropbox/References/Palmigiano, Venema - 2007 - Nabla algebras and Chu spaces.pdf:pdf},
isbn = {978-3-540-73859-6},
keywords = {coalgebra,modal algebra,relation lifting,vietoris hyper-},
pages = {394--408},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Nabla algebras and Chu spaces}},
year = {2007}
}
@incollection{Mislove2004,
abstract = {Labelled Markov processes (LMPs) are automata whose transitions are given by probability distributions. In this paper we present a ‘universal' LMP as the spectrum of a commutative C *-algebra consisting of formal linear combinations of labelled trees. We characterize the state space of the universal LMP as the set of homomorphims from an ordered commutative monoid of labelled trees into the multiplicative unit interval. This yields a simple semantics for LMPs which is fully abstract with respect to probabilistic bisimilarity. We also consider LMPs with entry points and exit points in the setting of iteration theories. We define an iteration theory of LMPs by specifying its categorical dual: a certain category of C *-algebras. We find that the basic operations for composing LMPs have simple definitions in the dual category.},
author = {Mislove, Michael W. and Ouaknine, Jo{\"{e}}l and Pavlovi{\'{c}}, Dusko},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Walukiewicz, Igor},
file = {:Users/liang-tingchen/Dropbox/References/Mislove, Ouaknine, Pavlovi{\'{c}} - 2004 - Duality for labelled Markov processes.pdf:pdf},
pages = {393--707},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Duality for labelled Markov processes}},
url = {http://www.springerlink.com/index/jvfv65l0fqhm189w.pdf},
volume = {2987},
year = {2004}
}
@phdthesis{Vezzosi2018,
author = {Vezzosi, Andrea},
file = {:Users/liang-tingchen/Dropbox/References/Vezzosi - 2018 - On Induction, Coinduction and Equality in Martin-L{\"{o}}f and Homotopy Type Theory.pdf:pdf},
isbn = {978-91-7597-772-0},
publisher = {Chalmers University of Technology},
school = {Chalmers University of Technology and Gothenburg University},
title = {{On Induction, Coinduction and Equality in Martin-L{\"{o}}f and Homotopy Type Theory}},
year = {2018}
}
@book{Schneider2010,
abstract = {The CSP approach has been widely used in the specification, analysis and verification of concurrent and real-time systems, and for understanding the particular issues that can arise when concurrency is present. It provides a language which enables specifications and designs to be clearly expressed and understood, together with a supporting theory which allows them to be analyzed and shown to be correct. This book supports advanced level courses on concurrency covering timed and untimed CSP. The first half introduces the language of CSP, the primary semantic models (traces, failures, divergences and infinite traces), and their use in the modelling, analysis and verification of concurrent systems. The second half of the book introduces time into the language, brings in the timed semantic model (timed failures) and finally presents the theory of timewise refinement which links the two halves together. Accompanying website: http://www.cs.rhbnc.ac.uk/books/concurrency Containing the following: -Exercises and solutions -Instructors resources - Example CSP programs to run on FDR and ProBe},
author = {Schneider, Steve},
file = {:Users/liang-tingchen/Dropbox/References/Schneider - 2000 - Concurrent and Real-time Systems The CSP Approach.pdf:pdf},
pages = {526},
title = {{Concurrent and Real-time Systems: The CSP Approach}},
url = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471623733.html},
year = {2000}
}
@inproceedings{Abel2008a,
abstract = {A general version of the fundamental theorem for System F is presented which can be instantiated to obtain proofs of weak $\beta$- and $\beta$$\eta$-normalization and normalization by evaluation. {\textcopyright} 2008 Springer Berlin Heidelberg.},
author = {Abel, Andreas},
booktitle = {Logic for Programming, Artificial Intelligence, and Reasoning. LPAR 2008},
doi = {10.1007/978-3-540-89439-1_35},
editor = {Cervesato, Iliano and Veith, Helmut and Voronkov, Andrei},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2008 - Weak $\beta$$\eta$-normalization and normalization by evaluation for system F.pdf:pdf},
isbn = {3540894381},
issn = {03029743},
pages = {497--511},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Weak $\beta$$\eta$-normalization and normalization by evaluation for system F}},
volume = {5330},
year = {2008}
}
@article{Jay1995,
abstract = {Interpreting $\eta$-conversion as an expansion rule in the simply-typed $\lambda$-calculus maintains the confluence of reduction in a richer type structure. This use of expansions is supported by categorical models of reduction, where $\beta$-contraction, as the local counit, and $\eta$-expansion, as the local unit, are linked by local triangle laws. The latter form reduction loops, but strong normalization (to the long $\beta$$\eta$-normal forms) can be recovered by ‘cutting' the loops.},
author = {Jay, C Barry and Ghani, Neil},
doi = {10.1017/S0956796800001301},
file = {:Users/liang-tingchen/Dropbox/References/Jay, Ghani - 1995 - The virtues of eta-expansion.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {apr},
number = {2},
pages = {135--154},
title = {{The virtues of eta-expansion}},
url = {https://www.cambridge.org/core/product/identifier/S0956796800001301/type/journal{\_}article},
volume = {5},
year = {1995}
}
@article{Bou2008,
abstract = {This paper deals with many-valued modal logics, based only on the necessity operator, over a residuated lattice. We focus on three basic classes, according to the accessibility relation, of Kripke frames: the full class of frames evaluated in the residuated lattice (and so defining the minimum modal logic), the ones evaluated in the idempotent elements and the ones evaluated in 0 and 1. We show how to expand an axiomatization, with canonical constants in the language, of a finite residuated lattice into one of the modal logic, for each one of the three basic classes of Kripke frames, over the very lattice. And we also give axiomatizations for the case of a finite MV chain but this time without canonical constants.},
annote = {From Duplicate 2 ( 




















On the Minimum Many-Valued Modal Logic over a Finite Residuated Lattice




















- Bou, F{\'{e}}lix; Esteva, Francesc; Godo, Llu{\'{i}}s; Rodriguez, Ricardo O. )







},
archivePrefix = {arXiv},
arxivId = {0811.2107},
author = {Bou, F{\'{e}}lix Felix and Esteva, Francesc and Godo, Llu{\'{i}}s Lluis and Rodriguez, Ricardo O.},
doi = {10.1093/logcom/exp062},
eprint = {0811.2107},
file = {:Users/liang-tingchen/Dropbox/References/Bou et al. - 2008 - On the Minimum Many-Valued Modal Logic over a Finite Residuated Lattice.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {fuzzy logic,many-valued logic,many-valued modal logic,modal logic,substructural logic},
month = {nov},
number = {5},
pages = {1--53},
title = {{On the Minimum Many-Valued Modal Logic over a Finite Residuated Lattice}},
url = {http://arxiv.org/abs/0811.2107 http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exp062},
volume = {21},
year = {2008}
}
@phdthesis{Okasaki1996a,
abstract = {When a C programmer needs an efﬁcient data structure for a particular problem, he or she can often simply look one up in any of a number of good textbooks or handbooks. Unfortunately, programmers in functional languages such as Standard ML or Haskell do not have this luxury. Although some data structures designed for imperative languages such as C can be quite easily adapted to a functional setting, most cannot, usually because they depend in crucial ways on assignments, which are disallowed, or at least discouraged, in functional languages. To address this imbalance, we describe several techniques for designing functional data structures, and numerous original data structures based on these techniques, including multiple variations of lists, queues, double-ended queues, and heaps, many supporting more exotic features such as random access or efﬁcient catenation. In addition, we expose the fundamental role of lazy evaluation in amortized functional data structures. Traditional methods of amortization break down when old versions of a data structure, not just the most recent, are available for further processing. This property is known as persistence, and is taken for granted in functional languages. On the surface, persistence and amortization appear to be incompatible, but we show how lazy evaluation can be used to resolve this conﬂict, yielding amortized data structures that are efﬁcient even when used persistently. Turning this relationship between lazy evaluation and amortization around, the notion of amortization also provides the ﬁrst practical techniques for analyzing the time requirements of non-trivial lazy programs. Finally, our data structures offer numerous hints to programming language designers, illustrating the utility of combining strict and lazy evaluation in a single language, and providing non-trivial examples using polymorphic recursion and higher-order, recursive modules.},
author = {Okasaki, Chris},
file = {:Users/liang-tingchen/Dropbox/References/Okasaki - 1996 - Purely Functional Data Structures.pdf:pdf},
school = {Carnegie Mellon University},
title = {{Purely Functional Data Structures}},
year = {1996}
}
@misc{Carboni1997,
abstract = {If (e, M )is a factorization system on a category C , we define new classes of maps as follows: a map f : A ? B is in e' if each of its pullbacks lies in e(that is, if it is stably in e), and is in M * if some pullback of it along an effective descent map lies in M (that is, if it is locally in M ). We find necessary and sufficient conditions for (e', M * ) to be another factorization system, and show that a number of interesting factorization systems arise in this way. We further make the connexion with Galois theory, where M * is the class of coverings; and include self-contained modern accounts of factorization systems, descent theory, and Galois theory.},
author = {Carboni, Aurelio and Janelidze, George and Kelly, Gregory Maxwell and Par{\'{e}}, Robert},
booktitle = {Applied Categorical Structures},
doi = {10.1023/A:1008620404444},
file = {:Users/liang-tingchen/Dropbox/References/Carboni et al. - 1997 - On Localization and Stabilization for Factorization Systems.pdf:pdf},
issn = {0927-2852},
keywords = {Mathematics and Statistics},
month = {mar},
number = {1},
pages = {1--58},
publisher = {Springer Netherlands},
title = {{On Localization and Stabilization for Factorization Systems}},
url = {http://www.springerlink.com/content/x772343118423746/},
volume = {5},
year = {1997}
}
@article{Gregoire2002,
abstract = {Motivated by applications to proof assistants based on dependent types, we develop and prove correct a strong reducer and $\beta$-equivalence checker for the $\lambda$-calculus with products, sums, and guarded fixpoints. Our approach is based on compilation to the bytecode of an abstract machine performing weak reductions on non-closed terms, derived with minimal modifications from the ZAM machine used in the Objective Caml bytecode interpreter, and complemented by a recursive "read back" procedure. An implementation in the Coq proof assistant demonstrates important speed-ups compared with the original interpreter-based implementation of strong reduction in Coq.},
author = {Gr{\'{e}}goire, Benjamin and Leroy, Xavier},
doi = {10.1145/583852.581501},
file = {:Users/liang-tingchen/Dropbox/References/Gr{\'{e}}goire, Leroy - 2002 - A compiled implementation of strong reduction.pdf:pdf},
isbn = {1581134878},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {Abstract machine,Beta-equivalence,Calculus of constructions,Coq,Normalization by evaluation,Strong reduction,Virtual machine},
month = {sep},
number = {9},
pages = {235--246},
title = {{A compiled implementation of strong reduction}},
url = {http://portal.acm.org/citation.cfm?doid=583852.581501},
volume = {37},
year = {2002}
}
@article{Plotkin2004,
author = {Plotkin, Gordon D. and Power, A. John},
doi = {10.1016/j.entcs.2004.08.008},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Power - 2004 - Computational Effects and Operations An Overview.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {oct},
pages = {149--163},
title = {{Computational Effects and Operations: An Overview}},
url = {http://dx.doi.org/10.1016/j.entcs.2004.08.008},
volume = {73},
year = {2004}
}
@inproceedings{Gehrke2011,
author = {Gehrke, Mai},
booktitle = {Proceedings of the 36th International Symposiumd on Mathematical Foundations of Computer Science},
doi = {10.1007/978-3-642-22993-0_3},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke - 2011 - Duality and Recognition.pdf:pdf},
isbn = {9783642229923},
issn = {03029743},
pages = {3--18},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Duality and Recognition}},
url = {http://link.springer.com/10.1007/978-3-642-22993-0{\_}3},
volume = {6907},
year = {2011}
}
@phdthesis{Kick2003,
author = {Kick, Marco},
file = {:Users/liang-tingchen/Dropbox/References/Kick - 2003 - Coalgebraic Modelling of Timed Processes.pdf:pdf},
school = {University of Edinburgh},
title = {{Coalgebraic Modelling of Timed Processes}},
url = {http://www.lfcs.inf.ed.ac.uk/reports/04/ECS-LFCS-04-435/},
year = {2003}
}
@article{Orchard2019,
author = {Orchard, Dominic and Liepelt, Vilem-Benjamin and {Eades III}, Harley},
doi = {10.1145/3341714},
file = {:Users/liang-tingchen/Dropbox/References/Orchard, Liepelt, Eades III - 2019 - Quantitative program reasoning with graded modal types(2).pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {coeffects,graded modal types,implementation,linear types},
month = {jul},
number = {ICFP},
pages = {1--30},
title = {{Quantitative program reasoning with graded modal types}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341714},
volume = {3},
year = {2019}
}
@article{Erwig2004,
abstract = {The structure of monadic functional programs allows the integration of many different features by just changing the definition of the monad and not the rest of the program, which is a desirable feature from a software engineering and software maintenance point of view. We describe an algorithm for the automatic transformation of a group of functions into such a monadic form. We identify two correctness criteria and argue that the proposed transformation is at least correct in the sense that transformed programs yield the same results as the original programs modulo monad constructors. The translation of a set of functions into monadic form is in most cases only a first step toward an extension of a program by adding new features. The extended behavior can be realized by choosing an appropriate monad type and by inserting monadic actions into the functions that have been transformed into monadic form. We demonstrate an approach to the integration of monadic actions that is based on the idea of specifying context-dependent rewritings. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Erwig, Martin and Ren, Deling},
doi = {10.1016/j.scico.2004.03.004},
file = {:Users/liang-tingchen/Dropbox/References/Erwig, Ren - 2004 - Monadification of functional programs.pdf:pdf},
isbn = {0167-6423},
issn = {01676423},
journal = {Science of Computer Programming},
month = {aug},
number = {1-3},
pages = {101--129},
title = {{Monadification of functional programs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167642304000486},
volume = {52},
year = {2004}
}
@inproceedings{Straubing2002,
abstract = {There are many examples in the research literature of fami- lies of regular languages defined by purely model-theoretic means (that is, in terms of the kinds of formulas of predicate logic used to define them) that can be characterized algebraically (that is, in terms of the syntactic monoids or syntactic morphisms of the languages). In fact the existence of such algebraic characterizations appears to be the rule. The present paper gives an explanation of the phenomenon: A generalization of Eilenberg's variety theorem is proved, and then applied to logic. We find that a very wide assortment of families of regular languages de- fined in model-theoretic terms form varieties in this new sense,and that consequently membership in the family depends only on the syntactic morphism of the language.},
author = {Straubing, Howard},
booktitle = {LATIN 2002: Theoretical Informatics},
doi = {10.1007/3-540-45995-2_46},
editor = {Rajsbaum, Sergio},
file = {:Users/liang-tingchen/Dropbox/References/Straubing - 2002 - On logical descriptions of regular languages.pdf:pdf},
pages = {528--538},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On logical descriptions of regular languages}},
url = {http://www.springerlink.com/index/M7LL5EC23N259R0C.pdf},
year = {2002}
}
@article{Harding2013,
abstract = {We define a 2-category whose objects are fuzzy sets and whose maps are relations subject to certain natural conditions. We enrich this category with additional monoidal and involutive structure coming from t-norms and negations on the unit interval. We develop the basic properties of this category and consider its relation to other familiar categories. A discussion is made of extending these results to the setting of type-2 fuzzy sets. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Harding, John and Walker, Carol and Walker, Elbert},
doi = {10.1016/j.fss.2013.04.004},
file = {:Users/liang-tingchen/Dropbox/References/Harding, Walker, Walker - 2013 - Categories with fuzzy sets and relations.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {2-Category,Biproducts,Category with involution,Fuzzy sets,Relations as morphisms,Symmetric monoidal tensor},
pages = {149--165},
publisher = {Elsevier},
title = {{Categories with fuzzy sets and relations}},
url = {http://dx.doi.org/10.1016/j.fss.2013.04.004},
volume = {256},
year = {2013}
}
@inproceedings{Dwork2011a,
abstract = {Differential privacy describes a promise, made by a data curator to a data subject: you will not be affected, adversely or otherwise, by allowing your data to be used in any study, no matter what other studies, data sets, or information from other sources is available. At their best, differentially private database mechanisms can make confidential data widely available for accurate data analysis, without resorting to data clean rooms, institutional review boards, data usage agreements, restricted views, or data protection plans. To enjoy the fruits of the research described in this tutorial, the data analyst must accept that raw data can never be accessed directly and that eventually data utility is consumed: overly accurate answers to too many questions will destroy privacy. The goal of algorithmic research on differential privacy is to postpone this inevitability as long as possible.},
author = {Dwork, Cynthia},
booktitle = {2011 IEEE 52nd Annual Symposium on Foundations of Computer Science},
doi = {10.1109/FOCS.2011.88},
file = {:Users/liang-tingchen/Dropbox/References/Dwork - 2011 - The Promise of Differential Privacy A Tutorial on Algorithmic Techniques.pdf:pdf},
isbn = {978-0-7695-4571-4},
issn = {02725428},
keywords = {differential privacy,privacy,private data analysis},
month = {oct},
pages = {1--2},
publisher = {IEEE},
title = {{The Promise of Differential Privacy: A Tutorial on Algorithmic Techniques}},
url = {http://ieeexplore.ieee.org/document/6108143/},
year = {2011}
}
@incollection{Altenkirch2010a,
abstract = {The recent success of languages like Agda and Coq demonstrates the potential of using dependent types for programming. These systems rely on many high-level features like datatype definitions, pattern matching and implicit arguments to facilitate the use of the languages. However, these features complicate the metatheoretical study and are a potential source of bugs. To address these issues we introduce $\Pi$∑, a dependently typed core language. It is small enough for metatheoretical study and the type checker is small enough to be formally verified. In this language there is only one mechanism for recursion-used for types, functions and infinite objects-and an explicit mechanism to control unfolding, based on lifted types. Furthermore structural equality is used consistently for values and types; this is achieved by a new notion of $\alpha$-equality for recursive definitions. We show, by translating several high-level constructions, that $\Pi$∑ is suitable as a core language for dependently typed programming. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
author = {Altenkirch, Thorsten and Danielsson, Nils Anders and L{\"{o}}h, Andres and Oury, Nicolas},
booktitle = {Functional and Logic Programming. FLOPS 2010},
doi = {10.1007/978-3-642-12251-4_5},
editor = {Blume, Matthias and Kobayashi, Naoki and Vidal, Germ{\'{a}}n},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch et al. - 2010 - $\Pi$$\Sigma$ Dependent Types without the Sugar.pdf:pdf},
isbn = {3642122507},
issn = {03029743},
pages = {40--55},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{$\Pi$$\Sigma$: Dependent Types without the Sugar}},
url = {http://link.springer.com/10.1007/978-3-642-12251-4{\_}5},
volume = {6009},
year = {2010}
}
@article{Myers2011,
author = {Myers, Robert Samuel Ralph},
file = {:Users/liang-tingchen/Dropbox/References/Myers - 2011 - Rational Coalgebraic Machines in Varieties Languages, Completeness and Automatic Proofs.pdf:pdf},
institution = {Imperial College London},
month = {oct},
pages = {287},
title = {{Rational Coalgebraic Machines in Varieties : Languages, Completeness and Automatic Proofs.}},
year = {2011}
}
@book{Adamek1989,
address = {Dordrecht},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Trnkov{\'{a}}, V{\v{e}}ra},
isbn = {978-0792300106},
pages = {492},
publisher = {Kluwer Academic Publishers},
series = {Mathematics and Its Applications},
title = {{Automata and algebras in categories}},
year = {1989}
}
@article{Shafer2016,
abstract = {The book that launched the Dempster–Shafer theory of belief functions appeared 40 years ago. This intellectual autobiography looks back on how I came to write the book and how its ideas played out in my later work.},
author = {Shafer, Glenn},
doi = {10.1016/j.ijar.2016.07.009},
file = {:Users/liang-tingchen/Dropbox/References/Shafer - 2016 - A Mathematical Theory of Evidence turns 40.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Belief functions,Causality,Dempster–Shafer theory,Game-theoretic probability},
number = {November 1946},
pages = {7--25},
publisher = {Elsevier Inc.},
title = {{A Mathematical Theory of Evidence turns 40}},
url = {http://dx.doi.org/10.1016/j.ijar.2016.07.009},
volume = {79},
year = {2016}
}
@inproceedings{Hirota2014,
address = {New York, New York, USA},
author = {Hirota, Noriko and Asai, Kenichi},
booktitle = {Proceedings of the ACM SIGPLAN 2014 Workshop on Programming Languages meets Program Verification - PLPV '14},
doi = {10.1145/2541568.2541572},
file = {:Users/liang-tingchen/Dropbox/References/Hirota, Asai - 2014 - Formalizing a correctness property of a type-directed partial evaluator.pdf:pdf},
isbn = {9781450325677},
keywords = {abstract syntax,parametric higher-order,proof assistant coq,type-directed partial evaluator},
pages = {41--46},
publisher = {ACM Press},
title = {{Formalizing a correctness property of a type-directed partial evaluator}},
url = {http://dl.acm.org/citation.cfm?doid=2541568.2541572},
year = {2014}
}
@article{Barr1994,
author = {Barr, Michael},
doi = {10.1016/0304-3975(94)90060-4},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1994 - Additions and corrections to “Terminal coalgebras in well-founded set theory”.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {feb},
number = {1},
pages = {189--192},
title = {{Additions and corrections to “Terminal coalgebras in well-founded set theory”}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397594900604},
volume = {124},
year = {1994}
}
@article{Severi2019,
abstract = {We investigate a modality for controlling the behaviour of recursive functional programs on infinite structures which is completely silent in the syntax. The latter means that programs do not contain “marks” showing the application of the introduction and elimination rules for the modality. This shifts the burden of controlling recursion from the programmer to the compiler. To do this, we introduce a typed lambda calculus {\`{a}} la Curry with a silent modality and guarded recursive types. The typing discipline guarantees normalisation and can be transformed into an algorithm which infers the type of a program.},
author = {Severi, Paula},
doi = {10.23638/LMCS-15(1:8)2019},
file = {:Users/liang-tingchen/Dropbox/References/Severi - 2019 - A light modality for recursion.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Typed lambda calculus,denotational semantics,infinite data,productivity,type inference},
number = {1},
pages = {8:1--8:32},
title = {{A light modality for recursion}},
volume = {15},
year = {2019}
}
@inproceedings{Murase2017,
author = {Murase, Yuito},
booktitle = {LFMTP '17 Proceedings of the Workshop on Logical Frameworks and Meta-Languages: Theory and Practice Oxford, United Kingdom — September 08 - 08, 2017},
editor = {Miculan, Marino and Rabe, Florian},
file = {:Users/liang-tingchen/Dropbox/References/Murase - 2017 - Kripke-Style Contextual Modal Type Theory.pdf:pdf},
keywords = {contextual modal type theory,lambda calculus,modal logic},
publisher = {ACM Press},
title = {{Kripke-Style Contextual Modal Type Theory}},
year = {2017}
}
@phdthesis{Dagand2013a,
abstract = {This dissertation defends the idea of a closed dependent type the- ory whose inductive types are encoded in a universe. Each induc- tive definition arises by interpreting its description – itself a first- class citizen in the type theory. Datatype-generic programming thus becomes ordinary programming. This approach is illustrated by several generic programs. We then introduce an elaboration of inductive definitions down to the universe of datatypes. By elaborating an inductive definition – a syntactic artefact – to its code – its type theoretic denotation – we obtain an internalised account of inductive types inside type theory. This is a small step toward bootstrapping, i.e. implement- ing the inductive fragment in the type theory itself. Building upon this universe of datatypes, ornaments let us treat datatypes as the combination of a structure and a logic: they relate datatypes through their common structure. We set out to ratio- nalise this calculus of structures. We study a categorical model of ornaments, based on Cartesian morphisms of containers. We also illustrate the adequacy of our model by recasting the standard id- ioms into the categorical mould, and by translating the discovered categorical structures into type theoretic artefacts. Nonetheless, the extreme accuracy of these finely indexed datatypes is a curse for code reuse. Similar functions must be du- plicated across similarly structured – but logically incompatible – indexed datatypes. We shall see how code reuse can be achieved by ornamenting functions. We thus capture the relationship between functions such as the addition of natural numbers and the concate- nation of lists. We also demonstrate how the implementation of the former informs the implementation of the latter.},
author = {Dagand, Pierre-{\'{E}}variste},
file = {:Users/liang-tingchen/Dropbox/References/Dagand - 2013 - A Cosmology of Datatypes.pdf:pdf},
school = {University of Strathclyde},
title = {{A Cosmology of Datatypes}},
type = {Doctoral thesis},
year = {2013}
}
@article{Sedgewick1977,
abstract = {The Quicksort sorting algorithm and its best variants are presented and analyzed. Results are derived which make it possible to obtain exact formulas describing the total expected running time of particular implementations on real computers of Quicksort and an improvement called the median-of-three modification. Detailed analysis of the effect of an implementation technique called loop unwrapping is presented. The paper is intended not only to present results of direct practical utility, but also to illustrate the intriguing mathematics which arises in the complete analysis of this important algorithm.},
author = {Sedgewick, Robert},
doi = {10.1007/BF00289467},
file = {:Users/liang-tingchen/Dropbox/References/Sedgewick - 1977 - The analysis of Quicksort programs.pdf:pdf},
issn = {0001-5903},
journal = {Acta Informatica},
number = {4},
pages = {327--355},
title = {{The analysis of Quicksort programs}},
url = {http://link.springer.com/10.1007/BF00289467},
volume = {7},
year = {1977}
}
@article{RIJKE2015,
abstract = {Homotopy type theory may be seen as an internal language for the ∞-category of weak ∞-groupoids. Moreover, weak ∞-groupoids model the univalence axiom. Voevodsky proposes this (language for) weak ∞-groupoids as a new foundation for Mathematics called the univalent foundations. It includes the sets as weak ∞-groupoids with contractible connected components, and thereby it includes (much of) the traditional set theoretical foundations as a special case. We thus wonder whether those ‘discrete' groupoids do in fact form a (predicative) topos. More generally, homotopy type theory is conjectured to be the internal language of ‘elementary' of ∞-toposes. We prove that sets in homotopy type theory form a $\Pi$W-pretopos. This is similar to the fact that the 0-truncation of an ∞-topos is a topos. We show that both a subobject classifier and a 0-object classifier are available for the type theoretical universe of sets. However, both of these are large and moreover the 0-object classifier for sets is a function between 1-types (i.e. groupoids) rather than between sets. Assuming an impredicative propositional resizing rule we may render the subobject classifier small and then we actually obtain a topos of sets.},
author = {Rijke, Egbert and Spitters, Bas},
doi = {10.1017/S0960129514000553},
file = {:Users/liang-tingchen/Dropbox/References//Rijke, Spitters - 2015 - Sets in homotopy type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {05},
pages = {1172--1202},
title = {{Sets in homotopy type theory}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129514000553},
volume = {25},
year = {2015}
}
@incollection{Jacobs2010,
author = {Jacobs, Bart},
booktitle = {Proceedings of 6th IFIP TC 1/WG 2.2 International Conference},
doi = {10.1007/978-3-642-15240-5_1},
editor = {Calude, Cristian S. and Sassone, Vladimiro},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2010 - Convexity, Duality and Effects.pdf:pdf},
number = {1},
pages = {1--19},
publisher = {Springer Berlin Heidelberg},
series = {IFIP Advances in Information and Communication Technology},
title = {{Convexity, Duality and Effects}},
url = {http://link.springer.com/10.1007/978-3-642-15240-5{\_}1},
year = {2010}
}
@article{Ada,
abstract = {In the theory of accessible categories, pure subobjects, i.e. filtered colimits of split monomorphisms, play an important role. Here we investigate pure quotients, i.e., filtered colimits of split epimorphisms. For example, in abelian, finitely accessible categories, these are precisely the cokernels of pure subobjects, and pure subobjects are precisely the kernels of pure quotients.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}} - 2004 - On pure quotients and pure subobjects.pdf:pdf},
issn = {0011-4642},
journal = {Czechoslovak Mathematical Journal},
keywords = {abelian category,locally presentable category,pure quotient,pure subobject,semi-abelian category},
language = {eng},
number = {3},
pages = {623--636},
title = {{On pure quotients and pure subobjects}},
url = {http://dml.cz/dmlcz/127916},
volume = {54},
year = {2004}
}
@techreport{Mortberg2019,
abstract = {Cubical methods have played an important role in the development of Homotopy Type Theory and Univalent Foundations (HoTT/UF) in recent years. The original motivation behind these developments was to give constructive meaning to Voevodsky's univalence axiom, but they have since then led to a range of new results. Among the achievements of these methods is the design of new type theories and proof assistants with native support for notions from HoTT/UF, syntactic and semantic consistency results for HoTT/UF, as well as a variety of independence results and establishing that the univalence axiom does not increase the proof theoretic strength of type theory. This paper is based on lecture notes that were written for the 2019 Homotopy Type Theory Summer School at Carnegie Mellon University. The goal of these lectures was to give an introduction to cubical methods in HoTT/UF and provide sufficient background in order to make the current research in this very active area of HoTT/UF more accessible to newcomers. The focus of these notes is hence on both the syntactic and semantic aspects of these methods, in particular on cubical type theory and the various cubical set categories that give meaning to these theories.},
author = {M{\"{o}}rtberg, Anders},
file = {:Users/liang-tingchen/Dropbox/References/M{\"{o}}rtberg - 2019 - Cubical Methods in Homotopy Type Theory and Univalent Foundations.pdf:pdf},
keywords = {2019,acknowledgments,are borrowed from the,cavallo for commenting on,cubical set models,cubical type theory,d,earlier versions of these,elisabeth bonnevier and evan,grateful to carlo angiuli,homotopy type theory,like to thank the,multiple explanations and diagrams,notes,ph,the author is very,the author would also,thesis of angiuli,univalent foundations},
pages = {1--39},
title = {{Cubical Methods in Homotopy Type Theory and Univalent Foundations}},
url = {https://staff.math.su.se/anders.mortberg/papers/cubicalmethods.pdf},
year = {2019}
}
@article{Hasuo2011b,
author = {Hasuo, Ichiro and Jacobs, Bart},
doi = {10.1017/S0960129510000551},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo, Jacobs - 2011 - Traces for coalgebraic components.pdf:pdf},
isbn = {0960129510},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {02},
pages = {267--320},
title = {{Traces for coalgebraic components}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129510000551},
volume = {21},
year = {2011}
}
@phdthesis{Velebil1998,
author = {Velebil, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Velebil - 1998 - Categorical Domain Theory.pdf:pdf},
pages = {142},
school = {Czech Technical University},
title = {{Categorical Domain Theory}},
year = {1998}
}
@article{VanDalen1977,
abstract = {The comprehension principle of second order arithmetic asserts the existence of certain species (sets) corresponding to properties of natural numbers. In the intuitionistic theory of sequences of natural numbers there is an analoguous principle, implicit in Brouwer's writing and explicitly stated by Kripke, which asserts the existence of certain sequences corresponding to statements. The justification of this principle, Kripke's Schema , makes use of the concept of the so-called creative subject . For more information the reader is referred to Troelstra [5].},
author = {van Dalen, D.},
doi = {10.2307/2272124},
file = {:Users/liang-tingchen/Dropbox/References/van Dalen - 1977 - The use of Kripke's schema as a reduction principle.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {jun},
number = {2},
pages = {238--240},
title = {{The use of Kripke's schema as a reduction principle}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200050404/type/journal{\_}article},
volume = {42},
year = {1977}
}
@inproceedings{Calin2009,
author = {Calin, Georgel and Myers, Rob and Pattinson, Dirk and Schr{\"{o}}der, Lutz},
booktitle = {Proceedings of the 5th Workshop on Methods for Modalities (M4M5 2007)},
doi = {10.1016/j.entcs.2009.02.028},
file = {:Users/liang-tingchen/Dropbox/References/Calin et al. - 2009 - CoLoSS The Coalgebraic Logic Satisfiability Solver.pdf:pdf},
issn = {15710661},
keywords = {automatic proving,coalgebra,modal logic},
pages = {41--54},
series = {ENTCS},
title = {{CoLoSS: The Coalgebraic Logic Satisfiability Solver}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066109000334},
volume = {231},
year = {2009}
}
@article{Domingo-Ferrer2008,
abstract = {k-Anonymity is a privacy property requiring that all combinations of key attributes in a database be repeated at least for k records. It has been shown that k-anonymity alone does not always ensure privacy. A number of sophistications of k-anonymity have been proposed, like p-sensitive k-anonymity, l-diversity and t-closeness. This paper explores the shortcomings of those properties, none of which turns out to be completely convincing.},
author = {Domingo-Ferrer, Josep and Torra, Vicen{\c{c}}},
doi = {10.1109/ARES.2008.97},
file = {:Users/liang-tingchen/Dropbox/References/Domingo-Ferrer, Torra - 2008 - A critique of {\$}k{\$}-anonymity and some of its enhancements.pdf:pdf},
isbn = {0769531024},
journal = {ARES 2008 - 3rd International Conference on Availability, Security, and Reliability, Proceedings},
pages = {990--993},
title = {{A critique of {\$}k{\$}-anonymity and some of its enhancements}},
year = {2008}
}
@article{Troelstra1995,
abstract = {The paper deals with two versions of the fragment with unit, tensor, linear implication and storage operator (the exponential!) of intuitionistic linear logic. The first version, ILL, appears in a paper by Benton, Bierman, Hyland and de Paiva; the second one, ILL+, is described in this paper. ILL has a contraction rule and an introduction rule !I for the exponential; in ILL+, instead of a contraction rule, multiple occurrences of labels for assumptions are permitted under certain conditions; moreover, there is a different introduction rule for the exponential, !I+, which is closer in spirit to the necessitation rule for the normalizable version of S4 discussed by Prawitz in his monograph "Natural Deduction". It is relatively easy to adapt Prawitz's treatment of natural deduction for intuitionistic logic to ILL+; in particular one can formulate a notion of strong validity (as in Prawitz's "Ideas and Results in Proof Theory") permitting a proof of strong normalization. The conversion rules for ILL explicitly mentioned in the paper by Benton et al. do not suffice for normal forms with subformula property, but we can show that this can be remedied by addition of a special permutation conversion plus some "satellite" permutation conversions. Some discussion of the categorical models which might correspond to ILL+ is given. {\textcopyright} 1995.},
author = {Troelstra, A.S.},
doi = {10.1016/0168-0072(93)E0078-3},
file = {:Users/liang-tingchen/Dropbox/References/Troelstra - 1995 - Natural deduction for intuitionistic linear logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {may},
number = {1},
pages = {79--108},
title = {{Natural deduction for intuitionistic linear logic}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0168007293E00783},
volume = {73},
year = {1995}
}
@article{Bauer2012,
abstract = {We prove that the category of left-handed skew distributive lattices with zero and proper homomorphisms is dually equivalent to a category of sheaves over local Priestley spaces. Our result thus provides a non-commutative version of classical Priestley duality for distributive lattices. The result also generalizes the recent development of Stone duality for skew Boolean algebras.},
archivePrefix = {arXiv},
arxivId = {1206.5848},
author = {Bauer, Andrej and Cvetko-Vah, Karin and Gehrke, Mai and van Gool, Sam J. and Kudryavtseva, Ganna},
eprint = {1206.5848},
file = {:Users/liang-tingchen/Dropbox/References/Bauer et al. - 2012 - A non-commutative Priestley duality.pdf:pdf},
month = {jun},
pages = {19},
title = {{A non-commutative Priestley duality}},
url = {http://arxiv.org/abs/1206.5848},
year = {2012}
}
@article{Crary2007,
author = {Crary, Karl and Harper, Robert},
doi = {10.1016/j.entcs.2007.02.010},
file = {:Users/liang-tingchen/Dropbox/References/Crary, Harper - 2007 - Syntactic logical relations for polymorphic and recursive types.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {data abstraction,lambda calculus and related,logics of programs,operational semantics,polymorphism,systems,type structure},
month = {apr},
pages = {259--299},
title = {{Syntactic logical relations for polymorphic and recursive types}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066107000825},
volume = {172},
year = {2007}
}
@article{Company1931,
author = {Arbib, Michael A. and Manes, Ernest G.},
doi = {10.1016/0022-4049(80)90090-0},
file = {:Users/liang-tingchen/Dropbox/References/Arbib, Manes - 1980 - Machines in a category.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {dec},
pages = {9--20},
title = {{Machines in a category}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404980900900},
volume = {19},
year = {1980}
}
@incollection{Licata2016,
author = {Licata, Daniel R. and Shulman, Michael},
booktitle = {Logical Foundations of Computer Science. LFCS 2016},
doi = {10.1007/978-3-319-27683-0_16},
editor = {Artemov, Sergei and Nerode, Anil},
file = {:Users/liang-tingchen/Dropbox/References/Licata, Shulman - 2016 - Adjoint Logic with a 2-Category of Modes.pdf:pdf},
isbn = {9783319276823},
issn = {16113349},
pages = {219--235},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Adjoint Logic with a 2-Category of Modes}},
url = {http://link.springer.com/10.1007/978-3-319-27683-0{\_}16},
volume = {9537},
year = {2016}
}
@incollection{Amin2019,
abstract = {Meta-interpreters in Prolog are a powerful and elegant way to implement language extensions and non-standard semantics. But how can we bring the benefits of Prolog-style meta-interpreters to systems that combine functional and logic programming? In Prolog, a program can access its own structure via reflection, and meta-interpreters are simple to implement because the “pure” core language is small. Can we achieve similar elegance and power for larger systems that combine different paradigms? In this paper, we present a particular kind of functional logic meta-programming, based on embedding a small first-order logic system in an expressive host language. Embedded logic engines are not new, as exemplified by various systems including miniKanren in Scheme and LogicT in Haskell. However, previous embedded systems generally lack meta-programming capabilities in the sense of meta-interpretation. Indeed, shallow embeddings usually do not support reflection. Instead of relying on reflection for meta-programming, we show how to adapt popular multi-stage programming techniques to a logic programming setting and use the embedded logic to generate reified first-order structures, which are again simple to interpret. Our system has an appealing power-to-weight ratio, based on the simple and general notion of dynamically scoped mutable variables. We also show how, in many cases, non-standard semantics can be realized without explicit reification and interpretation, but instead by customizing program execution through the host language. As a key example, we extend our system with a tabling/memoization facility. The need to interact with mutable variables renders this a highly nontrivial challenge, and the crucial insight is to extract symbolic representations of their side effects from memoized rules. We demonstrate that multiple independent semantic modifications can be combined successfully in our system, for example tabling and tracing.},
author = {Amin, Nada and Byrd, William E. and Rompf, Tiark},
booktitle = {Programming Languages and Systems. APLAS 2019},
doi = {10.1007/978-3-030-34175-6_12},
editor = {Lin, Anthony Widjaja},
file = {:Users/liang-tingchen/Dropbox/References/Amin, Byrd, Rompf - 2019 - Lightweight Functional Logic Meta-Programming.pdf:pdf},
isbn = {9783030341749},
issn = {16113349},
pages = {225--243},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Lightweight Functional Logic Meta-Programming}},
url = {http://dx.doi.org/10.1007/978-3-030-34175-6{\_}12 http://link.springer.com/10.1007/978-3-030-34175-6{\_}12},
volume = {11893},
year = {2019}
}
@article{Courcelle1983,
abstract = {Infinite trees naturally arise in the formalization and the study of the semantics of programming languages. This paper investigates some of their combinatorial and algebraic properties that are especially relevant to semantics. This paper is concerned in particular with regular and algebraic infinite trees, not with regular or algebraic sets of infinite trees. For this reason most of the properties stated in this work become trivial when restricted either to finite trees or to infinite words. It presents a synthesis of various aspects of infinite trees, investigated by different authors in different contexts and hopes to be a unifying step towards a theory of infinite trees that could take place near the theory of formal languages and the combinatorics of thefree monoid. {\textcopyright} 1983.},
author = {Courcelle, Bruno},
doi = {10.1016/0304-3975(83)90059-2},
file = {:Users/liang-tingchen/Dropbox/References/Courcelle - 1983 - Fundamental properties of infinite trees.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {2},
pages = {95--169},
title = {{Fundamental properties of infinite trees}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397583900592},
volume = {25},
year = {1983}
}
@article{Harper2007,
abstract = {The LF logical framework codifies a methodology for representing deductive systems, such as programming languages and logics, within a dependently typed $\lambda$-calculus. In this methodology, the syntactic and deductive apparatus of a system is encoded as the canonical forms of associated LF types; an encoding is correct ( adequate ) if and only if it defines a compositional bijection between the apparatus of the deductive system and the associated canonical forms. Given an adequate encoding, one may establish metatheoretic properties of a deductive system by reasoning about the associated LF representation. The Twelf implementation of the LF logical framework is a convenient and powerful tool for putting this methodology into practice. Twelf supports both the representation of a deductive system and the mechanical verification of proofs of metatheorems about it. The purpose of this article is to provide an up-to-date overview of the LF $\lambda$-calculus, the LF methodology for adequate representation, and the Twelf methodology for mechanizing metatheory. We begin by defining a variant of the original LF language, called Canonical LF , in which only canonical forms (long $\beta$$\eta$-normal forms) are permitted. This variant is parameterized by a subordination relation , which enables modular reasoning about LF representations. We then give an adequate representation of a simply typed $\lambda$-calculus in Canonical LF, both to illustrate adequacy and to serve as an object of analysis. Using this representation, we formalize and verify the proofs of some metatheoretic results, including preservation, determinacy, and strengthening. Each example illustrates a significant aspect of using LF and Twelf for formalized metatheory.},
author = {HARPER, ROBERT and LICATA, DANIEL R.},
doi = {10.1017/S0956796807006430},
file = {:Users/liang-tingchen/Dropbox/References/HARPER, LICATA - 2007 - Mechanizing metatheory in a logical framework.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {4-5},
pages = {613--673},
title = {{Mechanizing metatheory in a logical framework}},
url = {https://www.cambridge.org/core/product/identifier/S0956796807006430/type/journal{\_}article},
volume = {17},
year = {2007}
}
@article{VanBreugel2008,
abstract = {Desharnais, Gupta, Jagadeesan and Panangaden introduced a family of behavioural pseudometrics for probabilistic transition systems. These pseudometrics are a quantitative analogue of probabilistic bisimilarity. Distance zero captures probabilistic bisimilarity. Each pseudometric has a discount factor, a real number in the interval (0, 1]. The smaller the discount factor, the more the future is discounted. If the discount factor is one, then the future is not discounted at all. Desharnais et al. showed that the behavioural distances can be calculated up to any desired degree of accuracy if the discount factor is smaller than one. In this paper, we show that the distances can also be approximated if the future is not discounted. A key ingredient of our algorithm is Tarski's decision procedure for the first order theory over real closed fields. By exploiting the Kantorovich-Rubinstein duality theorem we can restrict to the existential fragment for which more efficient decision procedures exist.},
author = {van Breugel, Franck and Sharma, Babita and Worrell, James},
doi = {10.2168/LMCS-4(2:2)2008},
editor = {Seidl, Helmut},
file = {:Users/liang-tingchen/Dropbox/References/van Breugel, Sharma, Worrell - 2008 - Approximating a behavioural pseudometric without discount for probabilistic systems.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,approximation algorithm,behavioural pseudometric,larity,probabilistic bisimi-,probabilistic transition system},
month = {apr},
number = {2},
pages = {2},
title = {{Approximating a behavioural pseudometric without discount for probabilistic systems}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=353},
volume = {4},
year = {2008}
}
@inproceedings{Wilke1991,
author = {Wilke, Thomas},
booktitle = {Automata, Languages and Programming, 18th Colloquium, Madrid, Spain, July 8–12, 1991 Proceedings},
doi = {10.1007/3-540-54233-7_166},
editor = {Albert, Javier Leach and Monien, Burkhard and Artalejo, Mario Rodr{\'{i}}guez},
file = {:Users/liang-tingchen/Dropbox/References/Wilke - 1991 - An EILENBERG theorem for ∞-languages.pdf:pdf},
pages = {588--599},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{An EILENBERG theorem for ∞-languages}},
url = {http://link.springer.com/10.1007/3-540-54233-7{\_}166},
year = {1991}
}
@inproceedings{Lungu2018,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (On Subtyping in Type Theories with Canonical Objects - Lungu, Georgiana Elena; Luo, Zhaohui)

Keywords: subtyping, type theory, conservative extension, canonical objects},
author = {Lungu, Georgiana Elena and Luo, Zhaohui},
booktitle = {22nd International Conference on Types for Proofs and Programs (TYPES 2016)},
doi = {10.4230/LIPIcs.TYPES.2016.13},
editor = {Ghilezan, Silvia and Geuvers, Herman and Iveti{\'{c}}, Jelena},
file = {:Users/liang-tingchen/Dropbox/References//Lungu, Luo - 2018 - On Subtyping in Type Theories with Canonical Objects.pdf:pdf},
isbn = {978-3-95977-065-1},
issn = {1868-8969},
keywords = {13,2016,4230,acknowledgements thanks go to,and phrases subtyping,anonymous referees for their,canonical objects,conservative extension,digital object identifier 10,during his visit to,helpful comments,helpful remarks on this,lipics,royal holloway and the,sergei soloviev for extremely,type theory,types,work},
number = {13},
pages = {13:1----13:31},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{On Subtyping in Type Theories with Canonical Objects}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9849},
volume = {97},
year = {2018}
}
@inproceedings{Wallace2010,
address = {New York, New York, USA},
author = {Najd, Shayan and Lindley, Sam and Svenningsson, Josef and Wadler, Philip},
booktitle = {Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation - PEPM 2016},
doi = {10.1145/2847538.2847541},
file = {:Users/liang-tingchen/Dropbox/References/Najd et al. - 2016 - Everything old is new again quoted domain-specific languages.pdf:pdf},
isbn = {9781450340977},
issn = {10397116},
keywords = {bedded language,domain-specific language,dsl,edsl,em-,might benefit from the,normalisation,partic-,qdsl,quotation,same technique,staged computation,subformula principle,ture that other dsls,ularly those that perform,where host code at},
number = {10-DEC-2010},
pages = {25--36},
publisher = {ACM Press},
title = {{Everything old is new again: quoted domain-specific languages}},
url = {http://dl.acm.org/citation.cfm?doid=2847538.2847541},
year = {2016}
}
@article{Kelly2004,
author = {Kelly, Gregory Maxwell and Lack, Stephen},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Lack - 2004 - Monoidal functors generated by adjunctions, with applications to transport of structure.pdf:pdf},
journal = {Fields Institute Communications},
pages = {319--340},
title = {{Monoidal functors generated by adjunctions, with applications to transport of structure}},
volume = {43},
year = {2004}
}
@article{Simpson2012,
abstract = {This paper investigates aspects of measure and randomness in the context of locale theory (point-free topology). We prove that every measure (continuousvaluation) $\mu$, on the -frame of opens of a fitted -localeX, extends to a measure on the lattice of all -sublocalesof X (Theorem 1). Furthermore, when $\mu$ is a finite measure with $\mu$(X)=M, the -localeX has a smallest -sublocaleof measure M (Theorem 2). In particular, when $\mu$ is a probability measure, X has a smallest -sublocaleof measure 1. All prefixes can be dropped from these statements whenever X is a strongly Lindel{\"{o}}f locale, as is the case in the following applications. When $\mu$ is the Lebesgue measure on the Euclidean space Rn, Theorem 1 produces an isometry-invariant measure that, via the inclusion of the powerset P(Rn) in the lattice of sublocales, assigns a weight to every subset of Rn. (Contradiction is avoided because disjoint subsets need not be disjoint as sublocales.) When $\mu$ is the uniform probability measure on Cantor space 0, 1 , the smallest measure-1 sublocale, given by Theorem 2, provides a canonical locale of random sequences, where randomness means that all probabilistic laws (measure-1 properties) are satisfied. {\textcopyright} 2012 Elsevier B.V.},
author = {Simpson, Alex},
doi = {10.1016/j.apal.2011.12.014},
file = {:Users/liang-tingchen/Dropbox/References/Simpson - 2012 - Measure, randomness and sublocales.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Foundations of measure theory,Foundations of probability theory,Locale theory},
month = {nov},
number = {11},
pages = {1642--1659},
publisher = {Elsevier B.V.},
title = {{Measure, randomness and sublocales}},
url = {http://dx.doi.org/10.1016/j.apal.2011.12.014 https://linkinghub.elsevier.com/retrieve/pii/S0168007211001874},
volume = {163},
year = {2012}
}
@incollection{Kuzu2011,
abstract = {For over fifty years, “record linkage” procedures have been refined to integrate data in the face of typographical and semantic errors. These procedures are traditionally performed over personal identifiers (e.g., names), but in modern decentralized environments, privacy concerns have led to regulations that require the obfuscation of such attributes. Various techniques have been proposed to resolve the tension, including secure multi-party computation protocols, however, such protocols are computationally intensive and do not scale for real world linkage scenarios. More recently, procedures based on Bloom filter encoding (BFE) have gained traction in various applications, such as healthcare, where they yield highly accurate record linkage results in a reasonable amount of time. Though promising, no formal security analysis has been designed or applied to this emerging model, which is of concern considering the sensitivity of the corresponding data. In this paper, we introduce a novel attack, based on constraint satisfaction, to provide a rigorous analysis for BFE and guidelines regarding how to mitigate risk against the attack. In addition, we conduct an empirical analysis with data derived from public voter records to illustrate the feasibility of the attack. Our investigations show that the parameters of the BFE protocol can be configured to make it relatively resilient to the proposed attack without significant reduction in record linkage performance.},
author = {Kuzu, Mehmet and Kantarcioglu, Murat and Durham, Elizabeth and Malin, Bradley},
booktitle = {Privacy Enhancing Technologies. PETS 2011},
doi = {10.1007/978-3-642-22263-4_13},
editor = {Fischer-H{\"{u}}bner, Simone and Hopper, Nicholas},
file = {:Users/liang-tingchen/Dropbox/References/Kuzu et al. - 2011 - A constraint satisfaction cryptanalysis of bloom filters in private record linkage.pdf:pdf},
pages = {226--245},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A constraint satisfaction cryptanalysis of bloom filters in private record linkage}},
volume = {6794},
year = {2011}
}
@article{Carboni1987,
author = {Carboni, A. and Walters, R.F.C.},
doi = {10.1016/0022-4049(87)90121-6},
file = {:Users/liang-tingchen/Dropbox/References/Carboni, Walters - 1987 - Cartesian bicategories I.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-2},
pages = {11--32},
title = {{Cartesian bicategories I}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404987901216},
volume = {49},
year = {1987}
}
@article{Jacobs2000,
author = {Jacobs, Bart},
doi = {10.1016/S1571-0661(05)80348-2},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2000 - Towards a Duality Result in Coalgebraic Modal Logic.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {160--195},
title = {{Towards a Duality Result in Coalgebraic Modal Logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105803482},
volume = {33},
year = {2000}
}
@article{Pitts2011,
abstract = {ABSTRACT This paper introduces a new recursion principle for inductively defined data modulo $\alpha$-equivalence of bound names that makes use of Odersky-style local names when recursing over bound names. It is formulated in simply typed $\lambda$-calculus extended with names that can be restricted to a lexical scope, tested for equality, explicitly swapped and abstracted. The new recursion principle is motivated by the nominal sets notion of ‘$\alpha$-structural recursion', whose use of names and associated freshness side-conditions in recursive definitions formalizes common practice with binders. The new calculus has a simple interpretation in nominal sets equipped with name-restriction operations. It is shown to adequately represent $\alpha$-structural recursion while avoiding the need to verify freshness side-conditions in definitions and computations. The paper is a revised and expanded version of Pitts (Nominal System T. In Proceedings of the 37th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, POPL 2010 (Madrid, Spain). ACM Press, pp. 159–170, 2010).},
author = {Pitts, Andrew M.},
doi = {10.1017/S0956796811000116},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2011 - Structural recursion with locally scoped names.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {may},
number = {03},
pages = {235--286},
title = {{Structural recursion with locally scoped names}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796811000116},
volume = {21},
year = {2011}
}
@article{Lindstrom1989,
author = {Lindstr{\"{o}}m, Ingrid},
file = {:Users/liang-tingchen/Dropbox/References/Lindstr{\"{o}}m - 1989 - A Construction of Non-Well-Founded Sets within Martin-L{\"{o}}f's Type Theory.pdf:pdf},
journal = {The Journal of Symbolic Logic},
number = {1},
pages = {57--64},
publisher = {Association for Symbolic Logic},
title = {{A Construction of Non-Well-Founded Sets within Martin-L{\"{o}}f's Type Theory}},
volume = {54},
year = {1989}
}
@article{Cirstea2009a,
author = {C{\^{i}}rstea, Corina and Kurz, Alexander and Pattinson, Dirk and Schr{\"{o}}der, Lutz and Venema, Yde},
doi = {10.1093/comjnl/bxp004},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea et al. - 2009 - Modal Logics are Coalgebraic.pdf:pdf},
issn = {0010-4620},
journal = {The Computer Journal},
keywords = {coalgebra,compositionality,concurrency,knowledge representation,modal logic},
month = {feb},
number = {1},
pages = {31--41},
title = {{Modal Logics are Coalgebraic}},
url = {http://comjnl.oxfordjournals.org/cgi/doi/10.1093/comjnl/bxp004},
volume = {54},
year = {2009}
}
@article{Longley2007,
abstract = {It is an empirical observation arising from the study of higher type computability that a wide range of approaches to defining a class of (hereditarily) total functionals over {\$}\backslashnat{\$} leads in practice to a relatively small handful of distinct type structures. Among these are the type structure C of Kleene–Kreisel continuous functionals , its effective substructure C eff and the type structure HEO of the hereditarily effective operations . However, the proofs of the relevant equivalences are often non-trivial, and it is not immediately clear why these particular type structures should arise so ubiquitously.},
author = {Longley, John R.},
doi = {10.1017/S0960129507006251},
file = {:Users/liang-tingchen/Dropbox/References/Longley - 2007 - On the ubiquity of certain total type structures.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {5},
pages = {841--953},
title = {{On the ubiquity of certain total type structures}},
url = {https://www.cambridge.org/core/product/identifier/S0960129507006251/type/journal{\_}article},
volume = {17},
year = {2007}
}
@incollection{Eilenberg1966,
abstract = {In the usual theory of categories, with any two objects A, B of a category A there is associated a set A (A B) of morphisms of A into B. Frequently the set A (A B) is endowed with an additional structure such as a privileged element or an abelian group structure. It has become clear that as the ramifications of the theory of categories increase, the structures that A (A B) will carry will be richer and more complex. The need for a general theory has been widely felt for some time, and beginnings have been made in various directions and often under restrictive hypotheses; e.g. by Mac Lane [15], Kelly [10], B{\'{e}}nabou [3], Linton [12]},
address = {Berlin, Heidelberg},
author = {Eilenberg, Samuel and Kelly, Gregory Maxwell},
booktitle = {Proceedings of the Conference on Categorical Algebra},
doi = {10.1007/978-3-642-99902-4_22},
file = {:Users/liang-tingchen/Dropbox/References/Eilenberg, Kelly - 1966 - Closed Categories.pdf:pdf},
isbn = {978-3-642-99904-8},
pages = {421--562},
publisher = {Springer Berlin Heidelberg},
title = {{Closed Categories}},
url = {http://dx.doi.org/10.1007/978-3-642-99902-4{\_}22 http://www.springerlink.com/index/10.1007/978-3-642-99902-4{\_}22},
year = {1966}
}
@phdthesis{North2017,
author = {North, Paige Randall},
file = {:Users/liang-tingchen/Dropbox/References/North - 2017 - Type theoretic weak factorization systems.pdf:pdf},
school = {University of Cambridge},
title = {{Type theoretic weak factorization systems}},
url = {https://www.repository.cam.ac.uk/bitstream/handle/1810/265152/thesis.pdf},
year = {2017}
}
@article{Ferrari2005a,
author = {Ferrari, Gianluigi and Montanari, Ugo and Tuosto, Emilio},
file = {:Users/liang-tingchen/Dropbox/References/Ferrari, Montanari, Tuosto - 2005 - Coalgebraic minimization of HD-automata for the $\pi$-calculus using polymorphic types.pdf:pdf},
isbn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {Finite state verification,Name passing calculi,P,algorithm,bisimulation,calculi,checking,co-algebras,dependent,finite,name,partition,passing,refinement,state,types,verification},
mendeley-tags = {algorithm,bisimulation,calculi,checking,co-algebras,dependent,finite,name,partition,passing,refinement,state,types,verification},
number = {2--3},
pages = {325--365},
title = {{Coalgebraic minimization of HD-automata for the $\pi$-calculus using polymorphic types}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/S0304397504006449},
volume = {331},
year = {2005}
}
@article{Pavlovic2013,
abstract = {Abstract$\backslash$nWe present a new model of computation, described in terms of monoidal categories. It conforms to the Church–Turing Thesis, and captures the same computable functions as the standard models. It provides a succinct categorical interface to most of them, free of their diverse implementation details, using the ideas and structures that in the meantime emerged from research in semantics of computation and programming. The salient feature of the language of monoidal categories is that it is supported by a sound and complete graphical formalism, string diagrams, which provide a concrete and intuitive interface for abstract reasoning about computation. The original motivation and the ultimate goal of this effort is to provide a convenient high level programming language for a theory of computational resources, such as one-way functions, and trapdoor functions, by adopting the methods for hiding the low level implementation details that emerged from practice.},
archivePrefix = {arXiv},
arxivId = {1208.5205},
author = {Pavlovi{\'{c}}, Dusko},
doi = {10.1016/j.ic.2013.03.007},
eprint = {1208.5205},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} - 2013 - Monoidal computer I Basic computability by string diagrams.pdf:pdf},
issn = {0890-5401},
journal = {Information and Computation},
pages = {94--116},
publisher = {Elsevier Inc.},
title = {{Monoidal computer I: Basic computability by string diagrams}},
url = {http://www.sciencedirect.com/science/article/pii/S0890540113000254{\%}5Cnhttp://www.sciencedirect.com/science/article/pii/S0890540113000254?np=y},
volume = {226},
year = {2013}
}
@incollection{Berger2018,
author = {Berger, Ulrich and Petrovska, Olga},
booktitle = {Sailing Routes in the World of Computation. CiE 2018},
doi = {10.1007/978-3-319-94418-0_7},
editor = {Manea, Florin and Miller, Russell G. and Nowotka, Dirk},
file = {:Users/liang-tingchen/Dropbox/References/Berger, Petrovska - 2018 - Optimized Program Extraction for Induction and Coinduction.pdf:pdf},
isbn = {978-3-319-94417-3},
pages = {70--80},
publisher = {Springer International Publishing},
title = {{Optimized Program Extraction for Induction and Coinduction}},
url = {http://link.springer.com/10.1007/978-3-319-94418-0{\_}7},
volume = {10936},
year = {2018}
}
@inproceedings{Polak2001,
author = {Pol{\'{a}}k, Libor},
booktitle = {Mathematical Foundations of Computer Science},
doi = {10.1007/3-540-44683-4_53},
editor = {Sgall, Jiř{\'{i}} and Pultr, Ale{\v{s}} and Kolman, Petr},
file = {:Users/liang-tingchen/Dropbox/References/Pol{\'{a}}k - 2001 - Syntactic Semiring of a Language.pdf:pdf},
keywords = {rational languages,syntactic semiring},
pages = {611--620},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Syntactic Semiring of a Language}},
year = {2001}
}
@article{Power2003,
abstract = {Turi and Plotkin gave a precise mathematical formulation of a notion of structural operational semantics in their paper “Towards a mathematical operational semantics.” Starting from that definition and at the level of generality of that definition, we give a mathematical formulation of some of the basic constructions one makes with structural operational semantics. In particular, given a single-step operational semantics, as is the spirit of their work, one composes transitions and considers streams of transitions in order to study the dynamics induced by the operational semantics. In all their leading examples, it is obvious that one can do that and it is obvious how to do it. But if their definition is to be taken seriously, one needs to be able to make such constructions at the level of generality of their definition rather than case-by-case. So this paper does so for several of the basic constructions associated with structural operational semantics, in particular those required in order to speak of a stream of transitions and hence of dynamics.},
author = {Power, A. John},
doi = {10.1016/S1571-0661(04)80643-1},
file = {:Users/liang-tingchen/Dropbox/References/Power - 2003 - Towards a theory of mathematical operational semantics.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jul},
number = {1},
pages = {257--272},
title = {{Towards a theory of mathematical operational semantics}},
url = {http://dx.doi.org/10.1016/S1571-0661(04)80643-1},
volume = {82},
year = {2003}
}
@article{Fong2018,
abstract = {This book is an invitation to discover advanced topics in category theory through concrete, real-world examples. It aims to give a tour: a gentle, quick introduction to guide later exploration. The tour takes place over seven sketches, each pairing an evocative application, such as databases, electric circuits, or dynamical systems, with the exploration of a categorical structure, such as adjoint functors, enriched categories, or toposes. No prior knowledge of category theory is assumed. A more up-to-date copy can be found here: http://math.mit.edu/{\~{}}dspivak/teaching/sp18/7Sketches.pdf A feedback form for typos, comments, questions, and suggestions is available here: https://docs.google.com/document/d/160G9OFcP5DWT8Stn7TxdVx83DJnnf7d5GML0{\_}FOD5Wg/edit},
archivePrefix = {arXiv},
arxivId = {1803.05316},
author = {Fong, Brendan and Spivak, David I},
eprint = {1803.05316},
file = {:Users/liang-tingchen/Dropbox/References/Fong, Spivak - 2018 - Seven Sketches in Compositionality An Invitation to Applied Category Theory.pdf:pdf},
title = {{Seven Sketches in Compositionality: An Invitation to Applied Category Theory}},
url = {http://arxiv.org/abs/1803.05316},
year = {2018}
}
@article{Huber2019,
abstract = {Cubical type theory is an extension of Martin-L{\"{o}}f type theory recently proposed by Cohen, Coquand, M{\"{o}}rtberg, and the author which allows for direct manipulation of n-dimensional cubes and where Voevodsky's Univalence Axiom is provable. In this paper we prove canonicity for cubical type theory: any natural number in a context build from only name variables is judgmentally equal to a numeral. To achieve this we formulate a typed and deterministic operational semantics and employ a computability argument adapted to a presheaf-like setting.},
archivePrefix = {arXiv},
arxivId = {1607.04156},
author = {Huber, Simon},
doi = {10.1007/s10817-018-9469-1},
eprint = {1607.04156},
file = {:Users/liang-tingchen/Dropbox/References/Huber - 2019 - Canonicity for Cubical Type Theory.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Canonicity,Cubical type theory,Dependent type theory},
month = {aug},
number = {2},
pages = {173--210},
publisher = {Springer Netherlands},
title = {{Canonicity for Cubical Type Theory}},
url = {https://doi.org/10.1007/s10817-018-9469-1 http://link.springer.com/10.1007/s10817-018-9469-1},
volume = {63},
year = {2019}
}
@incollection{Minkus2014,
abstract = {eBay is an online marketplace which allows people to easily engage in commerce with one another. Since the market's online nature precludes many physical cues of trust, eBay has instituted a reputation system through which users accumulate ratings based on their transactions. However, the eBay Feedback System as currently implemented has serious privacy flaws. When sellers leave feedback, buyers' purchase histories are exposed through no action of their own. In this paper, we describe and execute a series of attacks, leveraging the feedback system to reveal users' potentially sensitive purchases. As a demonstration, we collect and identify users who have bought gun-related items and sensitive medical tests. We contrast this information leakage with eBay users' privacy expectations as measured by an online survey. Finally, we make recommendations towards better privacy in the eBay feedback system.},
author = {Minkus, Tehila and Ross, Keith W.},
booktitle = {Privacy Enhancing Technologies. PETS 2014},
doi = {10.1007/978-3-319-08506-7_9},
editor = {Cristofaro, Emiliano De and Murdoch, Steven J.},
file = {:Users/liang-tingchen/Dropbox/References/Minkus, Ross - 2014 - I Know What You're Buying Privacy Breaches on eBay.pdf:pdf},
isbn = {9783319085050},
issn = {16113349},
pages = {164--183},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{I Know What You're Buying: Privacy Breaches on eBay}},
url = {http://link.springer.com/10.1007/978-3-319-08506-7{\_}9},
volume = {8555},
year = {2014}
}
@incollection{Barr1971,
author = {Barr, Michael},
booktitle = {Exact Categories and Categories of Sheaves},
doi = {10.1007/BFb0058580},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1971 - Exact Categories.pdf:pdf},
isbn = {978-3-540-05678-2},
pages = {1--120},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Exact Categories}},
year = {1971}
}
@article{Morris2009a,
author = {Morris, Peter and Altenkirch, Thorsten and Ghani, Neil},
doi = {10.1142/S0129054109006462},
file = {:Users/liang-tingchen/Dropbox/References/Morris, Altenkirch, Ghani - 2009 - A universe of strictly positive families.pdf:pdf},
isbn = {1920682465},
issn = {14451336},
journal = {International Journal of Foundations of Computer Science},
keywords = {Advanced Data Types,Dependently Typed Programming,Epigram,Generic Programming},
number = {01},
title = {{A universe of strictly positive families}},
volume = {20},
year = {2009}
}
@incollection{Huber2013,
abstract = {In contrast to classical cryptography, the challenge of privacy in the context of databases is to find a trade-off between a security guarantee and utility. Individuals in a database have to be protected while preseving the usefullnes of the data. In this paper, we provide an overview over the results in the field of database privacy with focus on privacy notions. On the basis of these notions, we provide a framework that allows for the definition meaningful guarantees based on the distribution on privacy breaches and sesitive predicates. Interestingly, these notions do not fulfill the privacy axioms defined by Kifer et al. in [1,2].},
author = {Huber, Matthias and M{\"{u}}ller-Quade, J{\"{o}}rn and Nilges, Tobias},
booktitle = {Number Theory and Cryptography},
doi = {10.1007/978-3-642-42001-6_15},
editor = {Fischlin, Marc and Katzenbeisser, Stefan},
file = {:Users/liang-tingchen/Dropbox/References/Huber, M{\"{u}}ller-Quade, Nilges - 2013 - Defining Privacy Based on Distributions of Privacy Breaches.pdf:pdf},
isbn = {9783642420009},
issn = {03029743},
pages = {211--225},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Defining Privacy Based on Distributions of Privacy Breaches}},
url = {http://link.springer.com/10.1007/978-3-642-42001-6{\_}15},
volume = {8260},
year = {2013}
}
@article{Maietti2003,
abstract = {Andr{\'{e}} Joyal constructed arithmetic universes to provide a categorical proof of G{\"{o}}del incompleteness results. He built them in three stages: he first took a Skolem theory, then the category of its predicates and finally he made the exact completion out of the latter. Here, we prove that the construction of an initial arithmetic universe is equivalent to that of an initial list-arithmetic pretopos and also of an initial arithmetic pretopos. The initial list-arithmetic pretopos is built out of its internal language formulated as a dependent typed calculus in the style of Martin-L{\"{o}}f's extensional type theory. Analogously, we prove that the second stage of Joyal's construction is equivalent to taking an initial arithmetic lextensive category or an initial regular locos. We conclude by proposing the notion of list-arithmetic pretopos as the general definition of arithmetic universe. We are motivated from the fact in any list-arithmetic pretopos we can show the existence of free internal categories and diagrams as in any of Joyal's arithmetic universes. {\textcopyright}2003 Published by Elsevier Science B. V.},
author = {Maietti, Maria Emilia},
doi = {10.1016/S1571-0661(04)80569-3},
file = {:Users/liang-tingchen/Dropbox/References/Maietti - 2003 - Joyal's arithmetic universes via type theory.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Categorical logic,Dependent type theory,Pretopoi},
month = {feb},
number = {4},
pages = {272--286},
title = {{Joyal's arithmetic universes via type theory}},
url = {http://dx.doi.org/10.1016/S1571-0661(04)80569-3 https://linkinghub.elsevier.com/retrieve/pii/S1571066104805693},
volume = {69},
year = {2003}
}
@article{Luo2008,
abstract = {In this paper we study subtyping for inductive types in dependent type theories in the framework of coercive subtyping. General structural subtyping rules for parameterised inductive types are formulated based on the notion of inductive schemata. Certain extensional equality rules play an important role in proving some of the crucial properties of the type system with these subtyping rules. In particular, it is shown that the structural subtyping rules are coherent and that transitivity is admissible in the presence of the functorial rules of computational equality.},
author = {LUO, ZHAOHUI and ADAMS, ROBIN},
doi = {10.1017/S0960129508006956},
file = {:Users/liang-tingchen/Dropbox/References/LUO, ADAMS - 2008 - Structural subtyping for inductive types with functorial equality rules.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {5},
pages = {931--972},
title = {{Structural subtyping for inductive types with functorial equality rules}},
url = {https://www.cambridge.org/core/product/identifier/S0960129508006956/type/journal{\_}article},
volume = {18},
year = {2008}
}
@article{Ringer2019,
abstract = {Development of formal proofs of correctness of programs can increase actual and perceived reliability and facilitate better understanding of program specifications and their underlying assumptions. Tools supporting such development have been available for over 40 years, but have only recently seen wide practical use. Projects based on construction of machine-checked formal proofs are now reaching an unprecedented scale, comparable to large software projects, which leads to new challenges in proof development and maintenance. Despite its increasing importance, the field of proof engineering is seldom considered in its own right; related theories, techniques, and tools span many fields and venues. This survey of the literature presents a holistic understanding of proof engineering for program correctness, covering impact in practice, foundations, proof automation, proof organization, and practical proof development.},
archivePrefix = {arXiv},
arxivId = {2003.06458},
author = {Ringer, Talia and Palmskog, Karl and Sergey, Ilya and Gligoric, Milos and Tatlock, Zachary},
doi = {10.1561/2500000045},
eprint = {2003.06458},
file = {:Users/liang-tingchen/Dropbox/References/Ringer et al. - 2019 - QED at Large A Survey of Engineering of Formally Verified Software.pdf:pdf},
issn = {2325-1107},
journal = {Foundations and Trends{\textregistered} in Programming Languages},
number = {2-3},
pages = {102--281},
title = {{QED at Large: A Survey of Engineering of Formally Verified Software}},
url = {http://www.nowpublishers.com/article/Details/PGL-045},
volume = {5},
year = {2019}
}
@article{Mesablishvili2006,
author = {Mesablishvili, Bachuki},
file = {:Users/liang-tingchen/Dropbox/References/Mesablishvili - 2006 - Monads of effective descent type and comonadicity.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {(co)monadicity,Coring,Descent data,Monad of effective descent type,Separable functor},
number = {1},
pages = {1--45},
title = {{Monads of effective descent type and comonadicity}},
volume = {16},
year = {2006}
}
@inproceedings{Plotkin1980a,
author = {Plotkin, Gordon D.},
booktitle = {Abstract Software Specifications},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin - 1980 - Dijkstra's predicate transformers and Smyth's powerdomains.pdf:pdf},
pages = {527--553},
publisher = {Springer},
title = {{Dijkstra's predicate transformers and Smyth's powerdomains}},
type = {Conference proceedings (article)},
year = {1980}
}
@article{Sweeney2002,
author = {Sweeney, Latanya},
doi = {10.1142/S021848850200165X},
file = {:Users/liang-tingchen/Dropbox/References/Sweeney - 2002 - Achieving {\$}k{\$}-anonymity privacy protection using generalization and suppression.pdf:pdf},
journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
keywords = {data anonymity,data fusion,data privacy,privacy,re-identification},
month = {oct},
number = {05},
pages = {571--588},
title = {{Achieving {\$}k{\$}-anonymity privacy protection using generalization and suppression}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S021848850200165X},
volume = {10},
year = {2002}
}
@article{Roßiger2000,
abstract = {Coalgebras are of growing importance in theoretical computer science. To develop languages for them is significant for the specification and verification of systems. Modallogic has proved to be suitable for this purpose. So far, most approaches have presented a language to describe only deterministic coalgebras. The present paper introduces a generalization that also covers non-deterministic systems. Models for our modal language are F-coalgebras where the functor F is inductively constructed from constant sets and the identity functor using product, coproduct, exponentiation, and the power set functor. Thus, Kripke-structures constitute a special case. First we introduce a language that is based on a multisorted modal setting: here the sorts are given by the subfunctors of F. Then we consider a restricted language that still has the same expressiveness. It turns out that, for the case of Kripke-structures, the obtained language is equivalent to the “usual” modallogic for these structures. Hence this approach actually constitutes a bridge between modal languages for coalgebras and the modallogic for Kripke-structures. A well-known result from modallogic can be transfered to our setting: for so-called image-finite coalgebras bisimilarity coincides with logical equivalence. Finally, we present a sound and complete deduction calculus in case the constants in F are finite.},
author = {R{\"{o}}{\ss}iger, Martin},
doi = {10.1016/S1571-0661(05)80353-6},
file = {:Users/liang-tingchen/Dropbox/References/R{\"{o}}{\ss}iger - 2000 - Coalgebras and Modal Logic.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {294--315},
title = {{Coalgebras and Modal Logic}},
url = {http://dx.doi.org/10.1016/S1571-0661(05)80353-6},
volume = {33},
year = {2000}
}
@incollection{Dybjer1999,
abstract = {Induction-recursion is a schema which formalizes the principles for introducing new sets in Martin-L{\"{o}}f ‘s type theory. It states that we may inductively dene a set while simultaneously dening a function from this set into an arbitrary type by structural recursion. This extends the notion of an inductively dened set substantially and allows us to introduce universes and higher order universes (but not a Mahlo universe). In this article we give a nite axiomatization of inductive-recursive denitions. We prove consistency by constructing a set-theoretic model which makes use of one Mahlo cardinal.},
author = {Dybjer, Peter and Setzer, Anton},
booktitle = {Typed Lambda Calculi and Applications. TLCA 1999},
doi = {10.1007/3-540-48959-2_11},
editor = {Girard, Jean-Yves},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer, Setzer - 1999 - A Finite Axiomatization of Inductive-Recursive Definitions.pdf:pdf},
isbn = {3540657630},
issn = {16113349},
pages = {129--146},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Finite Axiomatization of Inductive-Recursive Definitions}},
url = {http://link.springer.com/10.1007/3-540-48959-2{\_}11},
volume = {1581},
year = {1999}
}
@article{Fiore2018,
abstract = {We introduce the notion of a relative pseudomonad, which generalizes the notion of a pseudomonad, and define the Kleisli bicategory associated to a relative pseudomonad. We then present an efficient method to define pseudomonads on the Kleisli bicategory of a relative pseudomonad. The results are applied to define several pseudomonads on the bicategory of profunctors in an homogeneous way and provide a uniform approach to the definition of bicategories that are of interest in operad theory, mathematical logic, and theoretical computer science.},
archivePrefix = {arXiv},
arxivId = {1612.03678},
author = {Fiore, M. and Gambino, N. and Hyland, M. and Winskel, G.},
doi = {10.1007/s00029-017-0361-3},
eprint = {1612.03678},
file = {:Users/liang-tingchen/Dropbox/References/Fiore et al. - 2018 - Relative pseudomonads, Kleisli bicategories, and substitution monoidal structures.pdf:pdf},
issn = {1022-1824},
journal = {Selecta Mathematica},
keywords = {18C20,18D05,18D50},
month = {jul},
number = {3},
pages = {2791--2830},
publisher = {Springer International Publishing},
title = {{Relative pseudomonads, Kleisli bicategories, and substitution monoidal structures}},
url = {http://link.springer.com/10.1007/s00029-017-0361-3},
volume = {24},
year = {2018}
}
@article{Balan2015,
author = {Balan, Adriana and Kurz, Alexander and Velebil, Jiř{\'{i}}},
doi = {10.2168/LMCS-11(3:18)2015},
file = {:Users/liang-tingchen/Dropbox/References/Balan, Kurz, Velebil - 2015 - Positive fragments of coalgebraic logics.pdf:pdf},
journal = {Logical Methods in Computer Science},
number = {3},
pages = {1--50},
title = {{Positive fragments of coalgebraic logics}},
volume = {11},
year = {2015}
}
@article{Walukiewicz2000,
abstract = {Propositional $\mu$-calculus is an extension of the propositional modal logic with the least fixpoint operator. In the paper introducing the logic Kozen posed a question about completeness of the axiomatisation which is a small extension of the axiomatisation of the model system K. It is shown that this axiomatisation is complete.},
author = {Walukiewicz, Igor},
doi = {10.1006/inco.1999.2836},
file = {:Users/liang-tingchen/Dropbox/References/Walukiewicz - 2000 - Completeness of Kozen's axiomatisation of the propositional $\mu$-calculus.pdf:pdf},
isbn = {0-8186-7050-9},
issn = {08905401},
journal = {Information and Computation},
number = {1-2},
pages = {142--182},
title = {{Completeness of Kozen's axiomatisation of the propositional $\mu$-calculus}},
url = {http://www.sciencedirect.com/science/article/pii/S0890540199928365},
volume = {157},
year = {2000}
}
@inproceedings{Gibbons2014,
abstract = {A domain-specific language can be implemented by embedding within a general-purpose host language. This embedding may be deep or shallow, depending on whether terms in the language construct syntactic or semantic representations. The deep and shallow styles are closely related, and intimately connected to folds; in this paper, we explore that connection.},
address = {New York, New York, USA},
author = {Gibbons, Jeremy and Wu, Nicolas},
booktitle = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
doi = {10.1145/2628136.2628138},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons, Wu - 2014 - Folding domain-specific languages.pdf:pdf},
isbn = {9781450328739},
pages = {339--347},
publisher = {ACM Press},
title = {{Folding domain-specific languages}},
url = {http://dl.acm.org/citation.cfm?doid=2628136.2628138},
year = {2014}
}
@book{Perrin2004,
author = {Perrin, Dominique and Pin, Jean-{\'{E}}ric},
doi = {10.1016/S0079-8169(04)80001-1},
editor = {Perrin, Dominique and Pin, Jean-{\'{E}}ric},
file = {:Users/liang-tingchen/Dropbox/References/Perrin, Pin - 2004 - Infinite Words Automata, Semigroups, Logic and Games.pdf:pdf},
isbn = {978-0-12-532111-2},
pages = {1--3},
publisher = {Elsevier},
series = {Pure and Applied Mathematics},
title = {{Infinite Words Automata, Semigroups, Logic and Games}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0079816904800011},
volume = {141},
year = {2004}
}
@incollection{Antoniou2007,
address = {Berlin, Heidelberg},
author = {Antoniou, Grigoris and Dimaresis, Nikos and Governatori, Guido},
booktitle = {AI 2007: Advances in Artificial Intelligence},
doi = {10.1007/978-3-540-76928-6_62},
file = {:Users/liang-tingchen/Dropbox/References/Antoniou, Dimaresis, Governatori - 2007 - A System for Modal and Deontic Defeasible Reasoning.pdf:pdf},
pages = {609--613},
publisher = {Springer Berlin Heidelberg},
title = {{A System for Modal and Deontic Defeasible Reasoning}},
url = {http://portal.acm.org/citation.cfm?doid=1363686.1364226 http://link.springer.com/10.1007/978-3-540-76928-6{\_}62},
year = {2007}
}
@phdthesis{Segala1995,
author = {Segala, Roberto},
file = {:Users/liang-tingchen/Dropbox/References/Segala - 1995 - Modeling and Verification of Randomized Distributed Real-Time Systems.pdf:pdf},
school = {Massachusetts Institute of Technology},
title = {{Modeling and Verification of Randomized Distributed Real-Time Systems}},
year = {1995}
}
@article{Nganou2015,
author = {Nganou, Jean B.},
doi = {10.1007/s11083-014-9345-5},
file = {:Users/liang-tingchen/Dropbox/References/Nganou - 2015 - Profinite MV-algebras and multisets.pdf:pdf},
issn = {0167-8094},
journal = {Order},
keywords = {dually equivalent,finitely approximable,maximal ideal,multiset,mv-algebra,profinite,stone mv-algebra},
month = {jan},
number = {April 2014},
title = {{Profinite MV-algebras and multisets}},
url = {http://link.springer.com/10.1007/s11083-014-9345-5},
year = {2015}
}
@article{Petricek2018,
abstract = {Computer science provides an in-depth understanding of technical aspects of programming concepts, but if we want to understand how programming concepts evolve, how programmers think and talk about them and how they are used in practice, we need to consider a broader perspective that includes historical, philosophical and cognitive aspects. In this paper, we develop such broader understanding of monads, a programming concept that has an infamous formal definition, syntactic support in several programming languages and a reputation for being elegant and powerful, but also intimidating and difficult to grasp. This paper is not a monad tutorial. It will not tell you what a monad is. Instead, it helps you understand how computer scientists and programmers talk about monads and why they do so. To answer these questions, we review the history of monads in the context of programming and study the development through the perspectives of philosophy of science, philosophy of mathematics and cognitive sciences. More generally, we present a framework for understanding programming concepts that considers them at three levels: formal, metaphorical and implementation. We base such observations on established results about the scientific method and mathematical entities -- cognitive sciences suggest that the metaphors used when thinking about monads are more important than widely accepted, while philosophy of science explains how the research paradigm from which monads originate influences and restricts their use. Finally, we provide evidence for why a broader philosophical, sociological look at programming concepts should be of interest for programmers. It lets us understand programming concepts better and, fundamentally, choose more appropriate abstractions as illustrated in number of case studies that conclude the paper.},
archivePrefix = {arXiv},
arxivId = {1803.10195},
author = {Petricek, Tomas},
doi = {10.22152/programming-journal.org/2018/2/12},
eprint = {1803.10195},
file = {:Users/liang-tingchen/Dropbox/References/Petricek - 2018 - What we talk about when we talk about monads.pdf:pdf},
issn = {2473-7321},
journal = {The Art, Science, and Engineering of Programming},
keywords = {abstraction,and engineering of programming,metaphor,monad,philosophy of science,programming concept,science,the art},
month = {mar},
number = {3},
pages = {1--27},
title = {{What we talk about when we talk about monads}},
url = {http://programming-journal.org/2018/2/12},
volume = {2},
year = {2018}
}
@inproceedings{Bianco2009,
author = {Bianco, Alessandro and Mogavero, Fabio and Murano, Aniello},
booktitle = {2009 24th Annual IEEE Symposium on Logic In Computer Science},
doi = {10.1109/LICS.2009.28},
file = {:Users/liang-tingchen/Dropbox/References/Bianco, Mogavero, Murano - 2009 - Graded computation tree Logic.pdf:pdf},
isbn = {978-0-7695-3746-7},
keywords = {-temporal logics,automata-theoretic approach,conservativeness,graded modalities,minimality,satisfiability},
month = {aug},
pages = {342--351},
publisher = {IEEE},
title = {{Graded computation tree Logic}},
url = {http://ieeexplore.ieee.org/document/5230566/},
year = {2009}
}
@article{Dostal2014,
abstract = {Sifted colimits (those that commute with finite products in sets) play a major role in categorical universal algebra. For example, varieties of (many-sorted) algebras are precisely the free cocompletions under sifted colimits of (many-sorted) Lawvere theories. Such a characterisation does not depend on the existence of finite products in algebraic theories, but on the above fact that these products commute with sifted colimits and another condition: finite products form a sound class of limits. In this paper we study the notion of soundness for general classes of weights in enriched category theory. We show that soundness of a given class of weights is equivalent to having a `nice' characterisation of flat weights for that class. As an application, we give an elementary characterisation of sifted weights for the enrichment in categories and in preorders. We also provide a number of examples of sifted weights using our elementary criterion.},
archivePrefix = {arXiv},
arxivId = {1405.3090},
author = {Dost{\'{a}}l, Mat{\v{e}}j and Velebil, Jiř{\'{i}}},
eprint = {1405.3090},
file = {:Users/liang-tingchen/Dropbox/References/Dost{\'{a}}l, Velebil - 2014 - An elementary characterisation of sifted weights.pdf:pdf},
month = {may},
pages = {1--15},
title = {{An elementary characterisation of sifted weights}},
url = {http://arxiv.org/abs/1405.3090},
year = {2014}
}
@inproceedings{Chlipala2008,
abstract = {We present parametric higher-order abstract syntax (PHOAS), a new approach to formalizing the syntax of programming languages in computer proof assistants based on type theory. Like higher-order abstract syntax (HOAS), PHOAS uses the meta language's binding constructs to represent the object language's binding constructs. Unlike HOAS, PHOAS types are definable in general-purpose type theories that support traditional functional programming, like Coq's Calculus of Inductive Constructions. We walk through how Coq can be used to develop certified, executable program transformations over several statically-typed functional programming languages formalized with PHOAS; that is, each transformation has a machine-checked proof of type preservation and semantic preservation. Our examples include CPS translation and closure conversion for simply-typed lambda calculus, CPS translation for System F, and translation from a language with ML-style pattern matching to a simpler language with no variable-arity binding constructs. By avoiding the syntactic hassle associated with first-order representation techniques, we achieve a very high degree of proof automation.},
address = {New York, New York, USA},
author = {Chlipala, Adam},
booktitle = {Proceeding of the 13th ACM SIGPLAN international conference on Functional programming - ICFP '08},
doi = {10.1145/1411204.1411226},
file = {:Users/liang-tingchen/Dropbox/References/Chlipala - 2008 - Parametric higher-order abstract syntax for mechanized semantics.pdf:pdf},
isbn = {9781595939197},
issn = {03621340},
keywords = {compiler verification,de-,interactive proof assistants,pendent types,type-theoretic semantics},
number = {9},
pages = {143},
publisher = {ACM Press},
title = {{Parametric higher-order abstract syntax for mechanized semantics}},
url = {http://portal.acm.org/citation.cfm?doid=1411204.1411226},
volume = {43},
year = {2008}
}
@inproceedings{Brown2016,
abstract = {According to conventional wisdom, a self-interpreter for a strongly normalizing $\lambda$-calculus is impossible. We call this the normalization barrier. The normalization barrier stems from a theorem in computability theory that says that a to- tal universal function for the total computable functions is impossible. In this paper we break through the normaliza- tion barrier and define a self-interpreter for System F$\omega$, a strongly normalizing $\lambda$-calculus. After a careful analysis of the classical theorem, we show that static type checking in F$\omega$ can exclude the proof's diagonalization gadget, leaving open the possibility for a self-interpreter. Along with the self-interpreter, we program four other operations in F$\omega$, in- cluding a continuation-passing style transformation. Our op- erations rely on a new approach to program representation that may be useful in theorem provers and compilers.},
address = {New York, New York, USA},
author = {Brown, Matt and Palsberg, Jens},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837623},
file = {:Users/liang-tingchen/Dropbox/References/Brown, Palsberg - 2016 - Breaking through the normalization barrier a self-interpreter for f-omega.pdf:pdf},
isbn = {9781450335492},
issn = {07308566},
keywords = {2009,29,and hofer,f,lambda calculus,meta programming,ostermann,presented the first,rendel,self in-,self representation,self-interpreter for a typed,terpretation,$\lambda$ -calculus},
pages = {5--17},
publisher = {ACM Press},
title = {{Breaking through the normalization barrier: a self-interpreter for f-omega}},
url = {http://dl.acm.org/citation.cfm?doid=2837614.2837623},
year = {2016}
}
@inproceedings{Chlipala2010,
abstract = {Dependent types provide a strong foundation for specifying and verifying rich properties of programs through type-checking. The earliest implementations combined dependency, which allows types to mention program variables; with type-level computation, which facilitates expressive specifications that compute with recursive functions over types. While many recent applications of dependent types omit the latter facility, we argue in this paper that it deserves more attention, even when implemented without dependency. In particular, the ability to use functional programs as specifications enables statically-typed metaprogramming: programs write programs, and static type-checking guarantees that the generating process never produces invalid code. Since our focus is on generic validity properties rather than full correctness verification, it is possible to engineer type inference systems that are very effective in narrow domains. As a demonstration, we present Ur, a programming language designed to facilitate metaprogramming with first-class records and names. On top of Ur, we implement Ur/Web, a special standard library that enables the development of modern Web applications. Ad-hoc code generation is already in wide use in the popular Web application frameworks, and we show how that generation may be tamed using types, without forcing metaprogram authors to write proofs or forcing metaprogram users to write any fancy types.},
address = {New York, New York, USA},
author = {Chlipala, Adam},
booktitle = {Proceedings of the 2010 ACM SIGPLAN conference on Programming language design and implementation - PLDI '10},
doi = {10.1145/1806596.1806612},
file = {:Users/liang-tingchen/Dropbox/References/Chlipala - 2010 - Ur Statically-Typed Metaprogramming with Type-Level Record Computation.pdf:pdf},
isbn = {9781450300193},
keywords = {dependent types,languages,metaprogramming,reliability,security},
pages = {122},
publisher = {ACM Press},
title = {{Ur: Statically-Typed Metaprogramming with Type-Level Record Computation}},
url = {http://doi.acm.org/10.1145/1806596.1806612 http://portal.acm.org/citation.cfm?doid=1806596.1806612},
year = {2010}
}
@article{Rutten1998a,
abstract = {Coalgebras of set functors preserving weak pullbacks are particularly well-behaved. Invoking a result by Carboni, Kelly, and Wood (1990), we show that this can be explained by the fact that such functors can be uniquely extended to a relator. This insight next suggests a definition of metric bisimulation. CC?? 1998 Published by Elsevier Science B.V.},
author = {Rutten, J.J.M.M.},
doi = {10.1016/S1571-0661(04)00063-5},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 1998 - Relators and Metric Bisimulations.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
pages = {252--258},
title = {{Relators and Metric Bisimulations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104000635},
volume = {11},
year = {1998}
}
@article{Ambler1995,
author = {Ambler, Simon},
doi = {10.1016/0304-3975(95)00045-X},
file = {:Users/liang-tingchen/Dropbox/References/Ambler - 1995 - Duality and the completeness of the modal $\mu$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {nov},
number = {1},
pages = {3--27},
title = {{Duality and the completeness of the modal $\mu$-calculus}},
type = {Journal article},
volume = {151},
year = {1995}
}
@article{NorbertFuhr;ThomasRolleke1997,
abstract = {We present a probabilistic data model which is based on relations in non-first-normal-form (NF2). Here, tuples are assigned probabilistic weights giving the probability that a tuple belongs to a relation. This way, imprecise attribute values are modelled as a probabilistic subrelation. For information retrieval, the set of weighted index terms of a document can be represented in the same way, thus supporting the integration of information retrieval and database systems. By redefining the relational operators for this type of relations, the result of each operator is again a probabilistic NF2 relation, where the weight of a tuple gives the probability that this tuple belongs to the result.},
author = {Fuhr, Norbert and R{\"{o}}lleke, Thomas},
doi = {10.1145/239041.239045},
file = {:Users/liang-tingchen/Dropbox/References/Fuhr, R{\"{o}}lleke - 1997 - A probabilistic relational algebra for the integration of information retrieval and database systems.pdf:pdf},
issn = {10468188},
journal = {ACM Transactions on Information Systems},
month = {jan},
number = {1},
pages = {32--66},
title = {{A probabilistic relational algebra for the integration of information retrieval and database systems}},
url = {http://portal.acm.org/citation.cfm?doid=239041.239045},
volume = {15},
year = {1997}
}
@article{Jacobs2009,
author = {Jacobs, Bart and Sokolova, Ana},
doi = {10.1093/logcom/exn093},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Sokolova - 2010 - Exemplaric expressivity of modal logics.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {adjunction,coalgebra,dual,markov chains,markov processes,modal logic},
month = {feb},
number = {5},
pages = {1041--1068},
title = {{Exemplaric expressivity of modal logics}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exn093},
volume = {20},
year = {2010}
}
@article{Lumsdaine2015,
abstract = {We present a new coherence theorem for comprehension categories, providing strict models of dependent type theory with all standard constructors, including dependent products, dependent sums, identity types, and other inductive types.},
archivePrefix = {arXiv},
arxivId = {1411.1736},
author = {Lumsdaine, Peter Lefanu and Warren, Michael A.},
doi = {10.1145/2754931},
eprint = {1411.1736},
file = {:Users/liang-tingchen/Dropbox/References/Lumsdaine, Warren - 2015 - The Local Universes Model.pdf:pdf},
issn = {1529-3785},
journal = {ACM Transactions on Computational Logic},
keywords = {Categorical semantics,Coherence theorems,Comprehension categories,Dependent type theory},
month = {jul},
number = {3},
pages = {1--31},
title = {{The Local Universes Model}},
url = {https://dl.acm.org/doi/10.1145/2754931},
volume = {16},
year = {2015}
}
@article{Abramsky2002,
author = {Abramsky, Samson and Haghverdi, Esfandiar and Scott, Philip J.},
doi = {10.1017/S0960129502003730},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky, Haghverdi, Scott - 2002 - Geometry of Interaction and linear combinatory algebras.pdf:pdf},
isbn = {0960129502},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {05},
pages = {625--665},
title = {{Geometry of Interaction and linear combinatory algebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129502003730},
volume = {12},
year = {2002}
}
@incollection{Berger2001,
author = {Berger, Martin and Honda, Kohei and Yoshida, Nobuko},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2001},
doi = {10.1007/3-540-45413-6_7},
editor = {Abramsky, Samson},
file = {:Users/liang-tingchen/Dropbox/References/Berger, Honda, Yoshida - 2001 - Sequentiality and the $\pi$-Calculus.pdf:pdf},
pages = {29--45},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Sequentiality and the $\pi$-Calculus}},
url = {http://link.springer.com/10.1007/3-540-45413-6{\_}7},
volume = {2044},
year = {2001}
}
@article{Levy2006a,
abstract = {We present the call-by-push-value (CBPV) calculus, which decomposes the typed call-by-value (CBV) and typed call-by-name (CBN) paradigms into fine-grain primitives. On the operational side, we give big-step semantics and a stack machine for CBPV, which leads to a straightforward push/pop reading of CBPV programs. On the denotational side, we model CBPV using cpos and, more generally, using algebras for a strong monad. For storage, we present an O'Hearn-style "behaviour semantics'' that does not use a monad. We present the translations from CBN and CBV to CBPV. All these translations straightforwardly preserve denotational semantics. We also study their operational properties: simulation and full abstraction. We give an equational theory for CBPV, and show it equivalent to a categorical semantics using monads and algebras. We use this theory to formally compare CBPV to Filinski's variant of the monadic metalanguage, as well as to Marz's language SFPL, both of which have essentially the same type structure as CBPV. We also discuss less formally the differences between the CBPV and monadic frameworks. {\textcopyright} Springer Science + Business Media, LLC 2006.},
author = {Levy, Paul Blain},
doi = {10.1007/s10990-006-0480-6},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2006 - Call-by-push-value Decomposing call-by-value and call-by-name.pdf:pdf},
issn = {1388-3690},
journal = {Higher-Order and Symbolic Computation},
keywords = {Call-by-name,Call-by-push-value,Call-by-value,Computational effect,Lambda-calculus,Monad},
month = {dec},
number = {4},
pages = {377--414},
title = {{Call-by-push-value: Decomposing call-by-value and call-by-name}},
url = {http://link.springer.com/10.1007/s10990-006-0480-6},
volume = {19},
year = {2006}
}
@phdthesis{Vasilakopoulou2014,
archivePrefix = {arXiv},
arxivId = {1411.3038},
author = {Vasilakopoulou, Christina},
eprint = {1411.3038},
file = {:Users/liang-tingchen/Dropbox/References/Vasilakopoulou - 2014 - Generalization of Algebraic Operations.pdf:pdf},
school = {University of Cambridge},
title = {{Generalization of Algebraic Operations}},
year = {2014}
}
@article{Laidler2007,
author = {Kokke, Wen and Montesi, Fabrizio and Peressotti, Marco},
doi = {10.1145/3290337},
file = {:Users/liang-tingchen/Dropbox/References/Kokke, Montesi, Peressotti - 2019 - Better late than never a fully-abstract semantics for classical processes.pdf:pdf},
isbn = {0888067194},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Behavioural Theory,Curry-Howard correspondence,Deadlock-freedom},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Better late than never: a fully-abstract semantics for classical processes}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290337},
volume = {3},
year = {2019}
}
@article{Kupke2010,
author = {Kupke, Clemens and Rutten, Jan J.M.M.},
doi = {10.1016/j.ic.2009.10.009},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Rutten - 2010 - Complete sets of cooperations.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {dec},
number = {12},
pages = {1398--1420},
publisher = {Elsevier Inc.},
title = {{Complete sets of cooperations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540110000969},
volume = {208},
year = {2010}
}
@article{Shafer1979,
abstract = {This paper studies belief functions, set functions which are normalized and monotone of order ∞ ∞ . The concepts of continuity and condensability are defined for belief functions, and it is shown how to extend continuous or condensable belief functions from an algebra of subsets to the corresponding power set. The main tool used in this extension is the theorem that every belief function can be represented by an allocation of probability--i.e., by a ∩ ∩ -homomorphism into a positive and completely additive probability algebra. This representation can be deduced either from an integral representation due to Choquet or from more elementary work by Revuz and Honeycutt.},
author = {Shafer, Glenn},
file = {:Users/liang-tingchen/Dropbox/References/Shafer - 1979 - Allocations of Probability.pdf:pdf},
journal = {The Annals of Probability},
number = {5},
pages = {827--839},
title = {{Allocations of Probability}},
url = {https://projecteuclid.org/euclid.aop/1176994941},
volume = {7},
year = {1979}
}
@article{Barendregt1984,
author = {Barendregt, Henk and Barendsen, Erik},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt, Barendsen - 1984 - Introduction to lambda calculus.pdf:pdf},
issn = {0028-9825},
journal = {Nieuw archief voor wiskunde},
number = {2},
pages = {337--372},
title = {{Introduction to lambda calculus}},
url = {http://hdl.handle.net/2066/17289},
volume = {4},
year = {1984}
}
@article{Bourke2014,
abstract = {We define notions of regularity and (Barr-)exactness for 2-categories. In fact, we define three notions of regularity and exactness, each based on one of the three canonical ways of factorising a functor in Cat: as (surjective on objects, injective on objects and fully faithful), as (bijective on objects, fully faithful), and as (bijective on objects and full, faithful). The correctness of our notions is justified using the theory of lex colimits [12] introduced by Lack and the second author. Along the way, we develop an abstract theory of regularity and exactness relative to a kernel-quotient factorisation, extending earlier work of Street and others [24,3]. ?? 2013 Elsevier B.V.},
author = {Bourke, John and Garner, Richard},
doi = {10.1016/j.jpaa.2013.11.021},
file = {:Users/liang-tingchen/Dropbox/References/Bourke, Garner - 2014 - Two-dimensional regularity and exactness.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {7},
pages = {1346--1371},
publisher = {Elsevier B.V.},
title = {{Two-dimensional regularity and exactness}},
url = {http://dx.doi.org/10.1016/j.jpaa.2013.11.021},
volume = {218},
year = {2014}
}
@inproceedings{Okasaki2000,
abstract = {Every programmer has blind spots. Breadth-first numbering is an interesting toy problem that exposes a blind spot common to many--perhaps most--functional programmers.},
address = {New York, New York, USA},
author = {Okasaki, Chris},
booktitle = {Proceedings of the fifth ACM SIGPLAN international conference on Functional programming - ICFP '00},
doi = {10.1145/351240.351253},
file = {:Users/liang-tingchen/Dropbox/References/Okasaki - 2000 - Breadth-first numbering.pdf:pdf},
isbn = {1581132026},
issn = {03621340},
number = {9},
pages = {131--136},
publisher = {ACM Press},
title = {{Breadth-first numbering}},
url = {http://portal.acm.org/citation.cfm?id=351253 http://portal.acm.org/citation.cfm?doid=351240.351253},
volume = {35},
year = {2000}
}
@article{FU1997,
author = {FU, YUXI},
doi = {10.1017/S0960129596002058},
file = {:Users/liang-tingchen/Dropbox/References/FU - 1997 - Categorical properties of logical frameworks.pdf:pdf},
isbn = {0960129596},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {1},
pages = {1--47},
title = {{Categorical properties of logical frameworks}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129596002058},
volume = {7},
year = {1997}
}
@incollection{Lazrig2016,
author = {Lazrig, Ibrahim and Ong, Toan and Ray, Indrajit and Ray, Indrakshi and Kahn, Michael},
booktitle = {Data and Applications Security and Privacy XXX. DBSec 2016},
doi = {10.1007/978-3-319-41483-6_5},
editor = {Ranise, Silvio and Swarup, Vipin},
file = {:Users/liang-tingchen/Dropbox/References/Lazrig et al. - 2016 - Privacy Preserving Probabilistic Record Linkage Using Locality Sensitive Hashes.pdf:pdf},
isbn = {978-3-319-41482-9},
pages = {61--76},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Privacy Preserving Probabilistic Record Linkage Using Locality Sensitive Hashes}},
url = {http://link.springer.com/10.1007/978-3-319-41483-6{\_}5},
volume = {9766},
year = {2016}
}
@inproceedings{Goswami2017,
author = {Goswami, Puneet and Madan, Suman},
booktitle = {2017 International Conference on Computing, Communication and Automation (ICCCA)},
doi = {10.1109/CCAA.2017.8229787},
file = {:Users/liang-tingchen/Dropbox/References/Goswami, Madan - 2017 - Privacy preserving data publishing and data anonymization approaches A review.pdf:pdf},
isbn = {978-1-5090-6471-7},
keywords = {data anonymization,down specialization,privacy preservation,top-},
month = {may},
pages = {139--142},
publisher = {IEEE},
title = {{Privacy preserving data publishing and data anonymization approaches: A review}},
url = {http://ieeexplore.ieee.org/document/8229787/},
year = {2017}
}
@book{Iemhoff2000a,
author = {Iemhoff, Rosalie},
booktitle = {Advances in Modal Logic (Volume 2)},
file = {:Users/liang-tingchen/Dropbox/References/Iemhoff - 2000 - A modal analysis of some principles of the provability logic of Heyting Arithmetic.pdf:pdf},
isbn = {9039320454},
number = {193},
pages = {319--354},
title = {{A modal analysis of some principles of the provability logic of Heyting Arithmetic}},
volume = {2},
year = {2000}
}
@phdthesis{Murase2018,
author = {Murase, Yuito},
file = {:Users/liang-tingchen/Dropbox/References/Murase - 2018 - On Type Theories Internalizing Contexts.pdf:pdf},
school = {University of Tokyo on},
title = {{On Type Theories Internalizing Contexts}},
type = {Master},
year = {2018}
}
@article{Adamek1989a,
abstract = {Monadic decomposition of adjoints, as introduced by H. Appelgate and M. Tierney, are investigated: sharper conditions under which the decomposition 'converges' are found, examples of non-convergent decompositions are presented, and the role that solid (semi-topological) functors play is made clear. {\textcopyright} 1989.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Herrlich, Horst and Tholen, Walter},
doi = {10.1016/0022-4049(89)90129-1},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Herrlich, Tholen - 1989 - Monadic decompositions.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {2},
pages = {111--123},
title = {{Monadic decompositions}},
volume = {59},
year = {1989}
}
@article{Hasuo2015a,
abstract = {We devise a generic framework where a weakest precondition semantics, in the form of indexed posets, is derived from a monad whose Kleisli category is enriched by posets. It is inspired by Jacobs' recent identification of a categorical structure that is common in various predicate transformers, but adds generality in the following aspects: (1) different notions of modality (such as "may" vs. "must") are captured by Eilenberg-Moore algebras; (2) nested alternating branching-like in games and in probabilistic systems with nondeterministic environments-is modularly modeled by a monad on the Eilenberg-Moore category of another.},
author = {Hasuo, Ichiro},
doi = {10.1016/j.tcs.2015.03.047},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo - 2015 - Generic weakest precondition semantics from monads enriched with order.pdf:pdf},
isbn = {9783662441237},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Algebra,Categorical model,Coalgebra,Effect,Game,Monad,Nondeterminism,Precondition calculus,Program logic,Program verification},
number = {April 2014},
pages = {2--29},
publisher = {Elsevier B.V.},
title = {{Generic weakest precondition semantics from monads enriched with order}},
url = {http://dx.doi.org/10.1016/j.tcs.2015.03.047},
volume = {604},
year = {2015}
}
@book{Barr1985,
author = {Barr, Michael and Wells, Charles},
file = {:Users/liang-tingchen/Dropbox/References/Barr, Wells - 1985 - Toposes, triples and theories.pdf:pdf},
keywords = {and phrases,theories,toposes,triples},
number = {12},
pages = {1--288},
publisher = {Springer-Verlag},
title = {{Toposes, triples and theories}},
year = {1985}
}
@article{Ponse2007,
abstract = {We study two alternative bases for Belnap's four-valued logic and provide complete equational axiomatizations for them. One is called conditional composition logic. It has a single, ternary if-then-else connective with a sequential, operational reading, and four constants for the truth values. The other logic is called guard logic. The main motivation for this logic lies in its technical properties. It admits a useful type of canonical form (term representation), and a relatively simple strategy for equational reasoning. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Ponse, Alban and van der Zwaag, Mark B.},
doi = {10.1016/j.tcs.2007.09.027},
file = {:Users/liang-tingchen/Dropbox/References/Ponse, van der Zwaag - 2007 - Belnap's logic and conditional composition.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Belnap's logic,Completeness,Conditional composition,Equational axiomatizations,Guard logic},
month = {dec},
number = {1-3},
pages = {319--336},
title = {{Belnap's logic and conditional composition}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397507007098},
volume = {388},
year = {2007}
}
@article{Hyland1993,
author = {Hyland, Martin and de Paiva, Valeria},
doi = {10.1016/0168-0072(93)90146-5},
file = {:Users/liang-tingchen/Dropbox/References/Hyland, de Paiva - 1993 - Full intuitionistic linear logic (extended abstract).pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {nov},
number = {3},
pages = {273--291},
title = {{Full intuitionistic linear logic (extended abstract)}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0168007293901465},
volume = {64},
year = {1993}
}
@article{Altenkirch2015a,
abstract = {We show that the syntactically rich notion of strictly positive families can be reduced to a core type theory with a fixed number of type constructors exploiting the novel notion of indexed containers. As a result, we show indexed containers provide normal forms for strictly positive families in much the same way that containers provide normal forms for strictly positive types. Interestingly, this step from containers to indexed containers is achieved without having to extend the core type theory. Most of the construction presented here has been formalized using the Agda system.},
author = {Altenkirch, Thorsten and Ghani, Neil and Hancock, Peter and McBride, Conor and Morris, Peter},
doi = {10.1017/S095679681500009X},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch et al. - 2015 - Indexed containers.pdf:pdf},
isbn = {0956796815000},
issn = {0956-7968},
journal = {Journal of Functional Programming},
number = {1985},
pages = {e5},
title = {{Indexed containers}},
url = {https://www.cambridge.org/core/product/identifier/S095679681500009X/type/journal{\_}article},
volume = {25},
year = {2015}
}
@article{Pavlovic2012,
abstract = {Man-in-the-Middle (MM) is not only a ubiquitous attack pattern in security, but also an important paradigm of network computation and economics. Recognizing ongoing MM-attacks is an important security task; modeling MM-interactions is an interesting task for semantics of computation. Traced monoidal categories are a natural framework for MM-modelling, as the trace structure provides a tool to hide what happens *in the middle*. An effective analysis of what has been traced out seems to require an additional property of traces, called *normality*. We describe a modest model of network computation, based on partially ordered multisets (pomsets), where basic network interactions arise from the monoidal trace structure, and a normal trace structure arises from an iterative, i.e. coalgebraic structure over terms and messages used in computation and communication. The correspondence is established using a convenient monadic description of normally traced monoidal categories.},
annote = {23 pages, 20 figures, Coalgebraic Methods in Computer Science (CMCS) 2012},
archivePrefix = {arXiv},
arxivId = {1203.6324},
author = {Pavlovi{\'{c}}, Dusko},
eprint = {1203.6324},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} - 2012 - Tracing the Man in the Middle in Monoidal Categories.pdf:pdf},
journal = {ArXiv e-prints},
month = {mar},
pages = {23},
title = {{Tracing the Man in the Middle in Monoidal Categories}},
url = {http://arxiv.org/abs/1203.6324},
year = {2012}
}
@incollection{Altenkirch1999a,
abstract = {We present a definition of untyped A-terms using a heterogeneous datatype, i.e. an inductively defined operator. This operator can be extended to a Kleisli triple, which is a concise way to verify the substitution laws for A-calculus. We also observe that repetitions in the definition of the monad as well as in the proofs can be avoided by using well-founded recursion and induction instead of structural induction. We extend the construction to the simply typed A-calculus using dependent types, and show that this is an instance of a generalization of Kleisli triples. The proofs for the untyped case have been checked using the LEGO system.},
address = {Berlin, Heidelberg},
author = {Altenkirch, Thorsten and Reus, Bernhard},
booktitle = {Computer Science Logic},
doi = {10.1007/3-540-48168-0_32},
editor = {Flum, J{\"{o}}rg and Rodriguez-Artalejo, Mario},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Reus - 1999 - Monadic Presentations of Lambda Terms Using Generalized Inductive Types.pdf:pdf},
isbn = {978-3-540-48168-3},
issn = {16113349},
keywords = {A-calculus,Category theory,Inductive types,Type theory},
pages = {453--468},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Monadic Presentations of Lambda Terms Using Generalized Inductive Types}},
url = {http://link.springer.com/10.1007/3-540-48168-0{\_}32},
volume = {1683},
year = {1999}
}
@article{Ghani2002,
abstract = {This paper introduces coalgebraic monads as a unified model of term algebras covering fundamental examples such as initial algebras, final coalgebras, rational terms and term graphs. We develop a general method for obtaining finitary coalgebraic monads which allows us to generalise the notion of rational term and term graph to categories other than Set. As an application we sketch part of the correctness of the the term graph implementation of functional programming languages. {\textcopyright} 2002 Published by Elsevier Science B.V.},
author = {Ghani, Neil and L{\"{u}}th, Christoph and {De Marchi}, Federico},
doi = {10.1016/S1571-0661(04)80360-8},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, L{\"{u}}th, De Marchi - 2002 - Coalgebraic monads.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {oct},
number = {1},
pages = {71--91},
title = {{Coalgebraic monads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104803608},
volume = {65},
year = {2002}
}
@article{Riehl2017,
abstract = {We propose foundations for a synthetic theory of {\$}(\backslashinfty,1){\$}-categories within homotopy type theory. We axiomatize a directed interval type, then define higher simplices from it and use them to probe the internal categorical structures of arbitrary types. We define Segal types, in which binary composites exist uniquely up to homotopy; this automatically ensures composition is coherently associative and unital at all dimensions. We define Rezk types, in which the categorical isomorphisms are additionally equivalent to the type-theoretic identities - a "local univalence" condition. And we define covariant fibrations, which are type families varying functorially over a Segal type, and prove a "dependent Yoneda lemma" that can be viewed as a directed form of the usual elimination rule for identity types. We conclude by studying homotopically correct adjunctions between Segal types, and showing that for a functor between Rezk types to have an adjoint is a mere proposition. To make the bookkeeping in such proofs manageable, we use a three-layered type theory with shapes, whose contexts are extended by polytopes within directed cubes, which can be abstracted over using "extension types" that generalize the path-types of cubical type theory. In an appendix, we describe the motivating semantics in the Reedy model structure on bisimplicial sets, in which our Segal and Rezk types correspond to Segal spaces and complete Segal spaces.},
archivePrefix = {arXiv},
arxivId = {1705.07442},
author = {Riehl, Emily and Shulman, Michael},
eprint = {1705.07442},
file = {:Users/liang-tingchen/Dropbox/References/Riehl, Shulman - 2017 - A type theory for synthetic {\$}infty{\$}-categories.pdf:pdf},
journal = {Higher Structures},
keywords = {-categories,homotopy type theory,rezk spaces,segal spaces},
number = {1},
pages = {147--224},
title = {{A type theory for synthetic {\$}\backslashinfty{\$}-categories}},
url = {https://journals.mq.edu.au/index.php/higher{\_}structures/article/view/36},
volume = {1},
year = {2017}
}
@article{Paviotti2015,
abstract = {Guarded recursion is a form of recursion where recursive calls are guarded by delay modalities. Previous work has shown how guarded recursion is useful for constructing logics for reasoning about programming languages with advanced features, as well as for constructing and reasoning about elements of coinductive types. In this paper we investigate how type theory with guarded recursion can be used as a metalanguage for denotational semantics useful both for constructing models and for proving properties of these. We do this by constructing a fairly intensional model of PCF and proving it computationally adequate. The model construction is related to Escardo's metric model for PCF, but here everything is carried out entirely in type theory with guarded recursion, including the formulation of the operational semantics, the model construction and the proof of adequacy.},
author = {Paviotti, Marco and M{\o}gelberg, Rasmus Ejlers and Birkedal, Lars},
doi = {10.1016/j.entcs.2015.12.020},
file = {:Users/liang-tingchen/Dropbox/References/Paviotti, M{\o}gelberg, Birkedal - 2015 - A Model of PCF in Guarded Type Theory.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Denotational semantics,PCF,guarded recursion,synthetic domain theory,type theory},
month = {dec},
pages = {333--349},
publisher = {Elsevier B.V.},
title = {{A Model of PCF in Guarded Type Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.12.020 https://linkinghub.elsevier.com/retrieve/pii/S1571066115000870},
volume = {319},
year = {2015}
}
@inproceedings{Peri2015,
author = {Peri, Joseph S. J.},
booktitle = {Signal Processing, Sensor/Information Fusion, and Target Recognition XXIV},
doi = {10.1117/12.2177200},
editor = {Kadar, Ivan},
file = {:Users/liang-tingchen/Dropbox/References/Peri - 2015 - Categorification of the Dempster Shafer theory.pdf:pdf},
month = {may},
pages = {94740V},
title = {{Categorification of the Dempster Shafer theory}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2177200},
volume = {9474},
year = {2015}
}
@article{Kennison1971,
author = {Kennison, John F. and Gildenhuys, Dion},
doi = {10.1016/0022-4049(71)90001-6},
file = {:Users/liang-tingchen/Dropbox/References/Kennison, Gildenhuys - 1971 - Equational completion, model induced triples and pro-objects.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {4},
pages = {317--346},
title = {{Equational completion, model induced triples and pro-objects}},
volume = {1},
year = {1971}
}
@article{Bernardy2018,
author = {Bernardy, Jean-philippe and Boespflug, Mathieu and Newton, Ryan R and {Peyton Jones}, Simon and Spiwack, Arnaud},
doi = {10.1145/3158093},
file = {:Users/liang-tingchen/Dropbox/References/Bernardy et al. - 2017 - Linear Haskell practical linearity in a higher-order polymorphic language.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {GHC,Haskell,laziness,linear logic,linear types},
month = {dec},
number = {POPL},
pages = {1--29},
title = {{Linear Haskell: practical linearity in a higher-order polymorphic language}},
url = {http://dl.acm.org/citation.cfm?doid=3177123.3158093},
volume = {2},
year = {2017}
}
@incollection{Xu2012,
author = {Xu, Lili},
booktitle = {Trustworthy Global Computing. TGC 2012},
doi = {10.1007/978-3-642-41157-1_13},
editor = {Palamidessi, Catuscia and Ryan, Mark D.},
file = {:Users/liang-tingchen/Dropbox/References/Xu - 2012 - Modular Reasoning about Differential Privacy in a Probabilistic Process Calculus.pdf:pdf},
pages = {198--212},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modular Reasoning about Differential Privacy in a Probabilistic Process Calculus}},
url = {http://link.springer.com/10.1007/978-3-642-41157-1{\_}13},
volume = {8191},
year = {2012}
}
@article{VanBakel1997,
abstract = {We study the cube of type assignment systems, as introduced in Giannini et al. (Fund. Inform. 19 (1993) 87-126), and confront it with Barendregt's typed $\lambda$-cube (Barendregt, in: Handbook of Logic in Computer Science, Vol. 2, Clarenden Press, Oxford, 1992). The first is obtained from the latter through applying a natural type erasing function E to derivation rules, that erases type information from terms. In particular, we address the question whether a judgement, derivable in a type assignment system, is always an erasure of a derivable judgement in a corresponding typed system; we show that this property holds only for systems without polymorphism. The type assignment systems we consider satisfy the properties 'subject reduction' and 'strong normalization'. Moreover, we define a new type assignment cube that is isomorphic to the typed one.},
author = {van Bakel, Steffen and Liquori, Luigi and della Rocca, Simona Ronchi and Urzyczyn, Pawel},
doi = {10.1016/S0168-0072(96)00036-X},
file = {:Users/liang-tingchen/Dropbox/References/van Bakel et al. - 1997 - Comparing cubes of typed and type assignment systems.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {jul},
number = {3},
pages = {267--303},
title = {{Comparing cubes of typed and type assignment systems}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S016800729600036X},
volume = {86},
year = {1997}
}
@article{Hinze2005,
abstract = {This pearl explains Church numerals, twice. The first explanation links Church numerals to Peano numerals via the well-known encoding of data types in the polymorphic lambda-calculus. This view suggests that Church numerals are folds in disguise. The second explanation, which is more elaborate, but also more insightful, derives Church numerals from first principles, that is, from an algebraic specification of addition and multiplication. Additionally, we illustrate the use of the parametricity theorem by proving exponentiation as reverse application correct.},
author = {HINZE, RALF},
doi = {10.1017/S0956796804005313},
file = {:Users/liang-tingchen/Dropbox/References/HINZE - 2005 - THEORETICAL PEARL Church numerals, twice!.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
number = {1},
pages = {1--13},
title = {{THEORETICAL PEARL Church numerals, twice!}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796804005313},
volume = {15},
year = {2005}
}
@inproceedings{Jung2008,
author = {Jung, Achim and Moshier, M. Andrew and Vickers, Steven},
booktitle = {Proceedings of the 24th Conference on the Mathematical Foundations of Programming Semantics (MFPS XXIV)},
doi = {10.1016/j.entcs.2008.10.013},
file = {:Users/liang-tingchen/Dropbox/References/Jung, Moshier, Vickers - 2008 - Presenting dcpos and dcpo algebras.pdf:pdf},
issn = {15710661},
month = {oct},
pages = {209--229},
publisher = {Elsevier},
title = {{Presenting dcpos and dcpo algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066108004076 http://www.sciencedirect.com/science/article/pii/S1571066108004076},
volume = {218},
year = {2008}
}
@phdthesis{Fong2012,
abstract = {In this dissertation we develop a new formal graphical framework for causal reasoning. Starting with a review of monoidal categories and their associated graphical languages, we then revisit probability theory from a categorical perspective and introduce Bayesian networks, an existing structure for describing causal relationships. Motivated by these, we propose a new algebraic structure, which we term a causal theory. These take the form of a symmetric monoidal category, with the objects representing variables and morphisms ways of deducing information about one variable from another. A major advantage of reasoning with these structures is that the resulting graphical representations of morphisms match well with intuitions for flows of information between these variables. These categories can then be modelled in other categories, providing concrete interpretations for the variables and morphisms. In particular, we shall see that models in the category of measurable spaces and stochastic maps provide a slight generalisation of Bayesian networks, and naturally form a category themselves. We conclude with a discussion of this category, classifying the morphisms and discussing some basic universal constructions. ERRATA: (i) Pages 41-42: Objects of a causal theory are words, not collections, in {\$}V{\$}, and we include swaps as generating morphisms, subject to the identities defining a symmetric monoidal category. (ii) Page 46: A causal model is a strong symmetric monoidal functor.},
archivePrefix = {arXiv},
arxivId = {1301.6201},
author = {Fong, Brendan},
eprint = {1301.6201},
file = {:Users/liang-tingchen/Dropbox/References/Fong - 2012 - Causal Theories A Categorical Perspective on Bayesian Networks.pdf:pdf},
month = {jan},
school = {University of Oxford},
title = {{Causal Theories: A Categorical Perspective on Bayesian Networks}},
type = {Master of Science in Mathematics and the Foundations of Computer Science},
url = {http://arxiv.org/abs/1301.6201},
year = {2012}
}
@inproceedings{Leal2008,
author = {Leal, Raul Andres},
booktitle = {Proceedings of the Ninth Workshop on Coalgebraic Methods in Computer Science},
doi = {10.1016/j.entcs.2008.05.026},
file = {:Users/liang-tingchen/Dropbox/References/Leal - 2008 - Predicate Liftings Versus Nabla Modalities.pdf:pdf},
issn = {15710661},
keywords = {coalgebra,logical translator,modal logic,modality,moss,predicate lifting,singleton lifting},
number = {5},
pages = {195--220},
publisher = {Elsevier},
series = {ENTCS},
title = {{Predicate Liftings Versus Nabla Modalities}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S157106610800340X},
volume = {203},
year = {2008}
}
@book{Oosten2008,
author = {van Oosten, Jaap},
doi = {10.1016/S0049-237X(08)80001-8},
file = {:Users/liang-tingchen/Dropbox/References/van Oosten - 2008 - Realizability An Introduction to its Categorical Side.pdf:pdf},
isbn = {978-0444515841},
pages = {328},
publisher = {Elsevier Science},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{Realizability: An Introduction to its Categorical Side}},
year = {2008}
}
@article{Pientka2019,
abstract = {We describe a Martin-L$\backslash$"of style dependent type theory, called Cocon, that allows us to mix the intensional function space that is used to represent higher-order abstract syntax (HOAS) trees with the extensional function space that describes (recursive) computations. We mediate between HOAS representations and computations using contextual modal types. Our type theory also supports an infinite hierarchy of universes and hence supports type-level computation -- thereby providing metaprogramming and (small-scale) reflection. Our main contribution is the development of a Kripke-style model for Cocon that allows us to prove normalization. From the normalization proof, we derive subject reduction and consistency. Our work lays the foundation to incorporate the methodology of logical frameworks into systems such as Agda and bridges the longstanding gap between these two worlds.},
archivePrefix = {arXiv},
arxivId = {1901.03378},
author = {Pientka, Brigitte and Abel, Andreas and Ferreira, Francisco and Thibodeau, David and Zucchini, Rebecca},
eprint = {1901.03378},
file = {:Users/liang-tingchen/Dropbox/References/Pientka et al. - 2019 - Cocon Computation in Contextual Type Theory.pdf:pdf},
month = {jan},
number = {Sco 1976},
title = {{Cocon: Computation in Contextual Type Theory}},
url = {http://arxiv.org/abs/1901.03378},
year = {2019}
}
@article{Ahrens2018,
abstract = {The term UniMath refers both to a formal system for mathematics, as well as a computer-checked library of mathematics formalized in that system. The UniMath system is a core dependent type theory, augmented by the univalence axiom. The system is kept as small as possible in order to ease verification of it - in particular, general inductive types are not part of the system. In this work, we partially remedy the lack of inductive types by constructing some datatypes and their associated induction principles from other type constructors. This involves a formalization of a category-theoretic result on the construction of initial algebras, as well as a mechanism to conveniently use the datatypes obtained. We also connect this construction to a previous formalization of substitution for languages with variable binding. Altogether, we construct a framework that allows us to concisely specify, via a simple notion of binding signature, a language with variable binding. From such a specification we obtain the datatype of terms of that language, equipped with a certified monadic substitution operation and a suitable recursion scheme. Using this we formalize the untyped lambda calculus and the raw syntax of Martin-L$\backslash$"of type theory.},
author = {Ahrens, Benedikt and Matthes, Ralph and M{\"{o}}rtberg, Anders},
doi = {10.1007/s10817-018-9474-4},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Matthes, M{\"{o}}rtberg - 2018 - From Signatures to Monads in UniMath.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Inductive types,Initial algebra semantics,Representation of substitution,Univalent mathematics},
month = {jul},
pages = {1--34},
publisher = {Springer Netherlands},
title = {{From Signatures to Monads in UniMath}},
url = {https://doi.org/10.1007/s10817-018-9474-4 http://link.springer.com/10.1007/s10817-018-9474-4},
year = {2018}
}
@article{Tschantz2011,
abstract = {Differential privacy is a promising approach to privacy preserving data analysis with a well-developed theory for functions. Despite recent work on implementing systems that aim to provide differential privacy, the problem of formally verifying that these systems have differential privacy has not been adequately addressed. We develop a formal probabilistic automaton model of differential privacy for systems by adapting prior work on differential privacy for functions. We present the first sound verification technique for proving differential privacy of interactive systems. The technique is based on a form of probabilistic bisimulation relation. The novelty lies in the way we track quantitative privacy leakage bounds using a relation family instead of a single relation. We illustrate the proof technique on a representative automaton motivated by PINQ, an implemented system that is intended to provide differential privacy. Surprisingly, our analysis yields a privacy leakage bound of (2t* ??) rather than (t* ??) when ??differentially private functions are called t times. The extra leakage arises from accounting for bounded memory constraints of real computers. ?? 2011 Elsevier B.V.All rights reserved.},
author = {Tschantz, Michael Carl and Kaynar, Dilsun and Datta, Anupam},
doi = {10.1016/j.entcs.2011.09.015},
file = {:Users/liang-tingchen/Dropbox/References/Tschantz, Kaynar, Datta - 2011 - Formal verification of differential privacy for interactive systems (extended abstract).pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Bisimulation,Differential Privacy,Formal Methods,Privacy,Verification},
number = {1},
pages = {61--79},
publisher = {Elsevier B.V.},
title = {{Formal verification of differential privacy for interactive systems (extended abstract)}},
url = {http://dx.doi.org/10.1016/j.entcs.2011.09.015},
volume = {276},
year = {2011}
}
@article{Tholen1987,
abstract = {For an abstract categoryC, several sufficient conditions for the intersection of two or of a larger collection of full reflective subcategories ofCto be reflective are presented. The given criteria are applicable particularly whenCis a concrete topological category.},
author = {Tholen, Walter},
doi = {10.1016/0166-8641(87)90105-2},
file = {:Users/liang-tingchen/Dropbox/References/Tholen - 1987 - Reflective subcategories.pdf:pdf},
issn = {01668641},
journal = {Topology and its Applications},
month = {nov},
number = {2},
pages = {201--212},
title = {{Reflective subcategories}},
url = {http://dx.doi.org/10.1016/0166-8641(87)90105-2},
volume = {27},
year = {1987}
}
@article{Turner1979,
abstract = {This short article presents an algorithm for bracket abstraction [1] which avoids a combinatorial explosion in the size of the resulting expression when applied repeatedly for abstraction in a series of variables. It differs from a previous solution [2] in introducing only a finite number of additional combinators and in not requiring that all the variables to be abstracted be treated together in a single operation.},
author = {Turner, D. A.},
doi = {10.2307/2273733},
file = {:Users/liang-tingchen/Dropbox/References/Turner - 1979 - Another algorithm for bracket abstraction.pdf:pdf},
issn = {0022-4812},
journal = {The Journal of Symbolic Logic},
month = {jun},
number = {02},
pages = {267--270},
title = {{Another algorithm for bracket abstraction}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200048970/type/journal{\_}article},
volume = {44},
year = {1979}
}
@article{Okasaki1996,
abstract = {Traditional techniques for designing and analyzing amortized$\backslash$ndata structures in an imperative setting are of limited$\backslash$nuse in a functional setting because they apply only to singlethreaded$\backslash$ndata structures, yet functional data structures can$\backslash$nbe non-single-threaded. In earlier work, we showed how$\backslash$nlazy evaluation supports functional amortized data structures$\backslash$nand described a technique (the banker's method) for$\backslash$nanalyzing such data structures. In this paper, we present a$\backslash$nnew analysis technique (the...},
author = {Okasaki, Chris},
doi = {10.1145/232629.232636},
file = {:Users/liang-tingchen/Dropbox/References/Okasaki - 1996 - The role of lazy evaluation in amortized data structures.pdf:pdf},
isbn = {0897917707},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {jun},
number = {6},
pages = {62--72},
title = {{The role of lazy evaluation in amortized data structures}},
url = {http://portal.acm.org/citation.cfm?doid=232627.232636 http://portal.acm.org/citation.cfm?doid=232629.232636},
volume = {31},
year = {1996}
}
@article{Reynolds1998a,
author = {Reynolds, John C.},
doi = {10.1023/A:1010027404223},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds - 1998 - Definitional Interpreters for Higher-Order Programming Languages.pdf:pdf},
journal = {Higher-Order and Symbolic Computation},
keywords = {applicative language,closure,continuation,gedanken,higher-order function,interpreter,j-operator,lambda calculus,language definition,lisp,order of application,pal,programming language,reference,secd machine},
number = {4},
pages = {363--397},
publisher = {Kluwer Academic Publishers},
title = {{Definitional Interpreters for Higher-Order Programming Languages}},
url = {https://link.springer.com/article/10.1023/A:1010027404223},
volume = {11},
year = {1998}
}
@article{Hatcliff1997,
abstract = {Thirty-five years ago, thunks were used to simulate call-by-name under call-by-value in Algol 60. Twenty years ago, Plotkin presented continuation-based simulations of call-by-name under call-by-value and vice versa in the $\lambda$-calculus. We connect all three of these classical simulations by factorizing the continuation-based call-by-name simulation script c signn with a thunk-based call-by-name simulation script T sign followed by the continuation-based call-by-value simulation script c signv extended to thunks. (Matrix Presented) We show that script T sign actually satisfies all of Plotkin's correctness criteria for script c signn (i.e. his Indifference, Simulation and Translation theorems). Furthermore, most of the correctness theorems for script c signn can now be seen as simple corollaries of the corresponding theorems for script c signv and script T sign.},
author = {Hatcliff, John and Danvy, Olivie},
doi = {10.1017/S0956796897002748},
file = {:Users/liang-tingchen/Dropbox/References/Hatcliff, Danvy - 1997 - Thunks and the $\lambda$-calculus.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {may},
number = {3},
pages = {S0956796897002748},
publisher = {Inst of European and American Studies},
title = {{Thunks and the $\lambda$-calculus}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796897002748},
volume = {7},
year = {1997}
}
@article{Church1936,
abstract = {In a recent paper the author has proposed a definition of the commonly used term “effectively calculable” and has shown on the basis of this definition that the general case of the Entscheidungsproblem is unsolvable in any system of symbolic logic which is adequate to a certain portion of arithmetic and is $\omega$-consistent. The purpose of the present note is to outline an extension of this result to the engere Funktionenkalkul of Hilbert and Ackermann.},
author = {Church, Alonzo},
doi = {10.2307/2269326},
file = {:Users/liang-tingchen/Dropbox/References/Church - 1936 - Correction to A note on the Entscheidungsproblem.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {mar},
number = {1},
pages = {40--41},
title = {{A note on the Entscheidungsproblem}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200039086/type/journal{\_}article https://www.cambridge.org/core/product/identifier/S0022481200038664/type/journal{\_}article},
volume = {1},
year = {1936}
}
@incollection{Klima2014,
abstract = {Eilenberg correspondence, based on the concept of syntactic monoids, relates varieties of regular languages with pseudovarieties of finite monoids. Various modifications of this correspondence related more general classes of regular languages with classes of more complex algebraic objects. Such generalized varieties also have natural counterparts formed by classes of finite automata equipped with a certain additional algebraic structure. In this survey, we overview several variants of such varieties of enriched automata.},
archivePrefix = {arXiv},
arxivId = {1405.5595},
author = {Kl{\'{i}}ma, Ondřej},
booktitle = {Proceedings of the 14th International Conference on Automata and Formal Languages},
doi = {10.4204/EPTCS.151.3},
eprint = {1405.5595},
file = {:Users/liang-tingchen/Dropbox/References/Kl{\'{i}}ma - 2014 - On Varieties of Automata Enriched with an Algebraic Structure (Extended Abstract).pdf:pdf},
issn = {2075-2180},
month = {may},
pages = {49--54},
series = {Electronic Proceedings in Theoretical Computer Science},
title = {{On Varieties of Automata Enriched with an Algebraic Structure (Extended Abstract)}},
url = {http://arxiv.org/abs/1405.5595v1{\%}5Cnhttp://arxiv.org/abs/1405.5595 http://arxiv.org/abs/1405.5595v1},
year = {2014}
}
@inproceedings{Sheard2002,
abstract = {We propose a new extension to the purely functional programming language Haskell that supports compile-time meta-programming . The purpose of the system is to support the algorithmic construction of programs at compile-time.The ability to generate code at compile time allows the programmer to implement such features as polytypic programs, macro-like expansion, user directed optimization (such as inlining), and the generation of supporting data structures and functions from existing data structures and functions.Our design is being implemented in the Glasgow Haskell Compiler, ghc.},
address = {New York, New York, USA},
author = {Sheard, Tim and Jones, Simon Peyton},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell - Haskell '02},
doi = {10.1145/581690.581691},
file = {:Users/liang-tingchen/Dropbox/References/Sheard, Jones - 2002 - Template meta-programming for Haskell.pdf:pdf},
isbn = {1581136056},
keywords = {meta programming,templates},
number = {12},
pages = {1--16},
publisher = {ACM Press},
title = {{Template meta-programming for Haskell}},
url = {http://portal.acm.org/citation.cfm?doid=581690.581691},
volume = {37},
year = {2002}
}
@inproceedings{Kifer2010,
address = {New York, New York, USA},
author = {Kifer, Daniel and Lin, Bing-rong},
booktitle = {Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems of data - PODS '10},
doi = {10.1145/1807085.1807106},
file = {:Users/liang-tingchen/Dropbox/References/Kifer, Lin - 2010 - Towards an axiomatization of statistical privacy and utility.pdf:pdf},
isbn = {9781450300339},
keywords = {axioms,privacy,utility},
pages = {147},
publisher = {ACM Press},
title = {{Towards an axiomatization of statistical privacy and utility}},
url = {http://portal.acm.org/citation.cfm?doid=1807085.1807106},
year = {2010}
}
@inproceedings{Chen2015,
archivePrefix = {arXiv},
arxivId = {1504.02692},
author = {Chen, Liang-Ting and Urbat, Henning},
booktitle = {Proceedings of the 6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.50},
editor = {Moss, Lawrence S. and Sobocinski, Pawel},
eprint = {1504.02692},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Urbat - 2015 - A fibrational approach to automata theory.pdf:pdf},
keywords = {coalgebra,duality,eilenberg's variety theorem,grothendieck fibration},
pages = {50--65},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{A fibrational approach to automata theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5526},
year = {2015}
}
@article{Burstall1969,
abstract = {Thi s pape r discusse s th e techniqu e o f structura l inductio n fo r provin g theorem s abou t programs . Thi s techniqu e i s closel y relate d t o recursio n inductio n bu t make s us e o f th e inductiv e definitio n o f th e dat a structure s handle d b y th e programs . I t treat s program s wit h recursio n bu t withou t assignment s o r jumps . Som e syntacti c extension s t o Landin' s functiona l programmin g languag e ISWI M ar e suggeste d whic h mak e i t easie r t o progra m th e manipulatio n o f dat a structure s an d t o develo p proof s abou t suc h programs . Tw o sampl e proof s ar e give n t o demonstrat e th e technique , on e fo r a tre e sortin g algorith m an d on e fo r a simpl e compile r fo r expression},
author = {Burstall, R. M.},
doi = {10.1093/comjnl/12.1.41},
file = {:Users/liang-tingchen/Dropbox/References/Burstall - 1969 - Proving Properties of Programs by Structural Induction.pdf:pdf},
isbn = {1940-6029 (Electronic)$\backslash$r1064-3745 (Linking)},
issn = {0010-4620},
journal = {The Computer Journal},
month = {feb},
number = {1},
pages = {41--48},
pmid = {22144188},
title = {{Proving Properties of Programs by Structural Induction}},
url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/12.1.41},
volume = {12},
year = {1969}
}
@article{Kohlas2007,
abstract = {Random sets can be considered as random variables with values in a Boolean algebra, in particular in a field of sets. Many properties of random sets, in particular those relative to belief functions, can also be obtained by relaxing the algebraic structure of the domain. In fact, functions monotone to order ∞, like Choquet capacities, can be defined on semilattices. In this paper random variables with values in some kind of graded semilattices are studied. It is shown that this algebraic structure models important operations regarding information. It turns out that random variables in this algebra form themselves an algebra of the same kind. Their probability distribution corresponds to functions monotone of order ∞ or to belief functions in the sense of Dempster-Shafer theory of evidence. This paper proposes therefore a natural generalization of evidence theory to a general structure related to probabilistic argumentation systems. Those systems have many interesting models like probabilistic assumption-based reasoning with different kind of logics, systems of linear equations and inequalities with stochastic disturbances, etc. The theory presented leads thus to an interesting and novel way of combining logic and probability. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Kohlas, J{\"{u}}rg},
doi = {10.1016/j.ijar.2006.12.005},
file = {:Users/liang-tingchen/Dropbox/References/Kohlas - 2007 - Uncertain information Random variables in graded semilattices.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
month = {sep},
number = {1},
pages = {17--34},
title = {{Uncertain information: Random variables in graded semilattices}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X06001605},
volume = {46},
year = {2007}
}
@incollection{Dinesh2008,
abstract = {We consider the problem of checking whether the operations of an organization conform to a body of regulation. The immediate motivation comes from the analysis of the U.S. Food and Drug Administration regulations that apply to bloodbanks - organizations that collect, process, store, and use donations of blood and blood components. Statements in such regulations convey constraints on operations or sequences of operations that are performed by an organization. It is natural to express these constraints in a temporal logic. There are two important features of regulatory texts that need to be accommodated by a representation in logic. First, the constraints conveyed by regulation can be obligatory (required) or permitted (optional). Second, statements in regulation refer to others for conditions or exceptions. An organization conforms to a body of regulation if and only if it satisfies all the obligations. However, permissions provide exceptions to obligations, indirectly affecting conformance. In this paper, we extend linear temporal logic to distinguish between obligations and permissions, and to allow statements to refer to others. While the resulting logic allows for a direct representation of regulation, evaluating references between statements has high complexity. We discuss an empirically motivated assumption that lets us replace references with tests of lower complexity, leading to efficient trace-checking algorithms in practice.},
author = {Dinesh, Nikhil and Joshi, Aravind and Lee, Insup and Sokolsky, Oleg},
booktitle = {Runtime Verification. RV 2008},
doi = {10.1007/978-3-540-89247-2_6},
editor = {Leucker, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Dinesh et al. - 2008 - Checking Traces for Regulatory Conformance.pdf:pdf},
isbn = {354089246X},
issn = {03029743},
pages = {86--103},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Checking Traces for Regulatory Conformance}},
url = {http://link.springer.com/10.1007/978-3-540-89247-2{\_}6},
volume = {5289},
year = {2008}
}
@article{Gudder2006,
author = {Gudder, Stanley},
file = {:Users/liang-tingchen/Dropbox/References/Gudder - 2006 - An order for quantum observables.pdf:pdf},
journal = {Mathematica Slovaca},
number = {5},
pages = {573----589},
publisher = {Mathematical Institute of the Slovak Academy of Sciences},
title = {{An order for quantum observables}},
url = {http://eudml.org/doc/34627},
volume = {56},
year = {2006}
}
@inproceedings{DeVries2014,
abstract = {We introduce the sum-of-products (SOP) view for datatype-generic programming (in Haskell). While many of the libraries that are commonly in use today represent datatypes as arbitrary combinations of binary sums and products, SOP reflects the structure of datatypes more faithfully: each datatype is a single n-ary sum, where each component of the sum is a single n-ary product. This representation turns out to be expressible accurately in GHC with today's extensions. The resulting list-like structure of datatypes allows for the definition of powerful high-level traversal combinators, which in turn encourage the definition of generic functions in a compositional and concise style. A major plus of the SOP view is that it allows to separate function-specific metadata from the main structural representation and recombining this information later. {\textcopyright} 2014 ACM.},
address = {New York, New York, USA},
author = {de Vries, Edsko and L{\"{o}}h, Andres},
booktitle = {Proceedings of the 10th ACM SIGPLAN workshop on Generic programming - WGP '14},
doi = {10.1145/2633628.2633634},
file = {:Users/liang-tingchen/Dropbox/References/De Vries, L{\"{o}}h - 2014 - True sums of products.pdf:pdf},
isbn = {9781450330428},
keywords = {datatype-generic programming,generic views,json,lenses,metadata,sums of products,universes},
pages = {83--94},
publisher = {ACM Press},
title = {{True sums of products}},
url = {http://dl.acm.org/citation.cfm?doid=2633628.2633634},
year = {2014}
}
@article{Boldo2016,
abstract = {In the recent years, numerous proof systems have improved enough to be used for formally verifying non-trivial mathematical results. They, however, have different purposes and it is not always easy to choose which one is adapted to undertake a formalization effort. In this survey, we focus on properties related to real analysis: real numbers, arithmetic operators, limits, differentiability, integrability and so on. We have chosen to look into the formalizations provided in standard by the following systems: Coq, HOL4, HOL Light, Isabelle/HOL, Mizar, ProofPower-HOL, and PVS. We have also accounted for large developments that play a similar role or extend standard libraries: ACL2(r) for ACL2, C-CoRN/MathClasses for Coq, and the NASA PVS library. This survey presents how real numbers have been defined in these various provers and how the notions of real analysis described above have been formalized. We also look at the methods of automation these systems provide for real analysis.},
author = {BOLDO, SYLVIE and LELAY, CATHERINE and MELQUIOND, GUILLAUME},
doi = {10.1017/S0960129514000437},
file = {:Users/liang-tingchen/Dropbox/References/BOLDO, LELAY, MELQUIOND - 2016 - Formalization of real analysis a survey of proof assistants and libraries.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {oct},
number = {7},
pages = {1196--1233},
title = {{Formalization of real analysis: a survey of proof assistants and libraries}},
url = {https://www.cambridge.org/core/product/identifier/S0960129514000437/type/journal{\_}article},
volume = {26},
year = {2016}
}
@article{Clouston2016,
abstract = {We present the guarded lambda-calculus, an extension of the simply typed lambda-calculus with guarded recursive and coinductive types. The use of guarded recursive types ensures the productivity of well-typed programs. Guarded recursive types may be transformed into coinductive types by a type-former inspired by modal logic and Atkey-McBride clock quantification, allowing the typing of acausal functions. We give a call-by-name operational semantics for the calculus, and define adequate denotational semantics in the topos of trees. The adequacy proof entails that the evaluation of a program always terminates. We introduce a program logic with L{\"{o}}b induction for reasoning about the contextual equivalence of programs. We demonstrate the expressiveness of the calculus by showing the definability of solutions to Rutten's behavioural differential equations.},
author = {Clouston, Ranald and Bizjak, Ale{\v{s}} and Grathwohl, Hans and Birkedal, Lars},
doi = {10.2168/LMCS-12(3:7)2016},
editor = {Tarlecki, Andrzej},
file = {:Users/liang-tingchen/Dropbox/References/Clouston et al. - 2016 - The Guarded Lambda-Calculus Programming and Reasoning with Guarded Recursion for Coinductive Types.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Coinductive types,Denotational semantics,Guarded recursion,Program logic,Typed lambda-calculus},
month = {apr},
number = {3},
pages = {1--39},
title = {{The Guarded Lambda-Calculus: Programming and Reasoning with Guarded Recursion for Coinductive Types}},
url = {https://lmcs.episciences.org/2019},
volume = {12},
year = {2016}
}
@inproceedings{Kobayashi2009,
abstract = {The model checking of higher-order recursion schemes has important applications in the verification of higher-order programs. Ong has previously shown that the modal mu-calculus model checking of trees generated by order-n recursion scheme is n-EXPTIME complete, but his algorithm and its correctness proof were rather complex. We give an alternative, type-based verification method: Given a modal mu-calculus formula, we can construct a type system in which a recursion scheme is typable if, and only if, the (possibly infinite, ranked) tree generated by the scheme satisfies the formula. The model checking problem is thus reduced to a type checking problem. Our type-based approach yields a simple verification algorithm, and its correctness proof (constructed without recourse to game semantics) is comparatively easy to understand. Furthermore, the algorithm is polynomial-time in the size of the recursion scheme, assuming that the formula and the largest order and arity of non-terminals of the recursion scheme are fixed.},
archivePrefix = {arXiv},
arxivId = {1012.1255},
author = {Kobayashi, Naoki and Ong, C.-H. Luke},
booktitle = {Proceedings of the 24th Annual IEEE Symposium on Logic In Computer Science},
doi = {10.1109/LICS.2009.29},
eprint = {1012.1255},
file = {:Users/liang-tingchen/Dropbox/References/Kobayashi, Ong - 2009 - A Type System Equivalent to the Modal Mu-Calculus Model Checking of Higher-Order Recursion Schemes.pdf:pdf},
isbn = {978-0-7695-3746-7},
issn = {10436871},
month = {aug},
pages = {179--188},
publisher = {IEEE},
title = {{A Type System Equivalent to the Modal Mu-Calculus Model Checking of Higher-Order Recursion Schemes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5230581},
year = {2009}
}
@inproceedings{Eigner2013,
abstract = {Differential privacy is a confidentiality property for database queries which allows for the release of statistical information about the content of a database without disclosing personal data. The variety of database queries and enforcement mechanisms has recently sparked the development of a number of mechanized proof techniques for differential privacy. Personal data, however, are often spread across multiple databases and queries have to be jointly computed by multiple, possibly malicious, parties. Many cryptographic protocols have been proposed to protect the data in transit on the network and to achieve differential privacy in a distributed, adversarial setting. Proving differential privacy for such protocols is hard and, unfortunately, out of the scope of the aforementioned mechanized proof techniques. In this work, we present the first framework for the mechanized verification of distributed differential privacy. We propose a symbolic definition of differential privacy for distributed databases, which takes into account Dolev-Yao intruders and can be used to reason about compromised parties. Furthermore, we develop a linear, distance-aware type system to statically and automatically enforce distributed differential privacy in cryptographic protocol implementations (expressed in the RCF calculus). We also provide an algorithmic variant of our type system, which we prove sound and complete. Finally, we tested our analysis technique on a recently proposed protocol for privacy-preserving web analytics: we discovered a new attack acknowledged by the authors, proposed a fix, and successfully type-checked the revised variant.},
author = {Eigner, Fabienne and Maffei, Matteo},
booktitle = {2013 IEEE 26th Computer Security Foundations Symposium},
doi = {10.1109/CSF.2013.25},
file = {:Users/liang-tingchen/Dropbox/References/Eigner, Maffei - 2013 - Differential Privacy by Typing in Security Protocols.pdf:pdf},
isbn = {978-0-7695-5031-2},
issn = {10636900},
keywords = {cryptographic protocols,differential privacy,type systems},
month = {jun},
pages = {272--286},
publisher = {IEEE},
title = {{Differential Privacy by Typing in Security Protocols}},
url = {https://ieeexplore.ieee.org/document/6595834/},
year = {2013}
}
@phdthesis{Diehl2017,
address = {Portland, OR},
author = {Diehl, Larry},
doi = {10.15760/etd.5531},
file = {:Users/liang-tingchen/Dropbox/References/Diehl - 2017 - Fully Generic Programming Over Closed Universes of Inductive-Recursive Types.pdf:pdf},
pages = {273},
school = {Portland State University},
title = {{Fully Generic Programming Over Closed Universes of Inductive-Recursive Types}},
url = {http://pdxscholar.library.pdx.edu/open{\_}access{\_}etds http://archives.pdx.edu/ds/psu/20620},
year = {2017}
}
@article{MacQueen1986,
author = {MacQueen, David and Plotkin, Gordon and Sethi, Ravi},
doi = {10.1016/S0019-9958(86)80019-5},
file = {:Users/liang-tingchen/Dropbox/References/MacQueen, Plotkin, Sethi - 1986 - An ideal model for recursive polymorphic types.pdf:pdf},
issn = {00199958},
journal = {Information and Control},
month = {oct},
number = {1-2},
pages = {95--130},
title = {{An ideal model for recursive polymorphic types}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0019995886800195},
volume = {71},
year = {1986}
}
@incollection{Simon1993,
author = {Simon, Imre},
booktitle = {Proceedings of 20th Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1007/3-540-56939-1_92},
editor = {Lingas, Andrzej and Karlsson, Rolf and Carlsson, Svante},
file = {:Users/liang-tingchen/Dropbox/References/Simon - 1993 - The product of rational languages.pdf:pdf},
pages = {430--444},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The product of rational languages}},
url = {http://link.springer.com/10.1007/3-540-56939-1{\_}92},
year = {1993}
}
@article{Yeung1991,
abstract = {Let X(i), i = 1,...,n, be discrete random variables, and X $\backslash$napproximately (i) be a set variable corresponding to X(i). Define the$\backslash$nuniversal set OMEGA to be union i(n) = 1X approximately (i) and let $\backslash$nthe sigma-field generated by {\{}X approximately (i), i = 1,...,n{\}}. It $\backslash$nis shown that Shannon's information measures on the random vairables $\backslash$nX(i), i = 1,...,n, constitute a unique measure mu* on F, which is $\backslash$ncalled the I-Measure. In other words, the Shannon information measure$\backslash$n(i.e., Shannon's information measures as a whole) is a measure on F, $\backslash$nthus establishing the analogy between information theory and set $\backslash$ntheory. Therefore each information theoretic operation can formally $\backslash$nbe viewed as a set theoretic operation, and vice versa. This point of$\backslash$nview, which we believe is of fundamental importance, has apparently $\backslash$nbeen overlooked in the past by information theorists. As a $\backslash$nconsequence the I-Diagram is introduced, which is a geometrical $\backslash$nrepresentation of the relationship among the information measures. $\backslash$nThe J-Diagram is analogous to the Venn Diagram in set theory. The use$\backslash$nof the I-Diagram is discussed; some applications of which reveal $\backslash$nresults that may otherwise be difficult to discover. A formula is $\backslash$nalso derived for the value of the I-Measure of the atoms of F and its$\backslash$nsub-sigma-fields generated by some subsets of the basic set $\backslash$nvariables.},
author = {Yeung, R.W.},
doi = {10.1109/18.79902},
file = {:Users/liang-tingchen/Dropbox/References/Yeung - 1991 - A new outlook on Shannon's information measures.pdf:pdf},
isbn = {978-3-642-56669-1},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {may},
number = {3},
pages = {466--474},
title = {{A new outlook on Shannon's information measures}},
url = {http://ieeexplore.ieee.org/document/79902/},
volume = {37},
year = {1991}
}
@incollection{Wojdyga2008,
abstract = {This paper presents simple, syntactic strong normalization proofs for the simply-typed $\lambda$-calculus and the polymorphic $\lambda$-calculus (system F) with the full set of logical connectives, and all the permutative reductions. The normalization proofs use translations of terms and types of to terms and types of and from to . {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
address = {Berlin, Heidelberg},
author = {Wojdyga, Aleksander},
booktitle = {Mathematical Foundations of Computer Science 2008. MFCS 2008},
doi = {10.1007/978-3-540-85238-4_50},
editor = {Ochma{\'{n}}ski, Edward and Tyszkiewicz, Jerzy},
file = {:Users/liang-tingchen/Dropbox/References/Wojdyga - 2008 - Short Proofs of Strong Normalization.pdf:pdf},
isbn = {3540852379},
issn = {03029743},
keywords = {CPS-translation,Lambda calculus,Permutative reductions,Strong normalization,System F},
pages = {613--623},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Short Proofs of Strong Normalization}},
url = {http://link.springer.com/10.1007/978-3-540-85238-4{\_}50},
volume = {5162},
year = {2008}
}
@article{Zangurashvili2004,
author = {Zangurashvili, Dali},
file = {:Users/liang-tingchen/Dropbox/References/Zangurashvili - 2004 - Several constructions for factorization systems.pdf:pdf},
journal = {Theory and Applications of Categories},
number = {11},
pages = {326--354},
title = {{Several constructions for factorization systems}},
url = {http://www.emis.ams.org/journals/TAC/volumes/12/11/12-11.pdf},
volume = {12},
year = {2004}
}
@article{Bergstra2013,
abstract = {We introduce an algebra of data linkages. Data linkages are intended for modelling the states of computations in which dynamic data structures are involved. We present a simple model of computation in which states of computations are modelled as data linkages and state changes take place by means of certain actions. We describe the state changes and replies that result from performing those actions by means of a term rewriting system with rule priorities. The model in question is an upgrade of molecular dynamics. The upgrading is mainly concerned with the features to deal with values and the features to reclaim garbage.},
archivePrefix = {arXiv},
arxivId = {0804.4565},
author = {Bergstra, J. A. and Middelburg, C. A.},
doi = {10.3233/FI-2013-950},
eprint = {0804.4565},
file = {:Users/liang-tingchen/Dropbox/References/Bergstra, Middelburg - 2013 - Data linkage algebra, data linkage dynamics, and priority rewriting.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
keywords = {data linkage algebra,data linkage dynamics,garbage collection,priority rewrite system},
number = {4},
pages = {367--412},
title = {{Data linkage algebra, data linkage dynamics, and priority rewriting}},
volume = {128},
year = {2013}
}
@article{Banaschewski1976,
author = {Banaschewski, Bernhard and Nelson, Evelyn},
doi = {10.4153/CMB-1976-060-2},
file = {:Users/liang-tingchen/Dropbox/References/Banaschewski, Nelson - 1976 - Tensor products and biomorphisms.pdf:pdf},
issn = {1496-4287},
journal = {Canadian Mathematical Bulletin},
month = {dec},
number = {4},
pages = {385--402},
title = {{Tensor products and biomorphisms}},
url = {http://www.cms.math.ca/10.4153/CMB-1976-060-2},
volume = {19},
year = {1976}
}
@inproceedings{Barth2006,
abstract = {Contextual integrity is a conceptual framework for un- derstanding privacy expectations and their implications de- veloped in the literature on law, public policy, and political philosophy. We formalize some aspects of contextual in- tegrity in a logical framework for expressing and reasoning about norms of transmission of personal information. In comparison with access control and privacy policy frame- works such as RBAC, EPAL, and P3P, these norms focus on who personal information is about, how it is transmit- ted, and past and future actions by both the subject and the users of the information. Norms can be positive or neg- ative depending on whether they refer to actions that are allowed or disallowed. Our model is expressive enough to capture naturally many notions of privacy found in legisla- tion, including those found in HIPAA, COPPA, and GLBA. A number of important problems regarding compliance with privacy norms, future requirements associated with specific actions, and relations between policies and legal standards reduce to standard decision procedures for temporal logic.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Barth, Adam and Datta, Anupam and Mitchell, J.C. and Nissenbaum, Helen},
booktitle = {2006 IEEE Symposium on Security and Privacy (S{\&}P'06)},
doi = {10.1109/SP.2006.32},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/Barth et al. - 2006 - Privacy and contextual integrity framework and applications.pdf:pdf},
isbn = {0-7695-2574-1},
issn = {10816011},
pages = {15 pp.--198},
pmid = {25246403},
publisher = {IEEE},
title = {{Privacy and contextual integrity: framework and applications}},
url = {http://ieeexplore.ieee.org/document/1624011/},
volume = {2006},
year = {2006}
}
@incollection{Goguen1995,
author = {Goguen, Healfdene},
booktitle = {Typed Lambda Calculi and Applications. TLCA 1995},
doi = {10.1007/BFb0014053},
editor = {Dezani-Ciancaglini, Mariangiola and Plotkin, Gordon},
file = {:Users/liang-tingchen/Dropbox/References/Goguen - 1995 - Typed operational semantics.pdf:pdf},
pages = {186--200},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Typed operational semantics}},
url = {http://link.springer.com/10.1007/BFb0014053},
volume = {902},
year = {1995}
}
@article{Iemhoff2001a,
abstract = {We present a basis for the admissible rules of intuitionistic propositional logic. Thereby a conjecture by de Jongh and Visser is proved. We also present a proof system for the admissible rules, and give semantic criteria for admissibility.},
author = {Iemhoff, Rosalie},
doi = {10.2307/2694922},
file = {:Users/liang-tingchen/Dropbox/References/Iemhoff - 2001 - On the admissible rules of intuitionistic propositional logic.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {mar},
number = {1},
pages = {281--294},
title = {{On the admissible rules of intuitionistic propositional logic}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200011324/type/journal{\_}article},
volume = {66},
year = {2001}
}
@article{Escardo2009,
abstract = {A number of authors have exported domain-theoretic techniques from denotational semantics to the operational study of contextual equivalence and order. We further develop this, and, moreover, we additionally export topological techniques. In particular, we work with an operational notion of compact set and show that total programs with values on certain types are uniformly continuous on compact sets of total elements. We apply this and other conclusions to prove the correctness of non-trivial programs that manipulate infinite data. What is interesting is that the development applies to sequential programming languages, in addition to languages with parallel features. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel and Ho, Weng Kin},
doi = {10.1016/j.ic.2008.12.003},
file = {:Users/liang-tingchen/Dropbox/References/Escard{\'{o}}, Ho - 2009 - Operational domain theory and topology of sequential programming languages.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {mar},
number = {3},
pages = {411--437},
title = {{Operational domain theory and topology of sequential programming languages}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540108001570},
volume = {207},
year = {2009}
}
@article{Assaf2015,
abstract = {The calculus of constructions can be extended with an infinite hierarchy of universes and cumu-lative subtyping. Subtyping is usually left implicit in the typing rules. We present an alternative version of the calculus of constructions where subtyping is explicit. We avoid problems related to coercions and dependent types by using the Tarski style of universes and by adding equations to reflect equality.},
author = {Assaf, Ali},
doi = {10.4230/LIPIcs.TYPES.2014.27},
file = {:Users/liang-tingchen/Dropbox/References/Assaf - 2015 - A calculus of constructions with explicit subtyping.pdf:pdf},
isbn = {9783939897880},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Calculus of constructions,Cumulativity,Subtyping,Type theory,Universes},
number = {May 2014},
pages = {27--46},
title = {{A calculus of constructions with explicit subtyping}},
volume = {39},
year = {2015}
}
@article{Blackwell1989a,
author = {Blackwell, Robert and Kelly, Gregory Maxwell and Power, A. John},
doi = {10.1016/0022-4049(89)90160-6},
file = {:Users/liang-tingchen/Dropbox/References/Blackwell, Kelly, Power - 1989 - Two-dimensional monad theory.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jul},
number = {1},
pages = {1--41},
title = {{Two-dimensional monad theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404989901606},
volume = {59},
year = {1989}
}
@article{SLack2004a,
abstract = {We introduce adhesive categories, which are categories with structure ensuring that pushouts along monomorphisms are well- behaved, as well as quasiadhesive categories which restrict attention to regular monomorphisms. Many examples of graphical structures used in computer science are shown to be examples of adhesive and quasi- adhesive categories. Double-pushout graph rewriting generalizes well to rewriting on arbitrary adhesive and quasiadhesive categories. Mathematics},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and L{\"{u}}cke, Dominik and Milius, Stefan},
doi = {10.1051/ita:2007028},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, L{\"{u}}cke, Milius - 2007 - Recursive coalgebras of finitary functors.pdf:pdf},
issn = {0988-3754},
journal = {RAIRO - Theoretical Informatics and Applications},
keywords = {adhesive categories,and phrases,category theory,extensive categories,quasiadhesive categories},
month = {oct},
number = {4},
pages = {447--462},
title = {{Recursive coalgebras of finitary functors}},
url = {http://www.rairo-ita.org/10.1051/ita:2007028},
volume = {41},
year = {2007}
}
@article{HINZE2000,
abstract = {A trie is a search tree scheme that employs the structure of search keys to organize information. Tries were originally devised as a means to represent a collection of records indexed by strings over a fixed alphabet. Based on work by C. P. Wadsworth and others, R. H. Connelly and F. L. Morris generalized the concept to permit indexing by elements built according to an arbitrary signature. Here we go one step further, and define tries and operations on tries generically for arbitrary datatypes of first-order kind, including parameterized and nested datatypes. The derivation employs techniques recently developed in the context of polytypic programming and can be regarded as a comprehensive case study in this new programming paradigm. It is well known that for the implementation of generalized tries, nested datatypes and polymorphic recursion are needed. Implementing tries for first-order kinded datatypes places even greater demands on the type system: it requires rank-2 type signatures and second-order nested datatypes. Despite these requirements, the definition of tries is surprisingly simple, which is mostly due to the framework of polytypic programming.},
author = {HINZE, RALF},
doi = {10.1017/S0956796800003713},
file = {:Users/liang-tingchen/Dropbox/References//HINZE - 2000 - Generalizing generalized tries.pdf:pdf},
isbn = {2210-271X},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {jul},
number = {4},
pages = {327--351},
publisher = {Cambridge University Press},
title = {{Generalizing generalized tries}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796800003713},
volume = {10},
year = {2000}
}
@phdthesis{Saillard2015,
author = {Saillard, Ronan},
file = {:Users/liang-tingchen/Dropbox/References/Saillard - 2015 - Typechecking in the lambda-Pi-Calculus Modulo Theory and Practice.pdf:pdf},
school = {Ecole Nationale Sup{\'{e}}rieure des Mines de Paris},
title = {{Typechecking in the lambda-Pi-Calculus Modulo : Theory and Practice}},
year = {2015}
}
@article{Carboni1991,
author = {Carboni, Aurelio and Kelly, Gregory Maxwell and Wood, Richard J.},
file = {:Users/liang-tingchen/Dropbox/References/Carboni, Kelly, Wood - 1991 - A 2-categorical approach to change of base and geometric morphisms I.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {1},
pages = {47--95},
title = {{A 2-categorical approach to change of base and geometric morphisms I}},
volume = {32},
year = {1991}
}
@inproceedings{Chang2017a,
abstract = {We present TURNSTILE, a metalanguage for creating typed embedded languages. To implement the type system, programmers write type checking rules resembling traditional judgment syntax. To implement the semantics, they incorporate elaborations into these rules. TURNSTILE critically depends on the idea of linguistic reuse. It exploits a macro system in a novel way to simultaneously type check and rewrite a surface program into a target language. Reusing a macro system also yields modular implementations whose rules may be mixed and matched to create other languages. Combined with typical compiler and runtime reuse, TURNSTILE produces performant typed embedded languages with little effort.},
address = {New York, New York, USA},
author = {Chang, Stephen and Knauth, Alex and Greenman, Ben},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
doi = {10.1145/3009837.3009886},
file = {:Users/liang-tingchen/Dropbox/References/Chang, Knauth, Greenman - 2017 - Type systems as macros.pdf:pdf},
isbn = {9781450346603},
issn = {07308566},
keywords = {Macros,Type systems,Typed embedded DSLs},
pages = {694--705},
publisher = {ACM Press},
title = {{Type systems as macros}},
url = {http://dl.acm.org/citation.cfm?doid=3009837.3009886},
year = {2017}
}
@incollection{Balan2011a,
abstract = {We investigate how finitary functors on Set can be extended or lifted to finitary functors on Preord and Poset and discuss applications to coalgebra.},
author = {Balan, Adriana and Kurz, Alexander},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-22944-2_7},
file = {:Users/liang-tingchen/Dropbox/References/Balan, Kurz - 2011 - Finitary functors From {\$}mathbf{\{}Set{\}}{\$} to {\$}mathbf{\{}Preord{\}}{\$} and {\$}mathbf{\{}Poset{\}}{\$}.pdf:pdf},
pages = {85--99},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Finitary functors: From {\$}\backslashmathbf{\{}Set{\}}{\$} to {\$}\backslashmathbf{\{}Preord{\}}{\$} and {\$}\backslashmathbf{\{}Poset{\}}{\$}}},
type = {Book part (with own title)},
volume = {6859},
year = {2011}
}
@phdthesis{Weteringen2016,
abstract = {This thesis details a class of partial orders on the space of probability distributions and the space of density operators which capture the idea of information content. Some links to domain theory and computational linguistics are also discussed. Chapter 1 details some useful theorems from order theory. In Chapter 2 we define a notion of an information ordering on the space of probability distributions and see that this gives rise to a large class of orderings. In Chapter 3 we extend the idea of an information ordering to the space of density operators and in particular look at the maximum eigenvalue order. We will discuss whether this order might be unique given certain restrictions. In Chapter 4 we discuss a possible application in distributional language models, namely in the study of entailment and disambiguation.},
archivePrefix = {arXiv},
arxivId = {1701.06924},
author = {van de Wetering, John},
eprint = {1701.06924},
file = {:Users/liang-tingchen/Dropbox/References/van de Wetering - 2017 - Ordering information on distributions.pdf:pdf},
month = {jul},
school = {Wolfson College, University of Oxford},
title = {{Ordering information on distributions}},
type = {Master Thesis},
url = {http://arxiv.org/abs/1701.06924},
year = {2017}
}
@article{Abel2017b,
abstract = {Type theory should be able to handle its own meta-theory, both to justify its foundational claims and to obtain a verified implementation. At the core of a type checker for intensional type theory lies an algorithm to check equality of types, or in other words, to check whether two types are convertible. We have formalized in Agda a practical conversion checking algorithm for a dependent type theory with one universe {\`{a}} la Russell, natural numbers, and $\eta$-equality for $\Pi$ types. We prove the algorithm correct via a Kripke logical relation parameterized by a suitable notion of equivalence of terms. We then instantiate the parameterized fundamental lemma twice: once to obtain canonicity and injectivity of type formers, and once again to prove the completeness of the algorithm. Our proof relies on inductive-recursive definitions, but not on the uniqueness of identity proofs. Thus, it is valid in variants of intensional Martin-L{\"{o}}f Type Theory as long as they support induction-recursion, for instance, Extensional, Observational, or Homotopy Type Theory.},
author = {Abel, Andreas and {\"{O}}hman, Joakim and Vezzosi, Andrea},
doi = {10.1145/3158111},
file = {:Users/liang-tingchen/Dropbox/References/Abel, {\"{O}}hman, Vezzosi - 2017 - Decidability of conversion for type theory in type theory.pdf:pdf},
journal = {Proceedings of the ACM on Programming Languages},
number = {POPL},
pages = {1--29},
title = {{Decidability of conversion for type theory in type theory}},
volume = {2},
year = {2017}
}
@book{Martin-Lof1984,
address = {Napoli},
author = {Martin-Löf, Per},
file = {:Users/liang-tingchen/Dropbox/References/Martin-Löf - 1984 - Intuitionistic Type Theory.pdf:pdf},
isbn = {88-7088-105-9},
number = {June},
publisher = {Bibliopolis},
series = {Studies in Proof Theory},
title = {{Intuitionistic Type Theory}},
year = {1984}
}
@article{Nganou2018,
author = {Nganou, Jean B},
doi = {10.1007/s10485-018-9547-x},
file = {:Users/liang-tingchen/Dropbox/References/Nganou - 2018 - Categorical Properties of Compact Hausdorff MV-Algebras.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {06d35,06d50,06e15,Compact MV-algebras,Completely distributive,E-multiset,Extremally disconnected,Projective MV-algebra,compact mv-algebras,completely distributive,disconnected,e-multiset,extremally,mathematics subject classification 03g20,projective mv-algebra},
month = {nov},
number = {October},
publisher = {Springer Netherlands},
title = {{Categorical Properties of Compact Hausdorff MV-Algebras}},
url = {https://doi.org/10.1007/s10485-018-9547-x http://link.springer.com/10.1007/s10485-018-9547-x},
year = {2018}
}
@incollection{Honda2014,
abstract = {Session types are types for distributed communicating pro- cesses. They were born from process encodings of data structures and typical interaction scenarios in an asynchronous version of the $\pi$-calculus, and are being studied and developed as a potential basis for structuring concurrent and distributed computing, as well as in their own right. In this paper, we introduce basic ideas of sessions and session types, outline their key technical elements, and discuss how they may be usable for programming, drawing from our experience and comparing with existing paradigms, especially concurrent objects such as actors. We discuss how session types can offer a programming framework in which communica- tions are structured both in program text and at run-time.},
author = {Honda, Kohei and Hu, Raymond and Neykova, Rumyana and Chen, Tzu-chun and Demangeon, Romain and Deni{\'{e}}lou, Pierre-malo and Yoshida, Nobuko},
booktitle = {Concurrent Objects and Beyond: Papers dedicated to Akinori Yonezawa on the Occasion of His 65th Birthday},
doi = {10.1007/978-3-662-44471-9_5},
file = {:Users/liang-tingchen/Dropbox/References/Honda et al. - 2014 - Structuring Communication with Session Types.pdf:pdf},
isbn = {978-3-662-44471-9},
issn = {16113349},
pages = {105--127},
title = {{Structuring Communication with Session Types}},
url = {http://link.springer.com/10.1007/978-3-662-44471-9{\_}5},
year = {2014}
}
@incollection{Moschovakis2009,
author = {Moschovakis, Yiannis N},
booktitle = {Computer Science Logic. CSL 2009},
doi = {10.1007/978-3-642-04027-6_5},
editor = {Gr{\"{a}}del, Erich and Kahle, Reinhard},
file = {:Users/liang-tingchen/Dropbox/References/Moschovakis - 2009 - Kleene's Amazing Second Recursion Theorem.pdf:pdf},
pages = {24--39},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Kleene's Amazing Second Recursion Theorem}},
url = {http://link.springer.com/10.1007/978-3-642-04027-6{\_}5},
volume = {5771},
year = {2009}
}
@article{Eremondi2019,
abstract = {Dependent types help programmers write highly reliable code. However, this reliability comes at a cost: it can be challenging to write new prototypes in (or migrate old code to) dependently-typed programming languages. Gradual typing makes static type disciplines more flexible, so an appropriate notion of gradual dependent types could fruitfully lower this cost. However, dependent types raise unique challenges for gradual typing. Dependent typechecking involves the execution of program code, but gradually-typed code can signal runtime type errors or diverge. These runtime errors threaten the soundness guarantees that make dependent types so attractive, while divergence spoils the type-driven programming experience.},
archivePrefix = {arXiv},
arxivId = {1906.06469},
author = {Eremondi, Joseph and Tanter, {\'{E}}ric and Garcia, Ronald},
doi = {10.1145/3341692},
eprint = {1906.06469},
file = {:Users/liang-tingchen/Dropbox/References/Eremondi, Tanter, Garcia - 2019 - Approximate normalization for gradual dependent types.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--30},
title = {{Approximate normalization for gradual dependent types}},
url = {https://dl.acm.org/doi/10.1145/3341692},
volume = {3},
year = {2019}
}
@incollection{Walt2013,
author = {Walt, Paul Van Der and Swierstra, Wouter},
booktitle = {Implementation and Application of Functional Languages},
doi = {10.1007/978-3-642-41582-1_10},
editor = {Hinze, Ralf},
file = {:Users/liang-tingchen/Dropbox/References/Walt, Swierstra - 2013 - Engineering Proof by Reflection in Agda.pdf:pdf},
isbn = {978-3-642-41581-4},
issn = {0302-9743},
keywords = {agda,dependently-typed programming,metaprogramming,proof by,reflection},
pages = {157--173},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Engineering Proof by Reflection in Agda}},
url = {http://dx.doi.org/10.1007/978-3-642-41582-1{\_}10},
year = {2013}
}
@article{Fung2010,
abstract = {The collection of digital information by governments, corporations, and individuals has created tremendous opportunities for knowledge- and information-based decision making. Driven bymutual benefits, or by regu- lations that require certain data to be published, there is a demand for the exchange and publication of data among various parties. Data in its original form, however, typically contains sensitive information about in- dividuals, and publishing such data will violate individual privacy. The current practice in data publishing reliesmainly on policies and guidelines as to what types of data can be published and on agreements on the use of published data. This approach alone may lead to excessive data distortion or insufficient protection. Privacy-preserving data publishing (PPDP) provides methods and tools for publishing useful information while preserving data privacy. Recently, PPDP has received considerable attention in research communi- ties, and many approaches have been proposed for different data publishing scenarios. In this survey, we will systematically summarize and evaluate different approaches to PPDP, study the challenges in prac- tical data publishing, clarify the differences and requirements that distinguish PPDP from other related problems, and propose future research directions},
author = {Fung, Benjamin C. M. and Wang, Ke and Chen, Rui and Yu, Philip S.},
doi = {10.1145/1749603.1749605},
file = {:Users/liang-tingchen/Dropbox/References/Fung et al. - 2010 - Privacy-preserving data publishing.pdf:pdf},
isbn = {ISSN{\~{}}{\~{}}26176633},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {jun},
number = {4},
pages = {1--53},
pmid = {16914745},
title = {{Privacy-preserving data publishing}},
url = {http://portal.acm.org/citation.cfm?doid=1749603.1749605},
volume = {42},
year = {2010}
}
@book{Goldblatt2009a,
author = {Goldblatt, Robert},
edition = {Revised},
isbn = {0486450260},
publisher = {Dover Publications Inc.},
shorttitle = {Topoi},
title = {{Topoi: The Categorial Analysis of Logic}},
type = {Book},
year = {2009}
}
@phdthesis{Brilakis2018,
author = {Brilakis, Konstantinos},
file = {:Users/liang-tingchen/Dropbox/References/Brilakis - 2018 - On Initial Categories with Families Formalization of unityped and simply typed CwFs in Agda.pdf:pdf},
school = {Chalmers University of Technology, University of Gothenburg},
title = {{On Initial Categories with Families: Formalization of unityped and simply typed CwFs in Agda}},
type = {Master's Thesis},
year = {2018}
}
@book{Nipkow2002,
address = {Berlin, Heidelberg},
doi = {10.1007/3-540-45949-9},
editor = {Nipkow, Tobias and Wenzel, Markus and Paulson, Lawrence C.},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 2002 - IsabelleHOL.pdf:pdf},
isbn = {978-3-540-43376-7},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Isabelle/HOL}},
url = {http://link.springer.com/10.1007/3-540-45949-9},
volume = {2283},
year = {2002}
}
@article{Knuth2005,
author = {Knuth, Kevin H.},
doi = {10.1016/j.neucom.2004.11.039},
file = {:Users/liang-tingchen/Dropbox/References/Knuth - 2005 - Lattice duality The origin of probability and entropy.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {bayesian inference,entropy,information theory,inquiry,lattice,probability},
month = {aug},
pages = {245--274},
title = {{Lattice duality: The origin of probability and entropy}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231205001165},
volume = {67},
year = {2005}
}
@inproceedings{Boulier2017,
abstract = {A family of syntactic models for the calculus of construction with universes (CC$\omega$) is described, all of them preserving conversion of the calculus definitionally, and thus giving rise directly to a program transformation of CC! into itself. Those models are based on the remark that negative type constructors (e.g., dependent product, coinductive types or universes) are underspecified in type theory-which leaves some freedom on extra intensional specifications. The model construction can be seen as a compilation phase from a complex type theory into a simpler type theory. Such models can be used to derive (the negative part of) independence results with respect to CC!, such as functional extensionality, propositional extensionality, univalence or the fact that bisimulation on a coinductive type may not coincide with equality. They can also be used to add new principles to the theory, which we illustrate by defining a version of CC$\omega$ with ad-hoc polymorphism that shows in particular that parametricity is not an implicit requirement of type theory. The correctness of some of the models/program transformations have been checked in the COQ proof assistant and have been instrumented as a COQ plugin.},
address = {New York, New York, USA},
author = {Boulier, Simon and P{\'{e}}drot, Pierre-Marie and Tabareau, Nicolas},
booktitle = {Proceedings of the 6th ACM SIGPLAN Conference on Certified Programs and Proofs - CPP 2017},
doi = {10.1145/3018610.3018620},
file = {:Users/liang-tingchen/Dropbox/References/Boulier, P{\'{e}}drot, Tabareau - 2017 - The next 700 syntactical models of type theory.pdf:pdf},
isbn = {9781450347051},
keywords = {Dependent type theory,Program translation},
pages = {182--194},
publisher = {ACM Press},
title = {{The next 700 syntactical models of type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3018610.3018620},
year = {2017}
}
@inproceedings{Wadler1989,
address = {New York, NY, USA},
author = {Wadler, Philip},
booktitle = {Proceedings of the 4th International Conference on Functional Programming Languages and Computer Architecture},
doi = {10.1145/99370.99404},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 1989 - Theorems for free!.pdf:pdf},
isbn = {0897913280},
pages = {347--359},
publisher = {ACM Press},
title = {{Theorems for free!}},
url = {http://dl.acm.org/citation.cfm?id=99404 http://portal.acm.org/citation.cfm?doid=99370.99404},
year = {1989}
}
@incollection{Dahlqvist2011,
abstract = {Fusion is arguably the simplest way to combine modal logics. For normal modal logics with Kripke semantics, many properties such as completeness and decidability are known to transfer from the component logics to their fusion. In this paper we investigate to what extent these results can be generalised to the case of arbitrary coalgebraic logics. Our main result generalises a construction of Kracht and Wolter and confirms that completeness transfers to fusion for a large class of logics over coalgebraic semantics. This result is independent of the rank of the logics and relies on generalising the notions of distance and box operator to coalgebraic models.},
author = {Dahlqvist, Fredrik and Pattinson, Dirk},
booktitle = {Proceedings of the 4th International Conference on Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-22944-2_12},
editor = {Corradini, Andrea and Klin, Bartek and C{\^{i}}rstea, Corina},
file = {:Users/liang-tingchen/Dropbox/References/Dahlqvist, Pattinson - 2011 - On the fusion of coalgebraic logics.pdf:pdf},
pages = {161--175},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On the fusion of coalgebraic logics}},
year = {2011}
}
@article{Hoyrup2009,
abstract = {In this paper, we investigate algorithmic randomness on more general spaces than the Cantor space, namely computable metric spaces. To do this, we first develop a unified framework allowing computations with probability measures. We show that any computable metric space with a computable probability measure is isomorphic to the Cantor space in a computable and measure-theoretic sense. We show that any computable metric space admits a universal uniform randomness test (without further assumption). {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Hoyrup, Mathieu and Rojas, Crist{\'{o}}bal},
doi = {10.1016/j.ic.2008.12.009},
file = {:Users/liang-tingchen/Dropbox/References/Hoyrup, Rojas - 2009 - Computability of probability measures and Martin-L{\"{o}}f randomness over metric spaces.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Algorithmic randomness,Almost computable function,Computability,Computable metric space,Computable probability measure,Enumerative lattice,Kolmogorov-Chaitin complexity,Universal test},
month = {jul},
number = {7},
pages = {830--847},
publisher = {Elsevier Inc.},
title = {{Computability of probability measures and Martin-L{\"{o}}f randomness over metric spaces}},
url = {http://dx.doi.org/10.1016/j.ic.2008.12.009 http://linkinghub.elsevier.com/retrieve/pii/S0890540109000170},
volume = {207},
year = {2009}
}
@article{Luo2013,
abstract = {Coercive subtyping is a useful and powerful framework of subtyping for type theories. The key idea of coercive subtyping is subtyping as abbreviation. In this paper, we give a new and adequate formulation of T [C], the system that extends a type theory T with coercive subtyping based on a set C of basic subtyping judgements, and show that coercive subtyping is a conservative extension and, in a more general sense, a definitional extension. We introduce an intermediate system, the star-calculus T [C]., in which the positions that require coercion insertions are marked, and show that T [C]. is a conservative extension of T and that T [C]. is equivalent to T [C]. This makes clear what we mean by coercive subtyping being a conservative extension, on the one hand, and amends a technical problem that has led to a gap in the earlier conservativity proof, on the other. We also compare coercive subtyping with the ′ordinary′ notion of subtyping-subsumptive subtyping, and show that the former is adequate for type theories with canonical objects while the latter is not. An improved implementation of coercive subtyping is done in the proof assistant Plastic. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
author = {Luo, Z. and Soloviev, S. and Xue, T.},
doi = {10.1016/j.ic.2012.10.020},
file = {:Users/liang-tingchen/Dropbox/References/Luo, Soloviev, Xue - 2013 - Coercive subtyping Theory and implementation.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Coercive subtyping,Conservativity,Definitional extension,Subsumptive subtyping,Type theory},
month = {feb},
pages = {18--42},
publisher = {Elsevier Inc.},
title = {{Coercive subtyping: Theory and implementation}},
url = {http://dx.doi.org/10.1016/j.ic.2012.10.020 https://linkinghub.elsevier.com/retrieve/pii/S0890540112001757},
volume = {223},
year = {2013}
}
@incollection{Gibbons2003a,
author = {Altenkirch, Thorsten and McBride, Conor},
booktitle = {Generic Programming IFIP TC2 / WG2.1 Working Conference Programming July 11–12, 2002, Dagstuhl, Germany},
doi = {10.1007/978-0-387-35672-3_1},
editor = {Gibbons, Jeremy and Jeuring, Johan},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, McBride - 2003 - Generic Programming within Dependently Typed Programming.pdf:pdf},
isbn = {9781475753202},
issn = {18684238},
pages = {1--20},
publisher = {Springer, Boston, MA},
series = {IFIP — The International Federation for Information Processing},
title = {{Generic Programming within Dependently Typed Programming}},
url = {http://link.springer.com/10.1007/978-0-387-35672-3{\_}1},
volume = {115},
year = {2003}
}
@inproceedings{altenkirch_et_al:LIPIcs:2016:5972,
abstract = {We develop normalisation by evaluation (NBE) for dependent types based on presheaf categories. Our construction is formulated using internal type theory using quotient inductive types. We use a typed presentation hence there are no preterms or realizers in our construction. NBE for simple types is using a logical relation between the syntax and the presheaf interpretation. In our construction, we merge the presheaf interpretation and the logical relation into a proof-relevant logical predicate. We have formalized parts of the construction in Agda.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (Normalisation by Evaluation for Dependent Types - Altenkirch, Thorsten; Kaposi, Ambrus)

Keywords: normalisation by evaluation, dependent types, internal type theory, logical relations, Agda},
author = {Altenkirch, Thorsten and Kaposi, Ambrus},
booktitle = {1st International Conference on Formal Structures for Computation and Deduction (FSCD 2016)},
doi = {10.4230/LIPIcs.FSCD.2016.6},
editor = {Kesner, Delia and Pientka, Brigitte},
file = {:Users/liang-tingchen/Dropbox/References//Altenkirch, Kaposi - 2016 - Normalisation by Evaluation for Dependent Types.pdf:pdf},
isbn = {978-3-95977-010-1},
issn = {1868-8969},
keywords = {Agda,Dependent types,Internal type theory,Logical relations,Normalisation by evaluation},
number = {6},
pages = {6:1----6:16},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Normalisation by Evaluation for Dependent Types}},
url = {http://drops.dagstuhl.de/opus/volltexte/2016/5972},
volume = {52},
year = {2016}
}
@incollection{Chen2008,
address = {Berlin, Heidelberg},
author = {Chen, Qingfeng and Zhang, Chengqi and Zhang, Shichao},
booktitle = {Secure Transaction Protocol Analysis},
doi = {10.1007/978-3-540-85074-8_2},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Zhang, Zhang - 2008 - Overview of security protocol analysis.pdf:pdf},
pages = {17--72},
publisher = {Springer Berlin Heidelberg},
title = {{Overview of security protocol analysis}},
url = {http://link.springer.com/10.1007/978-3-540-85074-8{\_}2},
year = {2008}
}
@article{Copello2018,
abstract = {In this article we continue the work started in [Ernesto Copello, {\'{A}}lvaro Tasistro, Nora Szasz, Ana Bove, and Maribel Fern{\'{a}}ndez. Alpha-structural induction and recursion for the $\lambda$-calculus in constructive type theory. Electronic Notes in Theoretical Computer Science, 323:109–124, 2016], deriving in Constructive Type Theory new induction principles for the $\lambda$-calculus, using (the historical) first order syntax with only one sort of names for both bound and free variables, and with $\alpha$-conversion based upon name swapping. The principles provide a flexible framework for mimicking pen-and-paper proofs within the rigorous formal setting of a proof assistant. We here report on one successful application, namely a complete proof of the Church-Rosser Theorem. The whole development has been machine-checked using the system Agda [Ulf Norell. Towards a Practical Programming Language Based on Dependent Type Theory. PhD thesis, Department of Computer Science and Engineering, Chalmers University of Technology, September 2007].},
author = {Copello, Ernesto and Szasz, Nora and Tasistro, {\'{A}}lvaro},
doi = {10.1016/j.entcs.2018.10.006},
file = {:Users/liang-tingchen/Dropbox/References//Copello, Szasz, Tasistro - 2018 - Machine-checked Proof of the Church-Rosser Theorem for the Lambda Calculus Using the Barendregt Variab.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Formal Metatheory,Lambda Calculus,Type Theory},
month = {oct},
pages = {79--95},
title = {{Machine-checked Proof of the Church-Rosser Theorem for the Lambda Calculus Using the Barendregt Variable Convention in Constructive Type Theory}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066118300720},
volume = {338},
year = {2018}
}
@article{Governatori2017,
abstract = {Defeasible logics provide several linguistic features to support the expression of defeasible knowledge. There is also a wide variety of such logics, expressing different intuitions about defeasible reasoning. However, the logics can only combine in trivial ways. This limits their usefulness in contexts where different intuitions are at play in different aspects of a problem. In particular, in some legal settings, different actors have different burdens of proof, which might be expressed as reasoning in different defeasible logics. In this paper, we introduce annotated defeasible logic as a flexible formalism permitting multiple forms of defeasibility, and establish some properties of the formalism. This paper is under consideration for acceptance in Theory and Practice of Logic Programming.},
archivePrefix = {arXiv},
arxivId = {1707.04734},
author = {Governatori, Guido and Maher, Michael J.},
doi = {10.1017/S1471068417000266},
eprint = {1707.04734},
file = {:Users/liang-tingchen/Dropbox/References/Governatori, Maher - 2017 - Annotated defeasible logic.pdf:pdf},
issn = {14753081},
journal = {Theory and Practice of Logic Programming},
keywords = {annotated logics,defeasible logic,legal reasoning,non-monotonic reasoning},
number = {5-6},
pages = {819--836},
title = {{Annotated defeasible logic}},
volume = {17},
year = {2017}
}
@article{Fric2010,
abstract = {First, we discuss basic probability notions from the viewpoint of category theory. Our approach is based on the following four “sine quibus non” conditions: 1. (elementary) category theory is efficient (and suffices); 2. random variables, observables, probability measures, and states are morphisms; 3. classical probability theory and fuzzy probability theory in the sense of S. Gudder and S. Bugajski are special cases of a more general model; 4. a good model allows natural modifications. Second, we show that the category ID of D-posets of fuzzy sets and sequentially continuous D-homomorphisms allows to characterize the passage from classical to fuzzy events as the minimal generalization having nontrivial quantum character: a degenerated state can be transported to a nondegenerated one. Third, we describe a general model of probability theory based on the category ID so that the classical and fuzzy probability theories become special cases and the model allows natural modifications. Finally, we present a modification in which the closed unit interval [0,1] as the domain of traditional states is replaced by a suitable simplex.},
author = {Fri{\v{c}}, Roman and Pap{\v{c}}o, Martin},
doi = {10.1007/s11225-010-9232-z},
file = {:Users/liang-tingchen/Dropbox/References/Fri{\v{c}}, Pap{\v{c}}o - 2010 - A Categorical Approach to Probability Theory.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
month = {feb},
number = {2},
pages = {215--230},
publisher = {Springer Netherlands},
title = {{A Categorical Approach to Probability Theory}},
url = {http://www.springerlink.com/content/5106n51j44lv6032/},
volume = {94},
year = {2010}
}
@article{Bucci2008,
author = {Filinski, Andrzej and Rohde, Henning Korsholm},
doi = {10.1051/ita:2005026},
file = {:Users/liang-tingchen/Dropbox/References/Filinski, Rohde - 2005 - Denotational aspects of untyped normalization by evaluation.pdf:pdf},
issn = {0988-3754},
journal = {RAIRO - Theoretical Informatics and Applications},
keywords = {and phrases,aspetti matematici e applicativi,automi e linguaggi formali,by the italian ministry,involutory antimorphisms,of education under,palindrome closures,palindromes,paper has been supported,project cofin 2005,pseudopalindromes,pseudostandard words,sturmian and episturmian words,the work for this},
month = {jul},
number = {3},
pages = {423--453},
title = {{Denotational aspects of untyped normalization by evaluation}},
url = {http://www.rairo-ita.org/10.1051/ita:2005026},
volume = {39},
year = {2005}
}
@article{Mitchell1988,
abstract = {Abstract data type declarations appear in typed programming languages like Ada, Alphard, {\{}CLU{\}} and {\{}ML.{\}} This form of declaration binds a list of identifiers to a type with associated operations, a composite ``value'' we call a data algebra. We use a second-order typed lambda calculus {\{}SOL{\}} to show how data algebras may be given types, passed as parameters, and returned as results of function calls. In the process, we discuss the semantics of abstract data type declarations and review a connection between typed programming languages and constructive logic.},
author = {Mitchell, John C. and Plotkin, Gordon D.},
doi = {10.1145/44501.45065},
file = {:Users/liang-tingchen/Dropbox/References/Mitchell, Plotkin - 1988 - Abstract types have existential type.pdf:pdf},
isbn = {0897911474},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
month = {jul},
number = {3},
pages = {470--502},
title = {{Abstract types have existential type}},
url = {http://portal.acm.org/citation.cfm?doid=44501.45065},
volume = {10},
year = {1988}
}
@article{Hanna1999,
author = {HANNA, KEITH},
doi = {10.1017/S095679689900338X},
file = {:Users/liang-tingchen/Dropbox/References/HANNA - 1999 - Implementing theorem provers in a purely functional style.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {S095679689900338X},
publisher = {Swansea University Libraries},
title = {{Implementing theorem provers in a purely functional style}},
url = {http://www.journals.cambridge.org/abstract{\_}S095679689900338X},
volume = {9},
year = {1999}
}
@article{Birkedal2019a,
abstract = {This paper improves the treatment of equality in guarded dependent type theory (GDTT), by combining it with cubical type theory (CTT). GDTT is an extensional type theory with guarded recursive types, which are useful for building models of program logics, and for programming and reasoning with coinductive types. We wish to implement GDTT with decidable type checking, while still supporting non-trivial equality proofs that reason about the extensions of guarded recursive constructions. CTT is a variation of Martin–L{\"{o}}f type theory in which the identity type is replaced by abstract paths between terms. CTT provides a computational interpretation of functional extensionality, enjoys canonicity for the natural numbers type, and is conjectured to support decidable type-checking. Our new type theory, guarded cubical type theory (GCTT), provides a computational interpretation of extensionality for guarded recursive types. This further expands the foundations of CTT as a basis for formalisation in mathematics and computer science. We present examples to demonstrate the expressivity of our type theory, all of which have been checked using a prototype type-checker implementation. We show that CTT can be given semantics in presheaves on C× D, where C is the cube category, and D is any small category with an initial object. We then show that the category of presheaves on C× $\omega$ provides semantics for GCTT.},
author = {Birkedal, Lars and Bizjak, Ale{\v{s}} and Clouston, Ranald and Grathwohl, Hans Bugge and Spitters, Bas and Vezzosi, Andrea},
doi = {10.1007/s10817-018-9471-7},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal et al. - 2019 - Guarded Cubical Type Theory.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Cubical type theory,Guarded recursion,Homotopy type theory},
month = {aug},
number = {2},
pages = {211--253},
publisher = {Springer Netherlands},
title = {{Guarded Cubical Type Theory}},
url = {https://doi.org/10.1007/s10817-018-9471-7 http://link.springer.com/10.1007/s10817-018-9471-7},
volume = {63},
year = {2019}
}
@article{Swan2019,
abstract = {We show that Church's thesis, the axiom stating that all functions on the naturals are computable, does not hold in the cubical assemblies model of cubical type theory. We show that nevertheless Church's thesis is consistent with univalent type theory by constructing a reflective subuniverse of cubical assemblies where it holds.},
archivePrefix = {arXiv},
arxivId = {1905.03014},
author = {Swan, Andrew and Uemura, Taichi},
eprint = {1905.03014},
file = {:Users/liang-tingchen/Dropbox/References/Swan, Uemura - 2019 - On Church's Thesis in Cubical Assemblies.pdf:pdf},
issn = {23318422},
journal = {arXiv},
month = {may},
pages = {1--23},
title = {{On Church's Thesis in Cubical Assemblies}},
url = {http://arxiv.org/abs/1905.03014},
year = {2019}
}
@phdthesis{Sokolova2005,
author = {Sokolova, Ana},
file = {:Users/liang-tingchen/Dropbox/References/Sokolova - 2005 - Coalgebraic Analysis of Probabilistic Systems.pdf:pdf},
school = {Eindhoven University of Technology},
title = {{Coalgebraic Analysis of Probabilistic Systems}},
year = {2005}
}
@incollection{Paulson1991,
author = {Paulson, Lawrence C. and Smith, Andrew W.},
booktitle = {In the Proceedings of Extensions of Logic Programming},
doi = {10.1007/BFb0038699},
editor = {Schroeder-Heister, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Paulson, Smith - 1991 - Logic programming, functional programming, and inductive definitions.pdf:pdf},
pages = {283--209},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Logic programming, functional programming, and inductive definitions}},
year = {1991}
}
@inproceedings{Aggarwal2005,
abstract = {In recent years, the wide availability of per- sonal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been pro- posed for privacy preserving data mining of multidimensional data records. One of the methods for privacy preserving data mining is that of anonymization, in which a record is released only if it is indistinguishable from k other entities in the data. We note that meth- ods such as k-anonymity are highly dependent upon spatial locality in order to effectively im- plement the technique in a statistically robust way. In high dimensional space the data be- comes sparse, and the concept of spatial local- ity is no longer easy to define from an applica- tion point of view. In this paper, we view the k-anonymization problem from the perspec- tive of inference attacks over all possible com- binations of attributes. We show that when the data contains a large number of attributes which may be considered quasi-identifiers, it becomes difficult to anonymize the data with- out an unacceptably high amount of infor- mation loss. This is because an exponential number of combinations of dimensions can be used to make precise inference attacks, even when individual attributes are partially spec- ified within a range. We provide an analysis of the effect of dimensionality on k-anonymity methods. We conclude that when a data set contains a large number of attributes which are open to inference attacks, we are faced with a choice of either completely suppressing most of the data or losing the desired level of anonymity. Thus, this paper shows that the curse of high dimensionality also applies to the problem of privacy preserving data mining.},
author = {Aggarwal, Charu C.},
booktitle = {Proceedings of the 31st VLDB Conference},
file = {:Users/liang-tingchen/Dropbox/References/Aggarwal - 2005 - On {\$}k{\$}-anonymity and the curse of dimensionality.pdf:pdf},
isbn = {1-59593-154-6},
pages = {901--909},
title = {{On {\$}k{\$}-anonymity and the curse of dimensionality}},
url = {http://portal.acm.org/citation.cfm?id=1083592.1083696},
year = {2005}
}
@article{Bes2013,
abstract = {We study expansions of the Weak Monadic Second Order theory of (N,{\textless}) by cardinality relations, which are predicates R(X1,...,Xn) whose truth value depends only on the cardinality of the sets X1,...,Xn. We first provide a (definable) criterion for definability of a cardinality relation in (N,{\textless}), and use it to prove that for every cardinality relation R which is not definable in (N,{\textless}), there exists a unary cardinality relation that is definable in (N,{\textless},R) and not in (N,{\textless}). These results resemble Muchnik and Michaux-Villemaire theorems for Presburger Arithmetic. We prove then that + and × are definable in (N,{\textless},R) for every cardinality relation R which is not definable in (N,{\textless}). This implies undecidability of the WMSO theory of (N,{\textless},R). We also consider the related satisfiability problem for the class of finite orderings, namely the question whether an MSO sentence in the language {\{}{\textless},R{\}} admits a finite model M where {\textless} is interpreted as a linear ordering, and R as the restriction of some (fixed) cardinality relation to the domain of M. We prove that this problem is undecidable for every cardinality relation R which is not definable in (N,{\textless}). {\textcopyright} Alexis B{\`{e}}s.},
author = {Hirschowitz, Tom},
doi = {10.2168/LMCS-9(3:10)2013},
editor = {Abramsky, Samson},
file = {:Users/liang-tingchen/Dropbox/References/Hirschowitz - 2013 - Cartesian closed 2-categories and permutation equivalence in higher-order rewriting.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Cardinality relations,Decidability,Definability,Monadic second-order logic},
month = {sep},
number = {3},
pages = {1--22},
title = {{Cartesian closed 2-categories and permutation equivalence in higher-order rewriting}},
url = {https://lmcs.episciences.org/1132},
volume = {9},
year = {2013}
}
@article{Wyler1973,
author = {Wyler, Oswald},
doi = {10.1016/0016-660X(72)90014-1},
file = {:Users/liang-tingchen/Dropbox/References/Wyler - 1973 - Convenient categories for topology.pdf:pdf},
issn = {0016660X},
journal = {General Topology and its Applications},
month = {sep},
number = {3},
pages = {225--242},
title = {{Convenient categories for topology}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0016660X72900141},
volume = {3},
year = {1973}
}
@incollection{Focardi2001,
abstract = {In the recent years, many formalizations of security properties have been proposed, most of which are based on different underlying models and are consequently difficult to compare. A classification of security properties is thus of interest for understanding the relationships among different definitions and for evaluating the relative merits. In this paper, many non-interference-like properties proposed for computer security are classified and compared in a unifying framework. The resulting taxonomy is evaluated through some case studies of access control in computer systems. The approach has been mechanized, resulting in the tool CoSeC. Various extensions (e.g., the application to cryptographic protocol analysis) and open problems are discussed.},
author = {Focardi, Riccardo and Gorrieri, Roberto},
booktitle = {Foundations of Security Analysis and Design. FOSAD 2000},
doi = {10.1007/3-540-45608-2_6},
editor = {Focardi, Riccardo and Gorrieri, Roberto},
file = {:Users/liang-tingchen/Dropbox/References/Focardi, Gorrieri - 2001 - Classification of security properties (Part I information flow).pdf:pdf},
isbn = {3540428968},
issn = {0302-9743},
pages = {331--396},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Classification of security properties (Part I: information flow)}},
url = {http://link.springer.com/10.1007/3-540-45608-2{\_}6},
volume = {2171},
year = {2001}
}
@article{Dwork2013,
abstract = {Private data analysis-the useful analysis of confidential data-requires a rigorous and practicable definition of privacy. Differential privacy, an emerging standard, is the subject of intensive investigation in several diverse research communities. We review the definition, explain its motivation, and discuss some of the challenges to bringing this concept to practice.},
author = {Dwork, Cynthia and Pottenger, Rebecca},
doi = {10.1136/amiajnl-2012-001047},
file = {:Users/liang-tingchen/Dropbox/References/Dwork, Pottenger - 2013 - Toward practicing privacy.pdf:pdf},
isbn = {1527-974X; 1067-5027},
issn = {1527-974X},
journal = {Journal of the American Medical Informatics Association},
month = {jan},
number = {1},
pages = {102--108},
pmid = {23243088},
title = {{Toward practicing privacy}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2012-001047},
volume = {20},
year = {2013}
}
@article{Ohearn2020,
abstract = {Program correctness and incorrectness are two sides of the same coin. As a programmer, even if you would like to have correctness, you might find yourself spending most of your time reasoning about incorrectness. This includes informal reasoning that people do while looking at or thinking about their code, as well as that supported by automated testing and static analysis tools. This paper describes a simple logic for program incorrectness which is, in a sense, the other side of the coin to Hoare's logic of correctness.},
author = {O'Hearn, Peter W.},
doi = {10.1145/3371078},
file = {:Users/liang-tingchen/Dropbox/References/O'Hearn - 2019 - Incorrectness logic.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Bugs,CCS Concepts: • Theory of computation → Programmin,Static Analysis},
month = {dec},
number = {POPL},
pages = {1--32},
title = {{Incorrectness logic}},
url = {https://doi.org/10.1145/3371078 http://dl.acm.org/citation.cfm?doid=3377388.3371078},
volume = {4},
year = {2019}
}
@article{Benke2003,
abstract = {We show how to write generic programs and proofs in Martin-L{\"{o}}f type theory. To this end we consider several extensions of Martin-L{\"{o}}f's logical framework for dependent types. Each extension has a universe of codes (signatures) for inductively defined sets with generic formation, introduction, elimination, and equality rules. These extensions are modeled on Dybjer and Setzer's finitely axiomatized theories of inductive-recursive definitions, which also have universes of codes for sets, and generic formation, introduction, elimination, and equality rules. Here we consider several smaller universes of interest for generic programming and universal algebra. We formalize one-sorted and many-sorted term algebras, as well as iterated, generalized, parameterized, and indexed inductive definitions. We also show how to extend the techniques of generic programming to these universes. Furthermore, we give generic proofs of reflexivity and substitutivity of a generic equality test: Most of the definitions in the paper have been implemented using the proof assistant Alfa for dependent type theory.},
author = {Benke, Marcin and Dybjer, Peter and Jansson, Patrik},
doi = {10.5555/985799.985801},
file = {:Users/liang-tingchen/Dropbox/References/Benke, Dybjer, Jansson - 2003 - Universes for generic programs and proofs in dependent type theory.pdf:pdf},
journal = {Nordic Journal of Computing},
number = {4},
pages = {265--289},
publisher = {Publishing Association Nordic Journal of Computing},
title = {{Universes for generic programs and proofs in dependent type theory}},
url = {https://dl.acm.org/doi/10.5555/985799.985801},
volume = {10},
year = {2003}
}
@article{Rompf2012,
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but developing high-quality program generators takes a large effort, even if a multi-stage programming language is used. We present lightweight modular staging, a library-based multistage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process. We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a standalone implementation with only modest effort. 2010 ACM.},
author = {Rompf, Tiark and Odersky, Martin},
doi = {10.1145/2184319.2184345},
file = {:Users/liang-tingchen/Dropbox/References/Rompf, Odersky - 2012 - Lightweight modular staging.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {jun},
number = {6},
pages = {121},
title = {{Lightweight modular staging}},
url = {http://dl.acm.org/citation.cfm?doid=2184319.2184345},
volume = {55},
year = {2012}
}
@article{Pitts2003,
abstract = {This paper formalises within first-order logic some common practices in computer science to do with representing and reasoning about syntactical structures involving lexically scoped binding constructs. It introduces Nominal Logic, a version of first-order many-sorted logic with equality containing primitives for renaming via name-swapping, for freshness of names, and for name-binding. Its axioms express properties of these constructs satisfied by the FM-sets model of syntax involving binding, which was recently introduced by the author and M.J. Gabbay and makes use of the Fraenkel-Mostowski permutation model of set theory. Nominal Logic serves as a vehicle for making two general points. First, name-swapping has much nicer logical properties than more general, non-bijective forms of renaming while at the same time providing a sufficient foundation for a theory of structural induction/recursion for syntax modulo $\alpha$-equivalence. Secondly, it is useful for the practice of operational semantics to make explicit the equivariance property of assertions about syntax - namely that their validity is invariant under name-swapping. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Pitts, Andrew M.},
doi = {10.1016/S0890-5401(03)00138-X},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2003 - Nominal logic, a first order theory of names and binding.pdf:pdf},
isbn = {3-540-42736-8},
issn = {08905401},
journal = {Information and Computation},
keywords = {Abstract syntax,Fresh names,Permutation,Variable binding},
month = {nov},
number = {2},
pages = {165--193},
pmid = {15006662},
title = {{Nominal logic, a first order theory of names and binding}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089054010300138X},
volume = {186},
year = {2003}
}
@inproceedings{DeJong2021b,
abstract = {We develop domain theory in constructive univalent foundations without Voevodsky's resizing axioms. In previous work in this direction, we constructed the Scott model of PCF and proved its computational adequacy, based on directed complete posets (dcpos). Here we further consider algebraic and continuous dcpos, and construct Scott's D∞ model of the untyped $\lambda$-calculus. A common approach to deal with size issues in a predicative foundation is to work with information systems or abstract bases or formal topologies rather than dcpos, and approximable relations rather than Scott continuous functions. Here we instead accept that dcpos may be large and work with type universes to account for this. For instance, in the Scott model of PCF, the dcpos have carriers in the second universe U1 and suprema of directed families with indexing type in the first universe U0. Seeing a poset as a category in the usual way, we can say that these dcpos are large, but locally small, and have small filtered colimits. In the case of algebraic dcpos, in order to deal with size issues, we proceed mimicking the definition of accessible category. With such a definition, our construction of Scott's D∞ again gives a large, locally small, algebraic dcpo with small directed suprema.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Domain Theory in Constructive and Predicative Univalent Foundations - de Jong, Tom; Escard{\'{o}}, Mart$\backslash$'$\backslash$in H{\"{o}}tzel)

Keywords: domain theory, constructivity, predicativity, univalent foundations},
author = {de Jong, Tom and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel},
booktitle = {29th EACSL Annual Conference on Computer Science Logic (CSL 2021)},
doi = {10.4230/LIPIcs.CSL.2021.28},
editor = {Baier, Christel and Goubault-Larrecq, Jean},
file = {:Users/liang-tingchen/Dropbox/References/de Jong, Escard{\'{o}} - 2021 - Domain Theory in Constructive and Predicative Univalent Foundations.pdf:pdf},
isbn = {978-3-95977-175-7},
issn = {1868-8969},
keywords = {Constructivity,Domain theory,Predicativity,Univalent foundations},
number = {28},
pages = {28:1----28:18},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Domain Theory in Constructive and Predicative Univalent Foundations}},
url = {https://drops.dagstuhl.de/opus/volltexte/2021/13462},
volume = {183},
year = {2021}
}
@article{Trnkova1969,
author = {Trnkov{\'{a}}, V{\v{e}}ra},
file = {:Users/liang-tingchen/Dropbox/References/Trnkov{\'{a}} - 1969 - Some properties of set functors.pdf:pdf},
journal = {Commentationes Mathematicae Universitatis Carolinae},
number = {2},
pages = {323--352},
title = {{Some properties of set functors}},
url = {http://www.dml.cz/bitstream/handle/10338.dmlcz/105237/CommentatMathUnivCarol{\_}010-1969-2{\_}15.pdf?sequence=1},
volume = {10},
year = {1969}
}
@inproceedings{Pirog2013,
abstract = {The monads used to model effectful computations traditionally concentrate on the 'destination' - the final results of the program. However, sometimes we are also interested in the 'journey' - the intermediate course of a computation - especially when reasoning about non-terminating interactive systems. In this article we claim that a necessary property of a monad for it to be able to describe the behaviour of a program is complete iterativity. We show how an ordinary monad can be modified to disclose more about its internal computational behaviour, by applying an associated transformer to a completely iterative monad. To illustrate this, we introduce two new constructions: a coinductive cousin of Cenciarelli and Moggi's generalised resumption transformer, and States - a State-like monad that accumulates the intermediate states. {\textcopyright} 2013 Elsevier B.V.},
author = {Pir{\'{o}}g, Maciej and Gibbons, Jeremy},
booktitle = {Proceedings of the Twenty-ninth Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1016/j.entcs.2013.09.019},
file = {:Users/liang-tingchen/Dropbox/References/Pir{\'{o}}g, Gibbons - 2013 - Monads for Behaviour.pdf:pdf},
issn = {15710661},
keywords = {completely iterative monads,effects,resumptions,tracing},
pages = {309--324},
publisher = {Elsevier B.V.},
title = {{Monads for Behaviour}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066113000650},
volume = {298},
year = {2013}
}
@incollection{Prisacariu2007,
abstract = {In this paper we propose a formal language for writing electronic contracts, based on the deontic notions of obligation, permission, and prohibition. We take an ought-to-do approach, where deontic operators are applied to actions instead of state-of-affairs. We propose an extension of the mu-calculus in order to capture the intuitive meaning of the deontic notions, and to express deterministic and concurrent actions. We provide a translation of the contract language into the logic, the semantics of which faithfully captures the meaning of obligation, permission and prohibition. We also show how our language captures most of the intuitive desirable properties of electronic contracts, as well as how it avoids most of the classical paradoxes of deontic logic. We finally show its applicability on a contract example.},
author = {Prisacariu, Cristian and Schneider, Gerardo},
booktitle = {Formal Methods for Open Object-Based Distributed Systems. FMOODS 2007.},
doi = {10.1007/978-3-540-72952-5_11},
editor = {Bonsangue, Marcello M. and Johnsen, Einar Broch},
file = {:Users/liang-tingchen/Dropbox/References/Prisacariu, Schneider - 2007 - A Formal Language for Electronic Contracts.pdf:pdf},
pages = {174--189},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Formal Language for Electronic Contracts}},
url = {http://link.springer.com/10.1007/978-3-540-72952-5{\_}11},
volume = {4468},
year = {2007}
}
@article{Moerdijk2002,
abstract = {We introduce a predicative version of topos (stratified pseudotopos) based on the notion of small maps in algebraic set theory, developed by Joyal and one of the authors. Examples of stratified pseudotoposes can be constructed in Martin-L{\"{o}}f type theory, which is a predicative theory. A stratified pseudotopos admits construction of the internal category of sheaves, which is again a stratified pseudotopos. We also show how to build models of Aczel-Myhill constructive set theory using this categorical structure. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Moerdijk, Ieke and Palmgren, Erik},
doi = {10.1016/S0168-0072(01)00079-3},
file = {:Users/liang-tingchen/Dropbox/References/Moerdijk, Palmgren - 2002 - Type theories, toposes and constructive set theory predicative aspects of AST.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Constructive set theory,Martin-L{\"{o}}f type theory,Pretoposes,Small maps,Toposes},
month = {apr},
number = {1-3},
pages = {155--201},
title = {{Type theories, toposes and constructive set theory: predicative aspects of AST}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007201000793},
volume = {114},
year = {2002}
}
@article{Awodey2018,
abstract = {The notion of a natural model of type theory is defined in terms of that of a representable natural transfomation of presheaves. It is shown that such models agree exactly with the concept of a category with families in the sense of Dybjer, which can be regarded as an algebraic formulation of type theory. We determine conditions for such models to satisfy the inference rules for dependent sums $\Sigma$, dependent products $\Pi$ and intensional identity types Id , as used in homotopy type theory. It is then shown that a category admits such a model if it has a class of maps that behave like the abstract fibrations in axiomatic homotopy theory: They should be stable under pullback, closed under composition and relative products, and there should be weakly orthogonal factorizations into the class. It follows that many familiar settings for homotopy theory also admit natural models of the basic system of homotopy type theory.},
archivePrefix = {arXiv},
arxivId = {1406.3219},
author = {Awodey, Steve},
doi = {10.1017/S0960129516000268},
eprint = {1406.3219},
file = {:Users/liang-tingchen/Dropbox/References/Awodey - 2018 - Natural models of homotopy type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {2},
pages = {241--286},
title = {{Natural models of homotopy type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129516000268/type/journal{\_}article},
volume = {28},
year = {2018}
}
@article{Breitner2016,
abstract = {Generative type abstractions – present in Haskell, OCaml, and other languages – are useful concepts to help prevent programmer errors. They serve to create new types that are distinct at compile time but share a run-time representation with some base type. We present a new mechanism that allows for zero-cost conversions between generative type abstractions and their representations, even when such types are deeply nested. We prove type safety in the presence of these conversions and have implemented our work in GHC.},
author = {BREITNER, JOACHIM and EISENBERG, RICHARD A. and {PEYTON JONES}, SIMON and WEIRICH, STEPHANIE},
doi = {10.1017/S0956796816000150},
file = {:Users/liang-tingchen/Dropbox/References/BREITNER et al. - 2016 - Safe zero-cost coercions for Haskell.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {Figure 1},
pages = {e15},
title = {{Safe zero-cost coercions for Haskell}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796816000150},
volume = {26},
year = {2016}
}
@inproceedings{Jacobs2013a,
abstract = {So-called effect algebras and modules are basic mathematical structures that were first identified in mathematical physics, for the study of quantum logic and quantum probability. They incorporate a double negation law {\$}p{\^{}}{\{}\backslashperp\backslashperp{\}} = p. Since then it has been realised that these effect structures form a useful abstraction that covers not only quantum logic, but also Boolean logic and probabilistic logic. Moreover, the duality between effect and convex structures lies at the heart of the duality between predicates and states. These insights are leading to a uniform framework for the semantics of computation and logic. This framework has been elaborated elsewhere for set-theoretic, discrete probabilistic, and quantum computation. Here the missing case of continuous probability is shown to fit in the same uniform framework. On a technical level, this involves an investigation of the logical aspects of the Giry monad on measurable spaces and of Lebesgue integration.},
author = {Jacobs, Bart},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.13},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2013 - Measurable Spaces and Their Effect Logic(2).pdf:pdf;:Users/liang-tingchen/Dropbox/References/Jacobs - 2013 - Measurable Spaces and Their Effect Logic.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
keywords = {-probabilistic system,Giry monad,Probabilistic system,duality,effect algebra,giry monad,measurable space},
month = {jun},
pages = {83--92},
publisher = {IEEE},
title = {{Measurable Spaces and Their Effect Logic}},
url = {http://ieeexplore.ieee.org/document/6571539/ http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6571539},
year = {2013}
}
@incollection{Kelly1974a,
author = {Kelly, Gregory Maxwell},
booktitle = {Proceedings Sydney Category Theory Seminar 1972/1973},
doi = {10.1007/BFb0063096},
editor = {Kelly, Gregory M.},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1974 - Doctrinal adjunction.pdf:pdf},
isbn = {978-3-540-06966-9},
pages = {257--280},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Doctrinal adjunction}},
url = {http://www.springerlink.com/index/10.1007/BFb0063096},
volume = {420},
year = {1974}
}
@article{Bouyer2010,
author = {Bouyer, Patricia and Cassez, Franck and Laroussinie, Fran{\c{c}}ois},
doi = {10.1007/s10849-010-9127-4},
file = {:Users/liang-tingchen/Dropbox/References/Bouyer, Cassez, Laroussinie - 2011 - Timed modal logics for real-time systems.pdf:pdf},
isbn = {1084901091274},
issn = {0925-8531},
journal = {Journal of Logic, Language and Information},
keywords = {model checking,timed automata,timed modal logic},
month = {apr},
number = {2},
pages = {169--203},
title = {{Timed modal logics for real-time systems}},
url = {http://www.springerlink.com/index/10.1007/s10849-010-9127-4 http://link.springer.com/10.1007/s10849-010-9127-4},
volume = {20},
year = {2011}
}
@phdthesis{Zeilberger2009,
author = {Zeilberger, Noam},
file = {:Users/liang-tingchen/Dropbox/References/Zeilberger - 2009 - The logical basis of evaluation order and pattern-matching.pdf:pdf},
isbn = {978-1-109-16301-8},
publisher = {Carnegie Mellon University},
school = {Carnegie Mellon University},
title = {{The logical basis of evaluation order and pattern-matching}},
year = {2009}
}
@article{Richman1983,
abstract = {The modern theory of computability is based on the works of Church, Markov and Turing who, starting from quite different models of computation, arrived at the same class of computable functions. The purpose of this paper is the show how the main results of the Church-Markov-Turing theory of computable functions may quickly be derived and understood without recourse to the largely irrelevant theories of recursive functions, Markov algorithms, or Turing machines. We do this by ignoring the problem of what constitutes a computable function and concentrating on the central feature of the Church-Markov-Turing theory: that the set of computable partial functions can be effectively enumerated. In this manner we are led directly to the heart of the theory of computability without having to fuss about what a computable function is.},
author = {Richman, Fred},
doi = {10.2307/2273473},
file = {:Users/liang-tingchen/Dropbox/References/Richman - 1983 - Church's thesis without tears.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
number = {3},
pages = {797--803},
title = {{Church's thesis without tears}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200037981/type/journal{\_}article},
volume = {48},
year = {1983}
}
@article{Dobbertin1986,
author = {Dobbertin, Hans},
doi = {10.1016/0022-4049(86)90003-4},
file = {:Users/liang-tingchen/Dropbox/References/Dobbertin - 1986 - Vaught measures and their applications in lattice theory.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1},
pages = {27--51},
title = {{Vaught measures and their applications in lattice theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404986900034},
volume = {43},
year = {1986}
}
@book{Shafer1976,
author = {Shafer, Glenn},
pages = {314},
publisher = {Princeton University Press},
title = {{A mathematical theory of evidence}},
year = {1976}
}
@article{Abel2017,
abstract = {We develop a methodology for writing interactive and object-based programs (in the sense of Wegner) in dependently typed functional programming languages. The methodology is implemented in the ooAgda library. ooAgda provides a syntax similar to the one used in object-oriented programming languages, thanks to Agda's copattern matching facility. The library allows for the development of graphical user interfaces (GUIs), including the use of action listeners.},
author = {Abel, Andreas M. and Adelsberger, Stephan and Setzer, Anton},
doi = {10.1017/S0956796816000319},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Adelsberger, Setzer - 2017 - Interactive programming in Agda – Objects and graphical user interfaces.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Abel, Adelsberger, Setzer - 2017 - Interactive programming in Agda – Objects and graphical user interfaces(2).pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {feb},
pages = {e8},
title = {{Interactive programming in Agda – Objects and graphical user interfaces}},
url = {https://www.cambridge.org/core/product/identifier/S0956796816000319/type/journal{\_}article},
volume = {27},
year = {2017}
}
@book{Jacobs1999,
abstract = {This book is an attempt to give a systematic presentation of both logic and type theory from a categorical perspective, using the unifying concept of fibred category. Its intended audience consists of logicians, type theorists, category theorists and (theoretical) computer scientists.},
address = {Amsterdam},
author = {Jacobs, Bart},
isbn = {0-444-50170-3},
pages = {784},
publisher = {North Holland},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{Categorical Logic and Type Theory}},
url = {http://www.sciencedirect.com/science/bookseries/0049237X/141},
year = {1999}
}
@article{Gabbay2002a,
abstract = {The permutation model of set theory with atoms (FM-sets), devised by Fraenkel and Mostowski in the 1930s, supports notions of ‘name-abstraction' and ‘fresh name' that provide a new way to represent, compute with, and reason about the syntax of formal systems involving variable-binding operations. Inductively defined FM-sets involving the name-abstraction set former (together with Cartesian product and disjoint union) can correctly encode syntax modulo renaming of bound variables. In this way, the standard theory of algebraic data types can be extended to encompass signatures involving binding operators. In particular, there is an associated notion of structural recursion for defining syntax-manipulating functions (such as capture avoiding substitution, set of free variables, etc.) and a notion of proof by structural induction, both of which remain pleasingly close to informal practice in computer science.},
author = {Gabbay, Murdoch J. and Pitts, Andrew M.},
doi = {10.1007/s001650200016},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay, Pitts - 2002 - A New Approach to Abstract Syntax with Variable Binding.pdf:pdf},
issn = {0934-5043},
journal = {Formal Aspects of Computing},
keywords = {abstract,abstract syntax,alpha-conversion,and,and reason about the,compute with,devised by fraenkel and,fm-sets,fresh name,in the 1930s,in-,involving variable-binding operations,mostowski,name-abstraction,permutation actions,set theory,set theory with atoms,structural induction,supports notions of,syntax of formal systems,that provide a new,the permutation model of,way to represent},
month = {mar},
number = {3-5},
pages = {341--363},
title = {{A New Approach to Abstract Syntax with Variable Binding}},
url = {http://link.springer.com/10.1007/s001650200016},
volume = {13},
year = {2002}
}
@incollection{James2013,
abstract = {Domain modelling based on UML Class Diagrams is an established industrial practice. In the context of the Railway industry, we show how to utilize such diagrams for verification. This involves the translation of UML Class Diagrams into the algebraic specification language CASL. To this end, we define new Class Diagram institutions and provide suitable institution comorphisms.},
address = {Berlin, Heidelberg},
author = {James, Phillip and Knapp, Alexander and Mossakowski, Till and Roggenbach, Markus},
booktitle = {Recent Trends in Algebraic Development Techniques: 21st International Workshop, WADT 2012},
doi = {10.1007/978-3-642-37635-1_11},
editor = {Mart{\'{i}}-Oliet, Narciso and Palomino, Miguel},
file = {:Users/liang-tingchen/Dropbox/References/James et al. - 2013 - Designing domain specific languages -- A craftsman's approach for the railway domain using Casl.pdf:pdf},
isbn = {978-3-642-37635-1},
issn = {03029743},
pages = {178--194},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Designing domain specific languages -- A craftsman's approach for the railway domain using Casl}},
url = {https://doi.org/10.1007/978-3-642-37635-1{\_}11 http://link.springer.com/10.1007/978-3-642-37635-1{\_}11},
volume = {7841},
year = {2013}
}
@book{Rogers1967,
author = {Rogers, Hartley},
isbn = {9780262680523},
pages = {506},
publisher = {MIT Press},
title = {{Theory of Recursive Functions and Effective Computability}},
url = {https://mitpress.mit.edu/books/theory-recursive-functions-and-effective-computability},
year = {1967}
}
@article{Lescanne2012,
author = {Lescanne, Pierre and Perrinel, Matthieu},
doi = {10.1007/s00236-012-0153-3},
file = {:Users/liang-tingchen/Dropbox/References/Lescanne, Perrinel - 2012 - “Backward” coinduction, Nash equilibrium and the rationality of escalation.pdf:pdf},
issn = {0001-5903},
journal = {Acta Informatica},
month = {mar},
title = {{“Backward” coinduction, Nash equilibrium and the rationality of escalation}},
url = {http://www.springerlink.com/index/10.1007/s00236-012-0153-3},
year = {2012}
}
@article{Dunfield2021,
abstract = {Bidirectional typing combines two modes of typing: type checking, which checks that a program satisfies a known type, and type synthesis, which determines a type from the program. Using checking enables bidirectional typing to support features for which inference is undecidable; using synthesis enables bidirectional typing to avoid the large annotation burden of explicitly typed languages. In addition, bidirectional typing improves error locality. We highlight the design principles that underlie bidirectional type systems, survey the development of bidirectional typing from the prehistoric period before Pierce and Turner's local type inference to the present day, and provide guidance for future investigations.},
archivePrefix = {arXiv},
arxivId = {1908.05839},
author = {Dunfield, Jana and Krishnaswami, Neel},
doi = {10.1145/3450952},
eprint = {1908.05839},
file = {:Users/liang-tingchen/Dropbox/References/Dunfield, Krishnaswami - 2022 - Bidirectional Typing.pdf:pdf},
issn = {0360-0300},
journal = {ACM Computing Surveys},
keywords = {Type checking,type inference},
month = {jun},
number = {5},
pages = {1--38},
title = {{Bidirectional Typing}},
url = {https://dl.acm.org/doi/10.1145/3450952},
volume = {54},
year = {2022}
}
@book{Eckmann1969,
doi = {10.1007/BFb0083078},
editor = {Eckmann, Beno and Tierney, Myles},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 1969 - Seminar on Triples and Categorical Homology Theory.pdf:pdf},
isbn = {978-3-540-04601-1},
keywords = {Equational Categories,Homology,Triples},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Seminar on Triples and Categorical Homology Theory}},
url = {http://www.springerlink.com/index/10.1007/BFb0083078 http://www.tac.mta.ca/tac/reprints/articles/18/tr18abs.html},
volume = {80},
year = {1969}
}
@article{Birkedal2019,
abstract = {In recent years, we have seen several new models of dependent type theory extended with some form of modal necessity operator, including nominal type theory, guarded and clocked type theory and spatial and cohesive type theory. In this paper, we study modal dependent type theory : dependent type theory with an operator satisfying (a dependent version of) the K axiom of modal logic. We investigate both semantics and syntax. For the semantics, we introduce categories with families with a dependent right adjoint (CwDRA) and show that the examples above can be presented as such. Indeed, we show that any category with finite limits and an adjunction of endofunctors give rise to a CwDRA via the local universe construction. For the syntax, we introduce a dependently typed extension of Fitch-style modal $\lambda$ -calculus, show that it can be interpreted in any CwDRA, and build a term model. We extend the syntax and semantics with universes.},
archivePrefix = {arXiv},
arxivId = {1804.05236},
author = {Birkedal, Lars and Clouston, Ranald and Mannaa, Bassel and {Ejlers M{\o}gelberg}, Rasmus and Pitts, Andrew M. and Spitters, Bas},
doi = {10.1017/S0960129519000197},
eprint = {1804.05236},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal et al. - 2019 - Modal dependent type theory and dependent right adjoints.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {Dependent type theory,category theory,modal logic},
month = {dec},
pages = {1--21},
title = {{Modal dependent type theory and dependent right adjoints}},
url = {https://www.cambridge.org/core/product/identifier/S0960129519000197/type/journal{\_}article},
year = {2019}
}
@book{Johnstone1978a,
address = {Berlin, Heidelberg},
author = {Johnstone, Peter T. and Par{\'{e}}, Robert and Rosebrugh, R. D. and Schumacher, D. and Wood, R. J. and Wraith, G. C.},
doi = {10.1007/BFb0061360},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone et al. - 1978 - Indexed Categories and Their Applications.pdf:pdf},
isbn = {978-3-540-08914-8},
issn = {0075-8434},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Indexed Categories and Their Applications}},
url = {http://link.springer.com/10.1007/BFb0061360},
volume = {661},
year = {1978}
}
@article{Imai2019,
abstract = {We propose session-ocaml, a novel library for session-typed concurrent/distributed programming in OCaml. Our technique solely relies on parametric polymorphism, which can encode core session type structures with strong static guarantees. Our key ideas are: (1) polarised session types, which give an alternative formulation of duality enabling OCaml to automatically infer an appropriate session type in a session with a reasonable notational overhead; and (2) a parameterised monad with a data structure called ‘slots' manipulated with lenses, which can statically enforce session linearity including delegations. We introduce a notational extension to enhance the session linearity for integrating the session types into the functional programming style. We show applications of session-ocaml to a travel agency use case and an SMTP protocol implementation. Furthermore, we evaluate the performance of [Figure presented] on a number of benchmarks.},
author = {Imai, Keigo and Yoshida, Nobuko and Yuen, Shoji},
doi = {10.1016/j.scico.2018.08.005},
file = {:Users/liang-tingchen/Dropbox/References/Imai, Yoshida, Yuen - 2019 - Session-ocaml A session-based library with polarities and lenses.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Functional programming,Lenses,OCaml,Parametric polymorphism,Session types},
month = {mar},
pages = {135--159},
publisher = {Elsevier B.V.},
title = {{Session-ocaml: A session-based library with polarities and lenses}},
url = {https://doi.org/10.1016/j.scico.2018.08.005 https://linkinghub.elsevier.com/retrieve/pii/S0167642318303289},
volume = {172},
year = {2019}
}
@article{Barendregt2019,
abstract = {Generalized numberings are an extension of Ershov's notion of numbering, based on partial combinatory algebra (pca) instead of the natural numbers. We study various algebraic properties of generalized numberings, relating properties of the numbering to properties of the pca. As in the lambda calculus, extensionality is a key notion here.},
archivePrefix = {arXiv},
arxivId = {1910.07750},
author = {Barendregt, H. P. and Terwijn, Sebastiaan A.},
eprint = {1910.07750},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt, Terwijn - 2019 - Partial combinatory algebra and generalized numberings.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Extensionality,Models of the lambda calculus,Partial combinatory algebra,Precomplete numberings},
month = {oct},
pages = {1--15},
title = {{Partial combinatory algebra and generalized numberings}},
url = {http://arxiv.org/abs/1910.07750},
year = {2019}
}
@inproceedings{Adamek2012a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Moss, Lawrence S.},
booktitle = {Proceedings of the 11th International Workshop on Coalgebraic Methods in Computer Science},
doi = {10.1007/978-3-642-32784-1_4},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Moss - 2012 - On finitary functors and their presentations.pdf:pdf},
keywords = {finitary functors,hausdorff functor,presentation of func-},
title = {{On finitary functors and their presentations}},
year = {2012}
}
@book{Gray1974,
abstract = {Lecture Notes aim to report new developments in all areas of mathematics and their applications - quickly, informally and at a high level. Mathematical texts analysing new developments in modelling and numerical simulation are welcome. Monograph manuscripts should be reasonably self-contained and rounded off. Thus they may, and often will, present not only results of the author but also related work by other people. They may be based on specialised lecture courses. Furthermore, the manuscripts should provide sufficient motivation, examples and applications. This clearly distinguishes Lecture Notes from journal articles or technical reports which normally are very concise. Articles intended for a journal but too long to be accepted by most journals, usually do not have this "lecture notes" character. For similar reasons it is unusual for doctoral theses to be accepted for the Lecture Notes series, though habilitation theses may be appropriate. {\textcopyright} Springer International Publishing Switzerland 2013.},
address = {Berlin, Heidelberg},
author = {Gray, John W.},
booktitle = {Lecture Notes in Mathematics},
doi = {10.1007/BFb0061280},
file = {:Users/liang-tingchen/Dropbox/References/Gray - 1974 - Formal Category Theory Adjointness for 2-Categories.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Gray - 1974 - Formal Category Theory Adjointness for 2-Categories(2).pdf:pdf},
isbn = {978-3-540-06830-3},
issn = {00758434},
number = {74},
pages = {284},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Formal Category Theory: Adjointness for 2-Categories}},
url = {http://link.springer.com/10.1007/BFb0061280},
volume = {391},
year = {1974}
}
@article{Vezzosi2021,
abstract = {Proof assistants based on dependent type theory provide expressive languages for both programming and proving within the same system. However, all of the major implementations lack powerful extensionality principles for reasoning about equality, such as function and propositional extensionality. These principles are typically added axiomatically which disrupts the constructive properties of these systems. Cubical type theory provides a solution by giving computational meaning to Homotopy Type Theory and Univalent Foundations, in particular to the univalence axiom and higher inductive types (HITs). This paper describes an extension of the dependently typed functional programming language Agda with cubical primitives, making it into a full-blown proof assistant with native support for univalence and a general schema of HITs. These new primitives allow the direct definition of function and propositional extensionality as well as quotient types, all with computational content. Additionally, thanks also to copatterns, bisimilarity is equivalent to equality for coinductive types. The adoption of cubical type theory extends Agda with support for a wide range of extensionality principles, without sacrificing type checking and constructivity.},
author = {Vezzosi, Andrea and M{\"{o}}rtberg, Anders and Abel, Andreas M.},
doi = {10.1017/S0956796821000034},
file = {:Users/liang-tingchen/Dropbox/References/Vezzosi, M{\"{o}}rtberg, Abel - 2021 - Cubical Agda A dependently typed programming language with univalence and higher inductive types.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {apr},
pages = {e8},
title = {{Cubical Agda: A dependently typed programming language with univalence and higher inductive types}},
url = {https://www.cambridge.org/core/product/identifier/S0956796821000034/type/journal{\_}article},
volume = {31},
year = {2021}
}
@article{Dumas2013,
abstract = {Exception handling is provided by most modern programming languages. It allows to deal with anomalous or exceptional events which require special processing. In computer algebra, exception handling is an efficient way to implement the dynamic evaluation paradigm: for instance, in linear algebra, dynamic evaluation can be used for applying programs which have been written for matrices with coefficients in a field to matrices with coefficients in a ring. Thus, a proof system for computer algebra should include a treatement of exceptions, which must rely on a careful description of a semantics of exceptions. The categorical notion of monad can be used for formalizing the raising of exceptions: this has been proposed by Moggi and implemented in Haskell. In this paper, we provide a proof system for exceptions which involves both raising and handling, by extending Moggi's approach. Moreover, the core part of this proof system is dual to a proof system for side effects in imperative languages, which relies on the categorical notion of comonad. Both proof systems are implemented in the Coq proof assistant.},
archivePrefix = {arXiv},
arxivId = {1310.2338},
author = {Dumas, Jean-guillaume and Duval, Dominique and Ekici, Burak and Reynaud, Jean-Claude},
eprint = {1310.2338},
file = {:Users/liang-tingchen/Dropbox/References/Dumas et al. - 2013 - Certified proofs in programs involving exceptions.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {1--17},
title = {{Certified proofs in programs involving exceptions}},
url = {http://arxiv.org/abs/1310.2338 http://hal.archives-ouvertes.fr/hal-00867237},
year = {2013}
}
@article{Shamkanov2014,
abstract = {Sequent calculus for the provability logic GL is considered, in which provability is based on the notion of a circular proof. Unlike ordinary derivations, circular proofs are represented by graphs allowed to contain cycles, rather than by finite trees. Using this notion, we obtain a syntactic proof of the Lyndon interpolation property for GL.},
author = {Shamkanov, Daniyar S.},
doi = {10.1134/S0001434614090326},
file = {:Users/liang-tingchen/Dropbox/References/Shamkanov - 2014 - Circular proofs for the {\{}G{\}}{\"{o}}del-{\{}L{\}}{\"{o}}b provability logic.pdf:pdf},
issn = {0001-4346},
journal = {Mathematical Notes},
keywords = {circular proof,provability logic,sequent calculus,split sequent,the G{\"{o}}del-L{\"{o}}b logic,the Lyndon interpolation property},
month = {sep},
number = {3-4},
pages = {575--585},
title = {{Circular proofs for the {\{}G{\}}{\"{o}}del-{\{}L{\}}{\"{o}}b provability logic}},
url = {http://link.springer.com/10.1134/S0001434614090326},
volume = {96},
year = {2014}
}
@article{Almeida1989,
author = {Almeida, Jorge},
file = {:Users/liang-tingchen/Dropbox/References/Almeida - 1989 - Residually finite congruences and quasi-regular subsets in uniform algebras.pdf:pdf},
journal = {Portugaliae mathematica},
number = {3},
pages = {313--328},
title = {{Residually finite congruences and quasi-regular subsets in uniform algebras}},
url = {https://eudml.org/doc/115673},
volume = {46},
year = {1989}
}
@article{Jacobs2012b,
author = {Jacobs, Bart and Mandemaker, Jorik},
doi = {10.1007/s10701-012-9654-8},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Mandemaker - 2012 - Coreflections in Algebraic Quantum Logic.pdf:pdf},
issn = {0015-9018},
journal = {Foundations of Physics},
keywords = {Effect algebra,Limit and colimit,Partial commutative monoid,Tensor product},
month = {jul},
number = {7},
pages = {932--958},
title = {{Coreflections in Algebraic Quantum Logic}},
url = {http://link.springer.com/10.1007/s10701-012-9654-8},
volume = {42},
year = {2012}
}
@article{Chorny2012,
author = {Chorny, B. and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/j.jpaa.2012.01.015},
file = {:Users/liang-tingchen/Dropbox/References/Chorny, Rosick{\'{y}} - 2012 - Class-locally presentable and class-accessible categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {oct},
number = {10},
pages = {2113--2125},
publisher = {Elsevier B.V.},
title = {{Class-locally presentable and class-accessible categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404912000321},
volume = {216},
year = {2012}
}
@article{Awodey2012,
abstract = {Homotopy type theory is an interpretation of Martin-L$\backslash$"of's constructive type theory into abstract homotopy theory. There results a link between constructive mathematics and algebraic topology, providing topological semantics for intensional systems of type theory as well as a computational approach to algebraic topology via type theory-based proof assistants such as Coq. The present work investigates inductive types in this setting. Modified rules for inductive types, including types of well-founded trees, or W-types, are presented, and the basic homotopical semantics of such types are determined. Proofs of all results have been formally verified by the Coq proof assistant, and the proof scripts for this verification form an essential component of this research.},
archivePrefix = {arXiv},
arxivId = {1201.3898},
author = {Awodey, Steve and Gambino, Nicola and Sojakova, Kristina},
eprint = {1201.3898},
file = {:Users/liang-tingchen/Dropbox/References/Awodey, Gambino, Sojakova - 2012 - Inductive types in homotopy type theory.pdf:pdf},
journal = {ArXiv e-prints},
month = {jan},
pages = {19},
title = {{Inductive types in homotopy type theory}},
url = {http://arxiv.org/abs/1201.3898},
year = {2012}
}
@incollection{Taha2004,
abstract = {Multi-stage programming (MSP) is a paradigm for developing generic software that does not pay a runtime penalty for this generality. This is achieved through concise, carefully-designed language extensions that support runtime code generation and program execution. Additionally, type systems for MSP languages are designed to statically ensure that dynamically generated programs are type-safe, and therefore require no type checking after they are generated. This hands-on tutorial is aimed at the reader interested in learning the basics of MSP practice. The tutorial uses a freely available MSP extension of OCaml called MetaOCaml, and presents a detailed analysis of the issues that arise in staging an interpreter for a small programming language. The tutorial concludes with pointers to various resources that can be used to probe further into related topics.},
author = {Taha, Walid},
booktitle = {Domain-Specific Program Generation},
doi = {10.1007/978-3-540-25935-0_3},
editor = {Lengauer, Christian and Batory, Don and ConselM, Charles and Odersky, Artin},
file = {:Users/liang-tingchen/Dropbox/References/Taha - 2004 - A Gentle Introduction to Multi-stage Programming.pdf:pdf},
pages = {30--50},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Gentle Introduction to Multi-stage Programming}},
url = {http://link.springer.com/10.1007/978-3-540-25935-0{\_}3},
volume = {3016},
year = {2004}
}
@article{Dubuc1974,
author = {Dubuc, Eduardo J.},
doi = {10.1016/0021-8693(74)90095-7},
file = {:Users/liang-tingchen/Dropbox/References/Dubuc - 1974 - Free monoids.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
month = {may},
number = {2},
pages = {208--228},
publisher = {Elsevier},
title = {{Free monoids}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0021869374900957},
volume = {29},
year = {1974}
}
@article{Szawiel2012,
abstract = {We characterize the equational theories and Lawvere theories that correspond to the categories of analytic and polynomial monads on Set, and hence also the categories of the symmetric and rigid operads in Set. We show that the category of analytic monads is equivalent to the category of regular-linear theories. The category of polynomial monads is equivalent to the category of rigid theories, i.e. regular-linear theories satisfying an additional global condition. This solves a problem A. Carboni and P. T. Johnstone. The Lawvere theories corresponding to these monads are identified via some factorization systems.},
archivePrefix = {arXiv},
arxivId = {1204.2703},
author = {Szawiel, Stanislaw and Zawadowski, Marek},
eprint = {1204.2703},
file = {:Users/liang-tingchen/Dropbox/References/Szawiel, Zawadowski - 2012 - Theories of analytic monads.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {distributive law,equational theory,factor-,interpretation,ization system,lawvere theory,monad,operad},
month = {apr},
pages = {29},
title = {{Theories of analytic monads}},
url = {http://arxiv.org/abs/1204.2703},
year = {2012}
}
@article{Komendantskaya2016,
abstract = {Coinductive definitions, such as that of an infinite stream, may often be described by elegant logic programs, but ones for which SLD-refutation is of no value as SLD-derivations fall into infinite loops. Such definitions give rise to questions of lazy corecursive derivations and parallelism, as execution of such logic programs can have both recursive and corecursive features at once. Observational and coalgebraic semantics have been used to study them abstractly. The programming developments have often occurred separately and have usually been implementation-led. Here, we give a coherent semantics-led account of the issues, starting with abstract category theoretic semantics, developing coalgebra to characterise naturally arising trees, and proceeding towards implementation of a new dialect, CoALP, of logic programming, characterised by guarded lazy corecursion and parallelism.},
archivePrefix = {arXiv},
arxivId = {1312.6568},
author = {Komendantskaya, Ekaterina and Power, John and Schmidt, Martin},
doi = {10.1093/logcom/exu026},
eprint = {1312.6568},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Power, Schmidt - 2016 - Coalgebraic logic programming from Semantics to Implementation.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Logic programming,coalgebra,coinduction,corecursion,observational semantics,parallelism},
month = {apr},
number = {2},
pages = {745--783},
title = {{Coalgebraic logic programming: from Semantics to Implementation}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exu026},
volume = {26},
year = {2016}
}
@article{Takahashi1995,
author = {Takahashi, M.},
doi = {10.1006/inco.1995.1057},
file = {:Users/liang-tingchen/Dropbox/References/Takahashi - 1995 - Parallel Reductions in $\lambda$-Calculus.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {1},
pages = {120--127},
title = {{Parallel Reductions in $\lambda$-Calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540185710577},
volume = {118},
year = {1995}
}
@misc{Velebil2010,
abstract = {We generalize the concept of dual adjunctions given by a schizophrenic object to those that are induced by schizophrenic modules. This concept allows one to treat various modal coalgebraic calculi in a uniform way. We show applications to classical modal coalgebraic logics, logics over posets, categories of presheaves etc. This is a joint work with Alexander Kurz.},
address = {Kanazawa, Japan},
author = {Velebil, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Velebil - 2010 - Logical Connections in the Many-sorted Setting.pdf:pdf},
title = {{Logical Connections in the Many-sorted Setting}},
url = {http://www.jaist.ac.jp/rcis/asubl4/},
year = {2010}
}
@article{Dostal2015,
author = {Dost{\'{a}}l, Matĕj and Velebil, Jiř{\'{i}}},
doi = {10.1007/s10485-015-9406-y},
file = {:Users/liang-tingchen/Dropbox/References/Dost{\'{a}}l, Velebil - 2015 - Morita Equivalence for Many-Sorted Enriched Theories.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {2010,cauchy completion,lawvere theory,mathematics subject classifications,morita equivalence,msc 18c10,msc 18d20},
title = {{Morita Equivalence for Many-Sorted Enriched Theories}},
url = {http://link.springer.com/10.1007/s10485-015-9406-y},
year = {2015}
}
@book{Manes1976,
author = {Manes, Ernest G.},
doi = {10.1007/978-1-4612-9860-1},
pages = {341},
publisher = {Springer-Verlag},
series = {Graduate Texts in Mathematics},
title = {{Algebraic Theories}},
volume = {26},
year = {1976}
}
@inproceedings{10.1145/3428217,
abstract = {We describe a design for generics in Go inspired by previous work on Featherweight Java by Igarashi, Pierce, and Wadler. Whereas subtyping in Java is nominal, in Go it is structural, and whereas generics in Java are defined via erasure, in Go we use monomorphisation. Although monomorphisation is widely used, we are one of the first to formalise it. Our design also supports a solution to The Expression Problem.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2005.11710},
author = {Griesemer, Robert and Hu, Raymond and Kokke, Wen and Lange, Julien and Taylor, Ian Lance and Toninho, Bernardo and Wadler, Philip and Yoshida, Nobuko},
booktitle = {Proceedings of the ACM on Programming Languages},
doi = {10.1145/3428217},
eprint = {2005.11710},
file = {:Users/liang-tingchen/Dropbox/References/Griesemer et al. - 2020 - Featherweight Go.pdf:pdf},
keywords = {Generics,Go,Monomorphisation},
month = {nov},
number = {OOPSLA},
publisher = {Association for Computing Machinery},
title = {{Featherweight Go}},
url = {https://doi.org/10.1145/3428217},
volume = {4},
year = {2020}
}
@unpublished{Altenkirch,
author = {Altenkirch, Thorsten and Anberr{\'{e}}e, Thomas and Li, Nuo},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Anberr{\'{e}}e, Li - 2012 - Definable Quotients in Type Theory.pdf:pdf},
title = {{Definable Quotients in Type Theory}},
year = {2012}
}
@article{Plotkin1977,
author = {Plotkin, Gordon D.},
doi = {10.1016/0304-3975(77)90044-5},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin - 1977 - LCF considered as a programming language.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {3},
pages = {223--255},
title = {{LCF considered as a programming language}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397577900445},
volume = {5},
year = {1977}
}
@book{Brink2001,
author = {Brink, Chris and Rewitsky, Ingrid M.},
isbn = {1575863448},
publisher = {CSLI Publications Stanford, CA, USA},
series = {Studies in Logic, Language, and Information},
title = {{A paradigm for program semantics: power structures and duality}},
type = {Book},
year = {2001}
}
@article{Dubois2007,
abstract = {Deciding whether one probability distribution is more informative (in the sense of representing a less indeterminate situation) than another one is typically done using well-established information measures such as, e.g., the Shannon entropy or other dispersion indices. In contrast, the relative specificity of possibility distributions is evaluated by means of fuzzy set inclusion. In this paper, we propose a technique for comparing probability distributions from the point of view of their relative dispersion without resorting to a numerical index. A natural partial ordering in terms of relative "peakedness" of probability functions is proposed which is closely related to order-1 stochastic dominance. There is also a close connection between this ordering on probability distributions and the standard specificity ordering on possibility distributions that can be derived by means of a known probability-possibility transformation. The paper proposes a direct proof showing that the (total) preordering on probability measures defined by probabilistic entropy refines the (partial) ordering defined by possibilistic specificity. This result, also valid for other dispersion indices, is discussed against the background of related work in statistics, mathematics (inequalities on convex functions), and the social sciences. Finally, an application of the possibilistic specificity ordering in the field of machine learning or, more specifically, the induction of decision forests is proposed. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Dubois, Didier and H{\"{u}}llermeier, Eyke},
doi = {10.1016/j.ijar.2006.06.017},
file = {:Users/liang-tingchen/Dropbox/References/Dubois, H{\"{u}}llermeier - 2007 - Comparing probability measures using possibility theory A notion of relative peakedness.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Decision forest,Dispersion,Entropy,Machine learning,Possibility distributions,Probability distributions,Probability-possibility transformation,Recursive partitioning,Specificity,Stochastic dominance},
month = {jul},
number = {2},
pages = {364--385},
title = {{Comparing probability measures using possibility theory: A notion of relative peakedness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X06000685},
volume = {45},
year = {2007}
}
@article{Hofstra2013,
abstract = {We introduce a new model construction for Martin-L{\"{o}}f intensional type theory, which is sound and complete for the 1-truncated version of the theory. The model formally combines, by gluing along the functor from the category of contexts to the category of groupoids, the syntactic model with a notion of realizability. As our main application, we use the model to analyse the syntactic groupoid associated to the type theory generated by a graph G, showing that it has the same homotopy type as the free groupoid generated by G. {\textcopyright} 2013 Elsevier B.V.},
author = {Hofstra, Pieter and Warren, Michael A.},
doi = {10.1016/j.apal.2013.05.002},
file = {:Users/liang-tingchen/Dropbox/References/Hofstra, Warren - 2013 - Combinatorial realizability models of type theory.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Gluing,Groupoid semantics,Homotopy type theory,Logical relations,Martin-L{\"{o}}f type theory,Realizability},
month = {oct},
number = {10},
pages = {957--988},
publisher = {Elsevier B.V.},
title = {{Combinatorial realizability models of type theory}},
url = {http://dx.doi.org/10.1016/j.apal.2013.05.002 https://linkinghub.elsevier.com/retrieve/pii/S0168007213000493},
volume = {164},
year = {2013}
}
@article{Kurz2005a,
author = {Kurz, Alexander and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1017/S0960129504004402},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Rosick{\'{y}} - 2005 - Operations and equations for coalgebras.pdf:pdf},
isbn = {0960129504004},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {1},
pages = {149--166},
title = {{Operations and equations for coalgebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129504004402},
volume = {15},
year = {2005}
}
@article{Barr1990,
author = {Barr, Michael},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1990 - Accessible categories and models of linear logic.pdf:pdf},
journal = {Journal of Pure and Applied Algebra},
pages = {219--232},
title = {{Accessible categories and models of linear logic}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Accessible+categories+and+models+of+linear+logic{\#}0},
volume = {69},
year = {1990}
}
@article{DeVink1999,
author = {de Vink, Erik P. and Rutten, Jan J.M.M.},
doi = {10.1016/S0304-3975(99)00035-3},
file = {:Users/liang-tingchen/Dropbox/References/de Vink, Rutten - 1999 - Bisimulation for probabilistic transition systems a coalgebraic approach.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {bisimulation,borel measures,coalgebras,final coalgebra,probabilistic transition systems,ultrametric spaces},
month = {jun},
number = {1-2},
pages = {271--293},
title = {{Bisimulation for probabilistic transition systems: a coalgebraic approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397599000353},
volume = {221},
year = {1999}
}
@article{Jacobs2016,
abstract = {This paper establishes a link between Bayesian inference (learning) and predicate and state transformer operations from programming semantics and logic. Specifically, a very general definition of backward inference is given via first applying a predicate transformer and then conditioning. Analogously, forward inference involves first conditioning and then applying a state transformer. These definitions are illustrated in many examples in discrete and continuous probability theory and also in quantum theory.},
author = {Jacobs, Bart and Zanasi, Fabio},
doi = {10.1016/j.entcs.2016.09.038},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Zanasi - 2016 - A predicatestate transformer semantics for Bayesian learning.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Bayes,Inference,Kleisli category,effectus,learning,predicate transformer,state transformer},
month = {oct},
pages = {185--200},
publisher = {Elsevier B.V.},
title = {{A predicate/state transformer semantics for Bayesian learning}},
url = {http://dx.doi.org/10.1016/j.entcs.2016.09.038 http://linkinghub.elsevier.com/retrieve/pii/S1571066116300883},
volume = {325},
year = {2016}
}
@article{Gumm2005,
abstract = {We relate weak limit preservation properties of coalgebraic type functors F to structure theoretic properties of the class of all F -coalgebras. In particular, we give coalgebraic characterizations for the condition that F weakly preserves pullbacks, kernel pairs or preimages. We also describe regular monos and epis. In case that | F (1)| ≠ 1 we show that F preserves preimages iff for every class of F -coalgebras. The case | F (1)| = 1 is left as an open problem.},
author = {Gumm, H. Peter and Schr{\"{o}}der, Tobias},
doi = {10.1007/s00012-005-1888-2},
file = {:Users/liang-tingchen/Dropbox/References/Gumm, Schr{\"{o}}der - 2005 - Types and coalgebraic structure.pdf:pdf},
issn = {0002-5240},
journal = {Algebra universalis},
keywords = {Mathematics and Statistics},
month = {aug},
number = {2-3},
pages = {229--252},
publisher = {Birkh{\"{a}}user Basel},
title = {{Types and coalgebraic structure}},
url = {http://www.springerlink.com/content/n10271g022404346/},
volume = {53},
year = {2005}
}
@article{Veldman1976,
author = {Veldman, Wim},
doi = {10.2307/2272955},
file = {:Users/liang-tingchen/Dropbox/References/Veldman - 1976 - An Intuitionistic Completeness Theorem for Intuitionistic Predicate Logic.pdf:pdf},
issn = {00224812},
journal = {The Journal of Symbolic Logic},
month = {mar},
number = {1},
pages = {159},
title = {{An Intuitionistic Completeness Theorem for Intuitionistic Predicate Logic}},
url = {http://www.jstor.org/stable/2272955?origin=crossref},
volume = {41},
year = {1976}
}
@article{Loregian2015,
abstract = {The present note is a recollection of the most striking and useful applications of co/end calculus. We put a considerable effort in making arguments and constructions rather explicit: after having given a series of preliminary definitions, we characterize co/ends as particular co/limits; then we derive a number of results directly from this characterization. The last sections discuss the most interesting examples where co/end calculus serves as a powerful abstract way to do explicit computations in diverse fields like Algebra, Algebraic Topology and Category Theory. The appendices serve to sketch a number of results in theories heavily relying on co/end calculus; the reader who dares to arrive at this point, being completely introduced to the mysteries of co/end fu, can regard basically every statement as a guided exercise.},
archivePrefix = {arXiv},
arxivId = {1501.02503},
author = {Loregian, Fosco},
eprint = {1501.02503},
file = {:Users/liang-tingchen/Dropbox/References/Loregian - 2015 - This is the (co)end, my only (co)friend.pdf:pdf},
journal = {ArXiv e-prints},
month = {jan},
title = {{This is the (co)end, my only (co)friend}},
url = {http://arxiv.org/abs/1501.02503},
year = {2015}
}
@article{Kowalski1971,
abstract = {Linear resolution with selection function (SL-resolution) is a restricted form of linear resolution. The main restriction is effected by a selection function which chooses from each clause a single literal to be resolved upon in that clause. This and other restrictions are adapted to linear resolution from Loveland's model elimination. We show that SL-resolution achieves a substantial reduction in the generation of redundant and irrelevant derivations and does so without significantly increasing the complexity of simplest proofs. We base our argument for the increased efficiency of SL-resolution upon precise calculation of these quantities. A more far reaching advantage of SL-resolution is its suitability for heuristic search. In particular, classification trees, subgoals, lemmas, and/orssearch trees can all be used to increase the efficiency of finding refutations. These considerations alone suggest the superiority of SL-resolution to theorem-proving procedures constructed solely for their heuristic attraction. From comparison with other theorem-proving methods, we conjecture that best proof procedures for first order logic will be obtained by further elaboration of SL-resolution. {\textcopyright} 1971.},
author = {Kowalski, Robert and Kuehner, Donald},
doi = {10.1016/0004-3702(71)90012-9},
file = {:Users/liang-tingchen/Dropbox/References/Kowalski, Kuehner - 1971 - Linear resolution with selection function.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
month = {dec},
number = {3-4},
pages = {227--260},
title = {{Linear resolution with selection function}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0004370271900129},
volume = {2},
year = {1971}
}
@article{Abel2020a,
abstract = {Consider two widely used definitions of equality. That of Leibniz: one value equals another if any predicate that holds of the first holds of the second. And that of Martin-L{\"{o}}f: the type identifying one value with another is occupied if the two values are identical. The former dates back several centuries, while the latter is widely used in proof systems such as Agda and Coq. Here we show that the two definitions are isomorphic: we can convert any proof of Leibniz equality to one of Martin-L{\"{o}}f identity and vice versa , and each conversion followed by the other is the identity. One direction of the isomorphism depends crucially on values of the type corresponding to Leibniz equality satisfying functional extensionality and Reynolds' notion of parametricity. The existence of the conversions is widely known (meaning that if one can prove one equality then one can prove the other), but that the two conversions form an isomorphism (internally) in the presence of parametricity and functional extensionality is, we believe, new. Our result is a special case of a more general relation that holds between inductive families and their Church encodings. Our proofs are given inside type theory, rather than meta-theoretically. Our paper is a literate Agda script.},
author = {Abel, Andreas M. and Cockx, Jesper and Devriese, Dominique and Timany, Amin and Wadler, Philip},
doi = {10.1017/S0956796820000155},
file = {:Users/liang-tingchen/Dropbox/References/Abel et al. - 2020 - Leibniz equality is isomorphic to Martin-L{\"{o}}f identity, parametrically.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jun},
pages = {e17},
title = {{Leibniz equality is isomorphic to Martin-L{\"{o}}f identity, parametrically}},
url = {https://www.cambridge.org/core/product/identifier/S0956796820000155/type/journal{\_}article},
volume = {30},
year = {2020}
}
@inproceedings{Brickell2008,
abstract = {Re-identification is a major privacy threat to public datasets containing individual records. Many privacy protection algorithms rely on generalization and suppression of "quasi-identifier" attributes such as ZIP code and birthdate. Their objective is usually syntactic sanitization: for example, k-anonymity requires that each "quasi-identifier" tuple appear in at least k records, while l-diversity requires that the distribution of sensitive attributes for each quasi-identifier have high entropy. The utility of sanitized data is also measured syntactically, by the number of generalization steps applied or the number of records with the same quasi-identifier. In this paper, we ask whether generalization and suppression of quasi-identifiers offer any benefits over trivial sanitization which simply separates quasi-identifiers from sensitive attributes. Previous work showed that k-anonymous databases can be useful for data mining, but k-anonymization does not guarantee any privacy. By contrast, we measure the tradeoff between privacy (how much can the adversary learn from the sanitized records?) and utility, measured as accuracy of data-mining algorithms executed on the same sanitized records. For our experimental evaluation, we use the same datasets from the UCI machine learning repository as were used in previous research on generalization and suppression. Our results demonstrate that even modest privacy gains require almost complete destruction of the data-mining utility. In most cases, trivial sanitization provides equivalent utility and better privacy than k-anonymity, l-diversity, and similar methods based on generalization and suppression.},
address = {New York, New York, USA},
author = {Brickell, Justin and Shmatikov, Vitaly},
booktitle = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD 08},
doi = {10.1145/1401890.1401904},
file = {:Users/liang-tingchen/Dropbox/References/Brickell, Shmatikov - 2008 - The Cost of Privacy Destruction of Data-Mining Utility in Anonymized Data Publishing.pdf:pdf},
isbn = {9781605581934},
keywords = {anonymity,data mining,privacy,utility},
pages = {70},
publisher = {ACM Press},
title = {{The Cost of Privacy: Destruction of Data-Mining Utility in Anonymized Data Publishing}},
url = {http://doi.acm.org/10.1145/1401890.1401904 http://dl.acm.org/citation.cfm?doid=1401890.1401904},
year = {2008}
}
@article{Street1980a,
author = {Street, Ross},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1980 - Fibrations in bicategories bicategories.pdf:pdf},
journal = {Cahiers Topologie G{\'{e}}om. Diff{\'{e}}rentielle},
number = {2},
pages = {111--160},
title = {{Fibrations in bicategories bicategories}},
volume = {21},
year = {1980}
}
@article{Baez2011,
abstract = {There are numerous characterizations of Shannon entropy and Tsallis entropy as measures of information obeying certain properties. Using work by Faddeev and Furuichi, we derive a very simple characterization. Instead of focusing on the entropy of a probability measure on a finite set, this characterization focuses on the `information loss', or change in entropy, associated with a measure-preserving function. Information loss is a special case of conditional entropy: namely, it is the entropy of a random variable conditioned on some function of that variable. We show that Shannon entropy gives the only concept of information loss that is functorial, convex-linear and continuous. This characterization naturally generalizes to Tsallis entropy as well.},
archivePrefix = {arXiv},
arxivId = {1106.1791},
author = {Baez, John C. and Fritz, Tobias and Leinster, Tom},
doi = {10.3390/e13111945},
eprint = {1106.1791},
file = {:Users/liang-tingchen/Dropbox/References/Baez, Fritz, Leinster - 2011 - A Characterization of Entropy in Terms of Information Loss.pdf:pdf},
issn = {1099-4300},
journal = {Entropy},
keywords = {Information theory,Measure-preserving function,Shannon entropy,Tsallis entropy},
month = {nov},
number = {12},
pages = {1945--1957},
title = {{A Characterization of Entropy in Terms of Information Loss}},
url = {http://www.mdpi.com/1099-4300/13/11/1945/},
volume = {13},
year = {2011}
}
@incollection{Jacobs2011,
author = {Jacobs, Bart and Rutten, Jan J.M.M.},
booktitle = {Advanced topics in bisimulation and coinduction},
editor = {Sangiorgi, Davide and Rutten, Jan J.M.M.},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Rutten - 2011 - An introduction to (co)algebra and (co)induction.pdf:pdf},
isbn = {9781107004979},
pages = {38--99},
publisher = {Cambridge University Press},
series = {Cambridge Tracts in Theoretical Computer Science},
title = {{An introduction to (co)algebra and (co)induction}},
year = {2011}
}
@article{Coumans2012,
author = {Coumans, D. C. S. and van Gool, Sam J.},
doi = {10.1093/logcom/exs016},
file = {:Users/liang-tingchen/Dropbox/References/Coumans, van Gool - 2012 - On generalizing free algebras for a functor.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {free algebras,partial algebras,quasi-equations,rank 0-1},
month = {may},
number = {3},
pages = {645--672},
title = {{On generalizing free algebras for a functor}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exs016},
volume = {23},
year = {2012}
}
@book{Approach2014,
address = {Cham},
annote = {NULL},
author = {Nipkow, Tobias and Klein, Gerwin},
doi = {10.1007/978-3-319-10542-0},
file = {:Users/liang-tingchen/Dropbox/References/Nipkow, Klein - 2017 - Concrete Semantics.pdf:pdf},
isbn = {978-3-319-10541-3},
publisher = {Springer International Publishing},
title = {{Concrete Semantics}},
url = {http://link.springer.com/10.1007/978-3-319-10542-0},
year = {2017}
}
@article{Chen2011,
author = {Chen, Rui and Mohammed, Noman and Fung, Benjamin Cm and Desai, Bipin C. and Xiong, Li},
file = {:Users/liang-tingchen/Dropbox/References/Chen et al. - 2011 - Publishing set-valued data via differential privacy.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
number = {11},
pages = {1087--1098},
title = {{Publishing set-valued data via differential privacy}},
volume = {4},
year = {2011}
}
@phdthesis{Capriotti2017,
abstract = {This thesis introduces the idea of two-level type theory, an extension of Martin-L$\backslash$"of type theory that adds a notion of strict equality as an internal primitive. A type theory with a strict equality alongside the more conventional form of equality, the latter being of fundamental importance for the recent innovation of homotopy type theory (HoTT), was first proposed by Voevodsky, and is usually referred to as HTS. Here, we generalise and expand this idea, by developing a semantic framework that gives a systematic account of type formers for two-level systems, and proving a conservativity result relating back to a conventional type theory like HoTT. Finally, we show how a two-level theory can be used to provide partial solutions to open problems in HoTT. In particular, we use it to construct semi-simplicial types, and lay out the foundations of an internal theory of {\$}(\backslashinfty, 1){\$}-categories.},
archivePrefix = {arXiv},
arxivId = {1702.04912},
author = {Capriotti, Paolo},
eprint = {1702.04912},
file = {:Users/liang-tingchen/Dropbox/References/Capriotti - 2016 - Models of Type Theory with Strict Equality.pdf:pdf},
number = {July},
school = {University of Nottingham},
title = {{Models of Type Theory with Strict Equality}},
type = {Doctoral Thesis},
url = {http://arxiv.org/abs/1702.04912},
year = {2016}
}
@incollection{Jacobs2014,
author = {Jacobs, Bart and Silva, Alexandra},
booktitle = {Horizons of the Mind. A Tribute to Prakash Panangaden},
doi = {10.1007/978-3-319-06880-0_20},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs, Silva - 2014 - Automata learning a categorical perspective.pdf:pdf},
isbn = {9783319068794},
issn = {16113349},
pages = {384--406},
title = {{Automata learning: a categorical perspective}},
year = {2014}
}
@inproceedings{Brady2011,
address = {New York, New York, USA},
author = {Brady, Edwin C},
booktitle = {Proceedings of the 5th ACM workshop on Programming languages meets program verification - PLPV '11},
doi = {10.1145/1929529.1929536},
file = {:Users/liang-tingchen/Dropbox/References/Brady - 2011 - IDRIS --- Systems Programming Meets Full Dependent Types.pdf:pdf},
isbn = {9781450304870},
keywords = {attempt to store concrete,but it does not,compactly or efficiently,data,formats precisely,languages,verification},
pages = {43},
publisher = {ACM Press},
title = {{IDRIS --- Systems Programming Meets Full Dependent Types}},
url = {http://portal.acm.org/citation.cfm?doid=1929529.1929536},
year = {2011}
}
@inproceedings{Cheng2003,
author = {Cheng, Eugenia and Hyland, Martin and Power, A. John},
booktitle = {Proceedings of 19th Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1016/S1571-0661(03)50012-3},
file = {:Users/liang-tingchen/Dropbox/References/Cheng, Hyland, Power - 2003 - Pseudo-distributive Laws.pdf:pdf},
issn = {15710661},
pages = {227--245},
publisher = {Elsevier Masson SAS},
title = {{Pseudo-distributive Laws}},
url = {http://dx.doi.org/10.1016/S1571-0661(03)50012-3 http://linkinghub.elsevier.com/retrieve/pii/S1571066103500123},
volume = {83},
year = {2003}
}
@article{Benthem2012,
author = {van Benthem, Johan and Bezhanishvili, Nick and Hodkinson, Ian},
doi = {10.1007/s11225-012-9388-9},
file = {:Users/liang-tingchen/Dropbox/References/Benthem, Bezhanishvili, Hodkinson - 2012 - Sahlqvist correspondence for modal mu-calculus.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
month = {feb},
pages = {31--60},
publisher = {Springer Netherlands},
title = {{Sahlqvist correspondence for modal mu-calculus}},
url = {http://www.springerlink.com/content/f86h0q38j6v1814p/ http://www.doc.ic.ac.uk/{~}nbezhani/Papers/Sahlmu.pdf},
volume = {100},
year = {2012}
}
@incollection{Hasuo2010,
abstract = {The technique of forward/backward simulations has been applied successfully in many distributed and concurrent applications. In this paper, however, we claim that the technique can actually have more genericity and mathematical clarity. We do so by identifying forward/backward simulations as lax/oplax morphisms of coalgebras. Starting from this observation, we present a systematic study of this generic notion of simulations. It is meant to be a generic version of the study by Lynch and Vaandrager, covering both non-deterministic and probabilistic systems. In particular we prove soundness and completeness results with respect to trace inclusion: the proof is by coinduction using the generic theory of traces developed by Jacobs, Sokolova and the author. By suitably instantiating our generic framework, one obtains the appropriate definition of forward/backward simulations for various kinds of systems, for which soundness and completeness come for free.},
author = {Hasuo, Ichiro},
booktitle = {CONCUR 2010–Concurrency Theory},
doi = {10.1007/11817949_27},
editor = {Gastin, Paul and Laroussinie, Francois},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo - 2010 - Generic forward and backward simulations II Probabilistic simulation.pdf:pdf},
isbn = {978-3-540-37376-6},
issn = {03029743},
pages = {447--461},
publisher = {Springer, Berlin, Heidelberg},
series = {LNCS},
title = {{Generic forward and backward simulations II: Probabilistic simulation}},
url = {http://www.springerlink.com/index/78665V2571662801.pdf{\%}5Cnpapers2://publication/uuid/D34A117F-A224-47CF-B7DE-E91D8A298387 http://link.springer.com/10.1007/11817949{\_}27},
volume = {6269},
year = {2010}
}
@incollection{B2013,
abstract = {Inspired by a number of different applications of rewriting logic, equational logic, and type theory that we present and further advance in this thesis, we study a unified formalism based on the key aspects of these quite different lines of research. The resulting formalism, that we call the open calculus of constructions, is intended as a step towards our long-term goal of developing a unified language for programming, specification and interactive theorem proving. $\backslash$nWe begin our work by exploring the application of rewriting logic as a semantic framework for concurrency. To this end, we give a unified treatment of different classes of Petri nets, a typical and important representative of a class of formalisms that are used for the modeling and specification of concurrent and distributed systems based on a multiset representation of a distributed state space. Specifically, we continue the line of research initiated by Meseguer and Montanari under the motto "Petri nets are monoids" by giving a rewriting semantics for different Petri nets classes. In particular, we have covered important high-level Petri net models, namely algebraic net specifications and colored Petri nets, and we have proved that the models of our representations are naturally isomorphic to the well-known Best-Devillers process semantics. Apart from their contribution to a conceptual unification in this field, the main practical advantage of our representations in rewriting logic is their executability, which allows us to use a rewriting engine such as Maude for the efficient symbolic execution of system models and for their analysis. $\backslash$nThe next application addressed in this thesis is the use of type theory, more precisely the calculus of inductive constructions, as a logical framework and for metalogical reasoning. Specifically, we have used the COQ proof assistant in a formally rigorous development of a UNITY-style temporal logic, which generalizes the original UNITY approach in important aspects. Since all inference rules of the temporal logic are proved as theorems in the metalogic, the result of the development is a verified temporal logic library, which due to the use of labeled transition systems as a semantic basis, can be employed for a wide range of system models, Petri nets and rewriting logic specifications being particular examples. The development also includes a new application of the proposition-as-types interpretation in the context of compositional reasoning. $\backslash$nThe use of membership equational logic or rewriting logic as a semantic and logical framework for higher-order languages, or more generally languages with binding constructs, obviously requires a first-order treatment of names and relevant operations such as substitutions. To systematically address such applications, we develop CINNI, a new calculus of names and substitutions, that takes names seriously in the sense that it does not abstract from names, and is generic in the sense that it can be instantiated to arbitrary object languages. Our calculus unifies the standard named notation and a notation based on de Bruijn indices by employing a representation that was originally developed by Berkling for the lambda-calculus. It furthermore nicely generalizes the calculus lambda upsilon of explicit substitutions developed by Lescanne, and, as we show, most metatheoretic results can be generalized to the new calculus. We furthermore give a very general confluence result for the composition of CINNI with the equations or rules capturing the dynamics of the object language, and we in particular discuss how our approach can be applied to the representation of the untyped lambda-calculus, Abadi and Cardelli's object calculus, also called the sigma-calculus, and Milner's pi-calculus for communicating and mobile systems. As a real-world application of CINNI we briefly discuss a specification of an active network programming language in the rewriting-logic-based language Maude. $\backslash$nWe more specifically address the use of membership equational logic and rewriting logic as a first-order logical framework by representing an important class of pure type systems. Pure type systems generalize a variety of different type theories, including the calculus of constructions and its well-known subsystems, and can be seen as higher-order logics via the propositions-as-types interpretation. Following a methodology based on Meseguer's general logics in combination with rewriting logic as a concrete logical framework, we have studied representations of pure type systems at different levels of abstractions, ranging from an abstract textbook representation to a more concrete executable representation of an important subclass, which can directly serve as a type inference and type checking algorithm. The latter representation is based on a new notion of uniform pure type systems, which take names seriously thanks to the CINNI calculus and simultaneously offer a possible solution to the known problem with alpha-closure pointed out by Pollack. Using an example, in which we validate proofs developed with the LEGO proof assistant in an extension of the calculus of constructions with universes, we have demonstrated how our approach directly leads to an executable prototype in a rewriting logic language such as Maude. $\backslash$nAs an application of type theory in the context of classical reasoning we study Howe's HOL/Nuprl connection, which addresses the problem of formal interoperability between proof assistents, from the viewpoint of Meseguer's general logics. We supplement Howe's semantic justification by a proof-theoretic correctness argument, a piece of work which has lead to proof-translation as new interesting application (explored in joint work with Naumov) that goes beyond Howe's original HOL/Nuprl connection. From a theoretical perspective we found that the core idea of the HOL/Nuprl connection, namely the beneficial coexistence of an intensional and an extensional logic in the same formal system, does not rely on any of the advanced concepts of Nuprl, but can equally well be used in Martin-L{\"{o}}f's type theory and can further be easily adopted to type theories in the line of calculus of constructions. $\backslash$nThe final and main contribution of this thesis is the development of a formalism that we call the open calculus of constructions (OCC). It is based on the surprisingly powerful interaction between its two key features, namely dependent types, in the spirit of Martin-L{\"{o}}f's type theory and the calculus of constructions, and the computational system of rewriting logic and its underlying membership equational logic, which is based on conditional rewriting modulo equations. The applications of membership equational logic, rewriting logic, and type theory, studied in this thesis have not only inspired the development of this unifying formalism, but they become applications of OCC itself and benefit from its use in an essential way. On the theoretical side, we introduce OCC by presenting a classical set-theoretic semantics and a formal system for which we prove soundness and consistency as a logic. The formal system is used to define derivable judgements together with their operational semantics, and is based on the ideas that we developed earlier in the context of uniform pure type systems. The model-theoretic semantics that we develop in this thesis is a very intuitive semantics with proof-irrelevance for impredicative universes, but unlike existing approaches it is more direct and can be given independently of the formal system. Using an experimental prototype of OCC, that we implemented in Maude following the approach to the specification of type theories mentioned before in combination with reflective techniques, we have developed a large collection of examples, many of which are closely related to the applications discussed earlier in this thesis. These examples do not only convey the pragmatics of OCC, but they simultaneously provide a proof-of-concept for our approach. Among the topics covered by our examples we find executable equational/behavioral specifications, programming with dependent types, symbolic execution of system models, formalization of algebraic and categorical concepts, inductive/coinductive theorem proving, and theorem proving modulo equational theories.},
author = {Wimmer, Simon and Hu, Shuwei and Nipkow, Tobias},
booktitle = {Interactive Theorem Proving. ITP 2018},
doi = {10.1007/978-3-319-94821-8_34},
file = {:Users/liang-tingchen/Dropbox/References/Wimmer, Hu, Nipkow - 2018 - Verified Memoization and Dynamic Programming.pdf:pdf},
isbn = {978-3-642-39633-5},
issn = {03029743},
pages = {579--596},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Verified Memoization and Dynamic Programming}},
url = {http://link.springer.com/10.1007/978-3-642-39634-2 http://link.springer.com/10.1007/978-3-319-94821-8{\_}34},
volume = {7998},
year = {2018}
}
@article{Mogelberg2019,
abstract = {Just like any other branch of mathematics, denotational semantics of programming languages should be formalised in type theory, but adapting traditional domain theoretic semantics, as originally formulated in classical set theory to type theory has proven challenging. This paper is part of a project on formulating denotational semantics in type theories with guarded recursion. This should have the benefit of not only giving simpler semantics and proofs of properties such as adequacy, but also hopefully in the future to scale to languages with advanced features, such as general references, outside the reach of traditional domain theoretic techniques.},
author = {{Ejlers M{\o}gelberg}, Rasmus and Paviotti, Marco},
doi = {10.1017/S0960129518000087},
file = {:Users/liang-tingchen/Dropbox/References/Ejlers M{\o}gelberg, Paviotti - 2019 - Denotational semantics of recursive types in synthetic guarded domain theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {3},
pages = {465--510},
title = {{Denotational semantics of recursive types in synthetic guarded domain theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129518000087/type/journal{\_}article},
volume = {29},
year = {2019}
}
@article{Barak2012,
abstract = {Informally, an obfuscator O is an (efficient, probabilistic) " compiler " that takes as input a program (or circuit) P and produces a new program O(P) that has the same functionality as P yet is " unintel-ligible " in some sense. Obfuscators, if they exist, would have a wide vari-ety of cryptographic and complexity-theoretic applications, ranging from software protection to homomorphic encryption to complexity-theoretic analogues of Rice's theorem. Most of these applications are based on an interpretation of the " unintelligibility " condition in obfuscation as mean-ing that O(P) is a " virtual black box, " in the sense that anything one can efficiently compute given O(P), one could also efficiently compute given oracle access to P . In this work, we initiate a theoretical investigation of obfuscation. Our main result is that, even under very weak formalizations of the above in-tuition, obfuscation is impossible. We prove this by constructing a family of functions F that are inherently unobfuscatable in the following sense: there is a property $\pi$ : F → {\{}0, 1{\}} such that (a) given any program that computes a function f ∈ F, the value $\pi$(f) can be efficiently computed, yet (b) given oracle access to a (randomly selected) function f ∈ F, no efficient algorithm can compute $\pi$(f) much better than random guessing. We extend our impossibility result in a number of ways, including even obfuscators that (a) are not necessarily computable in polynomial time, (b) only approximately preserve the functionality, and (c) only need to work for very restricted models of computation (TC 0). We also rule out several potential applications of obfuscators, by constructing " unob-fuscatable " signature schemes, encryption schemes, and pseudorandom function families.},
author = {Barak, Boaz and Goldreich, Oded and Impagliazzo, Russell and Rudich, Steven and Sahai, Amit and Vadhan, Salil and Yang, Ke},
doi = {10.1145/2160158.2160159},
file = {:Users/liang-tingchen/Dropbox/References/Barak et al. - 2012 - On the (im)possibility of obfuscating programs.pdf:pdf},
isbn = {3540424563},
issn = {00045411},
journal = {Journal of the ACM},
month = {apr},
number = {2},
pages = {1--48},
title = {{On the (im)possibility of obfuscating programs}},
url = {http://dl.acm.org/citation.cfm?doid=2160158.2160159},
volume = {59},
year = {2012}
}
@article{Adamek2013,
abstract = {Continuous lattices were characterised by Martin Escardo as precisely the objects that are Kan-injective w.r.t. a certain class of morphisms. We study Kan-injectivity in general categories enriched in posets. For every class H of morphisms we study the subcategory of all objects Kan-injective w.r.t. H and all morphisms preserving Kan-extensions. For categories such as Top{\_}0 and Pos we prove that whenever H is a set of morphisms, the above subcategory is monadic, and the monad it creates is a Kock-Zoeberlein monad. However, this does not generalise to proper classes: we present a class of continuous mappings in Top{\_}0 for which Kan-injectivity does not yield a monadic category.},
archivePrefix = {arXiv},
arxivId = {1311.1721},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Sousa, Lurdes and Velebil, Jiř{\'{i}}},
doi = {10.1017/S0960129514000024},
eprint = {1311.1721},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Sousa, Velebil - 2015 - Kan injectivity in order-enriched categories.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
number = {01},
pages = {6--45},
title = {{Kan injectivity in order-enriched categories}},
url = {http://arxiv.org/abs/1311.1721},
volume = {25},
year = {2015}
}
@article{Bezhanishvili2000,
abstract = {This paper is the concluding part of [1] and [2], and it investigates the inner structure of the lattice $\Lambda$(MHA) of all varieties of monadic Heyting algebras. For every n ≤ $\omega$, we introduce and investigate varieties of depth n and cluster n, and present two partitions of $\Lambda$(MHA), into varieties of depth n, and into varieties of cluster n. We pay a special attention to the lower part of $\Lambda$(MHA) and investigate finite and critical varieties of monadic Heyting algebras in detail. In particular, we prove that there exist exactly thirteen critical varieties in $\Lambda$(MHA) and that it is decidable whether a given variety of monadic Heyting algebras is finite or not. The representation of $\Lambda$(MHA) is also given. All these provide us with a satisfactory insight into $\Lambda$(MHA). Since $\Lambda$(MHA) is dual to the lattice NExtMIPC of all normal extensions of the intuitionistic modal logic MIPC, we also obtain a clearer picture of the lattice structure of intuitionistic modal logics over MIPC.},
author = {Bezhanishvili, Guram},
doi = {10.1023/A:1005285631357},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili - 2000 - Varieties of Monadic Heyting Algebras. Part III.pdf:pdf},
journal = {Studia Logica},
number = {2},
pages = {215--256},
title = {{Varieties of Monadic Heyting Algebras. Part III}},
url = {http://link.springer.com/article/10.1023{\%}2FA{\%}3A1005285631357},
volume = {64},
year = {2000}
}
@article{Hermida2011,
author = {Hermida, Claudio},
doi = {10.1016/j.ic.2010.09.009},
file = {:Users/liang-tingchen/Dropbox/References/Hermida - 2011 - A categorical outlook on relational modalities and simulations.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {bicategories of relations},
month = {dec},
number = {12},
pages = {1505--1517},
publisher = {Elsevier Inc.},
title = {{A categorical outlook on relational modalities and simulations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540111001428},
volume = {209},
year = {2011}
}
@book{Hutchison2010,
author = {Hutchison, David and Mitchell, John C},
doi = {10.1007/978-3-642-15838-4},
editor = {Domingo-Ferrer, Josep and Magkos, Emmanouil},
file = {:Users/liang-tingchen/Dropbox/References/Hutchison, Mitchell - 2010 - UNESCO Chair in Data Privacy, International Conference, PSD 2010, Corfu, Greece, September 22-24, 2010. Pro.pdf:pdf},
isbn = {9783642158377},
publisher = {Springer, Berlin, Heidelberg},
title = {{UNESCO Chair in Data Privacy, International Conference, PSD 2010, Corfu, Greece, September 22-24, 2010. Proceedings}},
url = {https://link.springer.com/book/10.1007{\%}2F978-3-642-15838-4{\#}about},
year = {2010}
}
@phdthesis{Iemhoff2001,
author = {Iemhoff, Rosalie},
file = {:Users/liang-tingchen/Dropbox/References/Iemhoff - 2001 - Provability logic and admissible rules.pdf:pdf},
isbn = {9057760649},
school = {University of Amsterdam},
title = {{Provability logic and admissible rules}},
year = {2001}
}
@article{Jonsson1952,
author = {J{\'{o}}nsson, Bjarni and Tarski, Alfred},
file = {:Users/liang-tingchen/Dropbox/References/J{\'{o}}nsson, Tarski - 1952 - Boolean algebras with operators.pdf:pdf},
journal = {American Journal of Mathematics},
number = {1},
pages = {127--162},
title = {{Boolean algebras with operators}},
url = {http://www.jstor.org/stable/2372074},
volume = {74},
year = {1952}
}
@incollection{Atkey2017,
abstract = {We present the semantics and proof system for an object-oriented language with active objects, asynchronous method calls,$\backslash$n and futures. The language, based on Creol, distinguishes itself in that unlike active object models, it permits more than$\backslash$n one thread of control within an object, though, unlike Java, only one thread can be active within an object at a given time$\backslash$n and rescheduling occurs only at specific release points. Consequently, reestablishing an object's monitor invariant is possible$\backslash$n at specific well-defined points in the code. The resulting proof system shows that this approach to concurrency is simpler$\backslash$n for reasoning than, say, Java's multithreaded concurrency model. From a methodological perspective, we identify constructs$\backslash$n which admit a simple proof system and those which require, for example, interference freedom tests.},
author = {Atkey, Robert},
booktitle = {Programming Languages and Systems. ESOP 2017.},
doi = {10.1007/978-3-662-54434-1_3},
editor = {Yang, Hongseok},
file = {:Users/liang-tingchen/Dropbox/References/Atkey - 2017 - Observed Communication Semantics for Classical Processes.pdf:pdf},
pages = {56--82},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Observed Communication Semantics for Classical Processes}},
url = {http://link.springer.com/10.1007/BFb0053558 http://link.springer.com/10.1007/978-3-662-54434-1{\_}3},
volume = {10201},
year = {2017}
}
@incollection{Freyd1991,
annote = {
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Freyd, Peter},
booktitle = {Category Theory},
doi = {10.1007/BFb0084215},
editor = {Carboni, Aurelio and Pedicchio, Maria and Rosolini, Guiseppe},
file = {:Users/liang-tingchen/Dropbox/References/Freyd - 1991 - Algebraically complete categories.pdf:pdf},
isbn = {978-3-540-54706-8},
pages = {95--104},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Algebraically complete categories}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/BFb0084215},
volume = {1488},
year = {1991}
}
@article{Spivak2012,
abstract = {In this paper we present a simple database definition language: that of categories and functors. A database schema is a small category and an instance is a set-valued functor on it. We show that morphisms of schemas induce three data migration functors, which translate instances from one schema to the other in canonical ways. These functors parameterize projections, unions, and joins over all tables simultaneously and can be used in place of conjunctive and disjunctive queries. We also show how to connect a database and a functional programming language by introducing a functorial connection between the schema and the category of types for that language. We begin the paper with a multitude of examples to motivate the definitions, and near the end we provide a dictionary whereby one can translate database concepts into category-theoretic concepts and vice versa. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1009.1166},
author = {Spivak, David I.},
doi = {10.1016/j.ic.2012.05.001},
eprint = {1009.1166},
file = {:Users/liang-tingchen/Dropbox/References/Spivak - 2012 - Functorial data migration.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Adjoint functors,Category theory,Data migration,Databases,Queries},
month = {aug},
pages = {31--51},
publisher = {Elsevier Inc.},
title = {{Functorial data migration}},
url = {http://dx.doi.org/10.1016/j.ic.2012.05.001 http://linkinghub.elsevier.com/retrieve/pii/S0890540112001010},
volume = {217},
year = {2012}
}
@inproceedings{Odersky1994,
abstract = {lambda nu is an extension of the lambda calculus with a$\backslash$nbinding construct for local names. The extension has$\backslash$nproperties analogous to classical lambda calculus and$\backslash$npreserves all observational equivalences of lambda. It is$\backslash$nuseful as a basis for modeling wide spectrum languages that$\backslash$nbuild on a functional core.},
address = {New York, New York, USA},
author = {Odersky, Martin},
booktitle = {Proceedings of the 21st ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '94},
doi = {10.1145/174675.175187},
file = {:Users/liang-tingchen/Dropbox/References/Odersky - 1994 - A functional theory of local names.pdf:pdf},
isbn = {0897916360},
issn = {07308566},
pages = {48--59},
publisher = {ACM Press},
title = {{A functional theory of local names}},
url = {http://portal.acm.org/citation.cfm?doid=174675.175187},
year = {1994}
}
@article{Hasuo2007,
abstract = {Trace semantics has been defined for various kinds of state-based systems, notably with different forms of branching such as non-determinism vs. probability. In this paper we claim to identify one underlying mathematical structure behind these "trace semantics," namely coinduction in a Kleisli category. This claim is based on our technical result that, under a suitably order-enriched setting, a final coalgebra in a Kleisli category is given by an initial algebra in the category Sets. Formerly the theory of coalgebras has been employed mostly in Sets where coinduction yields a finer process semantics of bisimilarity. Therefore this paper extends the application field of coalgebras, providing a new instance of the principle "process semantics via coinduction."},
archivePrefix = {arXiv},
arxivId = {0710.2505},
author = {Hasuo, Ichiro and Jacobs, Bart and Sokolova, Ana},
doi = {10.2168/LMCS-3(4:11)2007},
editor = {Rutten, Jan},
eprint = {0710.2505},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo, Jacobs, Sokolova - 2007 - Generic trace semantics via coinduction.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {nov},
number = {4},
pages = {36},
title = {{Generic trace semantics via coinduction}},
url = {http://arxiv.org/abs/0710.2505},
volume = {3},
year = {2007}
}
@article{Ahrens2018c,
abstract = {We present a device for specifying and reasoning about syntax for datatypes, programming languages, and logic calculi. More precisely, we consider a general notion of "signature" for specifying syntactic constructions. Our signatures subsume classical algebraic signatures (i.e., signatures for languages with variable binding, such as the pure lambda calculus) and extend to much more general examples. In the spirit of Initial Semantics, we define the "syntax generated by a signature" to be the initial object-if it exists-in a suitable category of models. Our notions of signature and syntax are suited for compositionality and provide, beyond the desired algebra of terms, a well-behaved substitution and the associated inductive/recursive principles. Our signatures are "general" in the sense that the existence of an associated syntax is not automatically guaranteed. In this work, we identify a large and simple class of signatures which do generate a syntax. This paper builds upon ideas from a previous attempt by Hirschowitz-Maggesi, which, in turn, was directly inspired by some earlier work of Ghani-Uustalu-Hamana and Matthes-Uustalu. The main results presented in the paper are computer-checked within the UniMath system.},
archivePrefix = {arXiv},
arxivId = {1805.03740},
author = {Ahrens, Benedikt and Hirschowitz, Andr{\'{e}} and Lafont, Ambroise and Maggesi, Marco},
doi = {10.4230/LIPIcs.CSL.2018.4},
eprint = {1805.03740},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2018 - High-level signatures and initial semantics.pdf:pdf},
isbn = {9783959770880},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Computerchecked proofs,Initial semantics,Monadic substitution,Signatures,Syntax},
number = {4},
pages = {1--4},
title = {{High-level signatures and initial semantics}},
volume = {119},
year = {2018}
}
@article{Marsden2014,
abstract = {In work of Fokkinga and Meertens a calculational approach to category theory is developed. The scheme has many merits, but sacrifices useful type information in the move to an equational style of reasoning. By contrast, traditional proofs by diagram pasting retain the vital type information, but poorly express the reasoning and development of categorical proofs. In order to combine the strengths of these two perspectives, we propose the use of string diagrams, common folklore in the category theory community, allowing us to retain the type information whilst pursuing a calculational form of proof. These graphical representations provide a topological perspective on categorical proofs, and silently handle functoriality and naturality conditions that require awkward bookkeeping in more traditional notation. Our approach is to proceed primarily by example, systematically applying graphical techniques to many aspects of category theory. We develop string diagrammatic formulations of many common notions, including adjunctions, monads, Kan extensions, limits and colimits. We describe representable functors graphically, and exploit these as a uniform source of graphical calculation rules for many category theoretic concepts. These graphical tools are then used to explicitly prove many standard results in our proposed diagrammatic style.},
archivePrefix = {arXiv},
arxivId = {1401.7220},
author = {Marsden, Daniel},
eprint = {1401.7220},
file = {:Users/liang-tingchen/Dropbox/References/Marsden - 2014 - Category Theory Using String Diagrams.pdf:pdf},
journal = {ArXiv preprint},
month = {jan},
pages = {1--60},
title = {{Category Theory Using String Diagrams}},
url = {http://arxiv.org/abs/1401.7220},
year = {2014}
}
@article{Goldblatt1985,
author = {Goldblatt, Robert},
doi = {10.2307/2274230},
file = {:Users/liang-tingchen/Dropbox/References/Goldblatt - 1985 - On the role of the Baire Category Theorem and Dependent Choice in the foundations of logic.pdf:pdf},
issn = {0022-4812},
journal = {The Journal of Symbolic Logic},
month = {jun},
number = {02},
pages = {412--422},
title = {{On the role of the Baire Category Theorem and Dependent Choice in the foundations of logic}},
url = {http://www.journals.cambridge.org/abstract{\_}S0022481200032758},
volume = {50},
year = {1985}
}
@article{Adamek2006b,
abstract = {Labeled unranked trees are used as a model of XML documents, and logical languages for them have been studied actively over the past several years. Such logics have different purposes: some are better suited for extracting data, some for expressing navigational properties, and some make it easy to relate complex properties of trees to the existence of tree automata for those properties. Furthermore, logics differ significantly in their model-checking properties, their automata models, and their behavior on ordered and unordered trees. In this paper we present a survey of logics for unranked trees.},
archivePrefix = {arXiv},
arxivId = {cs/0606062},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.2168/LMCS-2(5:4)2006},
editor = {unknown Anonymous},
eprint = {0606062},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2006 - Elgot algebras.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,automata,logic,logics,navigation,query evaluation,query languages,schemas,streaming,temporal,unranked trees,xml,xpath},
month = {nov},
number = {5},
pages = {1--31},
primaryClass = {cs},
title = {{Elgot algebras}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=243},
volume = {2},
year = {2006}
}
@phdthesis{Norell2007,
author = {Norell, Ulf},
file = {:Users/liang-tingchen/Dropbox/References/Norell - 2007 - Towards a Practical Programming Language Based on Dependent Type Theory.pdf:pdf},
isbn = {978-91-7291-996-9},
school = {Chalmers University of Technology and G{\"{o}}teborg University},
title = {{Towards a Practical Programming Language Based on Dependent Type Theory}},
type = {Doctoral Thesis},
year = {2007}
}
@article{Kelly1993a,
author = {Kelly, Gregory Maxwell and Lack, Stephen},
doi = {10.1007/BF00872987},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Lack - 1993 - Finite-product-preserving functors, Kan extensions, and strongly-finitary 2-monads.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {2-monads,categories with structure,finite-product-preserving functors,kan extensions},
number = {1},
pages = {85--94},
title = {{Finite-product-preserving functors, Kan extensions, and strongly-finitary 2-monads}},
url = {http://link.springer.com/10.1007/BF00872987},
volume = {1},
year = {1993}
}
@inproceedings{Lindley2013a,
abstract = {Haskell's type system has outgrown its Hindley-Milner roots to the extent that it now stretches to the basics of dependently typed pro- gramming. In this paper, we collate and classify techniques for pro- gramming with dependent types in Haskell, and contribute some new ones. In particular, through extended examples—merge-sort and rectangular tilings—we show how to exploit Haskell's con- straint solver as a theorem prover, delivering code which, as Agda programmers, we envy. We explore the compromises involved in simulating variations on the theme of the dependent function space in an attempt to help programmers put dependent types to work, and to inform the evolving language design both of Haskell and of dependently typed languages more broadly.},
address = {New York, New York, USA},
author = {Lindley, Sam and McBride, Conor},
booktitle = {Proceedings of the 2013 ACM SIGPLAN symposium on Haskell - Haskell '13},
doi = {10.1145/2503778.2503786},
file = {:Users/liang-tingchen/Dropbox/References/Lindley, McBride - 2013 - Hasochism.pdf:pdf},
isbn = {9781450323833},
issn = {15232867},
keywords = {data type promotion,dependent types,invariants,proof search,singletons},
pages = {81},
publisher = {ACM Press},
title = {{Hasochism}},
url = {http://dl.acm.org/citation.cfm?doid=2503778.2503786},
year = {2013}
}
@book{Harper2016,
author = {Harper, Robert},
doi = {10.1017/CBO9781139342131},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Harper - 2016 - Practical Foundations for Programming Languages.pdf:pdf},
isbn = {9781139342131},
publisher = {Cambridge University Press},
title = {{Practical Foundations for Programming Languages}},
url = {http://ebooks.cambridge.org/ref/id/CBO9781139342131},
year = {2016}
}
@article{Venema2006,
author = {Venema, Yde},
doi = {10.1016/j.ic.2005.06.003},
file = {:Users/liang-tingchen/Dropbox/References/Venema - 2006 - Automata and fixed point logic A coalgebraic perspective.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {04,106,2004,355,375,a significantly revised and,appeared under,automata,automata and fixed point,bisimulation,coalgebra,computer science,electronic notes in theoretical,expanded version of a,fixed point operators,game semantics,in proceedings cmcs,logics for coalgebras,modal logic,parity games,pp,preliminary conference paper which,the title,vol,ୋ this paper is},
month = {apr},
number = {4},
pages = {637--678},
title = {{Automata and fixed point logic: A coalgebraic perspective}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540106000083},
volume = {204},
year = {2006}
}
@article{Governatori2013a,
abstract = {In this paper we propose an extension of Defeasible Logic to represent and compute three concepts of defeasible permission. In particular, we discuss different types of explicit permissive norms that work as exceptions to opposite obligations. Moreover, we show how strong permissions can be represented both with, and without introducing a new consequence relation for inferring conclusions from explicit permissive norms. Finally, we illustrate how a preference operator applicable to contrary-to-duty obligations can be combined with a new operator representing ordered sequences of strong permissions which derogate from prohibitions. The logical system is studied from a computational standpoint and is shown to have liner computational complexity.},
archivePrefix = {arXiv},
arxivId = {1212.0079},
author = {Governatori, Guido and Olivieri, Francesco and Rotolo, Antonino and Scannapieco, Simone},
doi = {10.1007/s10992-013-9295-1},
eprint = {1212.0079},
file = {:Users/liang-tingchen/Dropbox/References/Governatori et al. - 2013 - Computing Strong and Weak Permissions in Defeasible Logic.pdf:pdf},
issn = {00223611},
journal = {Journal of Philosophical Logic},
keywords = {Computational complexity,Defeasible logic,Deontic logic,Permission},
number = {6},
pages = {799--829},
title = {{Computing Strong and Weak Permissions in Defeasible Logic}},
volume = {42},
year = {2013}
}
@article{Barr2002,
author = {Barr, Michael},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 2002 - HSP Subcategories of Eilenberg-Moore Algebras.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {birkhoff subcategories,factorizations,reflective subcategories},
number = {18},
pages = {461--468},
title = {{HSP Subcategories of Eilenberg-Moore Algebras}},
url = {http://www.tac.mta.ca/tac/volumes/10/18/10-18abs.html},
volume = {10},
year = {2002}
}
@article{Hughes2004a,
abstract = {We propose a new specification framework for information hiding properties such as anonymity and privacy. The framework is based on the concept of a function view, which is a concise representation of the attacker's partial knowledge about a function. We describe system behavior as a set of functions, and formalize different information hiding properties in terms of views of these functions. We present an ex- tensive case study, in which we use the function view framework to systematically classify and rigorously define a rich domain of identity-related properties, and to demonstrate that privacy and anonymity are independent. The key feature of our approach is its modularity. It yields precise, formal specifications of information hiding properties for any protocol formalism and any choice of the attacker model as long as the latter induce an observational equivalence relation on protocol instances. In particular, specifications based on function views are suitable for any cryptographic process calculus that defines some form of indistin- guishability between processes. Our definitions of information hiding properties take into account any feature of the security model, including probabilities, random number generation, timing, etc., to the ex- tent that it is accounted for by the formalism in which the system is specified.},
author = {Hughes, Dominic and Shmatikov, Vitaly},
file = {:Users/liang-tingchen/Dropbox/References/Hughes, Shmatikov - 2004 - Information Hiding, Anonymity and Privacy A Modular Approach.pdf:pdf},
issn = {0926-227X},
journal = {Journal of Computer Security},
keywords = {anonymity,information hiding,knowledge,kripke structure,logic,security,verification},
number = {1},
pages = {3--36},
title = {{Information Hiding, Anonymity and Privacy: A Modular Approach}},
volume = {12},
year = {2004}
}
@misc{Streicher2004,
author = {Streicher, Thomas},
file = {:Users/liang-tingchen/Dropbox/References/Streicher - 2004 - Realizability.pdf:pdf},
institution = {TU Darmstadt},
title = {{Realizability}},
url = {https://www2.mathematik.tu-darmstadt.de/{~}streicher/REAL/REAL.pdf},
year = {2004}
}
@misc{Wells2009,
author = {Wells, Charles},
file = {:Users/liang-tingchen/Dropbox/References/Wells - 2009 - Sketches Outline with References.pdf:pdf},
month = {sep},
title = {{Sketches: Outline with References}},
url = {http://www.cwru.edu/artsci/math/wells/pub/papers.html},
year = {2009}
}
@phdthesis{Tanaka2005,
author = {Tanaka, Miki},
file = {:Users/liang-tingchen/Dropbox/References/Tanaka - 2005 - Pseudo-Distributive Laws and a Unified Framework for Variable Binding.pdf:pdf},
pages = {167},
school = {University of Edinburgh},
title = {{Pseudo-Distributive Laws and a Unified Framework for Variable Binding}},
year = {2005}
}
@article{Abramsky2013a,
abstract = {We use a simple relational framework to develop the key notions and results on hidden variables and non-locality. The extensive literature on these topics in the foundations of quantum mechanics is couched in terms of probabilistic models, and properties such as locality and no-signalling are formulated probabilistically. We show that to a remarkable extent, the main structure of the theory, through the major No-Go theorems and beyond, survives intact under the replacement of probability distributions by mere relations.},
archivePrefix = {arXiv},
arxivId = {1007.2754},
author = {Abramsky, Samson},
doi = {10.1007/s11225-013-9477-4},
eprint = {1007.2754},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2013 - Relational Hidden Variables and Non-Locality.pdf:pdf},
isbn = {1122501394774},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {Hidden variables,Non-locality,Possibilistic models,Probabilistic models,Quantum mechanics},
month = {apr},
number = {2},
pages = {411--452},
title = {{Relational Hidden Variables and Non-Locality}},
url = {http://link.springer.com/10.1007/s11225-013-9477-4},
volume = {101},
year = {2013}
}
@article{Chargueraud2012,
abstract = {This paper provides an introduction to the locally nameless approach to the representation of syntax with variable binding, focusing in particular on the use of this technique in formal proofs. First, it explains the benefits of representing bound variables with de Bruijn indices while retaining names for free variables. It then describes the operations involved for manipulating syntax in that form, and shows how to define and reason about judgments on locally nameless terms.},
author = {Chargu{\'{e}}raud, Arthur},
doi = {10.1007/s10817-011-9225-2},
file = {:Users/liang-tingchen/Dropbox/References/Chargu{\'{e}}raud - 2012 - The locally nameless representation.pdf:pdf},
issn = {01687433},
journal = {Journal of Automated Reasoning},
keywords = {Binders,Cofinite quantification,Formal proofs,Locally nameless,Metatheory},
number = {3},
pages = {363--408},
title = {{The locally nameless representation}},
volume = {49},
year = {2012}
}
@inproceedings{Okasaki1995a,
abstract = {Amortization has been underutilized in the design of persistent$\backslash$ndata structures, largely because traditional accounting schemes break$\backslash$ndown in a persistent setting. Such schemes depend on saving$\backslash$n{\&}ldquo;credits{\&}rdquo; for future use, but a persistent data structure$\backslash$nmay have multiple {\&}ldquo;futures{\&}rdquo;, each competing for the same$\backslash$ncredits. We describe how lazy evaluation can often remedy this problem,$\backslash$nyielding persistent data structures with good amortized efficiency. In$\backslash$nfact, such data structures can be implemented purely functionally in any$\backslash$nfunctional language supporting lazy evaluation. As can example of this$\backslash$ntechnique, we present a purely functional (and therefore persistent)$\backslash$nimplementation of lists that simultaneously support catenation and all$\backslash$nother usual list primitives in constant amortized time. This data$\backslash$nstructure is much simpler than the only existing data structure with$\backslash$ncomparable bounds, the recently discovered catenable lists of Kaplan and$\backslash$nTarjan, which support all operations in constant worst-case time},
author = {Okasaki, C.},
booktitle = {Proceedings of IEEE 36th Annual Foundations of Computer Science},
doi = {10.1109/SFCS.1995.492666},
file = {:Users/liang-tingchen/Dropbox/References/Okasaki - 1995 - Amortization, lazy evaluation, and persistence lists with catenation via lazy linking.pdf:pdf},
isbn = {0-8186-7183-1},
issn = {02725428},
pages = {646--654},
publisher = {IEEE Comput. Soc. Press},
title = {{Amortization, lazy evaluation, and persistence: lists with catenation via lazy linking}},
url = {http://ieeexplore.ieee.org/document/492666/},
year = {1995}
}
@article{Cirstea2016,
abstract = {We define quantitative fixpoint logics for reasoning about linear time properties of states in systems with branching behaviour. We model such systems as coalgebras whose type arises as the composition of a branching monad with one or more polynomial endofunctors on the category of sets. The domain of truth values for our logics is determined by the choice of branching monad, as is the special modality used to abstract away branching in the semantics of the logics. To justify our choice of syntax and semantics for the logics, we prove the equivalence between their step-wise semantics and an alternative path-based semantics for the fixpoint-free fragments of the logics. Instances of these logics support reasoning about the possibility, probability or minimal cost of exhibiting a given linear time property. We conclude with two examples of logics that have a linear time flavour but do not admit a path-based semantics, namely a logic for reasoning about resource usage in infinitely-running computations, and a quantitative logic for reasoning about component interaction.},
archivePrefix = {arXiv},
arxivId = {1612.07844},
author = {C{\^{i}}rstea, Corina},
doi = {10.2168/LMCS-},
eprint = {1612.07844},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2016 - A coalgebraic approach to quantitative linear time logics.pdf:pdf},
isbn = {9783642548611},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Algebraic theories,Equational logic,Rewriting,Soundness and completeness,Variable binding,$\alpha$-equivalence},
month = {dec},
number = {3},
pages = {1--26},
title = {{A coalgebraic approach to quantitative linear time logics}},
url = {http://arxiv.org/abs/1612.07844},
volume = {7},
year = {2016}
}
@article{Abramsky2011,
abstract = {We give multiple descriptions of a topological universe of finitary sets, which can be seen as a natural limit completion of the hereditarily finite sets. This universe is characterized as a metric completion of the hereditarily finite sets; as a Stone space arising as the solution of a functorial fixed-point equation involving the Vietoris construction; as the Stone dual of the free modal algebra; and as the subspace of maximal elements of a domain equation involving the Plotkin (or convex) powerdomain. These results illustrate the methods developed in the author's 'Domain theory in logical form', and related literature, and have been taken up in recent work on topological coalgebras. The set-theoretic universe of finitary sets also supports an interesting form of set theory. It contains non-well founded sets and a universal set; and is closed under positive versions of the usual axioms of set theory.},
archivePrefix = {arXiv},
arxivId = {1111.7148},
author = {Abramsky, Samson},
eprint = {1111.7148},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2011 - A cook's tour of the finitary non-well-founded sets.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {computer,logic,mathematics,physics,quantum,science},
mendeley-tags = {computer,logic,mathematics,physics,quantum,science},
month = {nov},
title = {{A cook's tour of the finitary non-well-founded sets}},
type = {Journal article},
url = {http://arxiv.org/abs/1111.7148},
year = {2011}
}
@inproceedings{Rendel2010,
abstract = {Parsers and pretty-printers for a language are often quite similar, yet both are typically implemented separately, leading to redundancy and potential inconsistency. We propose a new interface of syntactic descriptions, with which both parser and pretty-printer can be described as a single program. Whether a syntactic description is used as a parser or as a pretty-printer is determined by the implementation of the interface. Syntactic descriptions enable programmers to describe the connection between concrete and abstract syntax once and for all, and use these descriptions for parsing or pretty-printing as needed. We also discuss the generalization of our programming technique towards an algebra of partial isomorphisms. {\textcopyright} 2010 ACM.},
address = {New York, New York, USA},
author = {Rendel, Tillmann and Ostermann, Klaus},
booktitle = {Proceedings of the third ACM Haskell symposium on Haskell - Haskell '10},
doi = {10.1145/1863523.1863525},
file = {:Users/liang-tingchen/Dropbox/References/Rendel, Ostermann - 2010 - Invertible syntax descriptions.pdf:pdf},
isbn = {9781450302524},
keywords = {embedded domain specific languages,invertible computation,parser combinators,pretty printing},
pages = {1},
publisher = {ACM Press},
title = {{Invertible syntax descriptions}},
url = {http://portal.acm.org/citation.cfm?doid=1863523.1863525},
year = {2010}
}
@article{Moss2004,
abstract = {This paper connects coalgebra with a long discussion in the foundations of game theory on the modeling of type spaces. We argue that type spaces are coalgebras, that universal type spaces are final coalgebras, and that the modal logics already proposed in the economic theory literature are closely related to those in recent work in coalgebraic modal logic. In the other direction, the categories of interest in this work are usually measurable spaces or compact (Hausdorff) topological spaces. A coalgebraic version of the construction of the universal type space due to Heifetz and Samet [Journal of Economic Theory 82 (2) (1998) 324–341] is generalized for some functors in those categories. Since the concrete categories of interest have not been explored so deeply in the coalgebra literature, we have some new results. We show that every functor on the category of measurable spaces built from constant functors, products, coproducts, and the probability measure space functor has a final coalgebra. Moreover, we construct this final coalgebra from the relevant version of coalgebraic modal logic. Specifically, we consider the set of theories of points in all coalgebras and endow this set with a measurable and coalgebra structure.},
author = {Moss, Lawrence S. and Viglizzo, Ignacio Dario},
doi = {10.1016/j.entcs.2004.02.036},
file = {:Users/liang-tingchen/Dropbox/References/Moss, Viglizzo - 2004 - Harsanyi type spaces and final coalgebras constructed from satisfied theories.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {beliefs,coalgebra,final coalgebra,harsanyi type space,measurable space,probabilities},
month = {dec},
pages = {279--295},
title = {{Harsanyi type spaces and final coalgebras constructed from satisfied theories}},
url = {http://dx.doi.org/10.1016/j.entcs.2004.02.036},
volume = {106},
year = {2004}
}
@inproceedings{Chapman2011,
abstract = {We present a closed dependent type theory whose inductive types are given not by a scheme for generative declarations, but by encoding in a universe. Each inductive datatype arises by interpreting its description - a first-class value in a datatype of descriptions. Moreover, the latter itself has a description. Datatype-generic programming thus becomes ordinary programming. We show some of the resulting generic operations and deploy them in particular, useful ways on the datatype of datatype descriptions itself. Simulations in existing systems suggest that this apparently self-supporting setup is achievable without paradox or infinite regress.},
address = {New York, New York, USA},
author = {Chapman, James and Dagand, Pierre-{\'{E}}variste and McBride, Conor and Morris, Peter},
booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming - ICFP '10},
doi = {10.1145/1863543.1863547},
file = {:Users/liang-tingchen/Dropbox/References/Chapman et al. - 2010 - The gentle art of levitation.pdf:pdf},
isbn = {9781605587943},
issn = {03621340},
month = {sep},
number = {9},
pages = {3},
publisher = {ACM Press},
title = {{The gentle art of levitation}},
url = {http://portal.acm.org/citation.cfm?doid=1932681.1863547 http://portal.acm.org/citation.cfm?doid=1863543.1863547},
volume = {45},
year = {2010}
}
@article{Aehlig2004,
abstract = {A purely syntactic and untyped variant of Normalisation by Evaluation for the {\$}\backslashlambda{\$} -calculus is presented in the framework of a two-level {\$}\backslashlambda{\$} -calculus with rewrite rules to model the inverse of the evaluation functional. Among its operational properties there is a standardisation theorem that formally establishes the adequacy of implementation in functional programming languages. An example implementation in Haskell is provided. The relation to the usual type-directed Normalisation by Evaluation is highlighted, using a short analysis of {\$}\backslasheta{\$} -expansion that leads to a perspicuous strong normalisation and confluence proof for {\$}\backslashbeta\backslasheta\backslash!\backslashup{\$} -reduction as a byproduct.},
author = {Aehlig, Klaus and Joachimski, Felix},
doi = {10.1017/S096012950400427X},
file = {:Users/liang-tingchen/Dropbox/References/Aehlig, Joachimski - 2004 - Operational aspects of untyped Normalisation by Evaluation.pdf:pdf},
isbn = {0960129504004},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {aug},
number = {4},
pages = {587--611},
title = {{Operational aspects of untyped Normalisation by Evaluation}},
url = {https://www.cambridge.org/core/product/identifier/S096012950400427X/type/journal{\_}article},
volume = {14},
year = {2004}
}
@article{Reutenauer1980,
author = {Reutenauer, Christophe},
doi = {10.1016/0021-8693(80)90097-6},
file = {:Users/liang-tingchen/Dropbox/References/Reutenauer - 1980 - S{\'{e}}ries formelles et alg{\`{e}}bres syntactiques.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
number = {2},
pages = {448--483},
title = {{S{\'{e}}ries formelles et alg{\`{e}}bres syntactiques}},
volume = {66},
year = {1980}
}
@article{Kreuzer2013,
author = {Bauer, Andrej and Pretnar, Matija},
doi = {10.2168/LMCS-10(4:9)2014},
editor = {Milius, Stefan},
file = {:Users/liang-tingchen/Dropbox/References/Bauer, Pretnar - 2014 - An Effect System for Algebraic Effects and Handlers.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,bounded variation,compactness,computational analysis,reverse mathematics},
month = {dec},
number = {4},
pages = {1--15},
title = {{An Effect System for Algebraic Effects and Handlers}},
url = {http://arxiv.org/abs/1308.3881 http://www.lmcs-online.org/ojs/viewarticle.php?id=1560},
volume = {10},
year = {2014}
}
@book{Bloom1993,
author = {Bloom, Stephen L. and {\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1007/978-3-642-78034-9},
file = {:Users/liang-tingchen/Dropbox/References/Bloom, {\'{E}}sik - 1993 - Iteration Theories.pdf:pdf},
isbn = {978-3-642-78036-3},
pages = {XV, 630},
publisher = {Springer-Verlag Berlin Heidelberg},
series = {Monographs in Theoretical Computer Science. An EATCS Series},
title = {{Iteration Theories}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-78034-9},
year = {1993}
}
@article{Moggi1991,
author = {Moggi, Eugenio},
doi = {10.1016/0890-5401(91)90052-4},
file = {:Users/liang-tingchen/Dropbox/References/Moggi - 1991 - Notions of computation and monads.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {jul},
number = {1},
pages = {55--92},
title = {{Notions of computation and monads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0890540191900524},
volume = {93},
year = {1991}
}
@book{Makkai1993,
author = {Makkai, Michael},
file = {:Users/liang-tingchen/Dropbox/References/Makkai - 1993 - Duality and Definability in First Order Logic.pdf:pdf},
isbn = {0821825658},
pages = {106},
publisher = {American Mathematical Society},
series = {Memoirs of the American Mathematical Society},
title = {{Duality and Definability in First Order Logic}},
year = {1993}
}
@article{Turner1979a,
author = {Turner, D. A.},
doi = {10.1002/spe.4380090105},
file = {:Users/liang-tingchen/Dropbox/References/Turner - 1979 - A new implementation technique for applicative languages.pdf:pdf},
issn = {00380644},
journal = {Software: Practice and Experience},
month = {jan},
number = {1},
pages = {31--49},
title = {{A new implementation technique for applicative languages}},
url = {http://doi.wiley.com/10.1002/spe.4380090105},
volume = {9},
year = {1979}
}
@article{Jacobs2012a,
abstract = {Traditionally in categorical logic predicates on an object/type X are represented as subobjects of X. Here we break with that tradition and use maps of the form p : X --{\textgreater} X + X with [id, id] o p = id as predicates. This new view gives a more dynamic, measurement-oriented view on predicates, that works well especially in a quantitative setting. In classical logic (in the category of sets) these new predicates coincide with the traditional ones (subsets, or characteristic maps X --{\textgreater} {\{}0,1{\}}); in probabilistic logic (in the category of sets and stochastic matrices), the new predicates correspond to fuzzy predicates X --{\textgreater} [0,1]; and in quantum logic (in Hilbert spaces) they correspond to effects (positive endomaps below the identity), which may be understood as fuzzy predicates on a changed basis. It is shown that, under certain conditions about coproducts +, predicates p : X --{\textgreater} X + X form effect algebras and carry a scalar multiplication (with probabilities). Suitable substitution functors give rise to indexed/fibred categories. In the quantum case the famous Born rule - describing the probability of observation outcomes - follows directly from the form of these substitution functors: probability calculation becomes substitution in predicate logic. Moreover, the characteristic maps associated with predicates provide tests in a dynamic logic, and turn out to capture measurement in a form that uniformly covers the classical, probabilistic and quantum case. The probabilities incorporated in predicates (as eigenvalues) serves as weights for the possible measurement outcomes.},
archivePrefix = {arXiv},
arxivId = {1205.3940},
author = {Jacobs, Bart},
eprint = {1205.3940},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2012 - New Directions in Categorical Logic, for Classical, Probabilistic and Quantum Logic.pdf:pdf},
journal = {ArXiv e-prints},
month = {may},
title = {{New Directions in Categorical Logic, for Classical, Probabilistic and Quantum Logic}},
url = {http://arxiv.org/abs/1205.3940},
year = {2012}
}
@incollection{Clouston2015,
author = {Clouston, Ranald and Bizjak, Ale{\v{s}} and Grathwohl, Hans Bugge and Birkedal, Lars},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2015},
doi = {10.1007/978-3-662-46678-0_26},
editor = {Pitts, Andrew M.},
file = {:Users/liang-tingchen/Dropbox/References/Clouston et al. - 2015 - Programming and Reasoning with Guarded Recursion for Coinductive Types.pdf:pdf},
isbn = {9783662466773},
issn = {16113349},
pages = {407--421},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Programming and Reasoning with Guarded Recursion for Coinductive Types}},
url = {http://link.springer.com/10.1007/978-3-662-46678-0{\_}26},
volume = {9034},
year = {2015}
}
@article{Breiman2001,
abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commit-ment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current prob-lems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
archivePrefix = {arXiv},
arxivId = {0010},
author = {Breiman, Leo},
doi = {10.2307/2676681},
eprint = {0010},
file = {:Users/liang-tingchen/Dropbox/References/Breiman - 2001 - Statistical Modeling The Two Cultures.pdf:pdf},
isbn = {08834237},
issn = {08834237},
journal = {Statistical Science},
number = {3},
pages = {199--231},
pmid = {10511666},
title = {{Statistical Modeling: The Two Cultures}},
volume = {16},
year = {2001}
}
@incollection{Artemov2007,
abstract = {G�del's modal logic approach to analyzing provability attracted a great deal of attention and eventually led to two distinct mathematical models. The first is the modal logic GL, also known as the Provability Logic, which was shown in 1979 by Solovay to be the logic of the formal provability predicate. The second is G�del's original modal logic of provability S4, together with its explicit counterpart, the Logic of Proofs LP, which was shown in 1995 by Artemov to provide an exact provability semantics for S4. These two models complement each other and cover a wide range of applications, from traditional proof theory to $\lambda$-calculi and formal epistemology.},
address = {New York, NY},
author = {Artemov, Sergei},
booktitle = {Mathematical Problems from Applied Logic II},
doi = {10.1007/978-0-387-69245-6_1},
file = {:Users/liang-tingchen/Dropbox/References/Artemov - 2007 - On Two Models of Provability.pdf:pdf},
pages = {1--52},
publisher = {Springer New York},
title = {{On Two Models of Provability}},
url = {http://link.springer.com/10.1007/978-0-387-69245-6{\_}1},
year = {2007}
}
@book{Sorensen2006,
author = {S{\o}rensen, Morten Heine and Urzyczyn, Pawel},
editor = {Abramsky, Samson and Artemov, S. and Gabbay, D. M. and Kechris, A. and Pillay, A. and Shore, R. A.},
file = {:Users/liang-tingchen/Dropbox/References/S{\o}rensen, Urzyczyn - 2006 - Lectures on the Curry-Howard Isomorphisms.pdf:pdf},
isbn = {978-0-444-52077-7},
pages = {456},
publisher = {Elsevier Inc.},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{Lectures on the Curry-Howard Isomorphisms}},
year = {2006}
}
@article{Biernacki2019,
author = {Biernacki, Dariusz and Pir{\'{o}}g, Maciej and Polesiuk, Piotr and Sieczkowski, Filip},
doi = {10.1145/3290319},
file = {:Users/liang-tingchen/Dropbox/References/Biernacki et al. - 2019 - Abstracting algebraic effects.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--28},
title = {{Abstracting algebraic effects}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290319},
volume = {3},
year = {2019}
}
@article{Adamek2004,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1016/j.tcs.2003.12.022},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2004 - On coalgebra based on classes.pdf:pdf},
issn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {Category of classes,Iterative monad,Set-based endofunctor,Terminal coalgebra,category,classes,coalgebra,endofunctor,iterative,monad,of,set-based,terminal},
mendeley-tags = {category,classes,coalgebra,endofunctor,iterative,monad,of,set-based,terminal},
month = {may},
number = {1-3},
pages = {3--23},
title = {{On coalgebra based on classes}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/B6V1G-4BSWJ2J-D/2/1e7e91297649a40fd832f7904c3f7e3a},
volume = {316},
year = {2004}
}
@incollection{Cirstea2007a,
abstract = {We present a coalgebraic semantics for reasoning about information update in multi-agent systems. The novelty is that we have one structure for both states and actions and thus our models do not involve the "change-of- model" phenomena that arise when using Kripke models. However, we prove that the usual models can be constructed from ours by categorical adjunction. The generality and abstraction of our coalgebraic model turns out to be extremely useful in proving preservation properties of update. In particular, we prove that positive knowledge is preserved and acquired as a result of epistemic update. We also prove common and nested knowledge properties of epistemic updates induced by specific epistemic actions such as public and private announcements, lying, and in particular unsafe actions of security protocols. Our model directly gives rise to a coalgebraic logic with both dynamic and epistemic modalities. We prove a soundness and completeness result for this logic, and illustrate the applicability of the logic by deriving knowledge properties of a simple security protocol. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
address = {Berlin, Heidelberg},
author = {C{\^{i}}rstea, Corina and Sadrzadeh, Mehrnoosh},
booktitle = {Proceedings of the 2nd International Conference on Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-540-73859-6_11},
editor = {Mossakowski, Till and Montanari, Ugo and Haveraaen, Magne},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea, Sadrzadeh - 2007 - Coalgebraic epistemic update without change of model.pdf:pdf},
isbn = {9783540738572},
issn = {03029743 16113349},
pages = {158--172},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Cmoputer Science},
title = {{Coalgebraic epistemic update without change of model}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-73859-6{\_}11 http://link.springer.com/10.1007/978-3-540-73859-6{\_}11},
volume = {4624},
year = {2007}
}
@article{Urabe2017,
abstract = {We introduce notions of simulation between semiring-weighted automata as models of quantitative systems. Our simulations are instances of the categorical/coalgebraic notions previously studied by Hasuo—hence soundness against language inclusion comes for free—but are concretely presented as matrices that are subject to linear inequality constraints. Pervasiveness of these formalisms allows us to exploit existing algorithms in: searching for a simulation, and hence verifying quantitative correctness that is formulated as language inclusion. Transformations of automata that aid search for simulations are introduced, too. This verification workflow is implemented for the plus-times and max-plus semirings. Furthermore, an extension to weighted tree automata is presented and implemented.},
author = {Urabe, Natsuki and Hasuo, Ichiro},
doi = {10.1016/j.ic.2016.03.007},
file = {:Users/liang-tingchen/Dropbox/References/Urabe, Hasuo - 2017 - Quantitative simulations by matrices.pdf:pdf},
issn = {10902651},
journal = {Information and Computation},
keywords = {Kleisli category,Language inclusion,Simulation,Tropical semiring,Weighted automaton},
month = {feb},
number = {Concur 2014},
pages = {110--137},
publisher = {Elsevier Inc.},
title = {{Quantitative simulations by matrices}},
url = {http://dx.doi.org/10.1016/j.ic.2016.03.007 http://linkinghub.elsevier.com/retrieve/pii/S0890540116000444},
volume = {252},
year = {2017}
}
@article{Pouillard2012,
author = {POUILLARD, NICOLAS and POTTIER, FRAN{\c{C}}OIS},
doi = {10.1017/S0956796812000251},
file = {:Users/liang-tingchen/Dropbox/References/POUILLARD, POTTIER - 2012 - A unified treatment of syntax with binders.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {4-5},
pages = {614--704},
title = {{A unified treatment of syntax with binders}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796812000251},
volume = {22},
year = {2012}
}
@incollection{Hancock2013,
abstract = {There are several different approaches to the theory of data types. At the simplest level, polynomials and containers give a theory of data types as free standing entities. At a second level of complexity, dependent polynomials and indexed containers handle more sophisticated data types in which the data have an associated indices which can be used to store important computational information. The crucial and salient feature of dependent polynomials and indexed containers is that the index types are defined in advance of the data. At the most sophisticated level, induction-recursion allows us to define data and indices simultaneously. This work investigates the relationship between the theory of small inductive recursive definitions and the theory of dependent polynomials and indexed containers. Our central result is that the expressiveness of small inductive recursive defthe initions is exactly the same as that of dependent polynomials and indexed containers. A second contribution of this paper is the definition of morphisms of small inductive recursive definitions. This allows us to extend our main result to an equivalence between the category of small inductive recursive definitions and the category of dependent polynomials/indexed containers. We comment on both the theoretical and practical ramifications of this result. {\textcopyright} 2013 Springer-Verlag.},
author = {Hancock, Peter and McBride, Conor and Ghani, Neil and Malatesta, Lorenzo and Altenkirch, Thorsten},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2013},
doi = {10.1007/978-3-642-38946-7_13},
editor = {Hasegawa, Masahito},
file = {:Users/liang-tingchen/Dropbox/References/Hancock et al. - 2013 - Small Induction Recursion.pdf:pdf},
isbn = {9783642389450},
issn = {03029743},
pages = {156--172},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Small Induction Recursion}},
url = {http://link.springer.com/10.1007/978-3-642-38946-7{\_}13},
volume = {7941},
year = {2013}
}
@techreport{Gratzer2020a,
author = {Gratzer, Daniel and Kavvos, G. Alex and Nuyts, Andreas and Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Gratzer et al. - 2020 - Type Theory {\`{a}} la Mode Dependent Type Theory with Multiple Modes and Modalities.pdf:pdf},
title = {{Type Theory {\`{a}} la Mode: Dependent Type Theory with Multiple Modes and Modalities}},
url = {https://www.google.com/url?sa=t{\&}rct=j{\&}q={\&}esrc=s{\&}source=web{\&}cd={\&}cad=rja{\&}uact=8{\&}ved=2ahUKEwjQ9sSn1dvsAhUGxYsBHc8wC2IQFjAAegQIBRAC{\&}url=https{\%}3A{\%}2F{\%}2Fjozefg.github.io{\%}2Fpapers{\%}2Ftype-theory-a-la-mode.pdf{\&}usg=AOvVaw2HMTJwDBgwdnVTRKkt17IK},
year = {2020}
}
@article{Kroupa2012,
abstract = {We generalise belief functions to many-valued events which are represented by elements of Lindenbaum algebra of infinite-valued {\L}ukasiewicz propositional logic. Our approach is based on mass assignments used in the Dempster-Shafer theory of evidence. A generalised belief function is totally monotone and it has Choquet integral representation with respect to a unique belief measure on Boolean events. {\textcopyright} 2012 Springer-Verlag.},
author = {Kroupa, Tom{\'{a}}{\v{s}}},
doi = {10.1007/s00500-012-0836-2},
file = {:Users/liang-tingchen/Dropbox/References/Kroupa - 2012 - Extension of belief functions to infinite-valued events.pdf:pdf},
issn = {1432-7643},
journal = {Soft Computing},
keywords = {Belief function,Choquet integral,MV-algebra,M{\"{o}}bius transform,{\L}ukasiewicz logic},
month = {nov},
number = {11},
pages = {1851--1861},
title = {{Extension of belief functions to infinite-valued events}},
url = {http://link.springer.com/10.1007/s00500-012-0836-2},
volume = {16},
year = {2012}
}
@book{Lambek1966,
author = {Lambek, Joachim},
doi = {10.1007/BFb0077265},
file = {:Users/liang-tingchen/Dropbox/References/Lambek - 1966 - Completions of Categories.pdf:pdf},
isbn = {978-3-540-03607-4},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Completions of Categories}},
url = {http://link.springer.com/10.1007/BFb0077265},
volume = {24},
year = {1966}
}
@article{Huet1997,
abstract = {Almost every programmer has faced the problem of representing a tree together with a subtree that is the focus of attention, where that focus may move left, right, up or down the tree. The Zipper is Huet's nifty name for a nifty data structure which fulfills this need. I wish I had known of it when I faced this task, because the solution I came up with was not quite so efficient or elegant as the Zipper.},
author = {HUET, G{\'{E}}RARD},
doi = {10.1017/S0956796897002864},
file = {:Users/liang-tingchen/Dropbox/References/HUET - 1997 - The Zipper.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {sep},
number = {5},
pages = {S0956796897002864},
title = {{The Zipper}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796897002864},
volume = {7},
year = {1997}
}
@incollection{Mu2002,
author = {Mu, Shin-cheng and Bird, Richard},
booktitle = {Mathematics of Program Construction. MPC 2002},
doi = {10.1007/3-540-45442-X_13},
editor = {Boiten, Eerke A. and M{\"{o}}ller, Bernhard},
file = {:Users/liang-tingchen/Dropbox/References/Mu, Bird - 2002 - Inverting Functions as Folds.pdf:pdf},
pages = {209--232},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Inverting Functions as Folds}},
url = {http://link.springer.com/10.1007/3-540-45442-X{\_}13},
volume = {2386},
year = {2002}
}
@article{Capretta2011,
author = {Capretta, Venanzio},
doi = {10.1016/j.tcs.2011.04.024},
file = {:Users/liang-tingchen/Dropbox/References/Capretta - 2011 - Coalgebras in functional programming and type theory.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {sep},
number = {38},
pages = {5006--5024},
publisher = {Elsevier B.V.},
title = {{Coalgebras in functional programming and type theory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397511003227},
volume = {412},
year = {2011}
}
@article{Power1995,
author = {Power, A. John},
doi = {10.1006/inco.1995.1112},
file = {:Users/liang-tingchen/Dropbox/References/Power - 1995 - Why Tricategories.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {aug},
number = {2},
pages = {251--262},
title = {{Why Tricategories?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540185711121},
volume = {120},
year = {1995}
}
@inproceedings{Kifer2011,
abstract = {Differential privacy is a powerful tool for providing privacy-preserving noisy query answers over statistical databases. It guarantees that the distribution of noisy query answers changes very little with the addition or deletion of any tuple. It is frequently accompanied by popularized claims that it provides privacy without any assumptions about the data and that it protects against attackers who know all but one record. In this paper we critically analyze the privacy protections offered by differential privacy. First, we use a no-free-lunch theorem, which defines non-privacy as a game, to argue that it is not possible to provide privacy and utility without making assumptions about how the data are generated. Then we explain where assumptions are needed. We argue that privacy of an individual is preserved when it is possible to limit the inference of an attacker about the participation of the individual in the data generating process. This is different from limiting the inference about the presence of a tuple (for example, Bob's participation in a social network may cause edges to form between pairs of his friends, so that it affects more than just the tuple labeled as "Bob"). The definition of evidence of participation, in turn, depends on how the data are generated -- this is how assumptions enter the picture. We explain these ideas using examples from social network research as well as tabular data for which deterministic statistics have been previously released. In both cases the notion of participation varies, the use of differential privacy can lead to privacy breaches, and differential privacy does not always adequately limit inference about participation.},
address = {New York, New York, USA},
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
booktitle = {Proceedings of the 2011 international conference on Management of data - SIGMOD '11},
doi = {10.1145/1989323.1989345},
file = {:Users/liang-tingchen/Dropbox/References/Kifer, Machanavajjhala - 2011 - No free lunch in data privacy.pdf:pdf},
isbn = {9781450306614},
issn = {07308078},
month = {apr},
pages = {193},
pmid = {18450441},
publisher = {ACM Press},
title = {{No free lunch in data privacy}},
url = {http://portal.acm.org/citation.cfm?doid=1989323.1989345 http://ieeexplore.ieee.org/document/4497436/},
year = {2011}
}
@incollection{Coquand1991,
author = {Coquand, Thierry},
booktitle = {Logical Frameworks},
doi = {10.1017/CBO9780511569807.011},
month = {sep},
pages = {255--279},
publisher = {Cambridge University Press},
title = {{An algorithm for testing conversion in type theory}},
url = {https://www.cambridge.org/core/product/identifier/CBO9780511569807A020/type/book{\_}part},
year = {1991}
}
@book{Girard1989a,
author = {Girard, Jean-Yves and Taylor, Paul and Lafont, Yves},
file = {:Users/liang-tingchen/Dropbox/References/Girard, Taylor, Lafont - 1989 - Proofs and Types.pdf:pdf},
isbn = {0 521 37181 3},
issn = {00224812},
month = {jun},
number = {2},
pages = {192},
publisher = {Cambridge University Press},
series = {Cambridge Tracts in Theoretical Computer Science},
title = {{Proofs and Types}},
volume = {56},
year = {1989}
}
@techreport{Milner1972,
address = {Stanford, CA, USA},
author = {Milner, Robin},
file = {:Users/liang-tingchen/Dropbox/References/Milner - 1972 - Logic for Computable Functions Description of a Machine Implementation.pdf:pdf},
publisher = {Stanford University},
title = {{Logic for Computable Functions: Description of a Machine Implementation.}},
year = {1972}
}
@book{Kock2006,
author = {Kock, Anders},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 2006 - Synthetic Differential Geometry.pdf:pdf},
isbn = {9780521687386},
month = {jul},
number = {March},
pages = {246},
publisher = {Cambridge University Press},
series = {London Mathematical Society Lecture Note Series},
title = {{Synthetic Differential Geometry}},
url = {http://www.cambridge.org/us/academic/subjects/mathematics/geometry-and-topology/synthetic-differential-geometry-2nd-edition},
year = {2006}
}
@incollection{Denux2010,
author = {Den{\oe}ux, Thierry and Masson, Marie-H{\'{e}}l{\`{e}}ne},
booktitle = {Integrated Uncertainty Management and Applications},
doi = {10.1007/978-3-642-11960-6_5},
editor = {Huynh, Van-Nam and Nakamori, Yoshiteru and Lawry, Jonathan and Inuiguchi, Masahiro},
file = {:Users/liang-tingchen/Dropbox/References/Den{\oe}ux, Masson - 2010 - Dempster-Shafer Reasoning in Large Partially Ordered Sets Applications in Machine Learning.pdf:pdf},
isbn = {978-3-642-11959-0},
pages = {39--54},
publisher = {Springer Berlin Heidelberg},
series = {Advances in Intelligent and Soft Computing},
title = {{Dempster-Shafer Reasoning in Large Partially Ordered Sets: Applications in Machine Learning}},
url = {http://link.springer.com/10.1007/978-3-642-11960-6{\_}5},
volume = {68},
year = {2010}
}
@inproceedings{Santocanale2010,
author = {Santocanale, Luigi and Venema, Yde},
booktitle = {Advances in Modal Logic},
editor = {And, Lev D. Beklemishev and Goranko, Valentin and Shehtman, Valentin},
file = {:Users/liang-tingchen/Dropbox/References/Santocanale, Venema - 2010 - Uniform Interpolation for Monotone Modal Logic.pdf:pdf},
isbn = {978-1-84890-013-4},
keywords = {coalgebra,monotone modal logic,neighborhood semantics,uniform interpolation},
pages = {350--370},
publisher = {College Publications},
title = {{Uniform Interpolation for Monotone Modal Logic}},
year = {2010}
}
@article{Hutton1999,
abstract = {In functional programming, fold is a standard operator that encapsulates a simple pattern of recursion for processing lists. This article is a tutorial on two key aspects of the fold operator for lists. First of all, we emphasize the use of the universal property of fold both as a proof principle that avoids the need for inductive proofs, and as a definition principle that guides the transformation of recursive functions into definitions using fold. Secondly, we show that even though the pattern of recursion encapsulated by fold is simple, in a language with tuples and functions as first-class values the fold operator has greater expressive power than might first be expected.},
author = {Hutton, Graham},
doi = {10.1017/S0956796899003500},
file = {:Users/liang-tingchen/Dropbox/References/Hutton - 1999 - A tutorial on the universality and expressiveness of fold(2).pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = {jul},
number = {4},
pages = {355--372},
title = {{A tutorial on the universality and expressiveness of fold}},
url = {http://www.cs.nott.ac.uk/{~}gmh/fold.pdf{\%}5Cnhttp://journals.cambridge.org/abstract{\_}S0956796899003500 http://www.journals.cambridge.org/abstract{\_}S0956796899003500},
volume = {9},
year = {1999}
}
@article{Abramsky2000,
abstract = {We develop a notion of realizability for Classical Linear Logic based on a concurrent process calculus.},
archivePrefix = {arXiv},
arxivId = {1512.06233},
author = {Abramsky, Samson},
doi = {10.1016/S1571-0661(04)00099-4},
eprint = {1512.06233},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2015 - Process Realizability.pdf:pdf},
isbn = {9788586426247},
issn = {15710661},
journal = {Foundations of Secure Computation: Proceedings of the 1999 Marktoberdorf Summer School},
month = {dec},
pages = {1--14},
title = {{Process Realizability}},
url = {http://arxiv.org/abs/1512.06233},
year = {2015}
}
@incollection{Dwork2008,
abstract = {Over the past five years a new approach to privacy-preserving data analysis has born fruit 13, 18, 7, 19, 5, 37, 35, 8, 32. This approach differs from much (but not all!) of the related literature in the statistics, databases, theory, and cryptography communities, in that a formal and ad omnia privacy guarantee is defined, and the data analysis techniques presented are rigorously proved to satisfy the guarantee. The key privacy guarantee that has emerged is differential privacy. Roughly speaking, this ensures that (almost, and quantifiably) no risk is incurred by joining a statistical database. In this survey, we recall the definition of differential privacy and two basic techniques for achieving it. We then show some interesting applications of these techniques, presenting algorithms for three specific tasks and three general results on differentially private learning.},
address = {Berlin, Heidelberg},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/9912410v1},
author = {Dwork, Cynthia},
booktitle = {Theory and Applications of Models of Computation},
doi = {10.1007/978-3-540-79228-4_1},
eprint = {9912410v1},
file = {:Users/liang-tingchen/Dropbox/References/Dwork - 2008 - Differential Privacy A Survey of Results.pdf:pdf},
isbn = {9783540792277},
issn = {03029743},
pages = {1--19},
primaryClass = {arXiv:cond-mat},
publisher = {Springer Berlin Heidelberg},
title = {{Differential Privacy: A Survey of Results}},
url = {http://www.springerlink.com/index/u963k75981004046.pdf{\%}5Cnhttp://link.springer.com/content/pdf/10.1007/978-3-642-38236-9.pdf http://link.springer.com/10.1007/978-3-540-79228-4{\_}1},
volume = {4978},
year = {2008}
}
@inproceedings{Pientka2008,
abstract = {Higher-order abstract syntax (HOAS) is a simple, powerful technique for implementing object languages, since it directly supports common and tricky routines dealing with variables, such as capture-avoiding substitution and renaming. This is achieved by representing binders in the object-language via binders in the meta-language. However, enriching functional programming languages with direct support for HOAS has been a major challenge, because recursion over HOAS encodings requires one to traverse lambda-abstractions and necessitates programming with open objects. We present a novel type-theoretic foundation based on contextual modal types which allows us to recursively analyze open terms via higher-order pattern matching. By design, variables occurring in open terms can never escape their scope. Using several examples, we demonstrate that our framework provides a name-safe foundation to operations typically found in nominal systems. In contrast to nominal systems however, we also support capture-avoiding substitution operations and even provide first-class substitutions to the programmer. The main contribution of this paper is a syntax-directed bi-directional type system where we distinguish between the data language and the computation language together with the progress and preservation proof for our language. {\textcopyright} 2008 ACM.},
address = {New York, New York, USA},
author = {Pientka, Brigitte},
booktitle = {Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '08},
doi = {10.1145/1328438.1328483},
file = {:Users/liang-tingchen/Dropbox/References/Pientka - 2008 - A type-theoretic foundation for programming with higher-order abstract syntax and first-class substitutions.pdf:pdf},
isbn = {9781595936899},
issn = {07308566},
keywords = {logical frameworks,type system},
pages = {371},
publisher = {ACM Press},
title = {{A type-theoretic foundation for programming with higher-order abstract syntax and first-class substitutions}},
url = {http://portal.acm.org/citation.cfm?doid=1328438.1328483},
year = {2008}
}
@inproceedings{Simpson2000,
author = {Simpson, A. and Plotkin, G.},
booktitle = {Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2000.855753},
file = {:Users/liang-tingchen/Dropbox/References/Simpson, Plotkin - 2000 - Complete axioms for categorical fixed-point operators.pdf:pdf},
isbn = {0-7695-0725-5},
issn = {1043-6871},
pages = {30--41},
publisher = {IEEE},
title = {{Complete axioms for categorical fixed-point operators}},
url = {http://ieeexplore.ieee.org/document/855753/},
year = {2000}
}
@article{Diehl2018,
abstract = {Dependently typed languages are well known for having a problem with code reuse. Traditional non-indexed algebraic datatypes (e.g. lists) appear alongside a plethora of indexed variations (e.g. vectors). Functions are often rewritten for both non-indexed and indexed versions of essentially the same datatype, which is a source of code duplication. We work in a Curry-style dependent type theory, where the same untyped term may be classified as both the non-indexed and indexed versions of a datatype. Many solutions have been proposed for the problem of dependently typed reuse, but we exploit Curry-style type theory in our solution to not only reuse data and programs, but do so at zero-cost (without a runtime penalty). Our work is an exercise in dependently typed generic programming, and internalizes the process of zero-cost reuse as the identity function in a Curry-style theory.},
author = {Diehl, Larry and Firsov, Denis and Stump, Aaron},
doi = {10.1145/3236799},
file = {:Users/liang-tingchen/Dropbox/References/Diehl, Firsov, Stump - 2018 - Generic zero-cost reuse for dependent types.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {dependent types,generic programming,reuse},
month = {jan},
number = {ICFP},
pages = {1--30},
title = {{Generic zero-cost reuse for dependent types}},
url = {http://dl.acm.org/citation.cfm?doid=3243631.3236799},
volume = {2},
year = {2018}
}
@article{Tarizadeh2013,
author = {Tarizadeh, Abolfazl},
doi = {10.4995/agt.2013.1575},
file = {:Users/liang-tingchen/Dropbox/References/Tarizadeh - 2013 - On the category of profinite spaces as a reflective subcategory.pdf:pdf},
issn = {1989-4147},
journal = {Applied General Topology},
keywords = {coarser topology,connected components,flective subcategory,profinite spaces,re-},
number = {2},
pages = {147--157},
title = {{On the category of profinite spaces as a reflective subcategory}},
url = {http://polipapers.upv.es/index.php/AGT/article/view/1575},
volume = {14},
year = {2013}
}
@inproceedings{wadler:LIPIcs:2015:5033,
abstract = {Contracts, gradual typing, and hybrid typing all permit less-precisely typed and more-precisely typed code to interact. Blame calculus encompasses these, and guarantees blame safety: blame for type errors always lays with less-precisely typed code. This paper serves as a complement to the literature on blame calculus: it elaborates on motivation, comments on the reception of the work, critiques some work for not properly attending to blame, and looks forward to applicati.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (A Complement to Blame - Wadler, Philip)

Keywords: contracts, gradual typing, hybrid typing, blame calculus},
author = {Wadler, Philip},
booktitle = {1st Summit on Advances in Programming Languages (SNAPL 2015)},
doi = {10.4230/LIPIcs.SNAPL.2015.309},
editor = {Ball, Thomas and Bodik, Rastislav and Krishnamurthi, Shriram and Lerner, Benjamin S and Morrisett, Greg},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 2015 - A Complement to Blame.pdf:pdf},
isbn = {978-3-939897-80-4},
issn = {1868-8969},
keywords = {Blame calculus,Contracts,Gradual typing,Hybrid typing},
pages = {309--320},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{A Complement to Blame}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5033},
volume = {32},
year = {2015}
}
@article{Chiribella2018,
abstract = {Dividing the world into subsystems is an important component of the scientific method. The choice of subsystems, however, is not defined a priori. Typically, it is dictated by our experimental capabilities, and, in general, different agents may have different capabilities. Here we propose a construction that associates every agent with a subsystem, equipped with its set of states and its set of transformations. In quantum theory, this construction accommodates the traditional notion of subsystems as factors of a tensor product, as well as the notion of classical subsystems of quantum systems. We then restrict our attention to systems where all physical transformations act invertibly. For such systems, the future states are a faithful encoding of the past states, in agreement with a requirement known as the Conservation of Information. For systems satisfying the Conservation of Information, we propose a dynamical definition of pure states, and show that all the states of all subsystems admit a canonical purification. This result extends the purification principle to a broader setting, in which coherent superpositions can be interpreted as purifications of incoherent mixtures. As an example, we illustrate the general construction for subsystems associated with group representations.},
archivePrefix = {arXiv},
arxivId = {1804.01943},
author = {Chiribella, Giulio},
eprint = {1804.01943},
file = {:Users/liang-tingchen/Dropbox/References/Chiribella - 2018 - Agents, subsystems, and the conservation of information.pdf:pdf},
keywords = {1,2,agent,and in the,and operations is a,commuting subalgebras,conservation of information,fundamental ingredient of our,group representations,in depth in quantum,information theory,it has been investigated,modelling of,purification,subsystem,the composition of systems,the world},
month = {apr},
number = {1},
pages = {1--34},
title = {{Agents, subsystems, and the conservation of information}},
url = {http://arxiv.org/abs/1804.01943},
year = {2018}
}
@article{Petkovic2006,
abstract = {In this paper, we give correspondences between unary algebras, semigroups and congruences on free semigroups. We establish isomorphisms between the complete lattice of varieties of semigroups and the complete lattices of families of varieties of unary algebras, and families of filters of congruences on free semigroups. Similar correspondences between generalized varieties and pseudovarieties of semigroups and corresponding families of algebras and congruences are also established.},
author = {Petkovi{\'{c}}, Tatjana and {\'{C}}iri{\'{c}}, M. and Bogdanovi{\'{c}}, S.},
doi = {10.1142/S1005386706000447},
file = {:Users/liang-tingchen/Dropbox/References/Petkovi{\'{c}}, {\'{C}}iri{\'{c}}, Bogdanovi{\'{c}} - 2006 - On Correspondences Between Unary Algebras , Automata , Semigroups and Congruences.pdf:pdf},
journal = {Algebra Colloquium},
keywords = {automata,pseudovarieties,regular identities,unary algebras,varieties},
number = {3},
pages = {495--506},
title = {{On Correspondences Between Unary Algebras , Automata , Semigroups and Congruences}},
volume = {13},
year = {2006}
}
@article{Jacobs2006,
author = {Jacobs, Bart},
doi = {10.1016/j.ic.2005.03.006},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2006 - Distributive laws for the coinductive solution of recursive equations.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {4},
pages = {561--587},
title = {{Distributive laws for the coinductive solution of recursive equations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540106000034},
volume = {204},
year = {2006}
}
@incollection{Mulry1994a,
abstract = {Monads, comonads and categories of algebras have become increasingly important tools in formulating and interpreting concepts in programming language semantics. A natural question that arises is how various categories of algebras for different monads relate functorially. In this paper we investigate when functors between categories with monads or comonads can be lifted to their corresponding Kleisli categories. Determining when adjoint pairs of functors can be lifted or inherited is of particular interest. The results lead naturally to various applications in both extensional and intensional semantics, including work on partial maps and data types and the work of Brookes/Geva on computational comonads.},
author = {Mulry, Philip S.},
booktitle = {Mathematical Foundations of Programming Semantics},
doi = {10.1007/3-540-58027-1_15},
editor = {Brookes, Stephen and Main, Michael and Melton, Austin and Mislove, Michael and Schmidt, David},
file = {:Users/liang-tingchen/Dropbox/References/Mulry - 1994 - Lifting theorems for Kleisli categories.pdf:pdf},
isbn = {9783540580270},
issn = {16113349},
keywords = {category{\_}theory,functor{\_}lifting,kleisli{\_}category},
pages = {304--319},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Lifting theorems for Kleisli categories}},
url = {http://dx.doi.org/10.1007/3-540-58027-1{\_}15 http://link.springer.com/10.1007/3-540-58027-1{\_}15},
volume = {802},
year = {1994}
}
@article{Lin2014,
author = {Lin, Hanti},
doi = {10.1007/s11229-014-0398-1},
file = {:Users/liang-tingchen/Dropbox/References/Lin - 2014 - On the regress problem of deciding how to decide.pdf:pdf},
issn = {0039-7857},
journal = {Synthese},
keywords = {Adaptive rationality,Bayesian theory of rationality,Bounded rationality,Deciding how to decide,Deliberation costs,Externalism,Internalism,Rational choice},
month = {mar},
number = {4},
pages = {661--670},
title = {{On the regress problem of deciding how to decide}},
url = {http://link.springer.com/10.1007/s11229-014-0398-1},
volume = {191},
year = {2014}
}
@article{Dagand2017,
abstract = {Functional programmers from all horizons strive to use, and sometimes abuse, their favorite type system in order to capture the invariants of their programs. A widely used tool in that trade consists in defining finely indexed datatypes. Operationally, these types classify the programmer's data, following the ML tradition. Logically, these types enforce the program invariants in a novel manner. This new programming pattern, by which one programs over inductive definitions to account for some invariants, lead to the development of a theory of ornaments (McBride, 2011 Ornamental Algebras, Algebraic Ornaments . Unpublished). However, ornaments originate as a dependently-typed object and may thus appear rather daunting to a functional programmer of the non-dependent kind. This article aims at presenting ornaments from first-principles and, in particular, to declutter their presentation from syntactic considerations. To do so, we shall give a sufficiently abstract model of indexed datatypes by means of many-sorted signatures. In this process, we formalize our intuition that an indexed datatype is the combination of a data- structure and a data- logic . Over this abstraction of datatypes, we shall recast the definition of ornaments, effectively giving a model of ornaments. Benefiting both from the operational and abstract nature of many-sorted signatures, ornaments should appear applicable and, one hopes, of interest beyond the type-theoretic circles, case in point being languages with generalized abstract datatypes or refinement types.},
author = {Dagand, Pierre-{\'{E}}variste},
doi = {10.1017/S0956796816000356},
file = {:Users/liang-tingchen/Dropbox/References/Dagand - 2017 - The essence of ornaments.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {feb},
pages = {e9},
title = {{The essence of ornaments}},
url = {https://www.cambridge.org/core/product/identifier/S0956796816000356/type/journal{\_}article},
volume = {27},
year = {2017}
}
@techreport{Doberkat2012b,
abstract = {Parikh's game logic is a dynamic modal logic which models strategic two person games; it contains propositional dynamic logic (PDL) as a fragment. We propose a stochastic interpretation for the distributive variant of this logic based on stochastic Kripke models. The important operator which sets this logic apart from PDL is demonization, which receives due attention. The relationship of logical and behavioral equivalence of Kripke models is investigated.},
author = {Doberkat, Ernst-Erich},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat - 2012 - A Stochastic Interpretation of Parikh's Game Logic.pdf:pdf},
institution = {Software Technology and Department of Mathematics Technische Universit{\"{a}}t Dortmund},
month = {apr},
pages = {20},
title = {{A Stochastic Interpretation of Parikh's Game Logic}},
year = {2012}
}
@incollection{Clouston2005,
abstract = {Coalgebras provide effective models of data structures and state-transition systems. A virtual covariety is a class of coalgebras closed under coproducts, images of coalgebraic morphisms, and subcoalgebras defined by split equalisers. A covariety has the stronger property of closure under all subcoalgebras, and is behavioural if it is closed under domains of morphisms, or equivalently under images of bisimulations. There are many computationally interesting properties that define classes of these kinds. We identify conditions on the underlying category of a comonad  which ensure that there is an exact correspondence between (behavioural/virtual) covarieties of  -coalgebras and subcomonads of  defined by comonad morphisms to  with natural categorical properties. We also relate this analysis to notions of coequationally defined classes of coalgebras.},
author = {Clouston, Ranald and Goldblatt, Robert},
booktitle = {Theoretical Aspects of Computing – ICTAC 2005},
doi = {10.1007/11560647_19},
editor = {Hung, Dang Van and Wirsing, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Clouston, Goldblatt - 2005 - Covarieties of Coalgebras Comonads and Coequations.pdf:pdf},
isbn = {978-3-540-29107-7},
pages = {288--302},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Covarieties of Coalgebras : Comonads and Coequations}},
url = {http://link.springer.com/chapter/10.1007/11560647{\_}19},
year = {2005}
}
@article{Varacca2006,
author = {Varacca, Daniele and Winskel, Glynn},
doi = {10.1017/S0960129505005074},
file = {:Users/liang-tingchen/Dropbox/References/Varacca, Winskel - 2006 - Distributing probability over non-determinism.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {01},
pages = {87},
title = {{Distributing probability over non-determinism}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129505005074},
volume = {16},
year = {2006}
}
@inproceedings{Atkey2009a,
address = {New York, New York, USA},
author = {Atkey, Robert and Lindley, Sam and Yallop, Jeremy},
booktitle = {Proceedings of the 2nd ACM SIGPLAN symposium on Haskell - Haskell '09},
doi = {10.1145/1596638.1596644},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, Lindley, Yallop - 2009 - Unembedding domain-specific languages.pdf:pdf},
isbn = {9781605585086},
keywords = {domain-specific languages,higher-order abstract syn-,tax,type classes,unembedding},
pages = {37},
publisher = {ACM Press},
title = {{Unembedding domain-specific languages}},
url = {http://portal.acm.org/citation.cfm?doid=1596638.1596644},
year = {2009}
}
@article{Kifer2012,
abstract = {" Privacy " and " utility " are words that frequently appear in the lit-erature on statistical privacy. But what do these words really mean? In recent years, many problems with intuitive notions of privacy and utility have been un-covered. Thus more formal notions of privacy and utility, which are amenable to mathematical analysis, are needed. In this paper we present our initial work on an axiomatization of privacy and utility. We present two privacy axioms which describe how privacy is affected by both post-processing data and by randomly se-lecting a privacy mechanism. We present three axioms for utility measures which also describe how measured utility is affected by post-processing. Our analysis of these axioms yields new insights into the construction of privacy definitions and utility measures. In particular, we characterize the class of relaxations of differ-ential privacy that can be obtained by changing constraints on probabilities; we show that the resulting constraints must be formed from concave functions. We also present several classes of utility metrics satisfying our axioms and explicitly show that measures of utility borrowed from statistics can lead to utility paradoxes when applied to statistical privacy. Finally, we show that the outputs of differ-entially private algorithms are best interpreted in terms of graphs or likelihood functions rather than query answers or synthetic data.},
author = {Kifer, Daniel and Lin, Bing-Rong},
file = {:Users/liang-tingchen/Dropbox/References/Kifer, Lin - 2012 - An Axiomatic View of Statistical Privacy and Utility.pdf:pdf},
journal = {Journal of Privacy and Confidentiality},
number = {1},
pages = {5--49},
title = {{An Axiomatic View of Statistical Privacy and Utility}},
url = {http://repository.cmu.edu/jpc/vol4/iss1/2/},
volume = {4},
year = {2012}
}
@incollection{Priestley2002,
author = {Priestley, Hilary A.},
booktitle = {Algebraid and Coalgebraic Methods},
doi = {10.1007/3-540-47797-7_2},
editor = {Backhouse, Roland and Crole, Roy and Gibbons, Jeremy},
file = {:Users/liang-tingchen/Dropbox/References/Priestley - 2002 - Ordered Sets and Complete Lattices.pdf:pdf},
isbn = {978-3-540-43613-3},
pages = {21--78},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Ordered Sets and Complete Lattices}},
url = {http://link.springer.com/10.1007/3-540-47797-7{\_}2},
volume = {2297},
year = {2002}
}
@book{Bishop2003,
author = {Bishop, Matt},
isbn = {0-201-44099-7},
pages = {1136},
publisher = {Addison Wesley Professional},
title = {{Computer Security: Art and Science}},
year = {2003}
}
@incollection{Sozeau2014,
abstract = {Universes are used in Type Theory to ensure consistency by checking that definitions are well-stratified according to a certain hierarchy. In the case of the Coq proof assistant, based on the predicative Calculus of Inductive Constructions (pCIC), this hierachy is built from an impredicative sort Prop and an infinite number of predicative Type i universes. A cumulativity relation represents the inclusion order of universes in the core theory. Originally, universes were thought to be floating levels, and definitions to implicitely constrain these levels in a consistent manner. This works well for most theories, however the globality of levels and constraints precludes generic constructions on universes that could work at different levels. Universe polymorphism extends this setup by adding local bindings of universes and constraints, supporting generic definitions over universes, reusable at different levels. This provides the same kind of code reuse facilities as ML-style parametric polymorphism. However, the structure and hierarchy of universes is more complex than bare polymorphic type variables. In this paper, we introduce a conservative extension of pCIC supporting universe polymorphism and treating its whole hierarchy. This new design supports typical ambiguity and implicit polymorphic generalization at the same time, keeping it mostly transparent to the user. Benchmarking the implementation as an extension of the Coq proof assistant on real-world examples gives encouraging results. {\textcopyright} 2014 Springer International Publishing.},
author = {Sozeau, Matthieu and Tabareau, Nicolas},
booktitle = {Interactive Theorem Proving. ITP 2014},
doi = {10.1007/978-3-319-08970-6_32},
editor = {Klein, Gerwin and Gamboa, Ruben},
file = {:Users/liang-tingchen/Dropbox/References/Sozeau, Tabareau - 2014 - Universe Polymorphism in Coq.pdf:pdf},
isbn = {9783319089690},
issn = {16113349},
pages = {499--514},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Universe Polymorphism in Coq}},
url = {http://link.springer.com/10.1007/978-3-319-08970-6{\_}32},
volume = {8558},
year = {2014}
}
@article{Abramsky1991,
abstract = {Some basic topics in the theory of concurrency are studied from the point of view of denotational semantics, and particularly the “domain theory in logical form” developed by the author. A domain of synchronization trees is defined by means of a recursive domain equation involving the Plotkin powerdomain. The logical counterpart of this domain is described, and shown to be related to it by Stone duality. The relationship of this domain logic to the standard Hennessy-Milner logic for transition systems is studied; the domain logic can be seen as a rational reconstruction of Hennessy-Milner logic from the standpoint of a very general and systematic theory. Finally, a denotational semantics for SCCS based on the domain of synchronization trees is given, and proved fully abstract with respect to bisimulation.},
author = {Abramsky, Samson},
doi = {10.1006/inco.1991.9999},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 1991 - A domain equation for bisimulation.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {jun},
number = {2},
pages = {161--218},
title = {{A domain equation for bisimulation}},
url = {http://dx.doi.org/10.1006/inco.1991.9999},
volume = {92},
year = {1991}
}
@article{Levy2005,
abstract = {Call-by-push-value is a "semantic machine code", providing a set of simple primitives from which both the call-by-value and call-by-name paradigms are built. We present its operational semantics as a stack machine, suggesting a term judgement of stacks. We then see that CBPV, incorporating these stack terms, has a simple categorical semantics based on an adjunction between values and stacks. There are no coherence requirements. We describe this semantics incrementally. First, we introduce locally indexed categories and the opGrothendieck construction, and use these to give the basic structure for interpreting the three judgements: values, stacks and computations. Then we look at the universal property required to interpret each type constructor. We define a model to be a strong adjunction with countable coproducts, countable products and exponentials. We see a wide range of instances of this structure: we give examples for divergence, storage, erratic choice, continuations, possible worlds and games (with or without a bracketing condition), in each case resolving the strong monad from the literature into a strong adjunction. And we give ways of constructing models from other models. Finally, we see that call-by-value and call-by-name are interpreted within the Kleisli and co-Kleisli parts, respectively, of a call-by-push-value adjunction.},
author = {Levy, Paul Blain},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2005 - Adjunction models for call-by-push-value with stacks.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Adjunction,CK-machine,Call-by-name,Call-by-push-value,Call-by-value,Continuations,Denotational semantics,Game semantics,Indexed category,Monad,Possible worlds},
number = {5},
pages = {75--110},
title = {{Adjunction models for call-by-push-value with stacks}},
volume = {14},
year = {2005}
}
@book{Johnstone2002a,
author = {Johnstone, Peter T.},
isbn = {978-0-19-851598-2},
pages = {716},
publisher = {Oxford University Press},
title = {{Sketches of an Elephant: A Topos Theory Compendium}},
volume = {2},
year = {2002}
}
@incollection{Girard,
abstract = {this paper is the use of dialects, i.e. data which are defined up to isomorphism. The distinction between the two conjunctions can be explained by the possible ways of merging dialects : this is a new insight in the theory of parallel computation. Geometry of interaction also works for various -calculi, for instance for pure},
address = {Cambridge},
author = {Girard, Jean-Yves},
booktitle = {Advances in Linear Logic},
doi = {10.1017/CBO9780511629150.002},
editor = {Girard, Jean-Yves and Lafont, Yves and Regnier, Laurent},
file = {:Users/liang-tingchen/Dropbox/References/Girard - Unknown - Linear Logic its syntax and semantics.pdf:pdf},
isbn = {0-521-55961-8},
pages = {1--42},
publisher = {Cambridge University Press},
title = {{Linear Logic: its syntax and semantics}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511629150A008 https://www.cambridge.org/core/product/identifier/CBO9780511629150A008/type/book{\_}part}
}
@article{Coquand1996,
author = {Coquand, Thierry},
doi = {10.1016/0167-6423(95)00021-6},
file = {:Users/liang-tingchen/Dropbox/References/Coquand - 1996 - An algorithm for type-checking dependent types.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
month = {may},
number = {1-3},
pages = {167--177},
title = {{An algorithm for type-checking dependent types}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0167642395000216},
volume = {26},
year = {1996}
}
@article{Hawblitzel2017,
abstract = {Distributed systems are notorious for harboring subtle bugs. Verification can, in principle, eliminate these bugs, but it has historically been difficult to apply at full-program scale, much less distributed system scale. We describe a meth-odology for building practical and provably correct distrib-uted systems based on a unique blend of temporal logic of actions-style state-machine refinement and Hoare-logic verification. We demonstrate the methodology on a complex implementation of a Paxos-based replicated state machine library and a lease-based sharded key-value store. We prove that each obeys a concise safety specification as well as desir-able liveness requirements. Each implementation achieves performance competitive with a reference system. With our methodology and lessons learned, we aim to raise the stan-dard for distributed systems from " tested " to " correct. "},
author = {Hawblitzel, Chris and Howell, Jon and Kapritsos, Manos and Lorch, Jacob R and Parno, Bryan and Roberts, Michael L and Setty, Srinath and Zill, Brian},
doi = {10.1145/3068608},
file = {:Users/liang-tingchen/Dropbox/References/Hawblitzel et al. - 2017 - IronFleet.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {jun},
number = {7},
pages = {83--92},
title = {{IronFleet}},
url = {http://delivery.acm.org/10.1145/3070000/3068608/p83-hawblitzel.pdf?ip=128.32.46.237{\&}id=3068608{\&}acc=ACTIVE SERVICE{\&}key=CA367851C7E3CE77.3158474DDFAA3F10.4D4702B0C3E38B35.4D4702B0C3E38B35{\&}{\_}{\_}acm{\_}{\_}=1518834583{\_}49439a74ef085bda2dfa451614e4eb6b http://dl.acm.org},
volume = {60},
year = {2017}
}
@article{Paulson2015,
abstract = {An Isabelle/HOL formalisation of G{\"{o}}del's two incompleteness theorems is presented. The work follows {\'{S}}wierczkowski's detailed proof of the theorems using hereditarily finite (HF) set theory (Dissertationes Mathematicae 422, 1–58, 2003). Avoiding the usual arithmetical encodings of syntax eliminates the necessity to formalise elementary number theory within an embedded logical calculus. The Isabelle formalisation uses two separate treatments of variable binding: the nominal package (Logical Methods in Computer Science 8(2:14), 1–35, 2012) is shown to scale to a development of this complexity, while de Bruijn indices (Indagationes Mathematicae 34, 381–392, 1972) turn out to be ideal for coding syntax. Critical details of the Isabelle proof are described, in particular gaps and errors found in the literature.},
author = {Paulson, Lawrence C.},
doi = {10.1007/s10817-015-9322-8},
file = {:Users/liang-tingchen/Dropbox/References/Paulson - 2015 - A Mechanised Proof of G{\"{o}}del's Incompleteness Theorems Using Nominal Isabelle.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Formalisation of mathematics,G{\"{o}}del's incompleteness theorems,Isabelle/HOL,Nominal syntax},
month = {jun},
number = {1},
pages = {1--37},
title = {{A Mechanised Proof of G{\"{o}}del's Incompleteness Theorems Using Nominal Isabelle}},
url = {http://link.springer.com/10.1007/s10817-015-9322-8},
volume = {55},
year = {2015}
}
@incollection{Casley1989,
author = {Casley, Ross and Crew, Roger F. and Meseguer, Jos{\'{e}} and Pratt, Vaughan},
booktitle = {Category Theory and Computer Science},
doi = {10.1007/BFb0018343},
editor = {Pitt, David H. and Rydeheard, David E. and Dybjer, Peter and Pitts, Andrew M. and Poign{\'{e}}, Axel},
file = {:Users/liang-tingchen/Dropbox/References/Casley et al. - 1989 - Temporal structures.pdf:pdf},
isbn = {978-3-540-46740-3},
pages = {21--51},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Temporal structures}},
year = {1989}
}
@book{Pin2015,
author = {Pin, Jean-{\'{E}}ric},
file = {:Users/liang-tingchen/Dropbox/References/Pin - 2015 - Mathematical Foundations of Automata Theory.pdf:pdf},
title = {{Mathematical Foundations of Automata Theory}},
year = {2015}
}
@article{Soria-comas2013,
author = {Soria-comas, Jordi and Domingo-ferrer, Josep},
file = {:Users/liang-tingchen/Dropbox/References/Soria-comas, Domingo-ferrer - 2013 - Differential Privacy via {\$}t{\$}-Closeness in Data Publishing.pdf:pdf},
isbn = {9781467358392},
journal = {Privacy, Security and Trust (PST), 2013 Eleventh Annual International Conference on},
pages = {27--35},
title = {{Differential Privacy via {\$}t{\$}-Closeness in Data Publishing}},
year = {2013}
}
@article{Ahrens2019a,
author = {Ahrens, Benedikt and Hirschowitz, Andr{\'{e}} and Lafont, Ambroise and Maggesi, Marco},
doi = {10.1145/3371099},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2019 - Reduction monads and their signatures.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {dec},
number = {POPL},
pages = {1--29},
title = {{Reduction monads and their signatures}},
url = {http://dl.acm.org/citation.cfm?doid=3377388.3371099},
volume = {4},
year = {2019}
}
@inproceedings{Narayanan2008,
author = {Narayanan, Arvind and Shmatikov, Vitaly},
booktitle = {2008 IEEE Symposium on Security and Privacy},
doi = {10.1109/SP.2008.33},
file = {:Users/liang-tingchen/Dropbox/References/Narayanan, Shmatikov - 2008 - Robust De-anonymization of Large Sparse Datasets.pdf:pdf},
isbn = {978-0-7695-3168-7},
issn = {1081-6011},
month = {may},
pages = {111--125},
pmid = {20113465},
publisher = {IEEE},
title = {{Robust De-anonymization of Large Sparse Datasets}},
url = {http://ieeexplore.ieee.org/document/4531148/},
year = {2008}
}
@article{Abel2011b,
author = {Abel, Andreas and Coquand, Thierry and Pagano, Miguel},
doi = {10.2168/LMCS-7 (2:4) 2011},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Coquand, Pagano - 2011 - A Modular Type-checking algorithm for Type Theory with Singleton Types and Proof Irrelevance.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,fuzzy logics,g,modal logics,proof theory},
number = {2},
title = {{A Modular Type-checking algorithm for Type Theory with Singleton Types and Proof Irrelevance}},
volume = {7},
year = {2011}
}
@article{Mossakowski2006,
abstract = {We introduce CoCasl as a light-weight but expressive coalgebraic extension of the algebraic specification language Casl. CoCasl allows the nested combination of algebraic datatypes and coalgebraic process types. Moreover, it provides syntactic sugar for an observer-indexed modal logic that allows e.g. expressing fairness properties. This logic includes a generic definition of modal operators for observers with structured equational result types. We prove existence of final models for specifications in a format that allows the use of equationally specified initial datatypes as observations, as well as modal axioms. The use of CoCasl is illustrated by specifications of the process algebras CSP and CCS.},
author = {Mossakowski, Till and Schr{\"{o}}der, Lutz and Roggenbach, Markus and Reichel, Horst},
doi = {10.1016/j.jlap.2005.09.006},
file = {:Users/liang-tingchen/Dropbox/References/Mossakowski et al. - 2006 - Algebraic-coalgebraic specification in CoCasl.pdf:pdf},
issn = {15678326},
journal = {Journal of Logic and Algebraic Programming},
keywords = {Algebraic specification,CCS,CSP,Casl,Coalgebra,Process algebra},
number = {1-2},
pages = {146--197},
title = {{Algebraic-coalgebraic specification in CoCasl}},
volume = {67},
year = {2006}
}
@article{Gonthier2008,
abstract = {Francis Guthrie certainly did it, when he coined his innocent little coloring puzzle in 1852. He man- aged to embarrass successively his mathematician brother, his brother's professor, Augustus de Mor- gan, and all of de Morgan's visitors, who couldn't solve it; the Royal Society, who only realized ten years later that Alfred Kempe's 1879 solution was wrong; and the three following generations of mathematicians who couldn't fix it [19].},
author = {Gonthier, Georges},
file = {:Users/liang-tingchen/Dropbox/References/Gonthier - 2008 - Formal proof–the four-color theorem.pdf:pdf},
journal = {Notices of the AMS},
number = {11},
pages = {1382--1393},
title = {{Formal proof–the four-color theorem}},
volume = {55},
year = {2008}
}
@incollection{Abel2008,
abstract = {An algebraic presentation of Martin-L{\"{o}}f's intuitionistic type theory is given which is based on the notion of a category with families with extra structure. We then present a type-checking algorithm for the normal forms of this theory, and sketch how it gives rise to an initial category with families with extra structure. In this way we obtain a purely algebraic formulation of the correctness of the type-checking algorithm which provides the core of proof assistants for intuitionistic type theory. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
address = {Berlin, Heidelberg},
author = {Abel, Andreas and Coquand, Thierry and Dybjer, Peter},
booktitle = {Functional and Logic Programming. FLOPS 2008},
doi = {10.1007/978-3-540-78969-7_2},
editor = {Garrigue, Jacques and Hermenegildo, Manuel V.},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Coquand, Dybjer - 2008 - On the Algebraic Foundation of Proof Assistants for Intuitionistic Type Theory.pdf:pdf},
isbn = {3540789685},
issn = {03029743},
pages = {3--13},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On the Algebraic Foundation of Proof Assistants for Intuitionistic Type Theory}},
url = {http://link.springer.com/10.1007/978-3-540-78969-7{\_}2},
volume = {4989},
year = {2008}
}
@article{Danos1996,
abstract = {There are two quite different possibilities for implementing linear head reduction in $\lambda$-calculus. Two ways which we are going to explain briefly here in the introduction and in details in the body of the paper. The paper itself is concerned with showing an unexpectedly simple relation between these two ways, which we term reversible and irreversible, namely that the latter may be obtained as a natural optimization of the former. {\textcopyright} 1996 Elsevier B.V. All rights reserved.},
author = {Danos, Vincent and Regnier, Laurent},
doi = {10.1016/S1571-0661(05)80402-5},
file = {:Users/liang-tingchen/Dropbox/References/Danos, Regnier - 1996 - Reversible, Irreversible and Optimal $\lambda$-machines.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {abstract machines,geometry of interaction,reversible computations,$\lambda$-calculus},
number = {C},
pages = {40--60},
title = {{Reversible, Irreversible and Optimal $\lambda$-machines}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105804025},
volume = {3},
year = {1996}
}
@incollection{Bauer2012a,
abstract = {This paper proposes a new theory of quantitative specifications. It generalizes the notions of step-wise refinement and compositional design operations from the Boolean to an arbitrary quantitative setting. It is shown that this general approach permits to recast many existing problems which arise in system design.},
author = {Bauer, Sebastian S and Fahrenberg, Uli and Legay, Axel and Thrane, Claus},
booktitle = {7th International Computer Science - Theory and Applications},
doi = {10.1007/978-3-642-30642-6_3},
editor = {Hirsch, Edward and Karhum{\"{a}}ki, Juhani and Lepist{\"{o}}, Arto and Prilutskii, Michail},
file = {:Users/liang-tingchen/Dropbox/References/Bauer et al. - 2012 - General Quantitative Specification Theories with Modalities.pdf:pdf},
isbn = {978-3-642-30641-9},
pages = {18--30},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{General Quantitative Specification Theories with Modalities}},
url = {http://dx.doi.org/10.1007/978-3-642-30642-6{\_}3},
year = {2012}
}
@article{Dalenius1977,
author = {Dalenius, T.},
journal = {Statistik Tidskrift},
number = {429},
title = {{Towards a methodology for statistical disclosure control}},
volume = {15},
year = {1977}
}
@inproceedings{Kurz2007,
author = {Kurz, Alexander and Rosick{\'{y}}, Jiř{\'{i}}},
booktitle = {Proceedings of the 2nd International Conference on Algebra and Coalgebra in Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Rosick{\'{y}} - 2007 - The Goldblatt-Thomason theorem for coalgebras.pdf:pdf},
isbn = {978-3-540-73857-2},
month = {aug},
pages = {342--355},
title = {{The Goldblatt-Thomason theorem for coalgebras}},
url = {http://dl.acm.org/citation.cfm?id=1770730.1770755},
year = {2007}
}
@incollection{Benzmuller2018,
author = {Benzm{\"{u}}ller, Christoph and Parent, Xavier and van der Torre, Leendert},
booktitle = {Sailing Routes in the World of Computation. CiE 2018},
doi = {10.1007/978-3-319-94418-0_6},
editor = {Manea, Florin and Miller, Russell G. and Nowotka, Dirk},
file = {:Users/liang-tingchen/Dropbox/References/Benzm{\"{u}}ller, Parent, van der Torre - 2018 - A Deontic Logic Reasoning Infrastructure.pdf:pdf},
isbn = {978-3-319-94417-3},
pages = {60--69},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Deontic Logic Reasoning Infrastructure}},
url = {http://link.springer.com/10.1007/978-3-319-94418-0 http://link.springer.com/10.1007/978-3-319-94418-0{\_}6},
volume = {10936},
year = {2018}
}
@article{Palmgren2019,
abstract = {First-order logic with dependent sorts, such as Makkai's first-order logic with dependent sorts (FOLDS), or Aczel's and Belo's dependently typed (intuitionistic) first-order logic (DFOL), may be regarded as logic enriched dependent type theories. Categories with families (cwfs) is an established semantical structure for dependent type theories, such as Martin-L{\"{o}}f type theory. We introduce in this article a notion of hyperdoctrine over a cwf, and show how FOLDS and DFOL fit in this semantical framework. A soundness and completeness theorem is proved for DFOL. The semantics is functorial in the sense of Lawvere, and uses a dependent version of the Lindenbaum-Tarski algebra for a DFOL theory. Agreement with standard first-order semantics is established. Applications of DFOL to constructive mathematics and categorical foundations are given. A key feature is a local propositions-as-types principle.},
author = {Palmgren, Erik},
doi = {10.1016/j.apal.2019.102715},
file = {:Users/liang-tingchen/Dropbox/References/Palmgren - 2019 - Categories with families and first-order logic with dependent sorts.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Categorical logic,Dependent types,Intuitionistic first-order logic,Models of type theory},
month = {jul},
number = {1},
pages = {102715},
publisher = {Elsevier B.V.},
title = {{Categories with families and first-order logic with dependent sorts}},
url = {https://doi.org/10.1016/j.apal.2019.102715 https://linkinghub.elsevier.com/retrieve/pii/S0168007219300727},
volume = {1},
year = {2019}
}
@article{McBride2004,
abstract = {Pattern matching has proved an extremely powerful and durable notion in functional programming. This paper contributes a new programming notation for type theory which elaborates the notion in various ways. First, as is by now quite well-known in the type theory community, definition by pattern matching becomes a more discriminating tool in the presence of dependent types, since it refines the explanation of types as well as values. This becomes all the more true in the presence of the rich class of datatypes known as inductive families (Dybjer, 1991). Secondly, as proposed by Peyton Jones (1997) for Haskell, and independently rediscovered by us, subsidiary case analyses on the results of intermediate computations, which commonly take place on the right-hand side of definitions by pattern matching, should rather be handled on the left. In simply-typed languages, this subsumes the trivial case of Boolean guards; in our setting it becomes yet more powerful. Thirdly, elementary pattern matching decompositions have a well-defined interface given by a dependent type; they correspond to the statement of an induction principle for the datatype. More general, user-definable decompositions may be defined which also have types of the same general form. Elementary pattern matching may therefore be recast in abstract form, with a semantics given by translation. Such abstract decompositions of data generalize Wadler's (1987) notion of ‘view'. The programmer wishing to introduce a new view of a type {\$}\backslashmathit{\{}T{\}}{\$} , and exploit it directly in pattern matching, may do so via a standard programming idiom. The type theorist, looking through the Curry–Howard lens, may see this as proving a theorem , one which establishes the validity of a new induction principle for {\$}\backslashmathit{\{}T{\}}{\$} . We develop enough syntax and semantics to account for this high-level style of programming in dependent type theory. We close with the development of a typechecker for the simply-typed lambda calculus, which furnishes a view of raw terms as either being well-typed, or containing an error. The implementation of this view is ipso facto a proof that typechecking is decidable.},
author = {MCBRIDE, CONOR and MCKINNA, JAMES},
doi = {10.1017/S0956796803004829},
file = {:Users/liang-tingchen/Dropbox/References/MCBRIDE, MCKINNA - 2004 - The view from the left.pdf:pdf;:Users/liang-tingchen/Dropbox/References/MCBRIDE, MCKINNA - 2004 - The view from the left(2).pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
number = {1},
pages = {69--111},
title = {{The view from the left}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796803004829 https://www.cambridge.org/core/product/identifier/S0956796803004829/type/journal{\_}article},
volume = {14},
year = {2004}
}
@article{Petkovic2005a,
abstract = {Pin's variety theorem for positive varieties of string languages and varieties of finite ordered semigroups is proved for trees, i.e., a bijective correspondence between positive varieties of tree languages and varieties of finite ordered algebras is established. This, in turn, is extended to generalized varieties of finite ordered algebras, which corresponds to Steinby's generalized variety theorem. Also, families of tree languages and classes of ordered algebras that are definable by ordered (syntactic or translation) monoids are characterized. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Petkovi{\'{c}}, Tatjana and Salehi, Saeed},
doi = {10.1016/j.tcs.2005.07.026},
file = {:Users/liang-tingchen/Dropbox/References/Petkovi{\'{c}}, Salehi - 2005 - Positive varieties of tree languages.pdf:pdf},
isbn = {9521215763},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {ordered algebras,ordered monoids,tree automata,tree languages,variety theorem},
month = {nov},
number = {1-2},
pages = {1--35},
title = {{Positive varieties of tree languages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397505004627},
volume = {347},
year = {2005}
}
@article{Cardelli2001,
abstract = {We add an operation of group creation to the typed pi-calculus, where a group is a type for channels. Creation of fresh groups has the effect of statically preventing certain communications, and can block the accidental or malicious leakage of secrets. We adapt a notion of secrecy introduced by Abadi, and prove a preservation of secrecy property. When applied to the ambient calculus, the same notion of group creation can be used to create and preserve shared secrets among mobile agents. {\textcopyright} Elsevier Ltd.},
author = {Cardelli, Luca and Ghelli, Giorgio and Gordon, Andrew D.},
doi = {10.1016/j.ic.2004.08.003},
file = {:Users/liang-tingchen/Dropbox/References/Cardelli, Ghelli, Gordon - 2005 - Secrecy and group creation.pdf:pdf},
isbn = {3-540-67897-2},
issn = {08905401},
journal = {Information and Computation},
keywords = {-calculus,secrecy,security types},
month = {jan},
number = {2},
pages = {127--155},
title = {{Secrecy and group creation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540104001750},
volume = {196},
year = {2005}
}
@techreport{Abramsky2009,
abstract = {We revisit our earlier work on the representation of quantum systems as Chu spaces, and investigate the use of coalgebra as an alternative framework. On the one hand, coalgebras allow the dynamics of repeated measurement to be captured, and provide mathematical tools such as final coalgebras, bisimulation and coalgebraic logic. However, the standard coalgebraic framework does not accommodate contravariance, and is too rigid to allow physical symmetries to be represented. We introduce a fibrational structure on coalgebras in which contravariance is represented by indexing. We use this structure to give a universal semantics for quantum systems based on a final coalgebra construction. We characterize equality in this semantics as projective equivalence. We also define an analogous indexed structure for Chu spaces, and use this to obtain a novel categorical description of the category of Chu spaces. We use the indexed structures of Chu spaces and coalgebras over a common base to define a truncation functor from coalgebras to Chu spaces. This truncation functor is used to lift the full and faithful representation of the groupoid of physical symmetries on Hilbert spaces into Chu spaces, obtained in our previous work, to the coalgebraic semantics.},
author = {Abramsky, Samson},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2009 - Coalgebras, Chu spaces, and representations of physical Systems.pdf:pdf},
institution = {OUCL},
month = {oct},
number = {RR-09-11},
pages = {26},
title = {{Coalgebras, Chu spaces, and representations of physical Systems}},
year = {2009}
}
@article{Bavera2018,
abstract = {Justification Logic (JL) is a refinement of modal logic in which assertions of knowledge and belief are accompanied by justifications: the formula [s] A states that s is a 'reason' for knowing/believing A. We study the computational interpretation of JL via the Curry-Howard isomorphism in which the modality [s] A is interpreted as: s is a type derivation justifying the validity of A. The resulting lambda calculus is such that its terms are aware of the reduction sequence that gave rise to them. This serves as a basis for understanding systems, many of which belong to the security domain, in which computation is history-aware.},
author = {Bavera, Francisco and Bonelli, Eduardo},
doi = {10.1093/logcom/exv037},
file = {:Users/liang-tingchen/Dropbox/References/Bavera, Bonelli - 2018 - Justification logic and audited computation.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Curry-Howard,History-based computation,Justification Logic,Lambda Calculus,Modal Logic},
month = {jul},
number = {5},
pages = {909--934},
title = {{Justification logic and audited computation}},
url = {https://academic.oup.com/logcom/article/28/5/909/2917815},
volume = {28},
year = {2018}
}
@book{Milner1997,
abstract = {Standard ML is a general-purpose programming language designed for large projects. This book provides a formal definition of Standard ML for the benefit of all concerned with the language, including users and implementers. Because computer programs are increasingly required to withstand rigorous analysis, it is all the more important that the language in which they are written be defined with full rigor.The Definition of Standard ML is the essential point of reference for Standard ML. Since its publication in 1990, the implementation technology of the language has advanced enormously and the number of users has grown. The revised edition includes a number of new features, omits little-used features, and corrects mistakes of definition.},
author = {Milner, Robert and Tofte, Mads and Harper, Robert and MacQueen, David},
file = {:Users/liang-tingchen/Dropbox/References/Milner et al. - 1997 - The Definition of Standard ML (Revised).pdf:pdf},
isbn = {9780262631815},
pages = {128},
title = {{The Definition of Standard ML (Revised)}},
url = {http://www.amazon.com/Definition-Standard-ML-Revised/dp/0262631814},
year = {1997}
}
@article{Shamkanov2016a,
author = {Shamkanov, Daniyar S.},
doi = {10.1070/SM8667},
file = {:Users/liang-tingchen/Dropbox/References/Shamkanov - 2016 - A realization theorem for the {\{}G{\}}{\"{o}}del-{\{}L{\}}{\"{o}}b provability logic.pdf:pdf},
issn = {1064-5616},
journal = {Sbornik: Mathematics},
keywords = {justification logic,provability logic,realization theorem},
month = {sep},
number = {9},
pages = {1344--1360},
title = {{A realization theorem for the {\{}G{\}}{\"{o}}del-{\{}L{\}}{\"{o}}b provability logic}},
url = {http://stacks.iop.org/1064-5616/207/i=9/a=1344?key=crossref.ee68049cf4575c37629c583451f324ca},
volume = {207},
year = {2016}
}
@incollection{Chen2014,
author = {Chen, Liang-Ting and Jung, Achim},
booktitle = {Proceedings of the 30th Conference on the Mathematical Foundations of Programming Semantics ({\{}MFPS XXX{\}})},
doi = {10.1016/j.entcs.2014.10.007},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Jung - 2014 - On a categorical framework for coalgebraic modal logic.pdf:pdf},
issn = {15710661},
pages = {109--128},
publisher = {Elsevier},
series = {ENTCS},
title = {{On a categorical framework for coalgebraic modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066114000747},
volume = {308},
year = {2014}
}
@article{Wang2017,
author = {Wang, Victoria and Tucker, John V},
doi = {10.1093/cybsec/tyx010},
file = {:Users/liang-tingchen/Dropbox/References/Wang, Tucker - 2017 - Surveillance and identity conceptual framework and formal models.pdf:pdf},
issn = {2057-2085},
journal = {Journal of Cybersecurity},
keywords = {abstract data types,formal methods,identity,social sorting,surveillance},
month = {nov},
number = {3},
pages = {145--158},
title = {{Surveillance and identity: conceptual framework and formal models}},
url = {http://academic.oup.com/cybersecurity/advance-article/doi/10.1093/cybsec/tyx010/4748787 https://academic.oup.com/cybersecurity/article/3/3/145/4748787},
volume = {3},
year = {2017}
}
@article{Constable2009,
abstract = {We prove constructively that for any propositional formula $\phi${\{}symbol{\}} in Conjunctive Normal Form, we can either find a satisfying assignment of true and false to its variables, or a refutation of $\phi${\{}symbol{\}} showing that it is unsatisfiable. This refutation is a resolution proof of ¬ $\phi${\{}symbol{\}}. From the formalization of our proof in Coq, we extract Robinson's famous resolution algorithm as a Haskell program correct by construction. The account is an example of the genre of highly readable formalized mathematics. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Constable, Robert and Moczyd{\l}owski, Wojciech},
doi = {10.1016/j.apal.2009.07.008},
file = {:Users/liang-tingchen/Dropbox/References/Constable, Moczyd{\l}owski - 2009 - Extracting the resolution algorithm from a completeness proof for the propositional calculus.pdf:pdf},
isbn = {978-3-540-72732-3},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Automated reasoning,Intuitionism,Program extraction,Resolution,Type theory},
month = {dec},
number = {3},
pages = {337--348},
publisher = {Elsevier B.V.},
title = {{Extracting the resolution algorithm from a completeness proof for the propositional calculus}},
url = {http://dx.doi.org/10.1016/j.apal.2009.07.008 http://linkinghub.elsevier.com/retrieve/pii/S0168007209001456},
volume = {161},
year = {2009}
}
@incollection{Kohlas2000,
address = {Dordrecht},
author = {Kohlas, J{\"{u}}rg and Shenoy, Prakash P},
booktitle = {Handbook of Defeasible Reasoning and Uncertainty Management Systems},
doi = {10.1007/978-94-017-1737-3_2},
file = {:Users/liang-tingchen/Dropbox/References/Kohlas, Shenoy - 2000 - Computation in Valuation Algebras.pdf:pdf},
number = {2100},
pages = {5--39},
publisher = {Springer Netherlands},
title = {{Computation in Valuation Algebras}},
url = {http://link.springer.com/10.1007/978-94-017-1737-3{\_}2},
volume = {5},
year = {2000}
}
@article{Kurz2012,
abstract = {Coalgebras for a functor model different types of transition systems in a uniform way. This paper focuses on a uniform account of finitary logics for set-based coalgebras. In particular, a general construction of a logic from an arbitrary set-functor is given and proven to be strongly complete under additional assumptions. We proceed in three parts. Part I argues that sifted colimit preserving functors are those functors that preserve universal algebraic structure. Our main theorem here states that a functor preserves sifted colimits if and only if it has a finitary presentation by operations and equations. Moreover, the presentation of the category of algebras for the functor is obtained compositionally from the presentations of the underlying category and of the functor. Part II investigates algebras for a functor over ind-completions and extends the theorem of J{\{}$\backslash$'o{\}}nsson and Tarski on canonical extensions of Boolean algebras with operators to this setting. Part III shows, based on Part I, how to associate a finitary logic to any finite-sets preserving functor T. Based on Part II we prove the logic to be strongly complete under a reasonable condition on T.},
archivePrefix = {arXiv},
arxivId = {1207.2732},
author = {Kurz, Alexander and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.2168/LMCS-8(3:14)2012},
eprint = {1207.2732},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Rosick{\'{y}} - 2012 - Strongly complete logics for coalgebras.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {algebraic theories,and phrases,coalgebras,modal logic,presen-,sifted colimits,stone duality},
month = {jul},
pages = {1--32},
title = {{Strongly complete logics for coalgebras}},
url = {http://arxiv.org/abs/1207.2732},
volume = {8},
year = {2012}
}
@article{Rosicky1981,
author = {Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/0022-4049(81)90105-5},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}} - 1981 - Concrete categories and infinitary languages.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {3},
pages = {309--339},
title = {{Concrete categories and infinitary languages}},
url = {http://dx.doi.org/10.1016/0022-4049(81)90105-5},
volume = {22},
year = {1981}
}
@inproceedings{Licata2013,
abstract = {Recent work on homotopy type theory exploits an exciting new correspondence between Martin-Lof's dependent type theory and the mathematical disciplines of category theory and homotopy theory. The category theory and homotopy theory suggest new principles to add to type theory, and type theory can be used in novel ways to formalize these areas of mathematics. In this paper, we formalize a basic result in algebraic topology, that the fundamental group of the circle is the integers. Though simple, this example is interesting for several reasons: it illustrates the new principles in homotopy type theory; it mixes ideas from traditional homotopy-theoretic proofs of the result with type-theoretic inductive reasoning; and it provides a context for understanding an existing puzzle in type theory---that a universe (type of types) is necessary to prove that the constructors of inductive types are disjoint and injective.},
author = {Licata, Daniel R. and Shulman, Michael},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.28},
file = {:Users/liang-tingchen/Dropbox/References/Licata, Shulman - 2013 - Calculating the Fundamental Group of the Circle in Homotopy Type Theory.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
month = {jun},
pages = {223--232},
publisher = {IEEE},
title = {{Calculating the Fundamental Group of the Circle in Homotopy Type Theory}},
url = {http://ieeexplore.ieee.org/document/6571554/},
volume = {1},
year = {2013}
}
@book{Kashiwara2006,
address = {Berlin/Heidelberg},
author = {Kashiwara, Masaki and Schapira, Pierre},
doi = {10.1007/3-540-27950-4},
file = {:Users/liang-tingchen/Dropbox/References/Kashiwara, Schapira - 2006 - Categories and Sheaves.pdf:pdf},
isbn = {3-540-27949-0},
pages = {497},
publisher = {Springer-Verlag},
series = {Grundlehren der mathematischen Wissenschaften},
title = {{Categories and Sheaves}},
url = {http://www.springerlink.com/index/10.1007/3-540-27950-4},
volume = {332},
year = {2006}
}
@article{Borst2017,
abstract = {Intrapreneurial employees and intrapreneurial projects are considered to be an important driver of innovation and strategic renewal within companies. While many studies addressed the top-down implementation of innovative projects, analyses of employee initiatives in promoting innovation within companies are scarce. This paper therefore takes a bottom-up approach and focuses on employee behaviour and how it can be stimulated towards intrapreneurship. We propose and test a two-step model where formal and informal work context affects employees' intrapreneurial behaviour, which then provides the basis for bottom-up initiated intrapreneurial projects. Our empirical data consist of questionnaire responses of 176 employees in six Dutch companies. The results of structural equation model estimations indicate that formal organisational factors (horizontal participation, resource availability) affect employees' intrapreneurial behaviour, but also highlight informal factors such as trust in the direct manager. We also find that innovativeness and personal initiative, but not risk taking, play a role for an effective translation of employees' behaviour into intrapreneurial projects.},
author = {Barendregt, Henk and Terwijn, Sebastiaan A.},
doi = {10.1016/j.apal.2019.04.013},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt, Terwijn - 2019 - Fixed point theorems for precomplete numberings(2).pdf:pdf},
isbn = {9789492896728},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {oct},
number = {10},
pages = {1151--1161},
title = {{Fixed point theorems for precomplete numberings}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S016800721930048X},
volume = {170},
year = {2019}
}
@inproceedings{Adamek2012c,
abstract = {For set functors preserving intersections, a new description of the final coalgebra and the initial algebra is presented: the former consists of all well-pointed coalgebras. These are the pointed coalgebras having no proper subobject and no proper quotient. And the initial algebra consists of all well-pointed coalgebras that are well-founded in the sense of Taylor [16]. Finally, the initial iterative algebra consists of all finite well-pointed coalgebras. Numerous examples are discussed e.g. automata, graphs, and labeled transition systems.},
annote = {From Duplicate 1 ( 




















Well-Pointed Coalgebras (Extended Abstract)




















- Ad{\'{a}}mek, Jiř{\'{i}}; Milius, Stefan; Moss, Lawrence; Sousa, Lurdes )















10.1007/978-3-642-28729-9{\_}6},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Moss, Lawrence S. and Sousa, Lurdes},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-642-28729-9_6},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2012 - Well-Pointed Coalgebras (Extended Abstract).pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {89--103},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Well-Pointed Coalgebras (Extended Abstract)}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}6},
volume = {7213},
year = {2012}
}
@article{Adamek2015a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Moss, Lawrence S. and Urbat, Henning},
doi = {10.1016/j.jcss.2014.12.002},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2015 - On finitary functors and their presentations.pdf:pdf},
journal = {Journal of Computer and System Sciences},
keywords = {Finitary functors,Hausdorff functor,presentation of functors},
number = {5},
pages = {813--833},
title = {{On finitary functors and their presentations}},
url = {http://www.sciencedirect.com/science/article/pii/S0022000014001640},
volume = {81},
year = {2015}
}
@inproceedings{Sunkle2015,
abstract = {Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance. {\&}copy; 2015 IEEE.},
author = {Sunkle, Sagar and Kholkar, Deepali and Kulkarni, Vinay},
booktitle = {2015 ACM/IEEE 18th International Conference on Model Driven Engineering Languages and Systems (MODELS)},
doi = {10.1109/MODELS.2015.7338275},
file = {:Users/liang-tingchen/Dropbox/References/Sunkle, Kholkar, Kulkarni - 2015 - Model-driven regulatory compliance A case study of ``Know Your Customer'' regulations.pdf:pdf},
isbn = {978-1-4673-6908-4},
keywords = {Adaptation models,Business,Industries,Law,Semantics,Vocabulary},
month = {sep},
pages = {436--445},
publisher = {IEEE},
title = {{Model-driven regulatory compliance: A case study of ``Know Your Customer'' regulations}},
url = {http://ieeexplore.ieee.org/document/7338275/},
year = {2015}
}
@article{Wadler2014,
abstract = {Continuing a line of work by Abramsky (1994), by Bellin and Scott (1994), and by Caires and Pfenning (2010), among others, this paper presents CP, a calculus in which propositions of classical linear logic correspond to session types. Continuing a line},
author = {Wadler, Philip},
doi = {10.1017/S095679681400001X},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 2014 - Propositions as sessions.pdf:pdf},
isbn = {9781450310543},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {may},
number = {2-3},
pages = {384--418},
title = {{Propositions as sessions}},
url = {http://www.journals.cambridge.org/abstract{\_}S095679681400001X},
volume = {24},
year = {2014}
}
@article{Wang2014a,
abstract = {In this paper a complete proper subclass of Hilbert-style S4 proofs, named non-circular, will be determined. This study originates from an investigation into the formal connection between S4, as Logic of Provability and Logic of Knowledge, and Artemov's innovative Logic of Proofs, LP, which later developed into Logic of Justification. The main result concerning the formal connection is the realization theorem, which states that S4 theorems are precisely the formulas which can be converted to LP theorems with proper justificational objects substituting for modal knowledge operators. We extend this result by showing that on the proof level, non-circular proofs are exactly the class of S4 proofs which can be realized to LP proofs. In turn, this study provides an alternative algorithm to achieve the realization theorem, and a novel logical system, called S4$\delta$, is introduced, which, under an adequate interpretation, is worth studying for its own sake. {\textcopyright} 2014 Elsevier B.V.},
author = {Wang, Ren-June},
doi = {10.1016/j.apal.2014.04.004},
file = {:Users/liang-tingchen/Dropbox/References/Wang - 2014 - Non-circular proofs and proof realization in modal logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Hilbert-style proofs,Justification logic,Modal logic,Realization theorem,Timed modal epistemic logic},
month = {jul},
number = {7-8},
pages = {1318--1338},
publisher = {Elsevier B.V.},
title = {{Non-circular proofs and proof realization in modal logic}},
url = {http://dx.doi.org/10.1016/j.apal.2014.04.004 https://linkinghub.elsevier.com/retrieve/pii/S0168007214000359},
volume = {165},
year = {2014}
}
@article{Weil2002,
author = {Weil, Pascal},
doi = {10.1142/S0218196702000912},
file = {:Users/liang-tingchen/Dropbox/References/Weil - 2002 - Profinite methods in semigroup theory.pdf:pdf},
issn = {0218-1967},
journal = {International Journal of Algebra and Computation},
month = {feb},
number = {01n02},
pages = {137--178},
title = {{Profinite methods in semigroup theory}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218196702000912},
volume = {12},
year = {2002}
}
@article{Ellerman2014,
abstract = {Classical logic is usually interpreted as the logic of propositions. But from Boole's original development up to modern categorical logic, there has always been the alternative interpretation of classical logic as the logic of subsets of any given (nonempty) universe set. Partitions on a universe set are dual to subsets of a universe set in the sense of the reverse-the-arrows category-theoretic duality--which is reflected in the duality between quotient objects and subobjects throughout algebra. Hence the idea arises of a dual logic of partitions. That dual logic is described here. Partition logic is at the same mathematical level as subset logic since models for both are constructed from (partitions on or subsets of) arbitrary unstructured sets with no ordering relations, compatibility or accessibility relations, or topologies on the sets.$\backslash$r$\backslash$nJust as Boole developed logical finite probability theory as a quantitative treatment of subset logic, applying the analogous mathematical steps to partition logic yields a logical notion of entropy so that information theory can be refounded on partition logic. But the biggest application is that when partition logic and the accompanying logical information theory are "lifted" to complex vector spaces, then the mathematical framework of quantum mechanics is obtained. Partition logic models indefiniteness (i.e., numerical attributes on a set become more definite as the inverse-image partition becomes more refined) while subset logic models the definiteness of classical physics (an entity either definitely has a property or definitely does not). Hence partition logic provides the backstory so the old idea of "objective indefiniteness" in QM can be fleshed out to a full interpretation of quantum mechanics.},
author = {Ellerman, David},
doi = {10.1093/jigpal/jzt036},
file = {:Users/liang-tingchen/Dropbox/References/Ellerman - 2014 - An introduction to partition logic.pdf:pdf},
issn = {1367-0751},
journal = {Logic Journal of IGPL},
keywords = {Logical entropy,Partition logic,Partition tautologies,Quantum mechanics,Subset logic,Subset-partition duality},
month = {feb},
number = {1},
pages = {94--125},
title = {{An introduction to partition logic}},
url = {https://academic.oup.com/jigpal/article-lookup/doi/10.1093/jigpal/jzt036},
volume = {22},
year = {2014}
}
@article{Silva2013,
abstract = {The powerset construction is a standard method for converting a nondeterministic automaton into a deterministic one recognizing the same language. In this paper, we lift the powerset construction from automata to the more general framework of coalgebras with structured state spaces. Coalgebra is an abstract framework for the uniform study of different kinds of dynamical systems. An endofunctor F determines both the type of systems (F-coalgebras) and a notion of behavioural equivalence ({\~{}}{\_}F) amongst them. Many types of transition systems and their equivalences can be captured by a functor F. For example, for deterministic automata the derived equivalence is language equivalence, while for non-deterministic automata it is ordinary bisimilarity. We give several examples of applications of our generalized determinization construction, including partial Mealy machines, (structured) Moore automata, Rabin probabilistic automata, and, somewhat surprisingly, even pushdown automata. To further witness the generality of the approach we show how to characterize coalgebraically several equivalences which have been object of interest in the concurrency community, such as failure or ready semantics.},
archivePrefix = {arXiv},
arxivId = {1302.1046},
author = {Silva, Alexandra and Bonchi, Filippo and Bonsangue, Marcello M. and Rutten, Jan J.M.M.},
doi = {10.2168/LMCS-9(1:9)2013},
eprint = {1302.1046},
file = {:Users/liang-tingchen/Dropbox/References/Silva et al. - 2013 - Generalizing determinization from automata to coalgebras.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,coalgebras,linear semantics,powerset construction},
month = {feb},
pages = {1--27},
title = {{Generalizing determinization from automata to coalgebras}},
url = {http://arxiv.org/abs/1302.1046},
volume = {9},
year = {2013}
}
@article{Visser1982,
abstract = {In this paper extensions of HA are studied that prove their own completeness, i.e. they prove A → □ A, where □ is interpreted as provability in the theory itself. Motivation is three-fold: (1) these theories are thought to have some intrinsic interest, (2) they are a tool for producing and studying provability principles, (3) they can be used to proved independence results. Work done in the paper connected with these motivations is respectively: 1. (i) A characterization is given of theories proving their own completeness, including an appropriate conservation result. 2. (ii) Some new provability principles are produced. The provability logic of HA is not a sublogic of the of PA. A provability logic plus completeness theorem is given for a certain intuitionistic extension of HA. De Jongh's theorem for propositional logic is a corollary. 3. (iii) FP-realizability in Beeson's proof that ∦HA KLS is replaced by theories proving their own completeness. New consequences are ∦HA+-MPR KLS, ∦HA+DNS KLS. {\textcopyright} 1982.},
author = {Visser, Albert},
doi = {10.1016/0003-4843(82)90024-9},
file = {:Users/liang-tingchen/Dropbox/References/Visser - 1982 - On the completenes principle A study of provability in heyting's arithmetic and extensions.pdf:pdf},
issn = {00034843},
journal = {Annals of Mathematical Logic},
month = {aug},
number = {3},
pages = {263--295},
title = {{On the completenes principle: A study of provability in heyting's arithmetic and extensions}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0003484382900249},
volume = {22},
year = {1982}
}
@article{Cantone2002,
abstract = {We present an efficient and practical algorithm for the internal sorting problem. Our algorithm works in-place and, on the average, has a running-time of O(n log n) in the size n of the input. More specifically, the algorithm performs n log n + 2.996n + o(n) comparisons and n log n + 2.645n + o(n) element moves on the average. An experimental comparison of our proposed algorithm with the most efficient variants of Quicksort and Heapsort is carried out and its results are discussed. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Cantone, D. and Cincotti, G.},
doi = {10.1016/S0304-3975(01)00288-2},
file = {:Users/liang-tingchen/Dropbox/References/Cantone, Cincotti - 2002 - QuickHeapsort, an efficient mix of classical sorting algorithms.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Analysis of algorithms,Heapsort,In-place sorting,Quicksort},
month = {aug},
number = {1},
pages = {25--42},
title = {{QuickHeapsort, an efficient mix of classical sorting algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397501002882},
volume = {285},
year = {2002}
}
@inproceedings{Forster2021,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Church's Thesis and Related Axioms in Coq's Type Theory - Forster, Yannick)

Keywords: Church's thesis, constructive type theory, constructive reverse mathematics, synthetic computability theory, Coq},
author = {Forster, Yannick},
booktitle = {29th EACSL Annual Conference on Computer Science Logic (CSL 2021)},
doi = {10.4230/LIPIcs.CSL.2021.21},
editor = {Baier, Christel and Goubault-Larrecq, Jean},
file = {:Users/liang-tingchen/Dropbox/References//Forster - 2021 - Church's Thesis and Related Axioms in Coq's Type Theory.pdf:pdf},
isbn = {978-3-95977-175-7},
issn = {1868-8969},
keywords = {2021,21,4230,and phrases church,churchs-thesis-coq,com,constructive reverse mathematics,constructive type theory,coq,csl,digital object identifier 10,github,lipics,s thesis,supplementary material https,synthetic computability theory,uds-psl},
number = {21},
pages = {21:1----21:19},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Church's Thesis and Related Axioms in Coq's Type Theory}},
url = {https://drops.dagstuhl.de/opus/volltexte/2021/13455},
volume = {183},
year = {2021}
}
@incollection{Gupta2007,
author = {Gupta, Gopal and Bansal, Ajay and Min, Richard and Simon, Luke and Mallya, Ajay},
booktitle = {Proceedings of the 23rd International Conference on Logic Programming},
doi = {10.1007/978-3-540-74610-2_4},
editor = {Dahl, V{\'{e}}ronica and Niemel{\"{a}}, Ilkka},
file = {:Users/liang-tingchen/Dropbox/References/Gupta et al. - 2007 - Coinductive Logic Programming and Its Applications.pdf:pdf},
issn = {0302-9743},
number = {ii},
pages = {27--44},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Coinductive Logic Programming and Its Applications}},
year = {2007}
}
@article{Schroder2015,
author = {Schr{\"{o}}der, Lutz and Pattinson, Dirk and Litak, Tadeusz},
doi = {10.1093/logcom/exv043},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Pattinson, Litak - 2015 - A Van BenthemRosen theorem for coalgebraic predicate logic.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {bisimulation invariance,coalgebra,correspondence theory,gaifman locality,modal logic},
month = {jul},
pages = {exv043},
title = {{A Van Benthem/Rosen theorem for coalgebraic predicate logic}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/exv043},
year = {2015}
}
@article{Li2014,
abstract = {Personal data has value to both its owner and to institutions who would like to analyze it. Privacy mechanisms protect the owner's data while releasing to analysts noisy versions of aggregate query results. But such strict protections of individual's data have not yet found wide use in practice. Instead, Internet companies, for example, commonly provide free services in return for valuable sensitive information from users, which they exploit and sometimes sell to third parties. As the awareness of the value of the personal data in- creases, so has the drive to compensate the end user for her private information. The idea of monetizing private data can improve over the narrower view of hiding private data, since it empowers individuals to control their data through financial means. In this paper we propose a theoretical framework for as- signing prices to noisy query answers, as a function of their accuracy, and for dividing the price amongst data owners who deserve compensation for their loss of privacy. Our framework adopts and extends key principles from both dif- ferential privacy and query pricing in data markets. We identify essential properties of the price function and micro- payments, and characterize valid solutions.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1208.5258v2},
author = {Li, Chao and Li, Daniel Yang and Miklau, Gerome and Suciu, Dan},
doi = {10.1145/3139457},
eprint = {arXiv:1208.5258v2},
file = {:Users/liang-tingchen/Dropbox/References/Li et al. - 2017 - A theory of pricing private data.pdf:pdf},
isbn = {9781450315982},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {arbitrage,data pricing,differential privacy},
month = {nov},
number = {12},
pages = {79--86},
publisher = {ACM Press},
title = {{A theory of pricing private data}},
url = {http://dl.acm.org/citation.cfm?id=2448502 http://dl.acm.org/citation.cfm?doid=2448496.2448502 http://dl.acm.org/citation.cfm?doid=3167461.3139457},
volume = {60},
year = {2017}
}
@incollection{Martini1996,
author = {Martini, Simone and Masini, Andrea},
booktitle = {Proof Theory of Modal Logic},
doi = {10.1007/978-94-017-2798-3_12},
editor = {Wansing, Heinrich},
file = {:Users/liang-tingchen/Dropbox/References/Martini, Masini - 1996 - A Computational Interpretation of Modal Proofs.pdf:pdf},
issn = {19585780},
pages = {213--241},
publisher = {Springer, Dordrecht},
series = {Applied Logic Series},
title = {{A Computational Interpretation of Modal Proofs}},
url = {http://link.springer.com/10.1007/978-94-017-2798-3{\_}12},
volume = {2},
year = {1996}
}
@article{Bonchi2014,
author = {Bonchi, Filippo and Bonsangue, Marcello M. and Hansen, Helle Hvid and Panangaden, Prakash and Rutten, Jan J.M.M. and Silva, Alexandra},
doi = {10.1145/2490818},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi et al. - 2014 - Algebra-coalgebra duality in brzozowski's minimization algorithm.pdf:pdf},
issn = {15293785},
journal = {ACM Transactions on Computational Logic},
month = {feb},
number = {1},
pages = {1--29},
title = {{Algebra-coalgebra duality in brzozowski's minimization algorithm}},
url = {http://dl.acm.org/citation.cfm?doid=2590829.2490818},
volume = {15},
year = {2014}
}
@incollection{Hinze2003,
abstract = {Generic Haskell is an extension of Haskell that supports the construction of generic programs. These lecture notes describe the basic constructs of Generic Haskell and highlight the underlying theory. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
author = {Hinze, Ralf and Jeuring, Johan},
booktitle = {Generic Programming---Advanced Lectures},
doi = {10.1007/978-3-540-45191-4_1},
editor = {Backhouse, Roland and Gibbons, Jeremy},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Jeuring - 2003 - Generic Haskell Practice and Theory.pdf:pdf},
issn = {16113349},
pages = {1--56},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generic Haskell: Practice and Theory}},
url = {http://link.springer.com/10.1007/978-3-540-45191-4{\_}1},
volume = {2793},
year = {2003}
}
@article{Pucella2005,
abstract = {Formalizing syntactic proofs of properties of logics, programming languages, security protocols, and other formal systems is a significant challenge, in large part because of the obligation to handle name-binding correctly. We present an approach called nominal abstract syntax that has attracted considerable interest since its introduction approximately six years ago. After an overview of other approaches, we describe nominal abstract syntax and nominal logic, a logic for reasoning about nominal abstract syntax. We also discuss applications of nominal techniques to programming, automated reasoning, and identify some future directions.},
archivePrefix = {arXiv},
arxivId = {cs/0511025},
author = {Cheney, James},
doi = {10.1145/1107523.1107537},
eprint = {0511025},
file = {:Users/liang-tingchen/Dropbox/References/Cheney - 2005 - Nominal Logic and Abstract Syntax.pdf:pdf},
issn = {01635700},
journal = {ACM SIGACT News},
month = {dec},
number = {4},
pages = {47},
primaryClass = {cs},
title = {{Nominal Logic and Abstract Syntax}},
url = {http://portal.acm.org/citation.cfm?doid=1107523.1107537},
volume = {36},
year = {2005}
}
@article{Cignoli2004,
abstract = {Stone duality between boolean algebras and inverse limits of finite sets is extended to a duality between locally finite MV-algebras and a category of multisets naturally arising as inverse limits of finite multisets.},
author = {Cignoli, Roberto and Dubuc, Eduardo J. and Mundici, Daniele},
doi = {10.1016/j.jpaa.2003.10.021},
file = {:Users/liang-tingchen/Dropbox/References/Cignoli, Dubuc, Mundici - 2004 - Extending Stone duality to multisets and locally finite MV-algebras.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {may},
number = {1-3},
pages = {37--59},
title = {{Extending Stone duality to multisets and locally finite MV-algebras}},
url = {http://dx.doi.org/10.1016/j.jpaa.2003.10.021},
volume = {189},
year = {2004}
}
@inproceedings{Pearl,
address = {New York, New York, USA},
author = {Kiselyov, Oleg and Shan, Chung-chieh and Friedman, Daniel P and Sabry, Amr},
booktitle = {Proceedings of the tenth ACM SIGPLAN international conference on Functional programming - ICFP '05},
doi = {10.1145/1086365.1086390},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov et al. - 2005 - Backtracking, interleaving, and terminating monad transformers.pdf:pdf},
isbn = {1595930647},
keywords = {continuations,control delimiters,gramming,haskell,logic pro-,prolog,streams},
pages = {192},
publisher = {ACM Press},
title = {{Backtracking, interleaving, and terminating monad transformers}},
url = {http://portal.acm.org/citation.cfm?doid=1086365.1086390},
year = {2005}
}
@article{Bouyer2003,
abstract = {Algebra offers an elegant and powerful approach to understand regular languages and finite automata. Such framework has been notoriously lacking for timed languages and timed automata. We introduce the notion of monoid recognizability for data languages, which includes timed languages as special case, in a way that respects the spirit of the classical situation. We study closure properties and hierarchies in this model and prove that emptiness is decidable under natural hypotheses. Our class of recognizable languages properly includes many families of deterministic timed languages that have been proposed until now, and the same holds for non-deterministic versions. {\textcopyright} 2003 Elsevier Science (USA). All rights reserved.},
author = {Bouyer, Patricia and Petit, Antoine and Th{\'{e}}rien, Denis},
doi = {10.1016/S0890-5401(03)00038-5},
file = {:Users/liang-tingchen/Dropbox/References/Bouyer, Petit, Th{\'{e}}rien - 2003 - An algebraic approach to data languages and timed languages.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {may},
number = {2},
pages = {137--162},
title = {{An algebraic approach to data languages and timed languages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540103000385},
volume = {182},
year = {2003}
}
@article{Shulman2018,
abstract = {We combine homotopy type theory with axiomatic cohesion, expressing the latter internally with a version of ‘adjoint logic' in which the discretization and codiscretization modalities are characterized using a judgemental formalism of ‘crisp variables.' This yields type theories that we call ‘spatial' and ‘cohesive,' in which the types can be viewed as having independent topological and homotopical structure. These type theories can then be used to study formally the process by which topology gives rise to homotopy theory (the ‘fundamental ∞-groupoid' or ‘shape'), disentangling the ‘identifications' of homotopy type theory from the ‘continuous paths' of topology. In a further refinement called ‘real-cohesion,' the shape is determined by continuous maps from the real numbers, as in classical algebraic topology. This enables us to reproduce formally some of the classical applications of homotopy theory to topology. As an example, we prove Brouwer's fixed-point theorem.},
archivePrefix = {arXiv},
arxivId = {1509.07584},
author = {Shulman, Michael A.},
doi = {10.1017/S0960129517000147},
eprint = {1509.07584},
file = {:Users/liang-tingchen/Dropbox/References/Shulman - 2018 - Brouwer's fixed-point theorem in real-cohesive homotopy type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {6},
pages = {856--941},
title = {{Brouwer's fixed-point theorem in real-cohesive homotopy type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129517000147/type/journal{\_}article},
volume = {28},
year = {2018}
}
@article{Kelly2000,
author = {Kelly, Gregory Maxwell and Lack, Stephen},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Lack - 2000 - On the monadicity of categories with chosen colimits.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Categories with limits,Enriched categories,Monadicity,Weighted limits},
number = {7},
pages = {148--170},
title = {{On the monadicity of categories with chosen colimits}},
volume = {7},
year = {2000}
}
@inproceedings{Urabe2015,
address = {Dagstuhl, Germany},
annote = {Keywords: category theory, coalgebra, simulation, verification, trace semantics},
author = {Urabe, Natsuki and Hasuo, Ichiro},
booktitle = {Proceedings of the 6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.320},
editor = {Moss, Lawrence S and Sobocinski, Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Urabe, Hasuo - 2015 - Coalgebraic infinite traces and Kleisli simulations.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
pages = {320--335},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Coalgebraic infinite traces and Kleisli simulations}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5542},
volume = {35},
year = {2015}
}
@incollection{Howard1980,
author = {Howard, W H},
booktitle = {To H. B. Curry: essays on combinatory logic, lambda calculus and formalism},
editor = {Seldin, J.P. and Hindley, J. Roger},
file = {:Users/liang-tingchen/Dropbox/References/Howard - 1980 - The formulae-as-types notion of construction.pdf:pdf},
pages = {479--490},
publisher = {Academic Press},
title = {{The formulae-as-types notion of construction}},
year = {1980}
}
@inproceedings{Bauer2006,
abstract = {Computability theory, which investigates computable functions and computable sets, lies at the foundation of computer science. Its classical presentations usually involve a fair amount of G{\"{o}}del encodings which sometime obscure ingenious arguments. Consequently, there have been a number of presentations of computability theory that aimed to present the subject in an abstract and conceptually pleasing way. We build on two such approaches, Hyland's effective topos and Richman's formulation in Bishop-style constructive mathematics, and develop basic computability theory, starting from a few simple axioms. Because we want a theory that resembles ordinary mathematics as much as possible, we never speak of Turing machines and G{\"{o}}del encodings, but rather use familiar concepts from set theory and topology. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Bauer, Andrej},
booktitle = {Proceedings of the 21st Annual Conference on Mathematical Foundations of Programming Semantics (MFPS XXI)},
doi = {10.1016/j.entcs.2005.11.049},
file = {:Users/liang-tingchen/Dropbox/References/Bauer - 2006 - First Steps in Synthetic Computability Theory.pdf:pdf},
issn = {15710661},
keywords = {constructive mathematics,synthetic computability theory},
month = {may},
pages = {5--31},
publisher = {Elsevier B.V.},
series = {Electronic Notes in Theoretical Computer Science},
title = {{First Steps in Synthetic Computability Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2005.11.049 https://linkinghub.elsevier.com/retrieve/pii/S1571066106001861},
volume = {155},
year = {2006}
}
@book{Ponse1996,
abstract = {Labelled transition systems are mathematical models for dynamic behaviour, or processes, and thus form a research field of common interest to logicians and theoretical computer scientists. In computer science, this notion is a fundamental one in the formal analysis of programming languages, in particular in process theory. In modal logic, transition systems are the central object of study under the name of Kripke models. This volume collects a number of research papers on modal logic and process theory. Its unifying theme is the notion of a bisimulation. Bisimulations are relations over transition systems, and provide a key tool in identifying the processes represented by these structures. The volume offers an up-to-date overview of perspectives on labelled transition systems and bisimulations.},
editor = {Ponse, Alban and de Rijke, Maarten and Venema, Yde},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 1996 - Modal Logic and Process Algebra A Bisimulation Perspective.pdf:pdf},
isbn = {188152695X},
pages = {352},
publisher = {CSLI Publications Stanford},
title = {{Modal Logic and Process Algebra: A Bisimulation Perspective}},
year = {1996}
}
@article{Wang2012,
abstract = {We present a theoretical framework for the analysis of privacy and security tradeoffs in secure biometric authentication systems. We use this framework to conduct a comparative information-theoretic analysis of two biometric systems that are based on linear error correction codes, namely fuzzy commitment and secure sketches. We derive upper bounds for the probability of false rejection ({\$}P{\_}{\{}FR{\}}{\$}) and false acceptance ({\$}P{\_}{\{}FA{\}}{\$}) for these systems. We use mutual information to quantify the information leaked about a user's biometric identity, in the scenario where one or multiple biometric enrollments of the user are fully or partially compromised. We also quantify the probability of successful attack ({\$}P{\_}{\{}SA{\}}{\$}) based on the compromised information. Our analysis reveals that fuzzy commitment and secure sketch systems have identical {\$}P{\_}{\{}FR{\}}, P{\_}{\{}FA{\}}, P{\_}{\{}SA{\}}{\$} and information leakage, but secure sketch systems have lower storage requirements. We analyze both single-factor (keyless) and two-factor (key-based) variants of secure biometrics, and consider the most general scenarios in which a single user may provide noisy biometric enrollments at several access control devices, some of which may be subsequently compromised by an attacker. Our analysis highlights the revocability and reusability properties of key-based systems and exposes a subtle design tradeoff between reducing information leakage from compromised systems and preventing successful attacks on systems whose data have not been compromised.},
archivePrefix = {arXiv},
arxivId = {1112.5630},
author = {Wang, Ye and Rane, Shantanu and Draper, Stark C. and Ishwar, Prakash},
doi = {10.1109/TIFS.2012.2210215},
eprint = {1112.5630},
file = {:Users/liang-tingchen/Dropbox/References/Wang et al. - 2012 - A Theoretical Analysis of Authentication, Privacy, and Reusability Across Secure Biometric Systems.pdf:pdf},
issn = {1556-6013},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {Biometrics,fuzzy commitment,information leakage,privacy,reusability,revocability,secure sketch,security},
month = {dec},
number = {6},
pages = {1825--1840},
title = {{A Theoretical Analysis of Authentication, Privacy, and Reusability Across Secure Biometric Systems}},
url = {http://ieeexplore.ieee.org/document/6248216/},
volume = {7},
year = {2012}
}
@techreport{Preston2008,
abstract = {These notes give an elementary approach to parts of the theory of standard Borel and analytic spaces.},
archivePrefix = {arXiv},
arxivId = {0809.3066},
author = {Preston, Chris},
eprint = {0809.3066},
file = {:Users/liang-tingchen/Dropbox/References/Preston - 2008 - Some Notes on Standard Borel and Related Spaces.pdf:pdf},
month = {sep},
title = {{Some Notes on Standard Borel and Related Spaces}},
url = {http://arxiv.org/abs/0809.3066},
year = {2008}
}
@article{Johann2008,
abstract = {GADTs are at the cutting edge of functional programming and become more widely used every day. Nevertheless, the semantic foundations underlying GADTs are not well understood. In this paper we solve this problem by showing that the standard theory of data types as carriers of initial algebras of functors can be extended from algebraic and nested data types to GADTs. We then use this observation to derive an initial algebra semantics for GADTs, thus ensuring that all of the accumulated knowledge about initial algebras can be brought to bear on them. Next, we use our initial algebra semantics for GADTs to derive expressive and principled tools - analogous to the well-known and widely-used ones for algebraic and nested data types - for reasoning about, programming with, and improving the performance of programs involving, GADTs; we christen such a collection of tools for a GADT an initial algebra package. Along the way, we give a constructive demonstration that every GADT can be reduced to one which uses only the equality GADT and existential quantification. Although other such reductions exist in the literature, ours is entirely local, is independent of any particular syntactic presentation of GADTs, and can be implemented in the host language, rather than existing solely as a metatheoretical artifact. The main technical ideas underlying our approach are (i) to modify the notion of a higher-order functor so that GADTs can be seen as carriers of initial algebras of higher-order functors, and (ii) to use left Kan extensions to trade arbitrary GADTs for simpler-but-equivalent ones for which initial algebra semantics can be derived. Copyright {\textcopyright} 2008 ACM.},
author = {Johann, Patricia and Ghani, Neil},
doi = {10.1145/1328897.1328475},
file = {:Users/liang-tingchen/Dropbox/References/Johann, Ghani - 2008 - Foundations for structured programming with GADTs.pdf:pdf},
isbn = {9781595936899},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
pages = {297},
title = {{Foundations for structured programming with GADTs}},
volume = {43},
year = {2008}
}
@article{Dinur2003,
author = {Dinur, Irit and Nissim, Kobbi},
doi = {10.1145/773153.773173},
file = {:Users/liang-tingchen/Dropbox/References/Dinur, Nissim - 2003 - Revealing information while preserving privacy.pdf:pdf},
isbn = {1581136706},
journal = {Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
keywords = {data reconstruction,integrity and security,subset-sums with noise},
pages = {202--210},
title = {{Revealing information while preserving privacy}},
url = {http://portal.acm.org/citation.cfm?doid=773153.773173{\%}5Cnhttp://doi.acm.org/10.1145/773153.773173},
year = {2003}
}
@article{Rutten2008,
author = {Rutten, Jan J.M.M.},
doi = {10.2168/LMCS-4(3:9)2008},
editor = {Mossakowski, Till},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 2008 - Rational streams coalgebraically.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {sep},
number = {3},
pages = {1--22},
title = {{Rational streams coalgebraically}},
url = {http://arxiv.org/abs/0807.4073 http://www.lmcs-online.org/ojs/viewarticle.php?id=376},
volume = {4},
year = {2008}
}
@incollection{Linton1969a,
author = {Linton, F. E. J.},
booktitle = {Seminar on Triples and Categorical Homology Theory},
doi = {10.1007/BFb0083080},
editor = {Eckmann, B.},
file = {:Users/liang-tingchen/Dropbox/References/Linton - 1969 - An outline of functorial semantics.pdf:pdf},
isbn = {978-3-540-04601-1},
pages = {7--52},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{An outline of functorial semantics}},
year = {1969}
}
@article{Carboni1991a,
abstract = {Motivated by the problem of internalizing Enriched Category Theory in a topos, we investigate the notion of a lax monad T on a bicategory B for which we can construct the bicategory BT of 'matrices of T-algebras' and we prove a factorization theorem to this effect. ?? 1991.},
author = {Carboni, Aurelio and Rosebrugh, Robert},
doi = {10.1016/0022-4049(91)90094-I},
file = {:Users/liang-tingchen/Dropbox/References/Carboni, Rosebrugh - 1991 - Lax monads.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1},
pages = {13--32},
title = {{Lax monads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499190094I},
volume = {76},
year = {1991}
}
@article{Power1998,
abstract = {We give an axiomatic account of what structure on a category C and an endofunctor H on C yield similar structure on the category H ---Coalg of H-coalgebras. We give conditions under which completeness, cocompleteness, symmetric monoidal closed structure, local presentability, and subobject classifiers lift. Our proof of the latter uses a general result about the existance of a subobject classifier in a category containing a small dense subcategory. Our leading example has C = Set with H the endofunctor for which a coalgebra is a finitely branching (labelled) transition system. We explain that example in detail.},
author = {Power, A. John and Watanabe, Hiroshi},
doi = {10.1016/S1571-0661(04)00057-X},
file = {:Users/liang-tingchen/Dropbox/References/Power, Watanabe - 1998 - An axiomatics for categories of coalgebras.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {0},
pages = {158--175},
title = {{An axiomatics for categories of coalgebras}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/S157106610400057X http://linkinghub.elsevier.com/retrieve/pii/S157106610400057X},
volume = {11},
year = {1998}
}
@article{Bloom1997,
abstract = {This paper is concerned with the questions of the existence or the construction of ﬁxed points. We are concerned with the properties of ﬁxed point solutions, especially equational properties.},
author = {Bloom, Stephen L. and {\'{E}}sik, Zolt{\'{a}}n},
doi = {10.1016/S0304-3975(96)00248-4},
file = {:Users/liang-tingchen/Dropbox/References/Bloom, {\'{E}}sik - 1997 - The equational logic of fixed points.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jun},
number = {1-2},
pages = {1--60},
title = {{The equational logic of fixed points}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397596002484},
volume = {179},
year = {1997}
}
@article{Gambino2013,
abstract = {We study polynomial functors over locally cartesian closed categories. After setting up the basic theory, we show how polynomial functors assemble into a double category, in fact a framed bicategory. We show that the free monad on a polynomial endofunctor is polynomial. The relationship with operads and other related notions is explored.},
author = {GAMBINO, NICOLA and KOCK, JOACHIM},
doi = {10.1017/S0305004112000394},
file = {:Users/liang-tingchen/Dropbox/References/GAMBINO, KOCK - 2013 - Polynomial functors and polynomial monads.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {jan},
number = {01},
pages = {153--192},
title = {{Polynomial functors and polynomial monads}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004112000394},
volume = {154},
year = {2013}
}
@article{Santos2017,
abstract = {We propose the new concept of Krivine ordered combinatory algebra ( {\$}\backslashmathcal{\{}{\^{}}KOCA{\}}{\$} ) as foundation for the categorical study of Krivine's classical realizability, as initiated by Streicher (2013).},
archivePrefix = {arXiv},
arxivId = {1410.5034},
author = {SANTOS, WALTER FERRER and FREY, JONAS and GUILLERMO, MAURICIO and MALHERBE, OCTAVIO and MIQUEL, ALEXANDRE},
doi = {10.1017/S0960129515000432},
eprint = {1410.5034},
file = {:Users/liang-tingchen/Dropbox/References/SANTOS et al. - 2017 - Ordered combinatory algebras and realizability.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {3},
pages = {428--458},
title = {{Ordered combinatory algebras and realizability}},
url = {https://www.cambridge.org/core/product/identifier/S0960129515000432/type/journal{\_}article},
volume = {27},
year = {2017}
}
@article{Pattinson2004,
author = {Pattinson, Dirk},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson - 2004 - Expressive logics for coalgebras via terminal sequence induction.pdf:pdf},
issn = {1939-0726},
journal = {Notre Dame Journal of Formal Logic},
keywords = {behavioral equivalence,coalgebra,modal logic},
number = {1},
pages = {19--33},
title = {{Expressive logics for coalgebras via terminal sequence induction}},
url = {http://projecteuclid.org/euclid.ndjfl/1094155277},
volume = {45},
year = {2004}
}
@article{Streicher2013,
abstract = {In a sequence of papers (Krivine 2001; Krivine 2003; Krivine 2009), J.-L. Krivine introduced his notion of classical realisability for classical second-order logic and Zermelo–Fraenkel set theory. Moreover, in more recent work (Krivine 2008), he has considered forcing constructions on top of it with the ultimate aim of providing a realisability interpretation for the axiom of choice.},
author = {Streicher, Thomas},
doi = {10.1017/S0960129512000989},
file = {:Users/liang-tingchen/Dropbox/References/Streicher - 2013 - Krivine's classical realisability from a categorical perspective.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Streicher - 2013 - Krivine's classical realisability from a categorical perspective(2).pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {dec},
number = {6},
pages = {1234--1256},
title = {{Krivine's classical realisability from a categorical perspective}},
url = {https://www.cambridge.org/core/product/identifier/S0960129512000989/type/journal{\_}article},
volume = {23},
year = {2013}
}
@article{Taylor1977,
author = {Taylor, Walter},
doi = {10.1007/BF00968693},
file = {:Users/liang-tingchen/Dropbox/References/Taylor - 1977 - Varieties of topological algebras.pdf:pdf},
issn = {00374466},
journal = {Journal of the Australian Mathematical Society (Series A)},
number = {02},
pages = {207--241},
title = {{Varieties of topological algebras}},
volume = {23},
year = {1977}
}
@article{Schrijvers2009,
abstract = {A constraint programming system combines two essential components: a constraint solver and a search engine. The constraint solver reasons about satisfiability of conjunctions of constraints, and the search engine controls the search for solutions by iteratively exploring a disjunctive search tree defined by the constraint program. In this paper we give a monadic definition of constraint programming in which the solver is defined as a monad threaded through the monadic search tree. We are then able to define search and search strategies as first-class objects that can themselves be built or extended by composable search transformers. Search transformers give a powerful and unifying approach to viewing search in constraint programming, and the resulting constraint programming system is first class and extremely flexible.},
author = {SCHRIJVERS, TOM and STUCKEY, PETER and WADLER, PHILIP},
doi = {10.1017/S0956796809990086},
file = {:Users/liang-tingchen/Dropbox/References/SCHRIJVERS, STUCKEY, WADLER - 2009 - Monadic constraint programming.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {nov},
number = {06},
pages = {663},
title = {{Monadic constraint programming}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796809990086},
volume = {19},
year = {2009}
}
@inproceedings{calculation-view-multiple-representation-editing-in-spreadsheets,
abstract = {Spreadsheet errors are ubiquitous and costly, an unfortunate combination that is well-reported. A large class of these errors can be attributed to the inability to clearly see the underlying computational structure, as well as poor support for abstraction (encapsulation, re-use, etc). In this paper we propose a novel solution: a multiple-representation spreadsheet containing additional representations that allow abstract operations, without altering the conventional grid representation or its formula syntax. Through a user study, we demonstrate that the use of multiple representations can significantly improve user performance when performing spreadsheet authoring and debugging tasks. We close with a discussion of design implications and outline future directions for this line of inquiry.},
author = {Sarkar, Advait and Gordon, Andy and {Peyton Jones}, Simon and Toronto, Neil},
booktitle = {IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
file = {:Users/liang-tingchen/Dropbox/References/Sarkar et al. - 2018 - Calculation View multiple-representation editing in spreadsheets.pdf:pdf},
month = {oct},
pages = {85--94},
publisher = {IEEE},
title = {{Calculation View: multiple-representation editing in spreadsheets}},
url = {https://www.microsoft.com/en-us/research/publication/calculation-view-multiple-representation-editing-in-spreadsheets/},
year = {2018}
}
@article{Lilis2019,
abstract = {Metaprogramming is the process of writing computer programs that treat programs as data, enabling them to analyze or transform existing programs or generate new ones. While the concept of metaprogramming has existed for several decades, activities focusing on metaprogramming have been increasing rapidly over the past few years, with most languages offering some metaprogramming support and the amount of metacode being developed growing exponentially. In this article, we introduce a taxonomy of metaprogramming languages and present a survey of metaprogramming languages and systems based on the taxonomy. Our classification is based on the metaprogramming model adopted by the language, the phase of the metaprogram evaluation, the metaprogram source location, and the relation between the metalanguage and the object language.},
author = {Lilis, Yannis and Savidis, Anthony},
doi = {10.1145/3354584},
file = {:Users/liang-tingchen/Dropbox/References/Lilis, Savidis - 2020 - A Survey of Metaprogramming Languages.pdf:pdf},
issn = {0360-0300},
journal = {ACM Computing Surveys},
keywords = {Aspect-oriented programming,Generative programming,Macro systems,Meta-object protocols,Metaprogramming,Multistage languages,Reflection},
month = {jan},
number = {6},
pages = {1--39},
title = {{A Survey of Metaprogramming Languages}},
url = {https://dl.acm.org/doi/10.1145/3354584},
volume = {52},
year = {2020}
}
@article{Of1982,
author = {Smyth, Michael B. and Plotkin, Gordon D.},
doi = {10.1137/0211062},
file = {:Users/liang-tingchen/Dropbox/References/Smyth, Plotkin - 1982 - The category-theoretic solution of recursive domain equations.pdf:pdf},
issn = {0097-5397},
journal = {SIAM Journal on Computing},
keywords = {1,13,26,39,40,41,and their followers,by scott and strachey,category,computability,data-types,domains,fixed-point,for example,gordon,in denota-,introduction,milne and strachey,partial-order,play a crucial role,recursive specifications of domains,semantics,stoy,tennent,the equation,tional semantics as developed},
month = {nov},
number = {4},
pages = {761--783},
title = {{The category-theoretic solution of recursive domain equations}},
url = {http://epubs.siam.org/doi/abs/10.1137/0211062},
volume = {11},
year = {1982}
}
@article{Ariola1997,
abstract = {This paper is concerned with the study of $\lambda$-calculus with explicit recursion, namely of cyclic $\lambda$-graphs. The starting point is to treat a $\lambda$-graph as a system of recursion equations involving $\lambda$-terms and to manipulate such systems in an unrestricted manner, using equational logic, just as is possible for first-order term rewriting. Surprisingly, now the confluence property breaks down in an essential way. Confluence can be restored by introducing a restraining mechanism on the substitution operation. This leads to a family of $\lambda$-graph calculi, which can be seen as an extension of the family of $\lambda$$\sigma$-calculi ($\lambda$-calculi with explicit substitution). While the $\lambda$$\sigma$-calculi treat the let-construct as a first-class citizen, our calculi support the letrec, a feature that is essential to reason about time and space behavior of functional languages and also about compilation and optimizations of programs. {\textcopyright} 1997 Academic Press.},
author = {Ariola, Zena M. and Klop, Jan Willem},
doi = {10.1006/inco.1997.2651},
file = {:Users/liang-tingchen/Dropbox/References/Ariola, Klop - 1997 - Lambda Calculus with Explicit Recursion.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {dec},
number = {2},
pages = {154--233},
title = {{Lambda Calculus with Explicit Recursion}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540197926511},
volume = {139},
year = {1997}
}
@inproceedings{Daviaud2016,
author = {Daviaud, Laure and Kuperberg, Denis and Pin, Jean-{\'{E}}ric},
booktitle = {Proceedings of the 33rd International Symposium on Theoretical Aspects of Computer Science},
doi = {10.4230/LIPIcs.STACS.2016.30},
file = {:Users/liang-tingchen/Dropbox/References/Daviaud, Kuperberg, Pin - 2016 - Varieties of cost functions.pdf:pdf},
keywords = {and phrases cost functions,regular language,syntactic algebra,varieties},
pages = {30:1----30:14},
publisher = {Schloss Dagstuhl–Leibniz-Zentrum f{\"{u}}r Informatik},
series = {LIPIcs},
title = {{Varieties of cost functions}},
url = {http://dx.doi.org/10.4230/LIPIcs.STACS.2016.30},
volume = {47},
year = {2016}
}
@article{Coecke2012,
abstract = {We introduce a graphical framework for Bayesian inference that is sufficiently general to accommodate not just the standard case but also recent proposals for a theory of quantum Bayesian inference wherein one considers density operators rather than probability distributions as representative of degrees of belief. The diagrammatic framework is stated in the graphical language of symmetric monoidal categories and of compact structures and Frobenius structures therein, in which Bayesian inversion boils down to transposition with respect to an appropriate compact structure. We characterize classical Bayesian inference in terms of a graphical property and demonstrate that our approach eliminates some purely conventional elements that appear in common representations thereof, such as whether degrees of belief are represented by probabilities or entropic quantities. We also introduce a quantum-like calculus wherein the Frobenius structure is noncommutative and show that it can accommodate Leifer's calculus of ‘conditional density operators'. The notion of conditional independence is also generalized to our graphical setting and we make some preliminary connections to the theory of Bayesian networks. Finally, we demonstrate how to construct a graphical Bayesian calculus within any dagger compact category.},
archivePrefix = {arXiv},
arxivId = {1102.2368},
author = {Coecke, Bob and Spekkens, Robert W.},
doi = {10.1007/s11229-011-9917-5},
eprint = {1102.2368},
file = {:Users/liang-tingchen/Dropbox/References/Coecke, Spekkens - 2012 - Picturing classical and quantum Bayesian inference.pdf:pdf},
issn = {00397857},
journal = {Synthese},
keywords = {Bayesian inference,Conditional density operator,Frobenius algebra,Graphical calculus,Symmetric monoidal category},
number = {3},
pages = {651--696},
title = {{Picturing classical and quantum Bayesian inference}},
volume = {186},
year = {2012}
}
@inproceedings{Pattinson2008,
author = {Pattinson, Dirk and Schr{\"{o}}der, Lutz},
booktitle = {Proceedings of the Foundations of Software Science and Computational Structures},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson, Schr{\"{o}}der - 2008 - Beyond rank 1 Algebraic semantics and finite models for coalgebraic logics.pdf:pdf},
pages = {66--80},
publisher = {Springer},
title = {{Beyond rank 1: Algebraic semantics and finite models for coalgebraic logics}},
url = {http://www.springerlink.com/index/PG816150G1873495.pdf},
year = {2008}
}
@phdthesis{Birkedal1999,
abstract = {We investigate the development of theories of types and computability via realizability. In the first part of the thesis, we suggest a general notion of realizability, based on weakly closed partial cartesian categories, which generalizes the usual notion of realizability over a partial combinatory algebra. We show how to construct categories of so-called assemblies and modest sets over any weakly closed partial cartesian category and that these categories of assemblies and modest sets model dependent predicate logic, that is, first-order logic over dependent type theory. We further characterize when a weakly closed partial cartesian category gives rise to a topos. Scott's category of equilogical spaces arises as a special case of our notion of realizability, namely as modest sets over the category of algebraic lattices. Thus, as a consequence, we conclude that the category of equilogical spaces models dependent predicate logic; we include a concrete description of this model. In the second part of the thesis, we study a notion of relative computability, which allows one to consider computable operations operating on not necessarily computable data. Given a partial combinatory algebra A, which we think of as continuous realizers, with a subalgebra A{\#}, which we think of as computable realizers, there results a realizability topos RT(A,A{\#}), which one intuitively can think of as having "continous objects and computable morphisms". We study the relationship between this topos and the standard realizability toposes RT(A) and RT(A{\#}) over A and A{\#}. In particular, we show that there is a localic local map of toposes from RT(A,A{\#}) to RT(A{\#}). To obtain a better understanding of the relationship between the internal logics of RT(A,A{\#}) and RT(A{\#}), we then provide a complete axiomatization of arbitrary local maps of toposes. Based on this axiomatization we investigate the relationship between the internal logics of two toposes connected via a local map. Moreover, we suggest a modal logic for local maps. Returning to the realizability models we show in particular that the modal logic for local maps in the case of RT(A,A{\#}) and RT(A{\#}) can be seen as a modal logic for computability. Moreover, we characterize some interesting subcategories of RT(A,A{\#}) (in much the same way as assemblies and modest sets are characterized in standard realizability toposes) and show the validity of some logical principles in RT(A,A{\#}). This book is a slight revision of the author's Ph.D. thesis, written at Carnegie Mellon University, Pittsburgh, under the guidance of Prof. Dana S. Scott. This book is available in two formats: pdf and postscript. The pdf version has active hyper-references. May 23, 2000 Lars Birkedal {\textcopyright} 2000 Elsevier B.V.},
author = {Birkedal, Lars},
doi = {10.1016/S1571-0661(05)80642-5},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal - 1999 - Developing theories of types and computability via realizability.pdf:pdf},
issn = {15710661},
school = {Carnegie Mellon University},
title = {{Developing theories of types and computability via realizability}},
type = {Doctoral Thesis},
volume = {CMU-CS-99-},
year = {1999}
}
@article{Brengos2014a,
abstract = {We generalize the work by P. Soboci$\backslash$'nski on relational presheaves and their connection with weak (bi)simulation for labelled transistion systems to a coalgebraic setting. We show that the coalgebraic notion of saturation studied in our previous work can be expressed in the language of lax Kleisli-valued presheaves in terms of existence of a certain adjoint situation between presheaf categories. This observation allows us to generalize the notion of the coalgebraic (weak) bisimulation to lax Kleisli-valued presheaves. At this level of generality interesting properties of strong and weak bisimilarity emerge: in the family of {\$}p{\$}-bisimilarities, which arises naturally in this setting, the former is the finest and the latter is the coarsest relation.},
archivePrefix = {arXiv},
arxivId = {1404.5267},
author = {Brengos, Tomasz},
eprint = {1404.5267},
file = {:Users/liang-tingchen/Dropbox/References/Brengos - 2014 - Lax Kleisli-valued presheaves and coalgebraic weak bisimulation.pdf:pdf},
journal = {ArXiv e-prints},
month = {apr},
pages = {1--20},
title = {{Lax Kleisli-valued presheaves and coalgebraic weak bisimulation}},
url = {http://arxiv.org/abs/1404.5267},
year = {2014}
}
@book{Rhodes2009,
address = {Boston, MA},
author = {Rhodes, John and Steinberg, Benjamin},
doi = {10.1007/b104443},
file = {:Users/liang-tingchen/Dropbox/References/Rhodes, Steinberg - 2009 - The q-theory of Finite Semigroups.pdf:pdf},
isbn = {978-0-387-09780-0},
publisher = {Springer US},
series = {Springer Monographs in Mathematics},
title = {{The q-theory of Finite Semigroups}},
url = {http://link.springer.com/10.1007/b104443},
year = {2009}
}
@article{Leymann1989,
abstract = {The theory of the universal relation model is discussed and different approaches for realizing universal relation systems are presented. Especially, various assumptions made in connection with this data model are discussed, revealing directives for designing semantically clear database schemes. {\textcopyright} 1989.},
author = {Leymann, Frank},
doi = {10.1016/0169-023X(89)90028-1},
file = {:Users/liang-tingchen/Dropbox/References/Leymann - 1989 - A survey of the universal relation model.pdf:pdf},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {Access path,Data manipulation,Data model,Database navigation,Database semantic,Object scheme,Query language,Relational database,Universal relation,Window},
month = {dec},
number = {4},
pages = {305--320},
title = {{A survey of the universal relation model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0169023X89900281},
volume = {4},
year = {1989}
}
@incollection{Miller2000,
abstract = {A large variety of computing systems, such as compilers, interpreters, static analyzers, and theorem provers, need to manipulate syntactic objects like programs, types, formulas, and proofs. A common characteristic of these syntactic objects is that they contain variable binders, such as quantifiers, formal parameters, and blocks. It is a common observation that representing such binders using only first-order expressions is problematic since the notions of bound variable names, free and bound occurrences, equality up to alpha-conversion, substitution, etc., are not addressed naturally by the structure of first-order terms (labeled trees). This overview describes a higher-level and more declarative approach to representing syntax within such computational systems. In particular, we shall focus on a representation of syntax called higher-order abstract syntax and on a more primitive version of that representation called $\lambda$-tree syntax.},
author = {Miller, Dale},
booktitle = {Computational Logic — CL 2000. CL 2000},
doi = {10.1007/3-540-44957-4_16},
editor = {Lloyd, John and Dahl, Veronica and Furbach, Ulrich and Kerber, Manfred and Lau, Kung-Kiu and Palamidessi, Catuscia},
file = {:Users/liang-tingchen/Dropbox/References/Miller - 2000 - Abstract Syntax for Variable Binders An Overview.pdf:pdf},
pages = {239--253},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Abstract Syntax for Variable Binders: An Overview}},
url = {http://link.springer.com/10.1007/3-540-44957-4{\_}16},
volume = {1861},
year = {2000}
}
@article{Hilken1996,
abstract = {This paper describes the simply typed 2$\lambda$-calculus, a language with three levels: types, terms and rewrites. The types and terms are those of the simply typed $\lambda$-calculus, and the rewrites are expressions denoting sequences of $\beta$-reductions and $\eta$-expansions. An equational theory is imposed on the rewrites, based on 2-categorical justifications, and the word problem for this theory is solved by finding a canonical expression in each equivalence class. The canonical form of rewrites allows us to prove several properties of the calculus, including a strong form of confluence and a classification of the long-$\beta$$\eta$-normal forms in terms of their rewrites. Finally we use these properties as the basic definitions of a theory of categorical rewriting, and find that the expected relationships between confluence, strong normalisation and normal forms hold.},
author = {Hilken, Barnaby P.},
doi = {10.1016/S0304-3975(96)80713-4},
file = {:Users/liang-tingchen/Dropbox/References/Hilken - 1996 - Towards a proof theory of rewriting the simply typed 2$\lambda$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1-2},
pages = {407--444},
title = {{Towards a proof theory of rewriting: the simply typed 2$\lambda$-calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397596807134},
volume = {170},
year = {1996}
}
@article{Mislove2007,
abstract = {Labelled Markov processes (LMPs) are labelled transition systems in which each transition has an associated probability. In this paper we present a universal LMP as the spectrum of a commutative C*-algebra consisting of formal linear combinations of labelled trees. This yields a simple trace-tree semantics for LMPs that is fully abstract with respect to probabilistic bisimilarity. We also consider LMPs with distinguished entry and exit points as stateful stochastic relations. This allows us to define a category GSRel of generalized stochastic relations, which has measurable spaces as objects and LMPs as morphisms. Our main result in this context is to provide a predicate-transformer duality for GSRel that generalises Kozen's duality for the category SRel of stochastic relations.},
author = {Mislove, Michael W. and Pavlovi{\'{c}}, Dusko and Worrell, James},
doi = {10.1016/j.entcs.2007.02.015},
file = {:Users/liang-tingchen/Dropbox/References/Mislove, Pavlovi{\'{c}}, Worrell - 2007 - Labelled Markov Processes as Generalised Stochastic Relations.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {(generalized) stochastic relation,c*-algebra,comonad,labelled markov process,probabilistic bisimulation,stone duality},
month = {apr},
pages = {459--478},
title = {{Labelled Markov Processes as Generalised Stochastic Relations}},
url = {http://dx.doi.org/10.1016/j.entcs.2007.02.015},
volume = {172},
year = {2007}
}
@inproceedings{Hasuo2015,
abstract = {In the context of formal verification in general and model checking in particular, parity games serve as a mighty vehicle: many problems are encoded as parity games, which are then solved by the seminal algorithm by Jurdzinski. In this paper we identify the essence of this workflow to be the notion of progress measure, and formalize it in general, possibly infinitary, lattice-theoretic terms. Our view on progress measures is that they are to nested/alternating fixed points what invariants are to safety/greatest fixed points, and what ranking functions are to liveness/least fixed points. That is, progress measures are combination of the latter two notions (invariant and ranking function) that have been extensively studied in the context of (program) verification. We then apply our theory of progress measures to a general model-checking framework, where systems are categorically presented as coalgebras. The framework's theoretical robustness is witnessed by a smooth transfer from the branching-time setting to the linear-time one. Although the framework can be used to derive some decision procedures for finite settings, we also expect the proposed framework to form a basis for sound proof methods for some undecidable/infinitary problems.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1511.00346},
author = {Hasuo, Ichiro and Shimizu, Shunsuke and C{\^{i}}rstea, Corina},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837673},
eprint = {1511.00346},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo, Shimizu, C{\^{i}}rstea - 2016 - Lattice-theoretic progress measures and coalgebraic model checking.pdf:pdf},
isbn = {9781450335492},
issn = {07308566},
keywords = {coalgebra,fixed-point logic,model checking},
pages = {718--732},
publisher = {ACM Press},
title = {{Lattice-theoretic progress measures and coalgebraic model checking}},
url = {http://arxiv.org/abs/1511.00346 http://dl.acm.org/citation.cfm?doid=2837614.2837673},
year = {2016}
}
@article{Pitts2010,
author = {Pitts, Andrew M.},
doi = {10.1145/1707801.1706321},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2010 - Nominal system T.pdf:pdf},
isbn = {9781605584799},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {-,calculus of,functions with structural recursion,higher-order,languages,modulo,often omitted as obvious,tal,theory,this paper presents a,to-,verification},
number = {1},
pages = {159},
title = {{Nominal system T}},
volume = {45},
year = {2010}
}
@incollection{Pientka2020,
abstract = {We describe a category-theoretic semantics for a simply typed variant of Cocon, a contextual modal type theory where the box modality mediates between the weak function space that is used to represent higher-order abstract syntax (HOAS) trees and the strong function space that describes (recursive) computations about them. What makes Cocon different from standard type theories is the presence of first-class contexts and contextual objects to describe syntax trees that are closed with respect to a given context of assumptions. Following M. Hofmann's work, we use a presheaf model to characterise HOAS trees. Surprisingly, this model already provides the necessary structure to also model Cocon. In particular, we can capture the contextual objects of Cocon using a comonad b that restricts presheaves to their closed elements. This gives a simple semantic characterisation of the invariants of contextual types (e.g. substitution invariance) and identifies Cocon as a type-theoretic syntax of presheaf models. We express our category-theoretic constructions by using a modal internal type theory that is implemented in Agda-Flat.},
author = {Pientka, Brigitte and Sch{\"{o}}pp, Ulrich},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2020},
doi = {10.1007/978-3-030-45231-5_26},
file = {:Users/liang-tingchen/Dropbox/References/Pientka, Sch{\"{o}}pp - 2020 - Semantical Analysis of Contextual Types.pdf:pdf},
isbn = {9783030452308},
issn = {16113349},
pages = {502--521},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Semantical Analysis of Contextual Types}},
url = {http://link.springer.com/10.1007/978-3-030-45231-5{\_}26},
volume = {12077},
year = {2020}
}
@phdthesis{Leal2011,
author = {Leal, Raul Andres},
file = {:Users/liang-tingchen/Dropbox/References/Leal - 2011 - Modalities Through the Looking Glass A study on coalgebraic modal logic and their applications.pdf:pdf},
isbn = {9789057762314},
school = {University of Amsterdan},
title = {{Modalities Through the Looking Glass: A study on coalgebraic modal logic and their applications}},
year = {2011}
}
@inproceedings{Bernardy2015,
abstract = {We extend Martin-L{\"{o}}f's Logical Framework with special constructions and typing rules providing internalized parametricity. Compared to previous similar proposals, this version comes with a denotational semantics which is a refinement of the standard presheaf semantics of dependent type theory. Further, this presheaf semantics is a refinement of the one used to interpret nominal sets with restrictions. The present calculus is a candidate for the core of a proof assistant with internalized parametricity.},
address = {Nijmegen, The Netherlands},
author = {Bernardy, Jean-Philippe and Coquand, Thierry and Moulin, Guilhem},
booktitle = {The 31st Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXI)},
doi = {10.1016/j.entcs.2015.12.006},
editor = {Ghica, Dan R.},
file = {:Users/liang-tingchen/Dropbox/References/Bernardy, Coquand, Moulin - 2015 - A Presheaf Model of Parametric Type Theory.pdf:pdf},
issn = {15710661},
keywords = {Parametricity,Presheaf semantics,Type theory},
pages = {67--82},
publisher = {Elsevier B.V.},
series = {Electronic Notes in Theoretical Computer Science},
title = {{A Presheaf Model of Parametric Type Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.12.006 https://linkinghub.elsevier.com/retrieve/pii/S1571066115000730},
volume = {319},
year = {2015}
}
@article{Abramsky1991a,
author = {Abramsky, Samson},
doi = {10.1016/0168-0072(91)90065-T},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 1991 - Domain theory in logical form.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
number = {1-2},
pages = {1--77},
title = {{Domain theory in logical form}},
type = {Journal article},
url = {http://linkinghub.elsevier.com/retrieve/pii/016800729190065T},
volume = {51},
year = {1991}
}
@incollection{B2016,
address = {Cham},
author = {Idelberger, Florian and Governatori, Guido and Riveret, R{\'{e}}gis and Sartor, Giovanni},
booktitle = {Rule Technologies. Research, Tools, and Applications. RuleML 2016},
doi = {10.1007/978-3-319-42019-6_11},
editor = {Alferes, Jose Julio and Bertossi, Leopoldo and Governatori, Guido and Fodor, Paul and Roman, Dumitru},
file = {:Users/liang-tingchen/Dropbox/References/Idelberger et al. - 2016 - Evaluation of Logic-Based Smart Contracts for Blockchain Systems.pdf:pdf},
isbn = {978-3-319-42018-9},
keywords = {smart contract},
pages = {167--183},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Evaluation of Logic-Based Smart Contracts for Blockchain Systems}},
url = {http://link.springer.com/10.1007/978-3-319-42019-6{\_}11},
volume = {9718},
year = {2016}
}
@incollection{Pattinson2001a,
author = {Pattinson, Dirk},
booktitle = {Proc. 18th Symposium on Theoretical Aspects of Computer Science (STACS 2001)},
doi = {10.1007/3-540-44693-1_45},
editor = {{H. Reichel and A. Ferreira}},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson - 2001 - Semantical Principles in the Modal Logic of Coalgebras.pdf:pdf},
number = {Section 2},
pages = {514--526},
series = {Lecture Notes in Computer Science},
title = {{Semantical Principles in the Modal Logic of Coalgebras}},
year = {2001}
}
@inproceedings{Narayanan2009,
archivePrefix = {arXiv},
arxivId = {0903.3276},
author = {Narayanan, Arvind and Shmatikov, Vitaly},
booktitle = {2009 30th IEEE Symposium on Security and Privacy},
doi = {10.1109/SP.2009.22},
eprint = {0903.3276},
file = {:Users/liang-tingchen/Dropbox/References/Narayanan, Shmatikov - 2009 - De-anonymizing Social Networks.pdf:pdf},
isbn = {978-0-7695-3633-0},
issn = {10816011},
month = {may},
pages = {173--187},
pmid = {26482121},
publisher = {IEEE},
title = {{De-anonymizing Social Networks}},
url = {http://ieeexplore.ieee.org/document/5207644/},
year = {2009}
}
@article{Capretta2006,
abstract = {The concept of recursive coalgebra of a functor was introduced in the 1970s by Osius in his work on categorical set theory to discuss the relationship between wellfounded induction and recursively specified functions. In this paper, we motivate the use of recursive coalgebras as a paradigm of structured recursion in programming semantics, list some basic facts about recursive coalgebras and, centrally, give new conditions for the recursiveness of a coalgebra based on comonads, comonad-coalgebras and distributive laws of functors over comonads. We also present an alternative construction using countable products instead of cofree comonads. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Capretta, Venanzio and Uustalu, Tarmo and Vene, Varmo},
doi = {10.1016/j.ic.2005.08.005},
file = {:Users/liang-tingchen/Dropbox/References/Capretta, Uustalu, Vene - 2006 - Recursive coalgebras from comonads.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Comonads,Distributive laws,Recursive coalgebras,Structured recursion,Wellfounded coalgebras},
month = {apr},
number = {4},
pages = {437--468},
title = {{Recursive coalgebras from comonads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540105001963},
volume = {204},
year = {2006}
}
@article{Tait1967,
abstract = {T 0 will denote G{\"{o}}del's theory T[3] of functionals of finite type (f.t.) with intuitionistic quantification over each f.t. added. T 1 will denote T 0 together with definition by bar recursion of type o, the axiom schema of bar induction, and the schema},
author = {Tait, W. W.},
doi = {10.2307/2271658},
file = {:Users/liang-tingchen/Dropbox/References/Tait - 1967 - Intensional interpretations of functionals of finite type I.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {aug},
number = {2},
pages = {198--212},
title = {{Intensional interpretations of functionals of finite type I}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200113866/type/journal{\_}article},
volume = {32},
year = {1967}
}
@article{Domingo-Ferrer2015,
abstract = {$\kappa$-anonymity and $\epsilon$-differential privacy are two mainstream privacy models, the former introduced to anonymize data sets and the latter to limit the knowledge gain that results from including one individual in the data set. Whereas basic $\kappa$-anonymity only protects against identity disclosure, t-closeness was presented as an extension of $\kappa$-anonymity that also protects against attribute disclosure. We show here that, if not quite equivalent, t-closeness and $\epsilon$-differential privacy are strongly related to one another when it comes to anonymizing data sets. Specifically, $\kappa$-anonymity for the quasi-identifiers combined with $\epsilon$-differential privacy for the confidential attributes yields stochastic t-closeness (an extension of t-closeness), with t a function of $\kappa$ and $\epsilon$ Conversely, t-closeness can yield $\epsilon$-differential privacy when t = exp($\epsilon$/2) and the assumptions made by t-closeness about the prior and posterior views of the data hold.},
archivePrefix = {arXiv},
arxivId = {1512.05110},
author = {Domingo-Ferrer, Josep and Soria-Comas, Jordi},
doi = {10.1016/j.knosys.2014.11.011},
eprint = {1512.05110},
file = {:Users/liang-tingchen/Dropbox/References/Domingo-Ferrer, Soria-Comas - 2015 - From {\$}t{\$}-closeness to differential privacy and vice versa in data anonymization.pdf:pdf},
isbn = {09507051},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Data anonymization,Semantic anonymization,Statistical disclosure control,Syntactic anonymization,t-closeness,$\epsilon$-differential privacy},
pages = {151--158},
publisher = {Elsevier B.V.},
title = {{From {\$}t{\$}-closeness to differential privacy and vice versa in data anonymization}},
url = {http://dx.doi.org/10.1016/j.knosys.2014.11.011},
volume = {74},
year = {2015}
}
@book{Barr1999,
abstract = {This book is a textbook in basic category theory, written specifically to be read by researchers and students in computing science. The authors expound the constructions basic to category theory in the context of examples and applications to computing science. Some categorical ideas and constructions are already used heavily in computing sciences and many of these use are described. Other ideas, in particular the concept of adjoint have not appeared as widely in the computing science literature. The authors give an elementary exposition of those ideas they believe to be basic categorical tools, with pointers to possible application. Michael Barr is Peter Redpath Professor in the Department of Mathematics and Statistics at McGill University in Montreal, Quebec. Charles Wells is Professor of Mathematics at Case Western Reserve University in Cleveland, Ohio. This new edition contains all the material from the first and second editions, including the four chapters excised from the second edition and the solutions to all the exercises, as well as added material on factorization systems, monoidal categories, and other topics. All errors known to the authors have been corrected.},
author = {Barr, Michael and Wells, Charles},
edition = {3},
file = {:Users/liang-tingchen/Dropbox/References/Barr, Wells - 1999 - Category Theory for Computing Science.pdf:pdf},
isbn = {2-921120-31-3},
pages = {526},
publisher = {Centre de recherches math{\'{e}}matiques},
title = {{Category Theory for Computing Science}},
year = {1999}
}
@article{Hughes2004,
author = {Hughes, Jesse and Jacobs, Bart},
doi = {10.1016/j.tcs.2004.07.022},
file = {:Users/liang-tingchen/Dropbox/References/Hughes, Jacobs - 2004 - Simulations in coalgebra.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebra,relation lifting,simulation},
month = {oct},
number = {1-2},
pages = {71--108},
title = {{Simulations in coalgebra}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S030439750400444X},
volume = {327},
year = {2004}
}
@article{Sjoberg2015,
abstract = {This paper presents the design of Zombie, a dependently-typed programming language that uses an adaptation of a congruence closure algorithm for proof and type inference. This algorithm allows the type checker to automatically use equality assumptions from the context when reasoning about equality. Most dependently-typed languages automatically use equalities that follow from beta-reduction during type checking; however, such reasoning is incompatible with congruence closure. In contrast, Zombie does not use automatic beta-reduction because types may contain potentially diverging terms. Therefore Zombie provides a unique opportunity to explore an alternative definition of equivalence in dependently-typed language design. Our work includes the specification of the language via a bidirectional type system, which works "up-to-congruence,'' and an algorithm for elaborating expressions in this language to an explicitly typed core language. We prove that our elaboration algorithm is complete with respect to the source type system, and always produces well typed terms in the core language. This algorithm has been implemented in the Zombie language, which includes general recursion, irrelevant arguments, heterogeneous equality and datatypes.},
author = {Sj{\"{o}}berg, Vilhelm and Weirich, Stephanie},
doi = {10.1145/2775051.2676974},
file = {:Users/liang-tingchen/Dropbox/References/Sj{\"{o}}berg, Weirich - 2015 - Programming up to Congruence.pdf:pdf},
isbn = {9781450333009},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {26,9,and provides a solid,congruence closure,core language,dependent types,entire language and consistency,for the normalizing fragment,foundation,has focused on the,metatheory of the,ombie,prior work on z,type safety for the},
month = {jan},
number = {1},
pages = {369--382},
title = {{Programming up to Congruence}},
url = {http://dl.acm.org/citation.cfm?doid=2775051.2676974},
volume = {50},
year = {2015}
}
@article{Power2000a,
abstract = {We introduce the notion of discrete countable Lawvere V-theory and study constructions that may be made on it. The notion of discrete countable Lawvere V-theory extends that of ordinary countable Lawvere theory by allowing the homsets of an ordinary countable Lawvere theory to become homobjects of a well-behaved axiomatically defined category such as that of $\omega$-cpo's. Every discrete countable Lawvere V-theory induces a V-enriched monad, equivalently a strong monad, on V. We show that discrete countable Lawvere V-theories allow us to model all the leading examples of computational effects other than continuations, and that they are closed under constructions of sum, tensor and distributive tensor, which are the fundamental ways in which one combines such effects. We also show that discrete countable Lawvere V-theories are closed under taking an image, allowing one to treat observation as a mathematical primitive in modelling effects.},
author = {Power, John},
doi = {10.1007/11548133_22},
file = {:Users/liang-tingchen/Dropbox/References/Power - 2000 - Enriched Lawvere theories.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Lawvere theory,Monad},
pages = {83--93},
title = {{Enriched Lawvere theories}},
volume = {6},
year = {2000}
}
@misc{Norell2016,
author = {Norell, Ulf},
month = {jan},
title = {{Agda reflection overhaul}},
url = {https://lists.chalmers.se/pipermail/agda/2016/008414.html},
urldate = {2019-05-23},
year = {2016}
}
@inproceedings{Stucki2015,
abstract = {State-of-the-art immutable collections have wildly differing performance characteristics across their operations, often forcing programmers to choose different collection implementations for each task. Thus, changes to the program can invalidate the choice of collections, making code evolution costly. It would be desirable to have a collection that performs well for a broad range of operations. To this end, we present the RRB-Vector, an immutable sequence collection that offers good performance across a large number of sequential and parallel operations. The underlying innovations are: (1) the Relaxed-Radix-Balanced (RRB) tree structure, which allows efficient structural reorganization, and (2) an optimization that exploits spatio-temporal locality on the RRB data structure in order to offset the cost of traversing the tree. In our benchmarks, the RRB-Vector speedup for parallel operations is lower bounded by 7x when executing on 4 CPUs of 8 cores each. The performance for discrete operations, such as appending on either end, or updating and removing elements, is consistently good and compares favorably to the most important immutable sequence collections in the literature and in use today. The memory footprint of RRB-Vector is on par with arrays and an order of magnitude less than competing collections.},
address = {New York, New York, USA},
author = {Stucki, Nicolas and Rompf, Tiark and Ureche, Vlad and Bagwell, Phil},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming - ICFP 2015},
doi = {10.1145/2784731.2784739},
file = {:Users/liang-tingchen/Dropbox/References/Stucki et al. - 2015 - RRB vector a practical general purpose immutable sequence.pdf:pdf},
isbn = {9781450336697},
issn = {0362-1340},
keywords = {arrays,data structures,immutable,radix-balanced,relaxed-radix-balanced,sequences,trees,vectors},
pages = {342--354},
publisher = {ACM Press},
title = {{RRB vector: a practical general purpose immutable sequence}},
url = {http://dl.acm.org/citation.cfm?doid=2784731.2784739},
volume = {32},
year = {2015}
}
@article{Worrell1999,
abstract = {We consider the behaviour of the terminalsequence of an accessible endofunctor T on a locally presentable category K. The preservation of monics by T is sufficient to imply convergence, necessarily to a terminal coalgebra. We can say much more if K is Set, and $\kappa$ is $\omega$. In that case it is well known that we do not necessarily get convergence at $\omega$, however we show that to ensure convergence we don't need to go to a higher cardinal, just to the next limit ordinal, $\omega$ + $\omega$. For an $\omega$-accessible endofunctor T on Set the construction of the terminal coalgebra can thus be seen as a two stage construction, with each stage being finitary. The first stage obtains the Cauchy completion of the initial T-algebra as the $\omega$-th object in the terminalsequenceA$\omega$. In the second stage this object is pruned to get the final coalgebra A$\omega$+$\omega$. We give an example where A$\omega$ is the solution of the corresponding domain equation in the category of complete ultra-metric spaces.},
author = {Worrell, James},
doi = {10.1016/S1571-0661(05)80267-1},
file = {:Users/liang-tingchen/Dropbox/References/Worrell - 1999 - Terminal sequences for accessible endofunctors.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {24--38},
title = {{Terminal sequences for accessible endofunctors}},
url = {http://dx.doi.org/10.1016/S1571-0661(05)80267-1},
volume = {19},
year = {1999}
}
@inproceedings{Keuchel2013a,
abstract = {Formal reasoning in proof assistants, also known as mechanization, has high development costs. Building modular reusable components is a key issue in reducing these costs. A stumbling block for reuse is that inductive definitions and proofs are closed to extension. This is a manifestation of the expression problem that has been addressed by the Meta-Theory {\`{a}} la Carte (MTC) framework in the context of programming language meta-theory. However, MTC's use of extensible Church-encodings is unsatisfactory. This paper takes a better approach to the problem with datatype-generic programming (DGP). It applies well-known DGP techniques to represent modular datatypes, to build functions from functor algebras with folds and to compose proofs from proof algebras by means of induction. Moreover, for certain functionality and proofs our approach can achieve more reuse than MTC: instead of composing modular components we provide a single generic definition once and for all.},
address = {New York, New York, USA},
author = {Keuchel, Steven and Schrijvers, Tom},
booktitle = {Proceedings of the 9th ACM SIGPLAN workshop on Generic programming - WGP '13},
doi = {10.1145/2502488.2502491},
file = {:Users/liang-tingchen/Dropbox/References/Keuchel, Schrijvers - 2013 - Generic datatypes {\`{a}} la carte.pdf:pdf;:Users/liang-tingchen/Dropbox/References/Keuchel, Schrijvers - 2013 - Generic datatypes {\`{a}} la carte(2).pdf:pdf},
isbn = {9781450323895},
keywords = {Datatype-generic programming,Fixed points,Mechanized meta-theory,Modularity},
pages = {13},
publisher = {ACM Press},
title = {{Generic datatypes {\`{a}} la carte}},
url = {http://dl.acm.org/citation.cfm?doid=2502488.2502491},
year = {2013}
}
@article{Karazeris2007,
author = {Karazeris, Panagis and Velebil, I},
file = {:Users/liang-tingchen/Dropbox/References/Karazeris, Velebil - 2007 - Dense morphisms of monads.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {and phrases,definable operation,locally finitely presentable category,monad morphism},
number = {14},
pages = {372--399},
title = {{Dense morphisms of monads}},
volume = {18},
year = {2007}
}
@inproceedings{Mackie1995,
address = {New York, New York, USA},
author = {Mackie, Ian},
booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '95},
doi = {10.1145/199448.199483},
file = {:Users/liang-tingchen/Dropbox/References/Mackie - 1995 - The geometry of interaction machine.pdf:pdf},
isbn = {0897916921},
issn = {07308566},
pages = {198--208},
publisher = {ACM Press},
title = {{The geometry of interaction machine}},
url = {http://portal.acm.org/citation.cfm?doid=199448.199483},
year = {1995}
}
@article{Bezem2021,
abstract = {We give a new syntax independent definition of the notion of a generalized algebraic theory as an initial object in a category of categories with families (cwfs) with extra structure. To this end we define inductively how to build a valid signature {\$}\backslashSigma{\$} for a generalized algebraic theory and the associated category of cwfs with a {\$}\backslashSigma{\$}-structure and cwf-morphisms that preserve this structure on the nose. Our definition refers to uniform families of contexts, types, and terms, a purely semantic notion. Furthermore, we show how to syntactically construct initial cwfs with {\$}\backslashSigma{\$}-structures. This result can be viewed as a generalization of Birkhoff's completeness theorem for equational logic. It is obtained by extending Castellan, Clairambault, and Dybjer's construction of an initial cwf. We provide examples of generalized algebraic theories for monoids, categories, categories with families, and categories with families with extra structure for some type formers of dependent type theory. The models of these are internal monoids, internal categories, and internal categories with families (with extra structure) in a category with families.},
archivePrefix = {arXiv},
arxivId = {2012.08370},
author = {Bezem, Marc and Coquand, Thierry and Dybjer, Peter and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel},
eprint = {2012.08370},
file = {:Users/liang-tingchen/Dropbox/References/Bezem et al. - 2021 - A Note on Generalized Algebraic Theories and Categories with Families.pdf:pdf},
journal = {ArXiv e-prints},
month = {dec},
title = {{A Note on Generalized Algebraic Theories and Categories with Families}},
url = {http://arxiv.org/abs/2012.08370},
year = {2021}
}
@article{Awodey2013,
abstract = {From a logical point of view, Stone duality for Boolean algebras relates theories in classical propositional logic and their collections of models. The theories can be seen as presentations of Boolean algebras, and the collections of models can be topologized in such a way that the theory can be recovered from its space of models. The situation can be cast as a formal duality relating two categories of syntax and semantics, mediated by homming into a common dualizing object, in this case 2.In the present work, we generalize the entire arrangement from propositional to first-order logic, using a representation result of Butz and Moerdijk. Boolean algebras are replaced by Boolean categories presented by theories in first-order logic, and spaces of models are replaced by topological groupoids of models and their isomorphisms. A duality between the resulting categories of syntax and semantics, expressed primarily in the form of a contravariant adjunction, is established by homming into a common dualizing object, now Sets, regarded once as a boolean category, and once as a groupoid equipped with an intrinsic topology.The overall framework of our investigation is provided by topos theory. Direct proofs of the main results are given, but the specialist will recognize toposophical ideas in the background. Indeed, the duality between syntax and semantics is really a manifestation of that between algebra and geometry in the two directions of the geometric morphisms that lurk behind our formal theory. Along the way, we give an elementary proof of Butz and Moerdijk's result in logical terms. ?? 2012 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {1008.3145},
author = {Awodey, Steve and Forssell, Henrik},
doi = {10.1016/j.apal.2012.10.016},
eprint = {1008.3145},
file = {:Users/liang-tingchen/Dropbox/References/Awodey, Forssell - 2013 - First-order logical duality.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Categorical logic,First-order logic,Topological semantics,Topos theory},
month = {mar},
number = {3},
pages = {319--348},
publisher = {Elsevier B.V.},
title = {{First-order logical duality}},
url = {http://dx.doi.org/10.1016/j.apal.2012.10.016 http://linkinghub.elsevier.com/retrieve/pii/S0168007212001807},
volume = {164},
year = {2013}
}
@article{Antoniou2000a,
abstract = {The importance of transformations and normal forms in logic programming, and generally in computer science, is well documented. This paper investigates transformations and normal forms in the context of Defeasible Logic, a simple but efficient formalism for nonmonotonic reasoning based on rules and priorities. The transformations described in this paper have two main benefits: on one hand they can be used as a theoretical tool that leads to a deeper understanding of the formalism, and on the other hand they have been used in the development of an efficient implementation of defeasible logic.},
archivePrefix = {arXiv},
arxivId = {cs/0003082},
author = {Antoniou, Grigoris and Billington, David and Governatori, Guido and Maher, Michael J.},
doi = {10.1145/371316.371517},
eprint = {0003082},
file = {:Users/liang-tingchen/Dropbox/References/Antoniou et al. - 2001 - Representation results for defeasible logic.pdf:pdf},
issn = {15293785},
journal = {ACM Transactions on Computational Logic},
month = {apr},
number = {2},
pages = {255--287},
primaryClass = {cs},
title = {{Representation results for defeasible logic}},
url = {http://arxiv.org/abs/cs/0003082 http://portal.acm.org/citation.cfm?doid=371316.371517},
volume = {2},
year = {2001}
}
@article{Lucyshyn-Wright2014,
abstract = {In a paper of 1974, Brian Day employed a notion of factorization system in the context of enriched category theory, replacing the usual diagonal lifting property with a corresponding criterion phrased in terms of hom-objects. We set forth the basic theory of such enriched factorization systems. In particular, we establish stability properties for enriched prefactorization systems, we examine the relation of enriched to ordinary factorization systems, and we provide general results for obtaining enriched factorizations by means of wide (co)intersections. As a special case, we prove results on the existence of enriched factorization systems involving enriched strong monomorphisms or strong epimorphisms.},
archivePrefix = {arXiv},
arxivId = {1401.0315},
author = {Lucyshyn-Wright, Rory B. B.},
eprint = {1401.0315},
file = {:Users/liang-tingchen/Dropbox/References/Lucyshyn-Wright - 2014 - Enriched factorization systems.pdf:pdf},
journal = {ArXiv e-prints},
month = {jan},
pages = {1--19},
title = {{Enriched factorization systems}},
url = {http://arxiv.org/abs/1401.0315},
year = {2014}
}
@article{Hughes1989,
author = {Hughes, J.},
doi = {10.1093/comjnl/32.2.98},
file = {:Users/liang-tingchen/Dropbox/References/Hughes - 1989 - Why Functional Programming Matters.pdf:pdf},
issn = {0010-4620},
journal = {The Computer Journal},
month = {feb},
number = {2},
pages = {98--107},
title = {{Why Functional Programming Matters}},
url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/32.2.98},
volume = {32},
year = {1989}
}
@article{Jacobs2010a,
abstract = {Abstract. This paper starts from the elementary observation that what is usually called a predicate lifting in coalgebraic modal logic is in fact an endomap of indexed categories. This leads to a systematic review of basic results in predicate logic for functors and monads , ...},
author = {Jacobs, Bart},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2010 - Predicate logic for functors and monads.pdf:pdf},
journal = {Preprint},
title = {{Predicate logic for functors and monads}},
url = {http://www.cs.ru.nl/{~}bart/PAPERS/predlift-indcat.pdf},
year = {2010}
}
@techreport{Harrison1995,
abstract = {One way to ensure correctness of the inference performed by computer theorem provers is to force all proofs to be done step by step in a simple, more or less traditional, deductive system. Using techniques pioneered in Edinburgh LCF, this can be made palatable. However, some believe such an approach will never be efficient enough for large, complex proofs. One alternative, commonly called reflection, is to analyze proofs using a second layer of logic, a metalogic, and so justify abbreviating or simplifying proofs, making the kinds of shortcuts humans often do or appealing to specialized decision algorithms. In this paper we contrast the fully-expansive LCF approach with the use of reflection. We put forward arguments to suggest that the inadequacy of the LCF approach has not been adequately demonstrated, and neither has the practical utility of reflection (notwithstanding its undoubted intellectual interest). The LCF system with which we are most concerned is the HOL proof assistant. The plan of the paper is as follows. We examine ways of providing user extensibility for theorem provers, which naturally places the LCF and reflective approaches in opposition. A detailed introduction to LCF is provided, emphasizing ways in which it can be made efficient. Next, we present a short introduction to metatheory and its usefulness, and, starting from G{\"{o}}del's proofs and Feferman's transfinite progressions of theories, look at logical `reflection principles'. We show how to introduce computational `reflection principles' which do not extend the power of the logic, but may make deductions in it more efficient, and speculate about their practical usefulness. Applications or proposed applications of computational reflection in theorem proving are surveyed, following which we draw some conclusions. In an appendix, we attempt to clarify a couple of other notions of `reflection' often encountered in the literature. The paper questions the too-easy acceptance of reflection principles as a practical necessity. However I hope it also serves as an adequate introduction to the concepts involved in reflection and a survey of relevant work. To this end, a rather extensive bibliography is provided.},
address = {Cambridge},
author = {Harrison, John},
file = {:Users/liang-tingchen/Dropbox/References/Harrison - 1995 - Metatheory and Reflection in Theorem Proving A Survey and Critique.pdf:pdf},
institution = {SRI Cambridge},
title = {{Metatheory and Reflection in Theorem Proving: A Survey and Critique}},
type = {Technical Report},
url = {http://www.cl.cam.ac.uk/users/jrh/papers.html},
year = {1995}
}
@article{Mannaa2020,
author = {Mannaa, Bassel and M{\o}gelberg, Rasmus Ejlers and Veltri, Niccol{\`{o}}},
doi = {10.23638/LMCS-16(4:17)2020},
file = {:Users/liang-tingchen/Dropbox/References//Mannaa, M{\o}gelberg, Veltri - 2020 - Ticking clocks as dependent right adjoints Denotational semantics for clocked type theory.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {13156,4002-00442,Computer Science - Logic in Computer Science,and by a research,and phrases,by dff-research project 1,coinductive types,denotational,dependent type theory,fnu,for independent research for,from the danish council,from villum,grant,grant no,guarded recursion,modal types,semantics,the natural sciences,this work was supported},
month = {dec},
number = {4},
title = {{Ticking clocks as dependent right adjoints: Denotational semantics for clocked type theory}},
url = {https://lmcs.episciences.org/6980},
volume = {16},
year = {2020}
}
@incollection{Porst1991,
author = {Porst, Hans-E. and Tholen, Walter},
booktitle = {Category Theory at Work},
file = {:Users/liang-tingchen/Dropbox/References/Porst, Tholen - 1991 - Concrete dualities.pdf:pdf},
isbn = {3-88538-218-0},
pages = {111--136},
publisher = {Heldermann Verlag Berlin},
title = {{Concrete dualities}},
type = {Journal article},
year = {1991}
}
@incollection{Wadler2003,
abstract = {John Hughes has made pretty printers one of the prime demonstrations of using combinators to develop a library, and algebra to implement it. This note presents a new design for pretty printers which improves on Hughes's classic design. The new design is based on a single concatenation operator which is associative and has a left and right unit. Hughes's design requires two separate operators for concatenation, where horizontal concatenation has a right unit but no left unit, and vertical concatenation has neither unit.},
author = {Wadler, Philip},
booktitle = {The Fun of Programming},
doi = {10.1007/978-1-349-91518-7_11},
editor = {Gibbons, Jeremy and Moor, Oege De},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 2017 - A prettier printer.pdf:pdf},
publisher = {Bloomsbury Publishing},
series = {Cornerstones of Computing},
title = {{A prettier printer}},
year = {2017}
}
@inproceedings{Yallop2016,
abstract = {Generic programming libraries such as Scrap Your Boilerplate eliminate the need to write repetitive code, but typically introduce significant performance overheads. This leaves programmers with the unfortunate choice of writing succinct but slow programs or writing tedious but efficient programs. We show how to systemat-ically transform an implementation of the Scrap Your Boilerplate library in the multi-stage programming language MetaOCaml to eliminate the overhead, making it possible to combine the benefits of high-level abstract programming with the efficiency of low-level code.},
address = {New York, New York, USA},
author = {Yallop, Jeremy},
booktitle = {Proceedings of the 2016 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation - PEPM 2016},
doi = {10.1145/2847538.2847546},
file = {:Users/liang-tingchen/Dropbox/References/Yallop - 2016 - Staging generic programming.pdf:pdf},
isbn = {9781450340977},
keywords = {Generic programming,ML,MetaOCaml,Multi-stage programming,Partial evaluation},
pages = {85--96},
publisher = {ACM Press},
title = {{Staging generic programming}},
url = {http://dl.acm.org/citation.cfm?doid=2847538.2847546},
year = {2016}
}
@article{Street1987,
author = {Street, Ross},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1987 - Correction to “Fibrations in bicategories”.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {1},
pages = {53--56},
title = {{Correction to “Fibrations in bicategories”}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1987{\_}{\_}28{\_}1{\_}53{\_}0},
volume = {28},
year = {1987}
}
@inproceedings{Lamping1990,
address = {New York, New York, USA},
author = {Lamping, John},
booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '90},
doi = {10.1145/96709.96711},
file = {:Users/liang-tingchen/Dropbox/References/Lamping - 1990 - An algorithm for optimal lambda calculus reduction.pdf:pdf},
isbn = {0897913434},
pages = {16--30},
publisher = {ACM Press},
title = {{An algorithm for optimal lambda calculus reduction}},
url = {http://portal.acm.org/citation.cfm?doid=96709.96711},
year = {1990}
}
@inproceedings{Pientka2019a,
abstract = {We describe a Martin-L$\backslash$"of-style dependent type theory, called Cocon, that allows us to mix the intensional function space that is used to represent higher-order abstract syntax (HOAS) trees with the extensional function space that describes (recursive) computations. We mediate between HOAS representations and computations using contextual modal types. Our type theory also supports an infinite hierarchy of universes and hence supports type-level computation thereby providing metaprogramming and (small-scale) reflection. Our main contribution is the development of a Kripke-style model for Cocon that allows us to prove normalization. From the normalization proof, we derive subject reduction and consistency. Our work lays the foundation to incorporate the methodology of logical frameworks into systems such as Agda and bridges the longstanding gap between these two worlds.},
author = {Pientka, Brigitte and Thibodeau, David and Abel, Andreas and Ferreira, Francisco and Zucchini, Rebecca},
booktitle = {2019 34th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2019.8785683},
file = {:Users/liang-tingchen/Dropbox/References/Pientka et al. - 2019 - A Type Theory for Defining Logics and Proofs.pdf:pdf},
isbn = {978-1-7281-3608-0},
month = {jun},
pages = {1--13},
publisher = {IEEE},
title = {{A Type Theory for Defining Logics and Proofs}},
url = {https://ieeexplore.ieee.org/document/8785683/},
year = {2019}
}
@inproceedings{Fiore2008,
abstract = {The paper develops a mathematical theory in the spirit of categorical algebra that provides a model theory for second-order and dependently-sorted syntax. The theory embodies notions such as $\alpha$-equivalence, variable binding, capture-avoiding simultaneous substitution, term metavariable, meta-substitution, mono and multi sorting, and sort dependency. As a matter of illustration, a model is used to extract a second-order syntactic theory, which is thus guaranteed to be correct by construction. {\textcopyright} 2008 IEEE.},
author = {Fiore, Marcelo},
booktitle = {2008 23rd Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2008.38},
file = {:Users/liang-tingchen/Dropbox/References/Fiore - 2008 - Second-Order and Dependently-Sorted Abstract Syntax.pdf:pdf},
isbn = {978-0-7695-3183-0},
issn = {1043-6871},
month = {jun},
pages = {57--68},
publisher = {IEEE},
title = {{Second-Order and Dependently-Sorted Abstract Syntax}},
url = {http://ieeexplore.ieee.org/document/4557900/},
year = {2008}
}
@article{Tabareau2021,
abstract = {Reasoning modulo equivalences is natural for everyone, including mathematicians. Unfortunately, in proof assistants based on type theory, which are frequently used to mechanize mathematical results and carry out program verification efforts, equality is appallingly syntactic, and as a result, exploiting equivalences is cumbersome at best. Parametricity and univalence are two major concepts that have been explored in the literature to transport programs and proofs across type equivalences, but they fall short of achieving seamless, automatic transport. This work first clarifies the limitations of these two concepts when considered in isolation and then devises a fruitful marriage between both. The resulting concept, called univalent parametricity , is an extension of parametricity strengthened with univalence that fully realizes programming and proving modulo equivalences. Our approach handles both type and term dependency, as well as type-level computation. In addition to the theory of univalent parametricity, we present a lightweight framework implemented in the Coq proof assistant that allows the user to transparently transfer definitions and theorems for a type to an equivalent one, as if they were equal. For instance, this makes it possible to conveniently switch between an easy-to-reason-about representation and a computationally efficient representation as soon as they are proven equivalent. The combination of parametricity and univalence supports transport {\`{a}} la carte : basic univalent transport, which stems from a type equivalence, can be complemented with additional proofs of equivalences between functions over these types, in order to be able to transport more programs and proofs, as well as to yield more efficient terms. We illustrate the use of univalent parametricity on several examples, including a recent integration of native integers in Coq. This work paves the way to easier-to-use proof assistants by supporting seamless programming and proving modulo equivalences.},
archivePrefix = {arXiv},
arxivId = {1909.05027},
author = {Tabareau, Nicolas and Tanter, {\'{E}}ric and Sozeau, Matthieu},
doi = {10.1145/3429979},
eprint = {1909.05027},
file = {:Users/liang-tingchen/Dropbox/References/Tabareau, Tanter, Sozeau - 2021 - The Marriage of Univalence and Parametricity.pdf:pdf},
issn = {0004-5411},
journal = {Journal of the ACM},
keywords = {Coq,Type equivalence,parametricity,proof assistants,univalence},
month = {feb},
number = {1},
pages = {1--44},
title = {{The Marriage of Univalence and Parametricity}},
url = {https://dl.acm.org/doi/10.1145/3429979},
volume = {68},
year = {2021}
}
@inproceedings{Frumin2017,
abstract = {We study different formalizations of finite sets in homotopy type theory to obtain a general definition that exhibits both the computational facilities and the proof principles expected from finite sets. We use higher inductive types to define the type K(A) of " finite sets over type A " {\`{a}} la Kuratowski without assuming A has decidable equality. We show how to define basic functions and prove basic properties, and then we give two applications of our definition. On the foundational side, we use K to define the no-tions of " Kuratowski-finite type " and " Kuratowski-finite subobject " which we contrast with established notions, e.g., Bishop-finite types and enumerated types. We argue that Kuratowski-finiteness is the most general and flexible one of those, and we define the usual operations on finite types and subobjects. From the computational perspective, we show how to use K(A) for an abstract interface for well-known finite set im-plementations such as tree-and list-like data structures. This implies that a function defined on a concrete finite sets im-plementation can be obtained from a function defined on the abstract finite sets K(A), and correctness properties are in-herited. Hence, HoTT is the ideal setting for data refinement. Beside this, we define bounded quantification which lifts a decidable property on A to one on K(A).},
address = {New York, New York, USA},
author = {Frumin, Dan and Geuvers, Herman and Gondelman, L{\'{e}}on and van der Weide, Niels},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs - CPP 2018},
doi = {10.1145/3176245.3167085},
file = {:Users/liang-tingchen/Dropbox/References/Frumin et al. - 2018 - Finite sets in homotopy type theory.pdf:pdf},
isbn = {9781450355865},
keywords = {Coq,acm reference format,and niels van der,coq,dan frumin,finite sets,finite types,herman geuvers,higher inductive types,homotopy type theory,l{\'{e}}on gondelman},
pages = {201--214},
publisher = {ACM Press},
title = {{Finite sets in homotopy type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3176245.3167085},
year = {2018}
}
@article{Seal2013,
abstract = {We exhibit sufficient conditions for a monoidal monad T on a monoidal category C to induce a monoidal structure on the Eilenberg--Moore category C{\^{}}T that represents bimorphisms. The category of actions in C{\^{}}T is then shown to be monadic over the base category C.},
archivePrefix = {arXiv},
arxivId = {1205.0101},
author = {Seal, Gavin J.},
eprint = {1205.0101},
file = {:Users/liang-tingchen/Dropbox/References/Seal - 2013 - Tensors, monads and actions.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Action,Bimorphism,Eilenberg-Moore category,Monad,Monoidal category},
number = {15},
pages = {403--433},
title = {{Tensors, monads and actions}},
volume = {28},
year = {2013}
}
@article{Abel2020,
author = {Abel, Andreas and Bernardy, Jean-Philippe},
doi = {10.1145/3408972},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Bernardy - 2020 - A unified view of modalities in type systems.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {linear types,modal logic,subtyping.},
month = {aug},
number = {ICFP},
pages = {1--28},
title = {{A unified view of modalities in type systems}},
url = {https://dl.acm.org/doi/10.1145/3408972},
volume = {4},
year = {2020}
}
@article{Bonchi2011a,
author = {Bonchi, Filippo and K{\"{o}}nig, Barbara and H{\"{u}}lsbusch, Mathias},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi, K{\"{o}}nig, H{\"{u}}lsbusch - 2011 - A coalgebraic perspective on minimization, determinization and behavioural metrics.pdf:pdf},
pages = {10},
title = {{A coalgebraic perspective on minimization, determinization and behavioural metrics}},
type = {Journal article},
volume = {9},
year = {2011}
}
@article{Cubitt2015,
abstract = {The spectral gap -- the difference in energy between the ground state and the first excited state -- is one of the most important properties of a quantum many-body system. Quantum phase transitions occur when the spectral gap vanishes and the system becomes critical. Much of physics is concerned with understanding the phase diagrams of quantum systems, and some of the most challenging and long-standing open problems in theoretical physics concern the spectral gap, such as the Haldane conjecture that the Heisenberg chain is gapped for integer spin, proving existence of a gapped topological spin liquid phase, or the Yang-Mills gap conjecture (one of the Millennium Prize problems). These problems are all particular cases of the general spectral gap problem: Given a quantum many-body Hamiltonian, is the system it describes gapped or gapless? Here we show that this problem is undecidable, in the same sense as the Halting Problem was proven to be undecidable by Turing. A consequence of this is that the spectral gap of certain quantum many-body Hamiltonians is not determined by the axioms of mathematics, much as Goedels incompleteness theorem implies that certain theorems are mathematically unprovable. We extend these results to prove undecidability of other low temperature properties, such as correlation functions. The proof hinges on simple quantum many-body models that exhibit highly unusual physics in the thermodynamic limit.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.04135v1},
author = {Cubitt, Toby S. and Perez-Garcia, David and Wolf, Michael M.},
doi = {10.1038/nature16059},
eprint = {arXiv:1502.04135v1},
file = {:Users/liang-tingchen/Dropbox/References/Cubitt, Perez-Garcia, Wolf - 2015 - Undecidability of the spectral gap.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
month = {dec},
number = {7581},
pages = {207--211},
pmid = {26659181},
publisher = {Nature Publishing Group},
title = {{Undecidability of the spectral gap}},
url = {http://dx.doi.org/10.1038/nature16059 http://www.nature.com/articles/nature16059},
volume = {528},
year = {2015}
}
@article{Kurz2012a,
author = {Kurz, Alexander and Leal, Raul Andres},
doi = {10.1016/j.tcs.2012.03.027},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Leal - 2012 - Modalities in the stone age A comparison of coalgebraic logics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {apr},
pages = {88--116},
publisher = {Elsevier B.V.},
title = {{Modalities in the stone age: A comparison of coalgebraic logics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397512002885},
volume = {430},
year = {2012}
}
@inproceedings{Atkey2013b,
abstract = {Total functional programming offers the beguiling vision that, just by virtue of the compiler accepting a program, we are guaranteed that it will always terminate. In the case of programs that are not intended to terminate, e.g., servers, we are guaranteed that programs will always be productive. Productivity means that, even if a program generates an infinite amount of data, each piece will be generated in finite time. The theoretical underpinning for productive programming with infinite output is provided by the category theoretic notion of final coalgebras. Hence, we speak of coprogramming with non-well-founded codata, as a dual to programming with wellfounded data like finite lists and trees. Systems that offer facilities for productive coprogramming, such as the proof assistants Coq and Agda, currently do so through syntactic guardedness checkers, which ensure that all self-recursive calls are guarded by a use of a constructor. Such a check ensures productivity. Unfortunately, these syntactic checks are not compositional, and severely complicate coprogramming. Guarded recursion, originally due to Nakano, is tantalising as a basis for a flexible and compositional type-based approach to coprogramming. However, as we show, guarded recursion by itself is not suitable for coprogramming due to the fact that there is no way to make finite observations on pieces of infinite data. In this paper, we introduce the concept of clock variables that index Nakano's guarded recursion. Clock variables allow us to "close over" the generation of infinite codata, and to make finite observations, something that is not possible with guarded recursion alone.},
address = {New York, New York, USA},
author = {Atkey, Robert and McBride, Conor},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500597},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, McBride - 2013 - Productive coprogramming with guarded recursion(2).pdf:pdf},
isbn = {9781450323260},
issn = {0362-1340},
keywords = {Coalgebras,Corecursion,Guarded recursion,Total functional programming},
month = {nov},
number = {9},
pages = {197},
publisher = {ACM Press},
title = {{Productive coprogramming with guarded recursion}},
url = {https://dl.acm.org/doi/10.1145/2544174.2500597 http://dl.acm.org/citation.cfm?doid=2500365.2500597},
volume = {48},
year = {2013}
}
@inproceedings{Møgelberg2014,
address = {New York, New York, USA},
author = {M{\o}gelberg, Rasmus Ejlers},
booktitle = {Proceedings of the Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS) - CSL-LICS '14},
doi = {10.1145/2603088.2603132},
file = {:Users/liang-tingchen/Dropbox/References/M{\o}gelberg - 2014 - A type theory for productive coprogramming via guarded recursion.pdf:pdf},
isbn = {9781450328869},
keywords = {categorical semantics,corecursion,de-,dependent types,guarded recursion,notational semantics},
number = {1},
pages = {1--10},
publisher = {ACM Press},
title = {{A type theory for productive coprogramming via guarded recursion}},
url = {http://dl.acm.org/citation.cfm?doid=2603088.2603132},
year = {2014}
}
@article{Miller2018,
author = {Miller, Dale},
doi = {10.1007/s10817-018-9483-3},
file = {:Users/liang-tingchen/Dropbox/References/Miller - 2018 - Mechanized Metatheory Revisited.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Mechanized metatheory,Mobility of binders,$\lambda$ Tree syntax},
month = {oct},
number = {September},
publisher = {Springer Netherlands},
title = {{Mechanized Metatheory Revisited}},
url = {https://doi.org/10.1007/s10817-018-9483-3 http://link.springer.com/10.1007/s10817-018-9483-3},
year = {2018}
}
@article{Dang2011,
author = {Dang, H.-H. and H{\"{o}}fner, P. and M{\"{o}}ller, B.},
doi = {10.1016/j.jlap.2011.04.003},
file = {:Users/liang-tingchen/Dropbox/References/Dang, H{\"{o}}fner, M{\"{o}}ller - 2011 - Algebraic separation logic.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
month = {aug},
number = {6},
pages = {221--247},
publisher = {Elsevier Inc.},
title = {{Algebraic separation logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832611000142},
volume = {80},
year = {2011}
}
@incollection{Barr1970,
author = {Barr, Michael},
booktitle = {Reports of the Midwest Category Seminar IV},
doi = {10.1007/BFb0060439},
editor = {{Mac Lane}, Saunders and Applegate, H. and Barr, Michael and Day, B. and Dubuc, Eduardo J. and Phreilambud and Pultr, A. and Street, Ross and Tierney, M. and Swierczkowski, S.},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1970 - Relational algebras.pdf:pdf},
isbn = {978-3-540-04926-5},
pages = {39--55},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Relational algebras}},
year = {1970}
}
@incollection{Mellies2006,
abstract = {String diagrams were introduced by Roger Penrose as a handy notation to manipulate morphisms in a monoidal category. In principle, this graphical notation should encompass the various pictorial systems introduced in proof-theory (like Jean-Yves Girard's proof-nets) and in concurrency theory (like Robin Milner's bigraphs). This is not the case however, at least because string diagrams do not accomodate boxes -- a key ingredient in these pictorial systems. In this short tutorial, based on our accidental rediscovery of an idea by Robin Cockett and Robert Seely, we explain how string diagrams may be extended with a notion of functorial box to depict a functor separating an inside world (its source category) from an outside world (its target category). We expose two elementary applications of the notation: first, we characterize graphically when a faithful balanced monoidal functor C -{\textgreater} D transports a trace operator from the category D to the category C, and we then exploit this to construct well-behaved fixpoint operators in cartesian closed categories generated by models of linear logic; second, we explain how the categorical semantics of linear logic induces that the exponential box of proof-nets decomposes as two enshrined functorial boxes.},
author = {Melli{\`{e}}s, Paul-Andr{\'{e}}},
booktitle = {Computer Science Logic. CSL 2006},
doi = {10.1007/11874683_1},
editor = {{\'{E}}sik, Zolt{\'{a}}n},
file = {:Users/liang-tingchen/Dropbox/References/Melli{\`{e}}s - 2006 - Functorial Boxes in String Diagrams.pdf:pdf},
isbn = {978-3-540-45458-8},
issn = {03029743},
pages = {1--30},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Functorial Boxes in String Diagrams}},
url = {http://link.springer.com/10.1007/11874683{\_}1},
volume = {4207},
year = {2006}
}
@inproceedings{Magalhaes2010,
abstract = {Datatype-generic programming increases program reliability by reducing code duplication and enhancing reusability and modularity. Several generic programming libraries for Haskell have been developed in the past few years. These libraries have been compared in detail with respect to expressiveness, extensibility, typing issues, etc., but performance comparisons have been brief, limited, and preliminary. It is widely believed that generic programs run slower than hand-written code. In this paper we present an extensive benchmark suite for generic functions and analyze the potential for automatic code optimization at compilation time. Our benchmark confirms that generic programs, when compiled with the standard optimization flags of the Glasgow Haskell Compiler (GHC), are substantially slower than their hand-written counterparts. However, we also find that more advanced optimization capabilities of GHC can be used to further optimize generic functions, sometimes achieving the same efficiency as hand-written code. Copyright {\textcopyright} 2010 ACM.},
address = {New York, New York, USA},
author = {Magalh{\~{a}}es, Jos{\'{e}} Pedro and Holdermans, Stefan and Jeuring, Johan and L{\"{o}}h, Andres},
booktitle = {Proceedings of the ACM SIGPLAN 2010 workshop on Partial evaluation and program manipulation - PEPM '10},
doi = {10.1145/1706356.1706366},
file = {:Users/liang-tingchen/Dropbox/References/Magalh{\~{a}}es et al. - 2010 - Optimizing generics is easy!.pdf:pdf},
isbn = {9781605587271},
keywords = {Benchmark,Functional programming,Generic programming,Haskell,Optimization},
pages = {33},
publisher = {ACM Press},
title = {{Optimizing generics is easy!}},
url = {http://portal.acm.org/citation.cfm?doid=1706356.1706366},
year = {2010}
}
@article{Kissig2011,
abstract = {We combine previous work on coalgebraic logic with the coalgebraic traces semantics of Hasuo, Jacobs, and Sokolova.},
archivePrefix = {arXiv},
arxivId = {1103.3239},
author = {Kissig, Christian and Kurz, Alexander},
eprint = {1103.3239},
file = {:Users/liang-tingchen/Dropbox/References/Kissig, Kurz - 2011 - Generic trace logics.pdf:pdf},
journal = {ArXiv e-prints},
month = {mar},
title = {{Generic trace logics}},
url = {http://arxiv.org/abs/1103.3239},
year = {2011}
}
@incollection{Johann2007,
abstract = {Initial algebra semantics is a cornerstone of the theory of modern functional programming languages. For each inductive data type, it provides a fold combinator encapsulating structured recursion over data of that type, a Church encoding, a build combinator which constructs data of that type, and a fold/build rule which optimises modular programs by eliminating intermediate data of that type. It has long been thought that initial algebra semantics is not expressive enough to provide a similar foundation for programming with nested types. Specifically, the folds have been considered too weak to capture commonly occurring patterns of recursion, and no Church encodings, build combinators, or fold/build rules have been given for nested types. This paper overturns this conventional wisdom by solving all of these problems. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Johann, Patricia and Ghani, Neil},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2007},
doi = {10.1007/978-3-540-73228-0_16},
editor = {Rocca, Simona Ronchi},
file = {:Users/liang-tingchen/Dropbox/References/Johann, Ghani - 2007 - Initial Algebra Semantics Is Enough!.pdf:pdf},
isbn = {9783540732273},
issn = {16113349},
number = {16},
pages = {207--222},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Initial Algebra Semantics Is Enough!}},
url = {http://link.springer.com/10.1007/978-3-540-73228-0{\_}16},
volume = {4583},
year = {2007}
}
@article{Moss1999,
author = {Moss, Lawrence S.},
doi = {10.1016/S0168-0072(98)00042-6},
file = {:Users/liang-tingchen/Dropbox/References/Moss - 1999 - Coalgebraic logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
number = {1-3},
pages = {277--317},
title = {{Coalgebraic logic}},
type = {Journal article},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168007298000426},
volume = {96},
year = {1999}
}
@incollection{Boyd1994,
abstract = {In the past few years a lot of attention has been paid to the use of special logics to analyse cryptographic protocols, foremost among these being the logic of Burrows, Abadi and Needham (the BAN logic). These logics have been successful in finding weaknesses in various examples. In this paper a limitation of the BAN logic is illustrated with two examples. These show that it is easy for the BAN logic to approve protocols that are in practice unsound.},
address = {Berlin, Heidelberg},
author = {Boyd, Colin and Mao, Wenbo},
booktitle = {Advances in Cryptology — EUROCRYPT '93},
doi = {10.1007/3-540-48285-7_20},
file = {:Users/liang-tingchen/Dropbox/References/Boyd, Mao - 1994 - On a Limitation of BAN Logic.pdf:pdf},
isbn = {978-3-540-57600-6 978-3-540-48285-7},
pages = {240--247},
publisher = {Springer Berlin Heidelberg},
title = {{On a Limitation of BAN Logic}},
url = {http://www.springerlink.com/content/g7431hcxpwq8f43v http://link.springer.com/10.1007/3-540-48285-7{\_}20},
volume = {765},
year = {1994}
}
@article{Troelstra1977,
author = {Troelstra, Anne Sjerp},
doi = {10.1016/1385-7258(77)90060-9},
file = {:Users/liang-tingchen/Dropbox/References/Troelstra - 1977 - A note on non-extensional operations in connection with continuity and recursiveness.pdf:pdf},
issn = {13857258},
journal = {Indagationes Mathematicae (Proceedings)},
number = {5},
pages = {455--462},
title = {{A note on non-extensional operations in connection with continuity and recursiveness}},
url = {https://linkinghub.elsevier.com/retrieve/pii/1385725877900609},
volume = {80},
year = {1977}
}
@article{Goguen1975,
abstract = {This paper develops a minimal realization theory for discrete-time machines with structure in a suitable closed monoidal category. By specifying the category a number of applications arise, most of them new. Minimal realization is stated as an adjunction between an input-output behavior functor and a realization functor. The very existence of an adjunction yields several new structural results on minimal realization. As preliminaries, certain aspects of categorical algebra are reviewed, and a theory of discrete-time transition systems is developed. The concept of an X-module and an initial object theorem are especially important. A number of examples of suitable categories is given, but discussion of the resulting machine theories is deferred to a subsequent paper. {\textcopyright} 1975 Academic Press, Inc.},
author = {Goguen, J. a.},
doi = {10.1016/S0022-0000(75)80012-2},
file = {:Users/liang-tingchen/Dropbox/References/Goguen - 1975 - Discrete-time machines in closed monoidal categories. I.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
pages = {1--43},
title = {{Discrete-time machines in closed monoidal categories. I}},
volume = {10},
year = {1975}
}
@article{Hinze2006,
abstract = {We introduce 2-3 finger trees, a functional representation of persistent sequences supporting access to the ends in amortized constant time, and concatenation and splitting in time logarithmic in the size of the smaller piece. Representations achieving these bounds have appeared previously, but 2-3 finger trees are much simpler, as are the operations on them. Further, by defining the split operation in a general form, we obtain a general purpose data structure that can serve as a sequence, priority queue, search tree, priority search queue and more.},
author = {Hinze, Ralf and Paterson, Ross},
doi = {10.1017/S0956796805005769},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Paterson - 2006 - Finger trees A simple general-purpose data structure.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
number = {2},
pages = {197--217},
title = {{Finger trees: A simple general-purpose data structure}},
volume = {16},
year = {2006}
}
@incollection{Abel2011,
author = {Abel, Andreas M.},
booktitle = {Foundations of Software Science and Computational Structures. FoSSaCS 2011},
doi = {10.1007/978-3-642-19805-2_5},
editor = {Hofmann, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2011 - Irrelevance in Type Theory with a Heterogeneous Equality Judgement.pdf:pdf},
isbn = {9783642198045},
issn = {03029743},
keywords = {algorithmic equality,dependent types,heterogeneously typed equality,logical relation,proof irrelevance,universal Kripke model},
pages = {57--71},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Irrelevance in Type Theory with a Heterogeneous Equality Judgement}},
url = {http://link.springer.com/10.1007/978-3-642-19805-2{\_}5},
volume = {6604},
year = {2011}
}
@article{Brady2013,
author = {Brady, Edwin},
doi = {10.1145/2544174.2500581},
file = {:Users/liang-tingchen/Dropbox/References/Brady - 2013 - Programming and reasoning with algebraic effects and dependent types.pdf:pdf},
isbn = {9781450323260},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {algebraic effects,and hence be built,dependent types,difficulties,however,i,monad using the statet,o,the order in which,this can create,transformed into a state,transformer,transformers are applied matters,with an io monad},
month = {nov},
number = {9},
pages = {133--144},
title = {{Programming and reasoning with algebraic effects and dependent types}},
url = {http://dl.acm.org/citation.cfm?doid=2544174.2500581},
volume = {48},
year = {2013}
}
@inproceedings{Berardi2017,
abstract = {A cyclic proof system, called CLKID-omega, gives us another way of representing inductive definitions and efficient proof search. The 2011 paper by Brotherston and Simpson showed that the provability of CLKID-omega includes the provability of the classical system of Martin-Lof's inductive definitions, called LKID, and conjectured the equivalence. By this year the equivalence has been left an open question. In general, the conjecture was proved to be false in FoSSaCS 2017 paper by Berardi and Tatsuta. However, if we restrict both systems to only the natural number inductive predicate and add Peano arithmetic to both systems, the conjecture was proved to be true in FoSSaCS 2017 paper by Simpson. This paper shows that if we add arithmetic to both systems, they become equivalent, namely, the conjecture holds. The result of this paper includes that of the paper by Simpson as a special case. In order to construct a proof of LKID for a given cyclic proof, this paper shows every bud in the cyclic proof is provable in LKID, by cutting the cyclic proof into subproofs such that in each subproof the conclusion is a companion and the assumptions are buds. The global trace condition gives some induction principle, by using an extension of Podelski-Rybalchenko termination theorem from well-foundedness to induction schema. In order to prove this extension, this paper also shows that infinite Ramsey theorem is formalizable in Peano arithmetic.},
author = {Berardi, Stefano and Tatsuta, Makoto},
booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2017.8005114},
file = {:Users/liang-tingchen/Dropbox/References/Berardi, Tatsuta - 2017 - Equivalence of inductive definitions and cyclic proofs under arithmetic.pdf:pdf},
isbn = {978-1-5090-3018-7},
issn = {10436871},
month = {jun},
pages = {1--12},
publisher = {IEEE},
title = {{Equivalence of inductive definitions and cyclic proofs under arithmetic}},
url = {http://ieeexplore.ieee.org/document/8005114/},
year = {2017}
}
@article{Roelleke2008,
abstract = {This paper presents a probabilistic relational modelling (implementation) of the major probabilistic retrieval models. Such a high-level implementation is useful since it supports the ranking of any object, it allows for the reasoning across structured and unstructured data, and it gives the software (knowledge) engineer control over ranking and thus supports customisation. The contributions of this paper include the specification of probabilistic SQL (PSQL) and probabilistic relational algebra (PRA), a new relational operator for probability estimation (the relational Bayes), the probabilistic relational modelling of retrieval models, a comparison of modelling retrieval with traditional SQL versus modelling retrieval with PSQL, and a comparison of the performance of probability estimation with traditional SQL versus PSQL. The main findings are that the PSQL/PRA paradigm allows for the description of advanced retrieval models, is suitable for solving large-scale retrieval tasks, and outperforms traditional SQL in terms of abstraction and performance regarding probability estimation.},
author = {Roelleke, Thomas and Wu, Hengzhi and Wang, Jun and Azzam, Hany},
doi = {10.1007/s00778-007-0073-y},
file = {:Users/liang-tingchen/Dropbox/References/Roelleke et al. - 2008 - Modelling retrieval models in a probabilistic relational algebra with a new operator the relational Bayes.pdf:pdf},
issn = {1066-8888},
journal = {The VLDB Journal},
keywords = {DB + IR integration,Probabilistic databases,Probabilistic relational modelling,Retrieval models},
month = {nov},
number = {1},
pages = {5--37},
title = {{Modelling retrieval models in a probabilistic relational algebra with a new operator: the relational Bayes}},
url = {http://link.springer.com/10.1007/s00778-007-0073-y},
volume = {17},
year = {2008}
}
@incollection{Aydemir2007,
author = {Aydemir, Brian and Bohannon, Aaron and Weirich, Stephanie},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/j.entcs.2007.01.028},
file = {:Users/liang-tingchen/Dropbox/References/Aydemir, Bohannon, Weirich - 2007 - Nominal Reasoning Techniques in Coq.pdf:pdf},
issn = {15710661},
keywords = {coq,nominal reasoning techniques,variable binding},
month = {jun},
number = {5},
pages = {69--77},
title = {{Nominal Reasoning Techniques in Coq}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066107002320},
volume = {174},
year = {2007}
}
@article{Biering2007,
author = {Biering, Bodil and Birkedal, Lars and Torp-Smith, Noah},
doi = {10.1145/1275497.1275499},
file = {:Users/liang-tingchen/Dropbox/References/Biering, Birkedal, Torp-Smith - 2007 - BI-hyperdoctrines, higher-order separation logic, and abstraction.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
month = {aug},
number = {5},
pages = {24--es},
title = {{BI-hyperdoctrines, higher-order separation logic, and abstraction}},
url = {http://portal.acm.org/citation.cfm?doid=1275497.1275499},
volume = {29},
year = {2007}
}
@book{Baier2008,
author = {Baier, Christel and Katoen, Joost-Pieter},
isbn = {9780262026499},
pages = {984},
publisher = {MIT Press},
series = {Computer Science and Intelligent Systems},
title = {{Principles of Model Checking}},
year = {2008}
}
@article{DiNola2005,
abstract = {We define the entropy, lower and upper entropy, and the conditional entropy of a dynamical system consisting of an effect algebra with the Riesz decomposition property, a state, and a transformation. Such effect algebras allow many refinements of two partitions. We present the basic properties of these entropies and these notions are illustrated by many examples. Entropy on MV-algebras is postponed to Part II.},
author = {{Di Nola}, Antonio and Dvure{\v{c}}enskij, Anatolij and Hy{\v{c}}ko, Marek and Manara, Corrado},
file = {:Users/liang-tingchen/Dropbox/References/Di Nola et al. - 2005 - Entropy on effect algebras with the Riesz decomposition property I Basic properties.pdf:pdf},
journal = {Kybernetika},
number = {2},
pages = {143--160},
title = {{Entropy on effect algebras with the Riesz decomposition property I: Basic properties}},
url = {https://dml.cz/handle/10338.dmlcz/135647},
volume = {41},
year = {2005}
}
@inproceedings{Ahrens2017,
abstract = {We introduce and develop the notion of displayed categories. A displayed category over a category C is equivalent to 'a category D and functor F : D → C', but instead of having a single collection of 'objects of D' with a map to the objects of C, the objects are given as a family indexed by objects of C, and similarly for the morphisms. This encapsulates a common way of building categories in practice, by starting with an existing category and adding extra data/properties to the objects and morphisms. The interest of this seemingly trivial reformulation is that various properties of functors are more naturally defined as properties of the corresponding displayed categories. Grothendieck fibrations, for example, when defined as certain functors, use equality on objects in their definition. When defined instead as certain displayed categories, erence to equality on objects is required. Moreover, almost all examples of fibrations in nature are, in fact, categories whose standard construction can be seen as going via displayed categories. We therefore propose displayed categories as a basis for the development of fibrations in the type-Theoretic setting, and similarly for various other notions whose classical definitions involve equality on objects. Besides giving a conceptual clarification of such issues, displayed categories also provide a powerful tool in computer formalisation, unifying and abstracting common constructions and proof techniques of category theory, and enabling modular reasoning about categories of multicomponent structures. As such, most of the material of this article has been formalised in Coq over the UniMath library, with the aim of providing a practical library for use in further developments.},
archivePrefix = {arXiv},
arxivId = {1705.04296},
author = {Ahrens, Benedikt and Lumsdaine, Peter Le Fanu},
booktitle = {2nd International Conference on Formal Structures for Computation and Deduction (FSCD 2017)},
doi = {10.4230/LIPIcs.FSCD.2017.5},
editor = {Miller, Dale},
eprint = {1705.04296},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Lumsdaine - 2017 - Displayed categories.pdf:pdf},
isbn = {9783959770477},
issn = {18688969},
keywords = {Category theory,Computer proof assistants,Coq,Dependent type theory,Univalent mathematics},
pages = {5:1----5:16},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Displayed categories}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/7722/},
volume = {84},
year = {2017}
}
@article{Hyland2017a,
abstract = {Recent developments in the categorical foundations of universal algebra have given an impetus to an understanding of the lambda calculus coming from categorical logic: an interpretation is a semi-closed algebraic theory. Scott's representation theorem is then completely natural and leads to a precise Fundamental Theorem showing the essential equivalence between the categorical and more familiar notions.},
archivePrefix = {arXiv},
arxivId = {1211.5762},
author = {Hyland, J. M. E.},
doi = {10.1017/S0960129515000377},
eprint = {1211.5762},
file = {:Users/liang-tingchen/Dropbox/References/Hyland - 2017 - Classical lambda calculus in modern dress(2).pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {5},
pages = {762--781},
title = {{Classical lambda calculus in modern dress}},
url = {https://www.cambridge.org/core/product/identifier/S0960129515000377/type/journal{\_}article},
volume = {27},
year = {2017}
}
@article{Adamek2010b,
abstract = {Sifted colimits, important for algebraic theories, are “almost” just the combination of filtered colimits and reflexive coequalizers. For example, given a finitely cocomplete category A, then a functor with domain A preserves sifted colimits iff it preserves filtered colimits and reflexive coequalizers. But for general categories A that statement is not true: we provide a counter-example.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}} and Vitale, Enrico M.},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}}, Vitale - 2010 - What are sifted colimits.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {and phrases,filtered colimit,reflexive coequalizer,sifted colimit},
number = {13},
pages = {251--260},
title = {{What are sifted colimits?}},
url = {http://www.tac.mta.ca/tac/volumes/23/13/23-13abs.html},
volume = {23},
year = {2010}
}
@article{Selinger2011,
abstract = {This article is intended as a reference guide to various notions of monoidal categories and their associated string diagrams. It is hoped that this will be useful not just to mathematicians, but also to physicists, computer scientists, and others who use diagrammatic reasoning. We have opted for a somewhat informal treatment of topological notions, and have omitted most proofs. Nevertheless, the exposition is sufficiently detailed to make it clear what is presently known, and to serve as a starting place for more in-depth study. Where possible, we provide pointers to more rigorous treatments in the literature. Where we include results that have only been proved in special cases, we indicate this in the form of caveats.},
archivePrefix = {arXiv},
arxivId = {0908.3347},
author = {Selinger, Peter},
doi = {10.1007/978-3-642-12821-9_4},
eprint = {0908.3347},
file = {:Users/liang-tingchen/Dropbox/References/Selinger - 2011 - A survey of graphical languages for monoidal categories.pdf:pdf},
isbn = {9783642128202},
issn = {00758450},
journal = {Lecture Notes in Physics},
pages = {289--355},
title = {{A survey of graphical languages for monoidal categories}},
volume = {813},
year = {2011}
}
@inproceedings{Cohen2015,
abstract = {This paper presents a type theory in which it is possible to directly manipulate {\$}n{\$}-dimensional cubes (points, lines, squares, cubes, etc.) based on an interpretation of dependent type theory in a cubical set model. This enables new ways to reason about identity types, for instance, function extensionality is directly provable in the system. Further, Voevodsky's univalence axiom is provable in this system. We also explain an extension with some higher inductive types like the circle and propositional truncation. Finally we provide semantics for this cubical type theory in a constructive meta-theory.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (Cubical Type Theory: A Constructive Interpretation of the Univalence Axiom - Cohen, Cyril; Coquand, Thierry; Huber, Simon; M{\"{o}}rtberg, Anders)

Keywords: univalence axiom, dependent type theory, cubical sets},
archivePrefix = {arXiv},
arxivId = {1611.02108},
author = {Cohen, Cyril and Coquand, Thierry and Huber, Simon and M{\"{o}}rtberg, Anders},
booktitle = {21st International Conference on Types for Proofs and Programs (TYPES 2015)},
doi = {10.4230/LIPIcs.TYPES.2015.5},
editor = {Uustalu, Tarmo},
eprint = {1611.02108},
file = {:Users/liang-tingchen/Dropbox/References//Cohen et al. - 2015 - Cubical Type Theory A Constructive Interpretation of the Univalence Axiom.pdf:pdf},
isbn = {978-3-95977-030-9},
issn = {1868-8969},
keywords = {2015,4230,5,and phrases univalence axiom,cubical sets,dependent type theory,digital object identifier 10,lipics,types},
number = {5},
pages = {5:1----5:34},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Cubical Type Theory: A Constructive Interpretation of the Univalence Axiom}},
url = {http://arxiv.org/abs/1611.02108 http://drops.dagstuhl.de/opus/volltexte/2018/8475},
volume = {69},
year = {2015}
}
@inproceedings{Pfenning2002a,
abstract = {We develop a uniform type theory that integrates intensionality,$\backslash$nextensionality and proof irrelevance as judgmental concepts. Any object$\backslash$nmay be treated intensionally (subject only to {\&}alpha;-conversion),$\backslash$nextensionally (subject also to {\&}beta;{\&}eta;-conversion), or as irrelevant$\backslash$n(equal to any other object at the same type), depending on where it$\backslash$noccurs. Modal restrictions developed by R. Harper et al. (2000) for$\backslash$nsingle types are generalized and employed to guarantee consistency$\backslash$nbetween these views of objects. Potential applications are in logical$\backslash$nframeworks, functional programming and the foundations of first-order$\backslash$nmodal logics. Our type theory contrasts with previous approaches that, a$\backslash$npriori, distinguished propositions (whose proofs are all identified -$\backslash$nonly their existence is important) from specifications (whose$\backslash$nimplementations are subject to some definitional equalities)},
author = {Pfenning, Frank},
booktitle = {Proceedings 16th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2001.932499},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning - 2002 - Intensionality, extensionality, and proof irrelevance in modal type theory.pdf:pdf},
isbn = {0-7695-1281-X},
pages = {221--230},
publisher = {IEEE Comput. Soc},
title = {{Intensionality, extensionality, and proof irrelevance in modal type theory}},
url = {http://ieeexplore.ieee.org/document/932499/},
year = {2002}
}
@article{Hohle2014,
author = {H{\"{o}}hle, Ulrich},
doi = {10.1016/j.fss.2013.03.010},
file = {:Users/liang-tingchen/Dropbox/References/H{\"{o}}hle - 2014 - Categorical foundations of topology with applications to quantaloid enriched topological spaces.pdf:pdf},
issn = {0165-0114},
journal = {Fuzzy Sets and Systems},
keywords = {-algebra,Categorical neighborhood axiom,Lower separation axiom,Many valued topology,Non-commutative topology,Ordered monad,Quantaloid enriched category,Quantaloid-enriched topology,Regularity,Smooth Borel probability measure,Spectrum of C*-algebra,categorical neighborhood axiom,lower separation axiom,many valued topology,non-commutative topology,ordered monad,quantaloid enriched category,quantaloid-enriched topology,regularity,smooth borel probability measure,spectrum of c},
pages = {166--210},
publisher = {Elsevier},
title = {{Categorical foundations of topology with applications to quantaloid enriched topological spaces}},
url = {http://dx.doi.org/10.1016/j.fss.2013.03.010},
volume = {256},
year = {2014}
}
@article{Jaffar1994,
author = {Jaffar, Joxan and Maher, Michael J.},
doi = {10.1016/0743-1066(94)90033-7},
file = {:Users/liang-tingchen/Dropbox/References/Jaffar, Maher - 1994 - Constraint logic programming a survey.pdf:pdf},
issn = {07431066},
journal = {The Journal of Logic Programming},
month = {may},
number = {May 1993},
pages = {503--581},
title = {{Constraint logic programming: a survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0743106694900337},
volume = {19-20},
year = {1994}
}
@inproceedings{Fiore1999,
address = {Trento},
author = {Fiore, Marcelo P. and Plotkin, Gordon D. and Turi, Daniele},
booktitle = {Proceedings. 14th Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1999.782615},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Plotkin, Turi - 1999 - Abstract syntax and variable binding.pdf:pdf},
isbn = {0-7695-0158-3},
pages = {193--202},
publisher = {IEEE Comput. Soc},
title = {{Abstract syntax and variable binding}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=782615},
year = {1999}
}
@article{Launchbury1994,
abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language. The security of the encapsulation is assured by the type system, using parametricity. Intriguingly, this parametricity requires the provision of a (single) constant with a rank-2 polymorphic type.},
author = {Launchbury, John and {Peyton Jones}, Simon L.},
doi = {10.1145/773473.178246},
file = {:Users/liang-tingchen/Dropbox/References/Launchbury, Peyton Jones - 1994 - Lazy functional state threads.pdf:pdf},
isbn = {089791662X},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {jun},
number = {6},
pages = {24--35},
title = {{Lazy functional state threads}},
url = {http://portal.acm.org/citation.cfm?doid=773473.178246},
volume = {29},
year = {1994}
}
@article{Evfimievski2010,
abstract = {We present a novel definition of privacy in the framework of offline (retroactive) database query auditing. Given information about the database, a description of sensitive data, and assumptions about users' prior knowledge, our goal is to determine if answering a past user's query could have led to a privacy breach. According to our definition, an audited property A is private, given the disclosure of property B, if no user can gain confidence in A by learning B, subject to prior knowledge constraints. Privacy is not violated if the disclosure of B causes a loss of confidence in A. The new notion of privacy is formalized using the well-known semantics for reasoning about knowledge, where logical properties correspond to sets of possible worlds (databases) that satisfy these properties. Database users are modelled as either possibilistic agents whose knowledge is a set of possible worlds, or as probabilistic agents whose knowledge is a probability distribution on possible worlds. We analyze the new privacy notion, show its relationship with the conventional approach, and derive criteria that allow the auditor to test privacy efficiently in some important cases. In particular, we prove characterization theorems for the possibilistic case, and study in depth the probabilistic case under the assumption that all database records are considered a-priori independent by the user, as well as under more relaxed (or absent) prior-knowledge assumptions. In the probabilistic case we show that for certain families of distributions there is no efficient algorithm to test whether an audited property A is private given the disclosure of a property B, assuming P NP. Nevertheless, for many interesting families, such as the family of product distributions, we obtain algorithms that are efficient both in theory and in practice.},
author = {Evfimievski, Alexandre and Fagin, Ronald and Woodruff, David},
doi = {10.1145/1870103.1870105},
file = {:Users/liang-tingchen/Dropbox/References/Evfimievski, Fagin, Woodruff - 2010 - Epistemic privacy.pdf:pdf},
isbn = {9781605581088},
issn = {00045411},
journal = {Journal of the ACM},
month = {dec},
number = {1},
pages = {1--45},
title = {{Epistemic privacy}},
url = {http://portal.acm.org/citation.cfm?doid=1870103.1870105},
volume = {58},
year = {2010}
}
@inproceedings{Uemura2019,
abstract = {We construct a model of cubical type theory with a univalent and impredicative universe in a category of cubical assemblies. We show that this impredicative universe in the cubical assembly model does not satisfy a form of propositional resizing.},
archivePrefix = {arXiv},
arxivId = {1803.06649},
author = {Uemura, Taichi},
booktitle = {24th International Conference on Types for Proofs and Programs (TYPES 2018)},
doi = {10.4230/LIPIcs.TYPES.2018.7},
editor = {Dybjer, Peter and Santo, José Espírito and Pinto, Luís},
eprint = {1803.06649},
file = {:Users/liang-tingchen/Dropbox/References/Uemura - 2019 - Cubical assemblies, a univalent and impredicative universe and a failure of propositional resizing.pdf:pdf},
isbn = {9783959771061},
issn = {18688969},
keywords = {Cubical type theory,Impredicative universe,Propositional resizing,Realizability,Univalence},
number = {7},
pages = {7:1----7:20},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Cubical assemblies, a univalent and impredicative universe and a failure of propositional resizing}},
volume = {130},
year = {2019}
}
@article{Frankowski2006,
abstract = {Main investigations concerning Kripke models refer to two valued case. The papers devoted to many-valued modal logics do not contain even elementary theory of appropriate models. This paper provides very general notion of many valued Kripke model for every standard multimodality, and displays the suitable generalizations of the ideas known from the classical case: disjoint sum of Kripke models, bounded morphism (sometimes called p-morphism), bisimulation.},
author = {Frankowski, Szymon},
file = {:Users/liang-tingchen/Dropbox/References/Frankowski - 2006 - General approach to many valued Kripke models.pdf:pdf},
journal = {Bulletin of the Section of Logic},
number = {1},
pages = {11--26},
title = {{General approach to many valued Kripke models}},
url = {http://www.filozof.uni.lodz.pl/bulletin/pdf/35{\_}1{\_}2.pdf},
volume = {35},
year = {2006}
}
@inproceedings{Atkey2014,
abstract = {Reynolds' theory of relational parametricity captures the invariance of polymorphically typed programs under change of data representation. Reynolds' original work exploited the typing discipline of the polymorphically typed lambda-calculus System F, but there is now considerable interest in extending relational parametricity to type systems that are richer and more expressive than that of System F. This paper constructs parametric models of predicative and impredicative dependent type theory. The significance of our models is twofold. Firstly, in the impredicative variant we are able to deduce the existence of initial algebras for all indexed=functors. To our knowledge, ours is the first account of parametricity for dependent types that is able to lift the useful deduction of the existence of initial algebras in parametric models of System F to the dependently typed setting. Secondly, our models offer conceptual clarity by uniformly expressing relational parametricity for dependent types in terms of reflexive graphs, which allows us to unify the interpretations of types and kinds, instead of taking the relational interpretation of types as a primitive notion. Expressing our model in terms of reflexive graphs ensures that it has canonical choices for the interpretations of the standard type constructors of dependent type theory, except for the interpretation of the universe of small types, where we formulate a refined interpretation tailored for relational parametricity. Moreover, our reflexive graph model opens the door to generalisations of relational parametricity, for example to higher-dimensional relational parametricity.},
address = {New York, New York, USA},
author = {Atkey, Robert and Ghani, Neil and Johann, Patricia},
booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL '14},
doi = {10.1145/2535838.2535852},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, Ghani, Johann - 2014 - A relationally parametric model of dependent type theory.pdf:pdf},
isbn = {9781450325448},
keywords = {but there is now,cally typed $\lambda$ -calculus,considerable in-,languages,original work exploited the,polymorphi-,system f,theory,types,typing discipline of the},
pages = {503--515},
publisher = {ACM Press},
title = {{A relationally parametric model of dependent type theory}},
url = {http://dl.acm.org/citation.cfm?doid=2535838.2535852},
year = {2014}
}
@article{Altenkirch2017,
abstract = {We develop normalisation by evaluation (NBE) for dependent types based on presheaf categories. Our construction is formulated in the metalanguage of type theory using quotient inductive types. We use a typed presentation hence there are no preterms or realizers in our construction, and every construction respects the conversion relation. NBE for simple types uses a logical relation between the syntax and the presheaf interpretation. In our construction, we merge the presheaf interpretation and the logical relation into a proof-relevant logical predicate. We prove normalisation, completeness, stability and decidability of definitional equality. Most of the constructions were formalized in Agda.},
author = {Altenkirch, Thorsten and Kaposi, Ambrus},
doi = {10.23638/LMCS-13(4:1)2017},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Kaposi - 2017 - Normalisation by evaluation for type theory, in type theory.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Agda,Dependent types,Internal type theory,Logical relations,Normalisation by evaluation},
number = {4},
pages = {1--26},
title = {{Normalisation by evaluation for type theory, in type theory}},
volume = {13},
year = {2017}
}
@article{Kurz2006a,
author = {Kurz, Alexander},
doi = {10.1145/1140612.1140628},
file = {:Users/liang-tingchen/Dropbox/References/Kurz - 2006 - Coalgebras and their logics.pdf:pdf},
journal = {SIGACT News},
number = {2},
pages = {57--77},
title = {{Coalgebras and their logics}},
type = {Journal article},
volume = {37},
year = {2006}
}
@article{Dupont2003,
abstract = {Starting from known examples of factorization systems in 2-categories, we discuss possible definitions of proper factorization system in a 2-category. We focus our attention on the construction of the free proper factorization system on a given 2-category. ?? 2003 Elsevier Science B.V. All rights reserved.},
author = {Dupont, M. and Vitale, E.M.},
doi = {10.1016/S0022-4049(02)00244-X},
file = {:Users/liang-tingchen/Dropbox/References/Dupont, Vitale - 2003 - Proper factorization systems in 2-categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {apr},
number = {1-2},
pages = {65--86},
title = {{Proper factorization systems in 2-categories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S002240490200244X},
volume = {179},
year = {2003}
}
@article{Lack2012,
abstract = {We study limits in 2-categories whose objects are categories with extra structure and whose morphisms are functors preserving the structure only up to a coherent comparison map, which may or may not be required to be invertible. This is done using the framework of 2-monads. In order to characterize the limits which exist in this context, we need to consider also the functors which do strictly preserve the extra structure. We show how such a 2-category of weak morphisms which is "enhanced", by specifying which of these weak morphisms are actually strict, can be thought of as category enriched over a particular base cartesian closed category F. We give a complete characterization, in terms of F-enriched category theory, of the limits which exist in such 2-categories of categories with extra structure. ?? 2011 Elsevier Inc..},
archivePrefix = {arXiv},
arxivId = {1104.2111},
author = {Lack, Stephen and Shulman, Michael},
doi = {10.1016/j.aim.2011.08.014},
eprint = {1104.2111},
file = {:Users/liang-tingchen/Dropbox/References/Lack, Shulman - 2012 - Enhanced 2-categories and limits for lax morphisms.pdf:pdf},
issn = {00018708},
journal = {Advances in Mathematics},
keywords = {2-Category,2-Monad,Category with structure,Enriched category,Lax morphism,Limit,Weak morphism},
month = {jan},
number = {1},
pages = {294--356},
publisher = {Elsevier Inc.},
title = {{Enhanced 2-categories and limits for lax morphisms}},
url = {http://dx.doi.org/10.1016/j.aim.2011.08.014 http://linkinghub.elsevier.com/retrieve/pii/S000187081100315X},
volume = {229},
year = {2012}
}
@article{Kiselyov2018a,
abstract = {BACKGROUND: Cone-beam computed tomography (CBCT) has been changing the way dental practitioners use imaging. The radiation dose to the patient and how to effectively reduce the dose is still not completely clear to most users of this technology.$\backslash$n$\backslash$nOBJECTIVE: The objective of this study was to quantitate the change in radiation dose when using different CBCT settings.$\backslash$n$\backslash$nMETHODS: A CBCT machine was modified to allow different setting combinations. The variables consisted of 4 different mA choices (2, 5, 10, and 15), 2 kVp choices (100 and 120), and 3 fields of view (6 inches, 9 inches, and 12 inches). A radiation phantom with 10 thermoluminescent dosimeters (TLD) was used to measure radiation dose. One specific setting (15 mA, 120 kVp, and 12-inch FOV) was scanned 3 times to determine consistency.$\backslash$n$\backslash$nRESULTS: The CBCT showed less than 5{\%} variance in radiation dose values. An overall reduction in dose of about 0.62 times was achieved by reducing the kVp from 120 to 100. When reducing the field size the dose decreased 5{\%} to 10{\%}, while for organs that escaped the direct beam the reduction was far greater.$\backslash$n$\backslash$nCONCLUSIONS: A reduction in radiation dose can be achieved by using the lowest exposure settings and narrow collimation.},
author = {Kiselyov, Oleg},
doi = {10.1561/2500000038},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov - 2018 - Reconciling Abstraction with High Performance A MetaOCaml approach.pdf:pdf},
issn = {2325-1107},
journal = {Foundations and Trends{\textregistered} in Programming Languages},
number = {1},
pages = {1--101},
pmid = {18424119},
title = {{Reconciling Abstraction with High Performance: A MetaOCaml approach}},
url = {http://www.nowpublishers.com/article/Details/PGL-038},
volume = {5},
year = {2018}
}
@article{Lynch1995,
abstract = {A unified, comprehensive presentation of simulation techniques for verification of concurrent systems is given, in terms of a simple untimed automaton model. In particular, (1) refinements, (2) forward and backward simulations, (3) hybrid forward-backward and backward-forward simulations, and (4) history and prophecy relations are defined. History and prophecy relations are abstract versions of the history and prophecy variables of Abadi and Lamport, as well as the auxiliary variables of Owicki and Gries, Relationships between the different types of simulations, as well as soundness and completeness results, are stated and proved. Finally, it is shown how invariants can be incorporated into all the simulations. Even though many results are presented here for the first time, this paper can also be read as a survey (in a simple setting) of the research literature on simulation techniques. The development for untimed automata is designed to support a similar development for timed automata, Part II of this paper will show how the results of this paper can be carried over to the setting of timed automata.},
author = {Lynch, N. and Vaandrager, F.},
doi = {10.1006/inco.1995.1134},
file = {:Users/liang-tingchen/Dropbox/References/Lynch, Vaandrager - 1995 - Forward and backward simulations.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {sep},
number = {2},
pages = {214--233},
title = {{Forward and backward simulations}},
url = {http://www.sciencedirect.com/science/article/pii/S0890540185711340 http://linkinghub.elsevier.com/retrieve/pii/S0890540185711340},
volume = {121},
year = {1995}
}
@article{Bauer2019,
abstract = {We first show that in the function realizability topos RT(K2) every metric space is separable, and every object with decidable equality is countable. More generally, working with synthetic topology, every T0-space is separable and every discrete space is countable. It follows that intuitionistic logic does not show the existence of a non-separable metric space, or an uncountable set with decidable equality, even if we assume principles that are validated by function realizability, such as Dependent and Function choice, Markov's principle, and Brouwer's continuity and fan principles. MSC Codes 54E35, 03F60, 03F55},
author = {Bauer, Andrej and Swan, Andrew},
doi = {10.23638/LMCS-15(2:14)2019},
file = {:Users/liang-tingchen/Dropbox/References/Bauer, Swan - 2019 - Every metric space is separable in function realizability.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {Constructive mathematics,Function realizability,Metric spaces,Synthetic topology},
number = {2},
pages = {14:1--14:7},
title = {{Every metric space is separable in function realizability}},
volume = {15},
year = {2019}
}
@article{Szigeti1983,
author = {Szigeti, Jen{\"{o}}},
file = {:Users/liang-tingchen/Dropbox/References/Szigeti - 1983 - On limits and colimits in the Kleisli category.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
keywords = {Eilenberg-Moore category,Kleisli category,cocompleteness,completeness,lifting of adjoint functors},
number = {4},
pages = {381--391},
title = {{On limits and colimits in the Kleisli category}},
url = {http://eudml.org/doc/91336{\%}5Cnhttp://www.numdam.org/item?id=CTGDC{\_}1983{\_}{\_}24{\_}4{\_}381{\_}0},
volume = {24},
year = {1983}
}
@article{Adamek1997,
abstract = {For every sketch with countable limit specifications and countable colimit specifications we prove that there exists a finitary sketch (i.e., one with finite limit and colimit specifications) with the same category of finite models. The sketch is even coherent, i.e., describable by the finitary first-order logic. Assuming the non-existence of measurable cardinals, we also prove that for every geometric sketch there exists a coherent sketch with the same category of finite models. The latter result is, in fact, equivalent to the assumption of non-existence of measurable cardinals.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/S0022-4049(96)00159-4},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}} - 1997 - Finite models of sketches.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {mar},
number = {1-3},
pages = {3--23},
title = {{Finite models of sketches}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404996001594},
volume = {116},
year = {1997}
}
@article{Rioux2020,
abstract = {Focusing is a technique from proof theory that exploits type information to prune inessential nondeterminism from proof search procedures. Viewed through the lens of the Curry-Howard correspondence, a focused typing derivation yields terms in normal form. This paper explores how to exploit focusing for reasoning about contextual equivalences and full abstraction. We present a focused polymorphic call-by-push-value calculus and prove a computational completeness result: for every well-typed term, there exists a focused term that is $\beta$$\eta$-equivalent to it. This completeness result yields a powerful way to refine the context lemmas for establishing contextual equivalences, cutting down the set that must be considered to just focused contexts. The paper demonstrates the application of focusing to establish program equivalences, including free theorems. It also uses focusing to prove full abstraction of a translation of the pure, total call-by-push-value language into a language with divergence and simple effect types, yielding a novel solution to a simple-to-state, but hitherto difficult to solve problem.},
author = {Rioux, Nick and Zdancewic, Steve},
doi = {10.1145/3408977},
file = {:Users/liang-tingchen/Dropbox/References/Rioux, Zdancewic - 2020 - Computation focusing.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {compiler verification,focusing,full abstraction,program equivalence,type systems},
month = {aug},
number = {ICFP},
pages = {1--27},
title = {{Computation focusing}},
url = {https://dl.acm.org/doi/10.1145/3408977},
volume = {4},
year = {2020}
}
@inproceedings{Garg2011a,
address = {New York, New York, USA},
author = {Garg, Deepak and Jia, Limin and Datta, Anupam},
booktitle = {Proceedings of the 18th ACM conference on Computer and communications security - CCS '11},
doi = {10.1145/2046707.2046726},
file = {:Users/liang-tingchen/Dropbox/References/Garg, Jia, Datta - 2011 - Policy auditing over incomplete logs.pdf:pdf},
isbn = {9781450309486},
keywords = {audit,formal logic,incomplete logs,privacy policy},
pages = {151},
publisher = {ACM Press},
title = {{Policy auditing over incomplete logs}},
url = {http://dl.acm.org/citation.cfm?doid=2046707.2046726},
year = {2011}
}
@article{Maietti2005,
abstract = {We present a modular correspondence between various categorical structures and their internal languages in terms of extensional dependent type theories {\`{a}} la Martin-L{\"{o}}f. Starting from lex categories, through regular ones, we provide internal languages of pretopoi and topoi and some variations of them, such as, for example, Heyting pretopoi. With respect to the internal languages already known for some of these categories, such as topoi, the novelty of these calculi is that formulas corresponding to subobjects can be regained as particular types that are equipped with proof-terms according to the isomorphism 'propositions as mono types', which was invisible in previously described internal languages. {\textcopyright} 2005 Cambridge University Press.},
author = {MAIETTI, MARIA EMILIA},
doi = {10.1017/S0960129505004962},
file = {:Users/liang-tingchen/Dropbox/References/MAIETTI - 2005 - Modular correspondence between dependent type theories and categories including pretopoi and topoi.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {dec},
number = {06},
pages = {1089},
title = {{Modular correspondence between dependent type theories and categories including pretopoi and topoi}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129505004962},
volume = {15},
year = {2005}
}
@inproceedings{Jung2013,
author = {Jung, Achim and Rivieccio, Umberto},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.50},
file = {:Users/liang-tingchen/Dropbox/References/Jung, Rivieccio - 2013 - Kripke Semantics for Modal Bilattice Logic.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
keywords = {Bilattice logic,Priestley duality,algebraic logic,modal logic},
month = {jun},
pages = {438--447},
publisher = {IEEE},
title = {{Kripke Semantics for Modal Bilattice Logic}},
url = {http://ieeexplore.ieee.org/document/6571576/},
year = {2013}
}
@book{Bird1996,
author = {Bird, Richard and de Moor, Oege},
isbn = {978-0135072455},
pages = {312},
publisher = {Prentice-Hall},
title = {{The Algebra of Programming}},
url = {http://www.comlab.ox.ac.uk/oucl/publications/books/algebra/},
year = {1996}
}
@article{Adamek2006a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1017/S0960129506005706},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2006 - Iterative algebras at work.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {nov},
number = {06},
pages = {1085},
title = {{Iterative algebras at work}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129506005706},
volume = {16},
year = {2006}
}
@article{Johnstone1975,
author = {Johnstone, Peter T.},
doi = {10.1112/blms/7.3.294},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone - 1975 - Adjoint lifting theorems for categories of algebras.pdf:pdf},
issn = {0024-6093},
journal = {Bulletin of the London Mathematical Society},
month = {nov},
number = {3},
pages = {294--297},
title = {{Adjoint lifting theorems for categories of algebras}},
url = {http://blms.oxfordjournals.org/cgi/doi/10.1112/blms/7.3.294},
volume = {7},
year = {1975}
}
@article{Coquand2009,
abstract = {We present a constructive proof of Gelfand duality for C*-algebras by reducing the problem to Gelfand duality for real C*-algebras.},
author = {Coquand, Thierry and Spitters, Bas},
doi = {10.1017/S0305004109002515},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Spitters - 2009 - Constructive Gelfand duality for C-algebras.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
language = {English},
month = {may},
number = {02},
pages = {339},
publisher = {Cambridge University Press},
title = {{Constructive Gelfand duality for C*-algebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004109002515},
volume = {147},
year = {2009}
}
@book{Huth2000,
author = {Huth, Michael and Ryan, Mark},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Huth, Ryan - 2004 - Logic in Computer Science Modelling and Reasoning about Systems.pdf:pdf},
isbn = {9780521543101},
pages = {440},
publisher = {Cambridge University Press},
title = {{Logic in Computer Science: Modelling and Reasoning about Systems}},
year = {2004}
}
@article{Ginsberg1988,
author = {Ginsberg, Matthew L.},
doi = {10.1111/j.1467-8640.1988.tb00280.x},
file = {:Users/liang-tingchen/Dropbox/References/Ginsberg - 1988 - Multivalued logics a uniform approach to reasoning in artificial intelligence.pdf:pdf},
issn = {0824-7935},
journal = {Computational Intelligence},
keywords = {circumscription,commonsense,defaults,knowledge representation,nonmonotonic reasoning,reasoning,theorem proving,truth maintenance},
month = {sep},
number = {3},
pages = {265--316},
title = {{Multivalued logics: a uniform approach to reasoning in artificial intelligence}},
url = {http://doi.wiley.com/10.1111/j.1467-8640.1988.tb00280.x},
volume = {4},
year = {1988}
}
@article{Martin-Lof1996,
abstract = {The following three lectures were given in the form of a short course at the meeting Teoria della Dimostrazione e Filosofia della Logica, or- ganized in Siena, 6–9 April 1983, by the Scuola di Specializzazione in Logica Matematica of the Universit`a degli Studi di Siena. I am very grateful to Giovanni Sambin and Aldo Ursini of that school, not only for recording the lectures on tape, but, above all, for transcribing the tapes produced by the recorder: no machine could have done that work. This written version of the lectures is based on their transcription. The changes that I have been forced to make have mostly been of a stylistic nature, except at one point. In the second lecture, as I actually gave it, the order of conceptual priority between the notions of proof and immediate inference was wrong. Since I discovered my mistake later the same month as the meeting was held, I thought it better to let the written text diverge from the oral presentation rather than possi- bly confusing others by letting the mistake remain. The oral origin of these lectures is the source of the many redundancies of the written text. It is also my sole excuse for the lack of detailed references.},
author = {Martin-L{\"{o}}f, Per},
file = {:Users/liang-tingchen/Dropbox/References/Martin-L{\"{o}}f - 1996 - On the meanings of the logical constants and the justifications of the logical laws.pdf:pdf},
journal = {Nordic journal of philosophical logic},
number = {1},
pages = {11--60},
title = {{On the meanings of the logical constants and the justifications of the logical laws}},
volume = {1},
year = {1996}
}
@book{Barwise1996a,
author = {Barwise, Jon and Moss, Lawrence S.},
isbn = {1575860082},
publisher = {University of Chicago Press},
series = {CSLI Lecture Notes},
title = {{Vicious Circles}},
type = {Book},
year = {1996}
}
@article{Cockx2016a,
abstract = {Dependent pattern matching is an intuitive way to write programs and proofs in dependently typed languages. It is reminiscent of both pattern matching in functional languages and case analysis in on-paper mathematics. However, in general, it is incompatible with new type theories such as homotopy type theory (HoTT). As a consequence, proofs in such theories are typically harder to write and to understand. The source of this incompatibility is the reliance of dependent pattern matching on the so-called K axiom – also known as the uniqueness of identity proofs – which is inadmissible in HoTT. In this paper, we propose a new criterion for dependent pattern matching without K, and prove it correct by a translation to eliminators in the style of Goguen et al . (2006 Algebra, Meaning, and Computation ). Our criterion is both less restrictive than existing proposals, and solves a previously undetected problem in the old criterion offered by Agda. It has been implemented in Agda and is the first to be supported by a formal proof. Thus, it brings the benefits of dependent pattern matching to contexts where we cannot assume K, such as HoTT.},
author = {Cockx, Jesper and Devriese, Dominique and Piessens, Frank},
doi = {10.1017/S0956796816000174},
file = {:Users/liang-tingchen/Dropbox/References/Cockx, Devriese, Piessens - 2016 - Eliminating dependent pattern matching without K.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {aug},
pages = {e16},
title = {{Eliminating dependent pattern matching without K}},
url = {https://www.cambridge.org/core/product/identifier/S0956796816000174/type/journal{\_}article},
volume = {26},
year = {2016}
}
@book{Gabbay2005,
address = {Berlin/Heidelberg},
doi = {10.1007/1-4020-3092-4},
edition = {2},
editor = {Gabbay, Dov M. and Guenthner, F.},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 2005 - Handbook of Philosophical Logic.pdf:pdf},
isbn = {1-4020-3091-6},
pages = {372},
publisher = {Springer Netherlands},
series = {Handbook of Philosophical Logic},
title = {{Handbook of Philosophical Logic}},
url = {http://link.springer.com/10.1007/1-4020-3092-4},
volume = {12},
year = {2005}
}
@article{Brady2013a,
abstract = {Many components of a dependently typed programming language are by now well understood, for example, the underlying type theory, type checking, unification and evaluation. How to combine these components into a realistic and usable high-level language is, however, folklore, discovered anew by successive language implementors. In this paper, I describe the implementation of Idris , a new dependently typed functional programming language. Idris is intended to be a general-purpose programming language and as such provides high-level concepts such as implicit syntax, type classes and do notation. I describe the high-level language and the underlying type theory, and present a tactic-based method for elaborating concrete high-level syntax with implicit arguments and type classes into a fully explicit type theory. Furthermore, I show how this method facilitates the implementation of new high-level language constructs.},
author = {Brady, Edwin C},
doi = {10.1017/S095679681300018X},
file = {:Users/liang-tingchen/Dropbox/References/Brady - 2013 - Idris, a general-purpose dependently typed programming language Design and implementation.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {5},
pages = {552--593},
title = {{Idris, a general-purpose dependently typed programming language: Design and implementation}},
url = {https://www.cambridge.org/core/product/identifier/S095679681300018X/type/journal{\_}article},
volume = {23},
year = {2013}
}
@incollection{Abel1999,
abstract = {We present a new strong normalisation proof for a $\lambda$-calculus with interleaving strictly positive inductive types $\lambda$$\mu$ which avoids the use of impredicative reasoning, i.e., the theorem of Knaster-Tarski. Instead it only uses predicative, i.e., strictly positive inductive definitions on the metalevel. To achieve this we show that every strictly positive operator on types gives rise to an operator on saturated sets which is not only monotone but also (deterministically) set based - a concept introduced by Peter Aczel in the context of intuitionistic set theory. We also extend this to coinductive types using greatest fixpoints of strictly monotone operators on the metalevel. The use of the term interleaving for this situation is due to Ralph Matthes, e.g., see [Mat98]. An alternative would be mutually. Types for Proofs and ProgramsTypes for Proofs and Programs Look Inside Other actions Reprints and Permissions Export citation About this Book Add to Papers},
author = {Abel, Andreas M. and Altenkirch, Thorsten},
booktitle = {Types for Proofs and Programs,TYPES'99},
editor = {Coquand, Thierry and Dybjer, Peter and Nordstr{\"{o}}m, Bengt and Smith, Jan},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Altenkirch - 2000 - A predicative strong normalisation proof for a $\lambda$-calculus with interleaving inductive types.pdf:pdf},
pages = {21--40},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A predicative strong normalisation proof for a $\lambda$-calculus with interleaving inductive types}},
url = {http://link.springer.com/chapter/10.1007/3-540-44557-9{\_}2},
year = {2000}
}
@inproceedings{Governatori2015,
abstract = {In the past few years several business process compliance frameworks based on temporal logic have been proposed. In this paper we investigate whether the use of temporal logic is suitable for the task at hand: namely to check whether the specifications of a business process are compatible with the formalisation of the norms regulating the business process. We provide an example inspired by real life norms where the use of linear temporal logic produces a result that is not compatible with the legal understanding of the norms in the example.},
author = {Governatori, Guido and Hashmi, Mustafa},
booktitle = {2015 IEEE 19th International Enterprise Distributed Object Computing Conference},
doi = {10.1109/EDOC.2015.12},
file = {:Users/liang-tingchen/Dropbox/References/Governatori, Hashmi - 2015 - No Time for Compliance.pdf:pdf},
isbn = {978-1-4673-9203-7},
issn = {15417719},
keywords = {Business,Force,Law,Lead,Maintenance engineering,Semantics},
month = {sep},
number = {Section II},
pages = {9--18},
publisher = {IEEE},
title = {{No Time for Compliance}},
url = {http://ieeexplore.ieee.org/document/7321149/},
volume = {2015-Novem},
year = {2015}
}
@inproceedings{Takano1995,
address = {New York, New York, USA},
author = {Takano, Akihiko and Meijer, Erik},
booktitle = {Proceedings of the seventh international conference on Functional programming languages and computer architecture - FPCA '95},
doi = {10.1145/224164.224221},
file = {:Users/liang-tingchen/Dropbox/References/Takano, Meijer - 1995 - Shortcut deforestation in calculational form.pdf:pdf},
isbn = {0897917197},
number = {Oct},
pages = {306--313},
publisher = {ACM Press},
title = {{Shortcut deforestation in calculational form}},
url = {http://portal.acm.org/citation.cfm?doid=224164.224221},
volume = {i},
year = {1995}
}
@article{Cubric1998,
author = {{\v{C}}ubri{\'{c}}, Djordje},
doi = {10.1016/S0022-4049(96)00137-5},
file = {:Users/liang-tingchen/Dropbox/References/{\v{C}}ubri{\'{c}} - 1998 - Embedding of a free cartesian-closed category into the category of sets.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {apr},
number = {1-3},
pages = {121--147},
title = {{Embedding of a free cartesian-closed category into the category of sets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404996001375},
volume = {126},
year = {1998}
}
@article{Pavlovic1999,
author = {Pavlovi{\'{c}}, Dusko and Pratt, Vaughan},
doi = {10.1016/S1571-0661(05)80272-5},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}}, Pratt - 1999 - On coalgebra of real numbers.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {103--117},
title = {{On coalgebra of real numbers}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105802725},
volume = {19},
year = {1999}
}
@incollection{Riecanova2006,
author = {Rie{\v{c}}anov{\'{a}}, Zdenka and Marinov{\'{a}}, Ivica and Zajac, Michal},
booktitle = {Theory and Applications of Relational Structures as Knowledge Instruments II},
doi = {10.1007/11964810_14},
editor = {de Swart, Harrie and Or{\l}owska, Ewa and Schmidt, Gunther and Roubens, Marc},
file = {:Users/liang-tingchen/Dropbox/References/Rie{\v{c}}anov{\'{a}}, Marinov{\'{a}}, Zajac - 2006 - Some Aspects of Lattice and Generalized Prelattice Effect Algebras.pdf:pdf},
pages = {290--317},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Some Aspects of Lattice and Generalized Prelattice Effect Algebras}},
url = {http://link.springer.com/10.1007/11964810{\_}14},
volume = {4342},
year = {2006}
}
@incollection{Dwork2006a,
abstract = {We continue a line of research initiated in [10,11]on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user. Previous work focused on the case of noisy sums, in which f = ?i g(xi), where xi denotes the ith row of the database and g maps database rows to [0, 1]. We extend the study to general functions f, proving that privacy can be preserved by calibrating the standard devi- ation of the noise according to the sensitivity of the function f. Roughly speaking, this is the amount that any single argument to f can change its output. The new analysis shows that for several particular applications substantially less noise is needed than was previously understood to be the case. The first step is a very clean characterization of privacy in terms of indistinguishability of transcripts. Additionally, we obtain separation re- sults showing the increased value of interactive sanitization mechanisms over non-interactive.},
archivePrefix = {arXiv},
arxivId = {arXiv:1203.3453v5},
author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
booktitle = {Theory of Cryptography. TCC 2006.},
doi = {10.1007/11681878_14},
eprint = {arXiv:1203.3453v5},
file = {:Users/liang-tingchen/Dropbox/References/Dwork et al. - 2006 - Calibrating Noise to Sensitivity in Private Data Analysis.pdf:pdf},
isbn = {3-540-32731-2},
issn = {1520-6017},
number = {8},
pages = {265--284},
pmid = {21455981},
title = {{Calibrating Noise to Sensitivity in Private Data Analysis}},
url = {http://link.springer.com/10.1007/11681878{\_}14},
volume = {3876},
year = {2006}
}
@incollection{Baier2018,
abstract = {ficial intelligence; computer software; selection and evaluation; formal logic; graph theory; modal logic; petri nets; program compilers; programming language; semantics; separation logic; software engineering; theorem proving; type systems; verification},
address = {Cham},
author = {{Devesas Campos}, Marco and Levy, Paul Blain},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2018},
doi = {10.1007/978-3-319-89366-2_4},
editor = {Baier, Christel and {Dal Lago}, Ugo},
file = {:Users/liang-tingchen/Dropbox/References/Devesas Campos, Levy - 2018 - A Syntactic View of Computational Adequacy.pdf:pdf},
isbn = {978-3-319-89365-5},
keywords = {artificial intelligence,computer software,formal logic,graph theory,modal logic,petri nets,program compilers,programming language,selection and evaluation,semantics,separation logic,software engineering,theorem proving,type systems,verification},
pages = {71--87},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Syntactic View of Computational Adequacy}},
url = {http://link.springer.com/10.1007/978-3-319-89366-2{\_}4},
volume = {10803},
year = {2018}
}
@article{Boudes2012,
abstract = {We study the notion of stratification, as used in subsystems of linear logic with low complexity bounds on the cut-elimination procedure (the so-called light logics), from an abstract point of view, introducing a logical system in which stratification is handled by a separate modality. This modality, which is a generalization of the paragraph modality of Girard's light linear logic, arises from a general categorical construction applicable to all models of linear logic. We thus learn that stratification may be formulated independently of exponential modalities; when it is forced to be connected to exponential modalities, it yields interesting complexity properties. In particular, from our analysis stem three alternative reformulations of Baillot and Mazza's linear logic by levels: one geometric, one interactive, and one semantic.},
archivePrefix = {arXiv},
arxivId = {1206.6504},
author = {Boudes, Pierre and Mazza, Damiano and de Falco, Lorenzo Tortora},
eprint = {1206.6504},
file = {:Users/liang-tingchen/Dropbox/References/Boudes, Mazza, de Falco - 2012 - An abstract approach to stratification in linear logic.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {categorical semantics,denotational semantics,implicit computational complexity,light linear logics},
month = {jun},
title = {{An abstract approach to stratification in linear logic}},
url = {http://arxiv.org/abs/1206.6504},
year = {2012}
}
@incollection{Schroder2007b,
author = {Schr{\"{o}}der, Lutz and Pattinson, Dirk},
booktitle = {Automata, Languages and Programming},
doi = {10.1007/978-3-540-73420-8_41},
editor = {Schr{\"{o}}der, Lutz and Pattinson, Dirk},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Pattinson - 2007 - Modular algorithms for heterogeneous modal logics.pdf:pdf},
pages = {1--12},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modular algorithms for heterogeneous modal logics}},
year = {2007}
}
@article{Sozeau2017,
author = {Sozeau, Matthieu and Mangin, Cyprien},
doi = {10.1145/3341690},
file = {:Users/liang-tingchen/Dropbox/References/Sozeau, Mangin - 2019 - Equations reloaded high-level dependently-typed functional programming and proving in Coq.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {dependent pattern-matching,proof assistants,recursion},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Equations reloaded: high-level dependently-typed functional programming and proving in Coq}},
url = {https://doi.org/10.1145/3341690 http://dl.acm.org/citation.cfm?doid=3352468.3341690},
volume = {3},
year = {2019}
}
@article{Adamek2010a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Gumm, H. Peter and Trnkov{\'{a}}, V{\v{e}}ra},
doi = {10.1093/logcom/exn090},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Gumm, Trnkov{\'{a}} - 2009 - Presentation of Set Functors A Coalgebraic Perspective.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
month = {feb},
number = {5},
pages = {991--1015},
publisher = {Oxford Univ Press},
title = {{Presentation of Set Functors: A Coalgebraic Perspective}},
type = {Journal article},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exn090},
volume = {20},
year = {2009}
}
@article{Banaschewski1967,
author = {Banaschewski, Bernhard and Bruns, G.},
doi = {10.1007/BF01898828},
file = {:Users/liang-tingchen/Dropbox/References/Banaschewski, Bruns - 1967 - Categorical characterization of the MacNeille completion.pdf:pdf},
issn = {0003889X},
journal = {Archiv der Mathematik},
number = {4},
pages = {369--377},
title = {{Categorical characterization of the MacNeille completion}},
volume = {18},
year = {1967}
}
@article{Santocanale2010a,
abstract = {This paper exhibits a general and uniform method to prove axiomatic completeness for certain modal fixpoint logics. Given a set ?? of modal formulas of the form ??(x,p1,. . .,pn), where x occurs only positively in ??, we obtain the flat modal fixpoint language L{\#}(??) by adding to the language of polymodal logic a connective {\#}?? for each ???????. The term {\#}??(??1,. . .,??n) is meant to be interpreted as the least fixed point of the functional interpretation of the term ??(x,??1,. . .,??n). We consider the following problem: given ??, construct an axiom system which is sound and complete with respect to the concrete interpretation of the language L{\#}(??) on Kripke structures. We prove two results that solve this problem.First, let K{\#}(??) be the logic obtained from the basic polymodal K by adding a Kozen-Park style fixpoint axiom and a least fixpoint rule, for each fixpoint connective {\#}??. Provided that each indexing formula ?? satisfies a certain syntactic criterion, we prove this axiom system to be complete.Second, addressing the general case, we prove the soundness and completeness of an extension K{\#}+(??) of K{\#}(??). This extension is obtained via an effective procedure that, given an indexing formula ?? as input, returns a finite set of axioms and derivation rules for {\#}??, of size bounded by the length of ??. Thus the axiom system K{\#}+(??) is finite whenever ?? is finite. ?? 2010 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {0812.2390},
author = {Santocanale, Luigi and Venema, Yde},
doi = {10.1016/j.apal.2010.07.003},
eprint = {0812.2390},
file = {:Users/liang-tingchen/Dropbox/References/Santocanale, Venema - 2010 - Completeness for flat modal fixpoint logics.pdf:pdf},
isbn = {9783540755586},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Axiomatization,Completeness,Fixpoint logic,Modal algebra,Modal logic,Representation theorem},
number = {1},
pages = {55--82},
publisher = {Elsevier B.V.},
title = {{Completeness for flat modal fixpoint logics}},
url = {http://dx.doi.org/10.1016/j.apal.2010.07.003},
volume = {162},
year = {2010}
}
@incollection{Chen2019,
author = {Chen, Liang-Ting and Roggenbach, Markus and Tucker, John V},
booktitle = {Recent Trends in Algebraic Development Techniques -- 24th {\{}IFIP{\}} {\{}WG{\}} 1.3 International Workshop, {\{}WADT{\}} 2018, Egham, UK, July 2--5, 2018, Revised Selected Papers},
doi = {10.1007/978-3-030-23220-7_3},
editor = {Fiadeiro, Jos{\'{e}} Luiz and Țuțu, Ionuț},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Roggenbach, Tucker - 2019 - An Algebraic Theory for Data Linkage.pdf:pdf},
pages = {47--66},
publisher = {Springer},
series = {Lecture Notes in in Computer Science},
title = {{An Algebraic Theory for Data Linkage}},
url = {http://link.springer.com/10.1007/978-3-030-23220-7{\_}3},
volume = {11563},
year = {2019}
}
@article{Nanevski2005,
abstract = {Staging is a programming technique for dividing the computation in order to exploit the early availability of some arguments. In the early stages the program uses the available arguments to generate, at run time, the code for the late stages. A type system for staging should ensure that only well-typed expressions are generated, and that only expressions with no free variables are permitted for evaluation. In this paper, we present a calculus for staged computation in which code from the late stages is composed by splicing smaller code fragments into a larger context, possibly incurring capture of free variables. The type system ensures safety by tracking the names of free variables for each code fragment. The type system is based on the necessity operator □ from constructive modal logic, which we index with a set of names C. Our type □ C A classifies expressions of type A that belong to the late stage, and whose free names are in the set C.},
author = {Nanevski, Aleksandar and Pfenning, Frank},
doi = {10.1017/S095679680500568X},
file = {:Users/liang-tingchen/Dropbox/References/Nanevski, Pfenning - 2005 - Staged computation with names and necessity.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {nov},
number = {6},
pages = {893--939},
title = {{Staged computation with names and necessity}},
url = {https://www.cambridge.org/core/product/identifier/S095679680500568X/type/journal{\_}article},
volume = {15},
year = {2005}
}
@article{Borceux1986,
author = {Borceux, Francis and Dejean, Dominique},
file = {:Users/liang-tingchen/Dropbox/References/Borceux, Dejean - 1986 - Cauchy completion in category theory.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {2},
pages = {133--146},
title = {{Cauchy completion in category theory}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1986{\_}{\_}27{\_}2{\_}133{\_}0 https://eudml.org/doc/91378},
volume = {27},
year = {1986}
}
@article{Kozen2010,
author = {Kozen, Dexter},
doi = {10.3233/FI-2010-306},
file = {:Users/liang-tingchen/Dropbox/References/Kozen - 2010 - Church – Rosser Made Easy.pdf:pdf},
journal = {Fundamenta Informaticae},
keywords = {church,confluence,lambda-calculus,rosser theorem},
pages = {1--8},
title = {{Church – Rosser Made Easy}},
volume = {105},
year = {2010}
}
@inproceedings{Vazou2017,
address = {New York, New York, USA},
author = {Vazou, Niki and Lampropoulos, Leonidas and Polakow, Jeff},
booktitle = {Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell - Haskell 2017},
doi = {10.1145/3122955.3122963},
file = {:Users/liang-tingchen/Dropbox/References/Vazou, Lampropoulos, Polakow - 2017 - A tale of two provers verifying monoidal string matching in liquid Haskell and Coq.pdf:pdf},
isbn = {9781450351829},
keywords = {2017,a tale of two,acm reference format,and jeff polakow,coq,dependent and refinement types,formal verification,leonidas lampropoulos,liquid haskell,monoid laws,niki vazou,parallelization,theorem proving},
pages = {63--74},
publisher = {ACM Press},
title = {{A tale of two provers: verifying monoidal string matching in liquid Haskell and Coq}},
url = {http://dl.acm.org/citation.cfm?doid=3122955.3122963},
year = {2017}
}
@inproceedings{Gibbons2000,
abstract = {Remote procedure calls are computationally expensive, because network round-trips take several orders of magnitude longer than local interactions. One common technique for amortizing this cost is to batch together multiple independent requests into one com- pound request. Batching requests amounts to serializing the abstract syntax tree of a small program, in order to transmit it and run it remotely. The standard representation for abstract syntax is to use free monads; we show that free applicative functors are actually a better choice of representation for this scenario.},
address = {New York, New York, USA},
author = {Gibbons, Jeremy},
booktitle = {Proceedings of the 9th International Symposium on Haskell - Haskell 2016},
doi = {10.1145/2976002.2976005},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2016 - Free delivery (functional pearl).pdf:pdf},
isbn = {9781450344340},
keywords = {batched request,free applicative functor,free monad,remote procedure call},
pages = {45--50},
publisher = {ACM Press},
title = {{Free delivery (functional pearl)}},
url = {http://dl.acm.org/citation.cfm?doid=2976002.2976005},
year = {2016}
}
@article{Clark2008,
abstract = {We investigate first-order axiomatic descriptions of naturally occurring classes of Boolean topological structures (these structures can have operations and relations, and carry a compatible compact Hausdorff topology with a basis of clopen sets). Our methods utilize inverse limits and ultraproducts of finite structures. We illustrate the range of possible axiomatizations of these classes with applications of our methods to Boolean topological lattices, graphs, ordered structures, unary algebras and semigroups. For example, whereas the class of all k-colorable graphs is known to be axiomatizable by universal Horn sentences, we find the class of continuously k-colorable Boolean topological graphs is not even first-order axiomatizable. ?? 2008 Elsevier Inc. All rights reserved.},
author = {Clark, D. M. and Davey, Brian A. and Jackson, M. G. and Pitkethly, Jane G.},
doi = {10.1016/j.aim.2008.03.020},
file = {:Users/liang-tingchen/Dropbox/References/Clark et al. - 2008 - The axiomatizability of topological prevarieties.pdf:pdf},
issn = {00018708},
journal = {Advances in Mathematics},
keywords = {Graph,Inverse limit,Lattice,Natural duality,Ordered set,Profinite,Semigroup,Topological prevariety,Topological quasivariety,Unary algebra,Universal Horn class},
number = {5},
pages = {1604--1653},
title = {{The axiomatizability of topological prevarieties}},
volume = {218},
year = {2008}
}
@inproceedings{Machanavajjhala2008,
abstract = {In this paper, we propose the first formal privacy analysis of a data anonymization process known as the synthetic data generation, a technique becoming popular in the statistics community. The target application for this work is a mapping program that shows the commuting patterns of the population of the United States. The source data for this application were collected by the U.S. Census Bureau, but due to privacy constraints, they cannot be used directly by the mapping program. Instead, we generate synthetic data that statistically mimic the original data while providing privacy guarantees. We use these synthetic data as a surrogate for the original data. We find that while some existing definitions of privacy are inapplicable to our target application, others are too conservative and render the synthetic data useless since they guard against privacy breaches that are very unlikely. Moreover, the data in our target application is sparse, and none of the existing solutions are tailored to anonymize sparse data. In this paper, we propose solutions to address the above issues.},
author = {Machanavajjhala, Ashwin and Kifer, Daniel and Abowd, John and Gehrke, Johannes and Vilhuber, Lars},
booktitle = {2008 IEEE 24th International Conference on Data Engineering},
doi = {10.1109/ICDE.2008.4497436},
file = {:Users/liang-tingchen/Dropbox/References/Machanavajjhala et al. - 2008 - Privacy Theory meets Practice on the Map.pdf:pdf},
isbn = {978-1-4244-1836-7},
issn = {10844627},
month = {apr},
pages = {277--286},
publisher = {IEEE},
title = {{Privacy: Theory meets Practice on the Map}},
url = {http://ieeexplore.ieee.org/document/4497436/},
year = {2008}
}
@article{Bilkova2012a,
abstract = {The category Rel(Set) of sets and relations can be described as a category of spans and as the Kleisli category for the powerset monad. A set-functor can be lifted to a functor on Rel(Set) iff it preserves weak pullbacks. We show that these results extend to the enriched setting, if we replace sets by posets or preorders. Preservation of weak pullbacks becomes preservation of exact lax squares. As an application we present Moss's coalgebraic over posets.},
archivePrefix = {arXiv},
arxivId = {1210.1433},
author = {B{\'{i}}lkov{\'{a}}, Marta and Kurz, Alexander and Petrişan, Daniela and Velebil, Jiř{\'{i}}},
eprint = {1210.1433},
file = {:Users/liang-tingchen/Dropbox/References/B{\'{i}}lkov{\'{a}} et al. - 2012 - Relation liftings on preorders and posets.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {1--28},
title = {{Relation liftings on preorders and posets}},
url = {http://arxiv.org/abs/1210.1433},
year = {2012}
}
@article{Grandis1999,
author = {Grandis, Marco and Par{\'{e}}, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Grandis, Par{\'{e}} - 1999 - Limits in double categories.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {3},
pages = {162--220},
title = {{Limits in double categories}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1999{\_}{\_}40{\_}3{\_}162{\_}0},
volume = {40},
year = {1999}
}
@article{Machanavajjhala2015,
author = {Machanavajjhala, Ashwin and Kifer, Daniel},
doi = {10.1145/2660766},
file = {:Users/liang-tingchen/Dropbox/References/Machanavajjhala, Kifer - 2015 - Designing statistical privacy for your data.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {feb},
number = {3},
pages = {58--67},
title = {{Designing statistical privacy for your data}},
url = {http://dl.acm.org/citation.cfm?doid=2739250.2660766},
volume = {58},
year = {2015}
}
@article{Patterson2019,
author = {Patterson, Daniel and Ahmed, Amal},
doi = {10.1145/3341689},
file = {:Users/liang-tingchen/Dropbox/References/Patterson, Ahmed - 2019 - The next 700 compiler correctness theorems (functional pearl).pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {compilers,verification},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{The next 700 compiler correctness theorems (functional pearl)}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341689},
volume = {3},
year = {2019}
}
@inproceedings{Goncharov2015,
abstract = {We study a model of side-effecting processes obtained by starting from a monad modelling base effects and adjoining free operations using a cofree coalgebra construction; one thus arrives at what one may think of as types of non-wellfounded side-effecting trees, generalizing the infinite resumption monad. Types of this kind have received some attention in the recent literature; in particular, it has been shown that they admit guarded iteration. Here, we show that they also admit unguarded iteration, i.e. form complete Elgot monads, provided that the underlying base effect supports unguarded iteration.},
author = {Goncharov, Sergey and Rauch, Christoph and Schr{\"{o}}der, Lutz},
booktitle = {Proceedings of the 31st Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1016/j.entcs.2015.12.012},
file = {:Users/liang-tingchen/Dropbox/References/Goncharov, Rauch, Schr{\"{o}}der - 2015 - Unguarded Recursion on Coinductive Resumptions.pdf:pdf},
issn = {15710661},
keywords = {Recursion,coalgebra,coinduction,complete Elgot monad,resumptions},
pages = {183--198},
publisher = {Elsevier B.V.},
title = {{Unguarded Recursion on Coinductive Resumptions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066115000791},
volume = {319},
year = {2015}
}
@phdthesis{Bengtson2010,
abstract = {As the complexity of programs increase, so does the complexity of the models required to reason about them. Process calculi were introduced in the early 1980s and have since then been used to model communication protocols of varying size and scope. Whereas modeling sophisticated protocols in simple process algebras like CCS or the pi-calculus is doable, expressing the models required is often gruesome and error prone. To combat this, more advanced process calculi were introduced, which significantly reduce the complexity of the models. However, this simplicity comes at a price -- the theories of the calculi themselves instead become gruesome and error prone, and establishing their mathematical and logical properties has turned out to be difficult. Many of the proposed calculi have later turned out to be inconsistent.$\backslash$n$\backslash$nThe contribution of this thesis is twofold. Firstly we provide methodologies to formalise the meta-theory of process calculi in an interactive theorem prover. These are used to formalise significant parts of the meta-theory of CCS and the pi-calculus in the theorem prover Isabelle, using Nominal Logic to allow for a smooth treatment of the binders. Secondly we introduce and formalise psi-calculi, a framework for process calculi incorporating several existing ones, including those we already formalised, and which is significantly simpler and substantially more expressive. Our methods scale well as complexity of the calculi increases.$\backslash$n$\backslash$nThe formalised results include congruence results for both strong and weak bisimilarities, in the case of the pi-calculus for both the early and the late operational semantics. We also formalise the proof that the axiomatisation of strong late bisimilarity is sound and complete in the finite pi-calculus. We believe psi-calculi to be one of the most expressive frameworks for mobile process calculi, and our Isabelle formalisation to be the most extensive formalisation of process calculi ever done inside a theorem prover.},
annote = {NULL},
author = {Bengtson, Jesper},
file = {:Users/liang-tingchen/Dropbox/References/Bengtson - 2010 - Formalising process calculi.pdf:pdf},
isbn = {9789155478018},
pages = {1--498},
school = {Uppsala Universitet},
title = {{Formalising process calculi}},
url = {papers2://publication/uuid/9BC13A9D-9821-4A71-8891-E685DDA00F57{\%}5Cnpapers2://publication/uuid/BAD0427F-E215-41E7-82E2-C65FB84E48B6},
year = {2010}
}
@book{Adamek1990,
address = {New York},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Herrlich, Horst and Strecker, George E.},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Herrlich, Strecker - 1990 - Abstract and Concrete Categories.pdf:pdf},
keywords = {Category theory,category,theory},
mendeley-tags = {category,theory},
publisher = {Wiley-Interscience},
title = {{Abstract and Concrete Categories}},
type = {Book},
url = {http://www.iti.cs.tu-bs.de/{~}adamek/AHS.pdf},
year = {1990}
}
@article{Hinze2004,
abstract = {A polytypic function is a function that can be instantiated on many data types to obtain data type specific functionality. Examples of polytypic functions are the functions that can be derived in Haskell, such as show, read, and '=='. More advanced examples are functions for digital searching, pattern matching, unification, rewriting, and structure editing. For each of these problems, we not only have to define polytypic functionality, but also a type-indexed data type: a data type that is constructed in a generic way from an argument data type. For example, in the case of digital searching we have to define a search tree type by induction on the structure of the type of search keys. This paper shows how to define type-indexed data types, discusses several examples of type-indexed data types, and shows how to specialize type-indexed data types. The approach has been implemented in Generic Haskell, a generic programming extension of the functional language Haskell. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Hinze, Ralf and Jeuring, Johan and L{\"{o}}h, Andres},
doi = {10.1016/j.scico.2003.07.001},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Jeuring, L{\"{o}}h - 2004 - Type-indexed data types.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Digital searching,Generic Haskell,Polytypic programming},
month = {may},
number = {1-2},
pages = {117--151},
title = {{Type-indexed data types}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167642304000152},
volume = {51},
year = {2004}
}
@article{Blumensath2011,
author = {Blumensath, Achim},
doi = {10.1016/j.tcs.2011.02.037},
file = {:Users/liang-tingchen/Dropbox/References/Blumensath - 2011 - Recognisability for algebras of infinite trees.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jul},
number = {29},
pages = {3463--3486},
publisher = {Elsevier B.V.},
title = {{Recognisability for algebras of infinite trees}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.02.037 http://linkinghub.elsevier.com/retrieve/pii/S0304397511001617},
volume = {412},
year = {2011}
}
@misc{Christiansen2015,
author = {Christiansen, David},
title = {{Nested binders in syntax rules}},
url = {https://groups.google.com/d/msg/idris-lang/WhSTO{\_}Q9wZQ/{\_}4IG4Lc1FgAJ},
urldate = {2019-06-27},
year = {2015}
}
@article{Banaschewski1983,
author = {Banaschewski, Bernhard},
doi = {10.1007/BF01194543},
file = {:Users/liang-tingchen/Dropbox/References/Banaschewski - 1983 - The Birkhoff Theorem for varieties of finite algebras.pdf:pdf},
isbn = {0303604395},
journal = {Algebra universalis},
number = {1},
pages = {360--368},
title = {{The Birkhoff Theorem for varieties of finite algebras}},
volume = {17},
year = {1983}
}
@article{Pin1996,
author = {Pin, Jean-{\'{E}}ric and Weil, Pascal},
doi = {10.1007/BF01243597},
file = {:Users/liang-tingchen/Dropbox/References/Pin, Weil - 1996 - A Reiterman theorem for pseudovarieties of finite first-order structures.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {dec},
number = {4},
pages = {577--595},
title = {{A Reiterman theorem for pseudovarieties of finite first-order structures}},
url = {http://link.springer.com/10.1007/BF01243597},
volume = {35},
year = {1996}
}
@article{GIRARD2001,
abstract = {Go back to An-fang, the Peace Square at An-Fang, the Beginning Place at An-Fang, where all things start ({\ldots}) An-Fang was near a city, the only living city with a pre-atomic name ({\ldots}) The headquarters of the People Programmer was at An-Fang, and there the mistake happened: A ruby trembled. Two tourmaline nets failed to rectify the laser beam. A diamond noted the error. Both the error and the correction went into the general computer. Cordwainer Smith The Dead Lady of Clown Town, 1964.},
author = {GIRARD, JEAN-YVES},
doi = {10.1017/S096012950100336X},
file = {:Users/liang-tingchen/Dropbox/References/GIRARD - 2001 - Locus Solum From the rules of logic to the logic of rules.pdf:pdf},
isbn = {0960129501003},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {03},
pages = {301--506},
title = {{Locus Solum: From the rules of logic to the logic of rules}},
url = {http://www.journals.cambridge.org/abstract{\_}S096012950100336X},
volume = {11},
year = {2001}
}
@techreport{Kurz2006,
address = {M{\'{a}}laga},
author = {Kurz, Alexander},
file = {:Users/liang-tingchen/Dropbox/References/Kurz - 2006 - Coalgebras, Stone duality, modal Logic.pdf:pdf},
month = {oct},
title = {{Coalgebras, Stone duality, modal Logic}},
year = {2006}
}
@article{Cirstea2006,
abstract = {We propose a modular approachto defining notions of simulation, and modal logics whichcharacterise them. We use coalgebras to model state-based systems, relators to define notions of simulation for such systems, and inductive techniques to define the syntax and semantics of modal logics for coalgebras. We show that the expressiveness of an inductively defined logic for coalgebras w.r.t. a notion of simulation follows from an expressivity condition involving one stepin the definitionofthe logic, and the relator inducing that notion of simulation. Moreover, we show that notions of simulation and associated characterising logics for increasingly complex system types can be derived by lifting the operations used to combine system types, to a relational level as well as to a logical level. We use these results to obtain Baltag's logic for coalgebraic simulation, as well as notions of simulation and associated logics for a large class of non-deterministic and probabilistic systems. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {C{\^{i}}rstea, Corina},
doi = {10.1016/j.ic.2005.04.005},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2006 - A modular approach to defining and characterising notions of simulation.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Coalgebra,Modal logic,Probabilistic system,Simulation},
month = {apr},
number = {4},
pages = {469--502},
title = {{A modular approach to defining and characterising notions of simulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S089054010500194X},
volume = {204},
year = {2006}
}
@article{Vasconcelos2012,
author = {Vasconcelos, Vasco T},
doi = {10.1016/j.ic.2012.05.002},
file = {:Users/liang-tingchen/Dropbox/References/Vasconcelos - 2012 - Fundamentals of session types.pdf:pdf},
issn = {0890-5401},
journal = {Information and Computation},
pages = {52--70},
publisher = {Elsevier Inc.},
title = {{Fundamentals of session types}},
url = {http://dx.doi.org/10.1016/j.ic.2012.05.002},
volume = {217},
year = {2012}
}
@article{Stoughton1988,
author = {Stoughton, Allen},
doi = {10.1016/0304-3975(88)90149-1},
file = {:Users/liang-tingchen/Dropbox/References/Stoughton - 1988 - Substitution revisited.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {aug},
number = {3},
pages = {317--325},
title = {{Substitution revisited}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397588901491 https://linkinghub.elsevier.com/retrieve/pii/0304397588901491},
volume = {59},
year = {1988}
}
@phdthesis{Lawler2014,
archivePrefix = {arXiv},
arxivId = {1502.08017},
author = {Lawler, Finn},
eprint = {1502.08017},
file = {:Users/liang-tingchen/Dropbox/References/Lawler - 2014 - Fibrations of Predicates and Bicategories of Relations.pdf:pdf},
number = {September},
school = {Trinity College, Dublin},
title = {{Fibrations of Predicates and Bicategories of Relations}},
type = {PhD Thesis},
url = {http://arxiv.org/abs/1502.08017v1},
year = {2014}
}
@inproceedings{Li2007a,
abstract = {The Glasgow Haskell Compiler (GHC) has quite sophisticated support for concurrency in its runtime system, which is written in low-level C code. As GHC evolves, the runtime system becomes increasingly complex, error-prone, difficult to maintain and difficult to add new concurrency features.},
address = {New York, New York, USA},
author = {Li, Peng and Marlow, Simon and Jones, Simon Peyton and Tolmach, Andrew},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell workshop - Haskell '07},
doi = {10.1145/1291201.1291217},
file = {:Users/liang-tingchen/Dropbox/References/Li et al. - 2007 - Lightweight concurrency primitives for GHC.pdf:pdf},
isbn = {9781595936745},
keywords = {concurrency,concurrency abstrac-,haskell,might wish to experiment,new challenges,or data par-,such as multi-processor support,thread,tions,transactional memory,with a variety of},
number = {Figure 1},
pages = {107},
publisher = {ACM Press},
title = {{Lightweight concurrency primitives for GHC}},
url = {http://portal.acm.org/citation.cfm?doid=1291201.1291217},
year = {2007}
}
@article{Enqvist2014,
author = {Enqvist, Sebastian},
doi = {10.1093/logcom/exu045},
file = {:Users/liang-tingchen/Dropbox/References/Enqvist - 2014 - A new coalgebraic Lindstrom theorem.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {abstract model theory,coalgebra,lindstr{\"{o}}m,modal logic,s theorem},
month = {jul},
title = {{A new coalgebraic Lindstrom theorem}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exu045},
year = {2014}
}
@article{Truta2006,
abstract = {In this paper, we introduce a new privacy protection property called p-sensitive k-anonymity. The existing kanonymity property protects against identity disclosure, but it fails to protect against attribute disclosure. The new introduced privacy model avoids this shortcoming. Two necessary conditions to achieve p-sensitive kanonymity property are presented, and used in developing algorithms to create masked microdata with p-sensitive k-anonymity property using generalization and suppression.},
author = {Truta, Traian Marius and Vinay, Bindu},
doi = {10.1109/ICDEW.2006.116},
file = {:Users/liang-tingchen/Dropbox/References/Truta, Vinay - 2006 - Privacy protection p-Sensitive k-Anonymity property.pdf:pdf},
isbn = {0769525717},
journal = {ICDEW 2006 - Proceedings of the 22nd International Conference on Data Engineering Workshops},
title = {{Privacy protection: p-Sensitive k-Anonymity property}},
year = {2006}
}
@article{Lehmann1955,
author = {Lehmann, E. L.},
doi = {10.1214/aoms/1177728487},
file = {:Users/liang-tingchen/Dropbox/References/Lehmann - 1955 - Ordered Families of Distributions.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
month = {sep},
number = {3},
pages = {399--419},
title = {{Ordered Families of Distributions}},
url = {http://projecteuclid.org/euclid.aoms/1177728487},
volume = {26},
year = {1955}
}
@inproceedings{Krishnaswami2009,
abstract = {In this paper, we show how pattern matching can be seen to arise from a proof term assignment for the focused sequent calculus. This use of the Curry-Howard correspondence allows us to give a novel coverage checking algorithm, and makes it possible to give a rigorous correctness proof for the classical pattern compilation strategy of building decision trees via matrices of patterns. {\textcopyright} 2009 ACM.},
address = {New York, New York, USA},
author = {Krishnaswami, Neelakantan R.},
booktitle = {Proceedings of the 36th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '09},
doi = {10.1145/1480881.1480927},
file = {:Users/liang-tingchen/Dropbox/References/Krishnaswami - 2008 - Focusing on pattern matching.pdf:pdf},
isbn = {9781605583792},
issn = {07308566},
keywords = {Curry-Howard,Focusing,Pattern Matching,Type Theory},
pages = {366},
publisher = {ACM Press},
title = {{Focusing on pattern matching}},
url = {http://portal.acm.org/citation.cfm?doid=1480881.1480927},
year = {2008}
}
@inproceedings{Asai2015,
abstract = {A reflective language makes the language semantics open to user programs and allows them to access, extend, and modify it from within the same language framework. Because of its high flexibility and expressiveness, it can be an ideal platform for programming language research as well as practical applications in dynamic environments. However, efficient implementation of a reflective language is extremely difficult. Under the circumstance where the language semantics can change, a partial evaluator is required for compilation. This paper reports on the experience of using MetaOCaml as a compiler for a reflective language. With staging annotations, MetaOCaml achieves the same effect as using a partial evaluator. Unlike the standard partial evaluator, the run mechanism of MetaOCaml enables us to use the specialized (compiled) code in the current runtime environment. On the other hand, the lack of a binding-time analysis in MetaOCaml prohibits us from compiling a user program under modified compiled semantics.},
address = {New York, New York, USA},
author = {Asai, Kenichi},
booktitle = {Proceedings of the 2014 International Conference on Generative Programming: Concepts and Experiences - GPCE 2014},
doi = {10.1145/2658761.2658775},
file = {:Users/liang-tingchen/Dropbox/References/Asai - 2014 - Compiling a reflective language using MetaOCaml.pdf:pdf},
isbn = {9781450331616},
issn = {15232867},
keywords = {Binding-time analysis,MetaOCaml,Metacircular interpreter,Partial evaluation,Reflection,Staging},
number = {3},
pages = {113--122},
publisher = {ACM Press},
title = {{Compiling a reflective language using MetaOCaml}},
url = {http://dl.acm.org/citation.cfm?doid=2658761.2658775},
volume = {50},
year = {2014}
}
@inproceedings{Wang2014,
abstract = {— The concept of differential privacy stems from the study of private query of datasets. In this work, we apply this concept to metric spaces to study a mechanism that randomizes a deterministic query by adding mean-zero noise to keep differential privacy. For one-shot queries, we show that privacy of an n-dimensional input implies a lower bound n − n ln(on the entropy of the randomized output, and this lower bound is achieved by adding Laplacian noise. We then consider the privacy of a discrete-time linear feedback system in which noise is added to the system output at each time. The adversary estimates the system states from the output history. We show that, to keep the system differentially private, the output entropy is bounded below, and this lower bound is achieves by an explicit mechanism.},
author = {Wang, Yu and Huang, Zhenqi and Mitra, Sayan and Dullerud, Geir E},
booktitle = {53rd IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2014.7039713},
file = {:Users/liang-tingchen/Dropbox/References/Wang et al. - 2014 - Entropy-minimizing mechanism for differential privacy of discrete-time linear feedback systems.pdf:pdf},
isbn = {978-1-4673-6090-6},
month = {dec},
pages = {2130--2135},
publisher = {IEEE},
title = {{Entropy-minimizing mechanism for differential privacy of discrete-time linear feedback systems}},
url = {http://ieeexplore.ieee.org/document/7039713/},
year = {2014}
}
@incollection{Milner1994,
author = {Milner, Robin},
booktitle = {Programming Languages and Systems — ESOP '94. ESOP 1994},
doi = {10.1007/3-540-57880-3_2},
editor = {Sannella, Donald},
file = {:Users/liang-tingchen/Dropbox/References/Milner - 1994 - Pi-nets A graphical form of $\pi$-calculus.pdf:pdf},
pages = {26--42},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Pi-nets: A graphical form of $\pi$-calculus}},
url = {http://link.springer.com/10.1007/3-540-57880-3{\_}2},
volume = {788},
year = {1994}
}
@article{DeBruijn1991,
abstract = {The paper develops notation for strings of abstractors in typed lambda calculus, and shows how to treat them more or less as single abstractors. {\textcopyright} 1991.},
author = {de Bruijn, N.G.},
doi = {10.1016/0890-5401(91)90066-B},
file = {:Users/liang-tingchen/Dropbox/References/de Bruijn - 1991 - Telescopic mappings in typed lambda calculus.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {2},
pages = {189--204},
title = {{Telescopic mappings in typed lambda calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/089054019190066B},
volume = {91},
year = {1991}
}
@incollection{Sestoft2002,
abstract = {We describe lambda calculus reduction strategies using big-step operational semantics and show how to efficiently trace such reductions. This is used in a web-based lambda calculus reducer, at http://www.dina.kvl.dk/{\~{}}sestoft/lamreduce/ . ?? 2001 Published by Elsevier Science B.V.},
author = {Sestoft, Peter},
booktitle = {The Essence of Computation: Complexity, Analysis, Transformation},
doi = {10.1007/3-540-36377-7_19},
editor = {Mogensen, Torben {\AE}. and Schmidt, David A. and Sudborough, I. Hal},
file = {:Users/liang-tingchen/Dropbox/References/Sestoft - 2002 - Demonstrating lambda calculus reduction.pdf:pdf},
isbn = {9783540003267},
issn = {15710661},
pages = {420--435},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Demonstrating lambda calculus reduction}},
url = {http://link.springer.com/10.1007/3-540-36377-7{\_}19},
volume = {2566},
year = {2002}
}
@inproceedings{Winterhalter2019,
address = {New York, New York, USA},
author = {Winterhalter, Th{\'{e}}o and Sozeau, Matthieu and Tabareau, Nicolas},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs - CPP 2019},
doi = {10.1145/3293880.3294095},
file = {:Users/liang-tingchen/Dropbox/References/Winterhalter, Sozeau, Tabareau - 2019 - Eliminating reflection from type theory.pdf:pdf},
isbn = {9781450362221},
keywords = {2019,8th,acm reference format,and nicolas tabareau,dependent types,eliminating reflection from type,formalisation,in proceedings of the,matthieu sozeau,theory,th{\'{e}}o winterhalter,translation},
pages = {91--103},
publisher = {ACM Press},
title = {{Eliminating reflection from type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3293880.3294095},
year = {2019}
}
@incollection{Gianantonio2004,
abstract = {In this paper we present a theorem for defining fixed-points in categories of sheaves. This result gives a unifying and general account of most techniques used in computer science in order to ensure convergency of circular definitions, such as (but not limited to) well-founded recursion and contractivity in complete ultra metric spaces. This general fixed-point theorem encompasses also a similar set theoretic result presented in previous work, based on the notion of ordered family of equivalences, and implemented in the Coq proof assistant. {\textcopyright} Springer-Verlag 2004.},
author = {{Di Gianantonio}, Pietro and Miculan, Marino},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2004},
doi = {10.1007/978-3-540-24727-2_11},
editor = {Walukiewicz, Igor},
file = {:Users/liang-tingchen/Dropbox/References/Di Gianantonio, Miculan - 2004 - Unifying Recursive and Co-recursive Definitions in Sheaf Categories.pdf:pdf},
issn = {03029743},
pages = {136--150},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Unifying Recursive and Co-recursive Definitions in Sheaf Categories}},
url = {http://link.springer.com/10.1007/978-3-540-24727-2{\_}11},
volume = {2987},
year = {2004}
}
@inproceedings{Cirstea2015,
address = {Dagstuhl, Germany},
annote = {Keywords: coalgebra, linear time logic, fixpoint logic},
author = {C{\^{i}}rstea, Corina},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science (CALCO 2015)},
doi = {http://dx.doi.org/10.4230/LIPIcs.CALCO.2015.66},
editor = {Moss, Lawrence S and Sobocinski, Pawel},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2015 - Canonical coalgebraic linear time logics.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
pages = {66--85},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Canonical coalgebraic linear time logics}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5527},
volume = {35},
year = {2015}
}
@techreport{Necula1996,
author = {Necula, George C. and Lee, Peter},
booktitle = {Technical Report CMU-CS-96-165},
file = {:Users/liang-tingchen/Dropbox/References/Necula, Lee - 1996 - Proof-Carrying Code.pdf:pdf},
institution = {School of Computer Science, Carnegie Mellon University},
keywords = {operating system security and,protection,safety of un-,system extensibility},
month = {nov},
title = {{Proof-Carrying Code}},
year = {1996}
}
@inproceedings{Keller2010,
abstract = {We analyze a normalization function for the simply typed $\lambda$-calculus based on hereditary substitutions, a technique developed by Pfenning et al. The normalizer is implemented in Agda, a total language where all programs terminate. It requires no termination proof since it is structurally recursive which is recognized by Agda's termination checker. Using Agda as an interactive theorem prover we establish that our normalization function precisely identifies $\beta$$\eta$-equivalent terms and hence can be used to decide $\beta$$\eta$-equality. An interesting feature of this approach is that it is clear from the construction that $\beta$$\eta$-equality is primitive recursive. {\textcopyright} 2010 ACM.},
address = {New York, New York, USA},
author = {Keller, Chantal and Altenkirch, Thorsten},
booktitle = {Proceedings of the third ACM SIGPLAN workshop on Mathematically structured functional programming - MSFP '10},
doi = {10.1145/1863597.1863601},
file = {:Users/liang-tingchen/Dropbox/References/Keller, Altenkirch - 2010 - Hereditary substitutions for simple types, formalized.pdf:pdf},
isbn = {9781450302555},
keywords = {decidability of $\beta$$\eta$-equality,hereditary substitutions,normalizer,type theory},
pages = {3},
publisher = {ACM Press},
title = {{Hereditary substitutions for simple types, formalized}},
url = {http://portal.acm.org/citation.cfm?doid=1863597.1863601},
year = {2010}
}
@book{Blackburn2002a,
author = {Blackburn, Patrick and de Rijke, Maarten and Venema, Yde},
file = {:Users/liang-tingchen/Dropbox/References/Blackburn, Rijke, Venema - 2002 - Modal Logic.pdf:pdf},
publisher = {Cambridge University Press},
title = {{Modal Logic}},
type = {Book},
year = {2002}
}
@article{Hugues2006,
abstract = {"[M]athematicians care no more for logic than logicians for mathematics." Augustus de Morgan, 1868.   Proofs are traditionally syntactic, inductively generated objects. This paper presents an abstract mathematical formulation of propositional calculus (propositional logic) in which proofs are combinatorial (graph-theoretic), rather than syntactic. It defines a *combinatorial proof* of a proposition P as a graph homomorphism h : C -{\textgreater} G(P), where G(P) is a graph associated with P and C is a coloured graph. The main theorem is soundness and completeness: P is true iff there exists a combinatorial proof h : C -{\textgreater} G(P).},
archivePrefix = {arXiv},
arxivId = {math/0408282},
author = {Hugues, D. J D},
doi = {10.4007/annals.2006.164.1065},
eprint = {0408282},
file = {:Users/liang-tingchen/Dropbox/References/Hugues - 2006 - Proofs without syntax.pdf:pdf},
issn = {0003486X},
journal = {Annals of Mathematics},
pages = {1065--1076},
primaryClass = {math},
title = {{Proofs without syntax}},
volume = {164},
year = {2006}
}
@incollection{Castellan2021,
abstract = {We show how the categorical logic of the untyped, simply typed and dependently typed lambda calculus can be structured around the notion of category with families (cwf). To this end we introduce subcategories of simply typed cwfs (scwfs), where types do not depend on variables, and unityped cwfs (ucwfs), where there is only one type. We prove several equivalence and biequivalence theorems between cwf-based notions and basic notions of categorical logic, such as cartesian operads, Lawvere theories, categories with finite products and limits, cartesian closed categories, and locally cartesian closed categories. Some of these theorems depend on the restrictions of contextuality (in the sense of Cartmell) or democracy (in the sense of Clairambault and Dybjer). Some theorems are equivalences between notions with strict preservation of chosen structure. Others are biequivalences involving notions without chosen structure, and where properties are (necessarily) only preserved up to isomorphism. The cwf-based notions play the role of an abstract syntax of formal systems, and we discuss various constructions of initial ucwfs, scwfs, and cwfs with extra structure. As a corollary of our results we show that equality in the free locally cartesian closed category is undecidable.},
archivePrefix = {arXiv},
arxivId = {1904.00827},
author = {Castellan, Simon and Clairambault, Pierre and Dybjer, Peter},
booktitle = {Outstanding Contributions to Logic},
doi = {10.1007/978-3-030-66545-6_5},
eprint = {1904.00827},
file = {:Users/liang-tingchen/Dropbox/References/Castellan, Clairambault, Dybjer - 2021 - Categories with Families Unityped, Simply Typed, and Dependently Typed.pdf:pdf},
issn = {22112766},
pages = {135--180},
title = {{Categories with Families: Unityped, Simply Typed, and Dependently Typed}},
url = {http://link.springer.com/10.1007/978-3-030-66545-6{\_}5},
volume = {20},
year = {2021}
}
@article{Geun1986,
author = {Geun, Bin Im and Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Geun, Kelly - 1986 - On classes of morpbisms closed under limits.pdf:pdf},
journal = {Journal of Korean Mathematics Society},
number = {1},
pages = {1--18},
title = {{On classes of morpbisms closed under limits}},
volume = {23},
year = {1986}
}
@article{Lawvere1969,
author = {Lawvere, F. William},
file = {:Users/liang-tingchen/Dropbox/References/Lawvere - 1969 - Adjointness in foundations.pdf:pdf},
journal = {Dialectica},
pages = {1--16},
title = {{Adjointness in foundations}},
volume = {23},
year = {1969}
}
@incollection{Komendantskaya2008,
author = {Komendantskaya, Ekaterina and Power, John},
booktitle = {Logics in Artificial Intelligence. JELIA 2008},
doi = {10.1007/978-3-540-87803-2_22},
editor = {H{\"{o}}lldobler, Steffen and Lutz, Carsten and Wansing, Heinrich},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Power - 2008 - Fibrational Semantics for Many-Valued Logic Programs Grounds for Non-Groundness.pdf:pdf},
keywords = {categorical logic,fibrational,ground semantics,many-valued logic programs,semantics,sld-resolution},
pages = {258--271},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Fibrational Semantics for Many-Valued Logic Programs: Grounds for Non-Groundness}},
url = {http://link.springer.com/10.1007/978-3-540-87803-2{\_}22},
volume = {5293},
year = {2008}
}
@incollection{Paulin-Mohring2012a,
abstract = {This paper is a tutorial on using the Coq proof-assistant for reasoning on software correctness. It illustrates features of Coq like inductive definitions and proof automation on a few examples including arithmetic, algorithms on functional and imperative lists and cryptographic protocols. Coq is not a tool dedicated to software verification but a general purpose environment for developing mathematical proofs. However, it is based on a powerful language including basic functional programming and high-level specifications. As such it offers modern ways to literally program proofs in a structured way with advanced data-types, proofs by computation, and general purpose libraries of definitions and lemmas. Coq is well suited for software verification of programs involving advanced specifications like language semantics and real numbers. The Coq architecture is also based on a small trusted kernel, making possible to use third-party libraries while being sure that proofs are not compromised. {\textcopyright} 2012 Springer-Verlag.},
author = {Paulin-Mohring, Christine},
booktitle = {Tools for Practical Software Verification. LASER 2011},
doi = {10.1007/978-3-642-35746-6_3},
editor = {Meyer, Bertrand and Nordio, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Paulin-Mohring - 2012 - Introduction to the Coq Proof-Assistant for Practical Software Verification.pdf:pdf},
isbn = {9783642357459},
issn = {03029743},
pages = {45--95},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Introduction to the Coq Proof-Assistant for Practical Software Verification}},
url = {http://link.springer.com/10.1007/978-3-642-35746-6{\_}3},
volume = {7682},
year = {2012}
}
@article{Buneman1991,
abstract = {Much of relational algebra and the underlying principles of relational database design have a simple representation in the theory of domains that is traditionally used in the denotational semantics of programming languages. By investigating the possible orderings on powerdomains that are well known in the study of nondeterminism and concurrency it is possible to show that many of the ideas in relational databases apply to structures that are much more general than relations. This also suggests a method of representing database objects as typed objects in programming languages. In this paper we show how operations such as natural join and projection-which are fundamental to relational database design-can be generalized, and we use this generalized framework to give characterizations of several relational database concepts including functional dependencies and universal relations. All of these have a simple-minded semantics in terms of the underlying domains, which can be thought of as domains of partial descriptions of "real-world" objects. We also discuss the applicability of relational database theory to nonrelational structures such as records with variants, higher-order relations, recursive structures and other ordered spaces. {\textcopyright} 1991.},
author = {Buneman, Peter and Jung, Achim and Ohori, Atsushi},
doi = {10.1016/0304-3975(91)90266-5},
file = {:Users/liang-tingchen/Dropbox/References/Buneman, Jung, Ohori - 1991 - Using powerdomains to generalize relational databases.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1},
pages = {23--55},
title = {{Using powerdomains to generalize relational databases}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397591902665},
volume = {91},
year = {1991}
}
@article{Klin2009a,
author = {Klin, Bartek},
doi = {10.1016/j.ic.2007.10.006},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2009 - Bialgebraic methods and modal logic in structural operational semantics.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {structural operational semantics},
month = {feb},
number = {2},
pages = {237--257},
publisher = {Elsevier Inc.},
title = {{Bialgebraic methods and modal logic in structural operational semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540108001272},
volume = {207},
year = {2009}
}
@incollection{Hinze2013a,
abstract = {Sorting algorithms are one of the key pedagogical foundations of com-puter science, and their properties have been studied heavily. Perhaps less well known, however, is the fact that many of the basic sorting algorithms exist as a pair, and that these pairs arise naturally out of the duality between folds and unfolds. In this paper, we make this duality explicit, by showing how to define common sorting algorithms as folds of unfolds, or, dually, as unfolds of folds. This duality is preserved even when considering optimised sorting algorithms that require more exotic variations of folds and unfolds, and intermediary data structures. While all this material arises naturally from a categorical modelling of these recursion schemes, we endeavour to keep this presentation accessible to those not versed in abstract nonsense.},
author = {Hinze, Ralf and Magalh{\~{a}}es, Jos{\'{e}} Pedro and Wu, Nicolas},
booktitle = {The Beauty of Functional Code},
doi = {10.1007/978-3-642-40355-2-11},
editor = {Achten, Peter and Koopman, Pieter},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Magalh{\~{a}}es, Wu - 2013 - A duality of sorts.pdf:pdf},
isbn = {9783642403545},
issn = {03029743},
pages = {151--167},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A duality of sorts}},
volume = {8106},
year = {2013}
}
@inproceedings{Kupke2020,
abstract = {The classical Hennessy-Milner theorem says that two states of an image-finite transition system are bisimilar if and only if they satisfy the same formulas in a certain modal logic. In this paper we study this type of result in a general context, moving from transition systems to coalgebras and from bisimilarity to coinductive predicates. We formulate when a logic fully characterises a coinductive predicate on coalgebras, by providing suitable notions of adequacy and expressivity, and give sufficient conditions on the semantics. The approach is illustrated with logics characterising similarity, divergence and a behavioural metric on automata.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Expressive logics for coinductive predicates - Kupke, Clemens; Rot, Jurriaan)

Keywords: Coalgebra, Fibration, Modal Logic},
author = {Kupke, Clemens and Rot, Jurriaan},
booktitle = {Leibniz International Proceedings in Informatics, LIPIcs},
doi = {10.4230/LIPIcs.CSL.2020.26},
editor = {Fern{\'{a}}ndez, Maribel and Muscholl, Anca},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Rot - 2020 - Expressive logics for coinductive predicates.pdf:pdf},
isbn = {9783959771320},
issn = {18688969},
keywords = {2020,26,4230,Coalgebra,Fibration,Modal logic,acknowledgements we would like,and phrases coalgebra,csl,digital object identifier 10,fibration,for useful discussions and,funding this work was,grant code 795119,lipics,marie curie fellowship,modal logic,partially supported by a,the anonymous,to thank bart jacobs},
number = {26},
pages = {26:1----26:18},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Expressive logics for coinductive predicates}},
url = {https://drops.dagstuhl.de/opus/volltexte/2020/11669},
volume = {152},
year = {2020}
}
@incollection{Moor1992,
author = {Bird, Richard and Moor, Oege},
booktitle = {Formal Program Development},
doi = {10.1007/3-540-57499-9_16},
editor = {M{\"{o}}ller, Bernhard and Partsch, Helmut and Schuman, Steve},
file = {:Users/liang-tingchen/Dropbox/References/Bird, Moor - 1993 - From dynamic programming to greedy algorithms.pdf:pdf},
pages = {43--61},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{From dynamic programming to greedy algorithms}},
url = {http://link.springer.com/10.1007/3-540-57499-9{\_}16},
volume = {755},
year = {1993}
}
@inproceedings{Coquand2018,
abstract = {Cubical type theory provides a constructive justification to certain aspects of homotopy type theory such as Voevodsky's univalence axiom. This makes many extensionality principles, like function and propositional extensionality, directly provable in the theory. This paper describes a constructive semantics, expressed in a presheaf topos with suitable structure inspired by cubical sets, of some higher inductive types. It also extends cubical type theory by a syntax for the higher inductive types of spheres, torus, suspensions,truncations, and pushouts. All of these types are justified by the semantics and have judgmental computation rules for all constructors, including the higher dimensional ones, and the universes are closed under these type formers.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1802.01170},
author = {Coquand, Thierry and Huber, Simon and M{\"{o}}rtberg, Anders},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '18},
doi = {10.1145/3209108.3209197},
eprint = {1802.01170},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Huber, M{\"{o}}rtberg - 2018 - On Higher Inductive Types in Cubical Type Theory.pdf:pdf},
isbn = {9781450355834},
keywords = {15,Cubical Type Theory,Higher Inductive Types,Homotopy Type Theory,Univalent Foundations,a model,cubical type theory,established,has not yet been,higher inductive types,homo-,impressive developments,in a classical framework,plicial set model,provides,the sim-,topy type theory,univalent foundations},
pages = {255--264},
publisher = {ACM Press},
title = {{On Higher Inductive Types in Cubical Type Theory}},
url = {http://arxiv.org/abs/1802.01170 http://dl.acm.org/citation.cfm?doid=3209108.3209197},
year = {2018}
}
@inproceedings{Blelloch1995,
address = {New York, New York, USA},
author = {Blelloch, Guy and Greiner, John},
booktitle = {Proceedings of the seventh international conference on Functional programming languages and computer architecture - FPCA '95},
doi = {10.1145/224164.224210},
file = {:Users/liang-tingchen/Dropbox/References/Blelloch, Greiner - 1995 - Parallelism in sequential functional languages.pdf:pdf},
isbn = {0897917197},
pages = {226--237},
publisher = {ACM Press},
title = {{Parallelism in sequential functional languages}},
url = {http://portal.acm.org/citation.cfm?doid=224164.224210},
year = {1995}
}
@incollection{Fiadeiro2015,
abstract = {In this paper we focus on the formalization of component- based architecture self-reconfiguration as an action associated to quality- of-service (QoS) contracts violation.With this, we aim to develop on the vision of the component-based software engineering (CBSE) as a gener- ator of software artifacts responsible for QoS contracts. This formaliza- tion, together with a definition of a QoS contract, forms the basis of the framework we propose to enable a system to preserve its QoS contracts. Our approach is built on a theory of extended graph (e-graph) rewriting as a formalism to represent QoS contracts, component-based architec- tural structures and architecture reconfiguration. We use a rule-based strategy for the extensible part of our framework. The reconfiguration rules are expressed as e-graph rewriting rules whose left and right hand sides can be used to encode design patterns for addressing QoS proper- ties. These rules, given by a QoS property domain expert, are checked as safe, i.e., terminating and confluent, before its application by graph pattern-matching over the runtime representation of the system. 1},
author = {Castiglioni, Valentina and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
booktitle = {Formal Aspects of Component Software. FACS 2018},
doi = {10.1007/978-3-030-02146-7_4},
editor = {K., Bae and P, {\"{O}}lveczky},
file = {:Users/liang-tingchen/Dropbox/References/Castiglioni, Chatzikokolakis, Palamidessi - 2018 - A Logical Characterization of Differential Privacy via Behavioral Metrics.pdf:pdf},
isbn = {978-3-319-68033-0},
issn = {01676423},
pages = {75--96},
publisher = {Springer, Cham},
title = {{A Logical Characterization of Differential Privacy via Behavioral Metrics}},
url = {http://dx.doi.org/10.1007/978-3-030-02146-7{\_}4 http://link.springer.com/10.1007/978-3-030-02146-7{\_}4},
volume = {11222},
year = {2018}
}
@article{Brengos2014,
abstract = {In the first part of the paper we recall the coalgebraic approach to handling the so-called invisible transitions that appear in different state-based systems semantics. We claim that these transitions are always part of the unit of a certain monad. Hence, coalgebras with internal moves are exactly coalgebras over a monadic type. The rest of the paper is devoted to supporting our claim by studying two important behavioural equivalences for state-based systems with internal moves, namely: weak bisimulation and trace semantics. We continue our research on weak bisimulations for coalgebras over order enriched monads. The key notions used in this paper and proposed by us in our previous work are the notions of an order saturation monad and a saturator. A saturator operator can be intuitively understood as a reflexive, transitive closure operator. There are two approaches towards defining saturators for coalgebras with internal moves. Here, we give necessary conditions for them to yield the same notion of weak bisimulation. Finally, we propose a definition of trace semantics for coalgebras with silent moves via a uniform fixed point operator. We compare strong and weak bisimilation together with trace semantics for coalgebras with internal steps.},
archivePrefix = {arXiv},
arxivId = {1402.6281},
author = {Brengos, Tomasz},
eprint = {1402.6281},
file = {:Users/liang-tingchen/Dropbox/References/Brengos - 2014 - On coalgebras with internal moves.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {bisimulation,coalgebra,conway operator,epsilon transition,fixed,internal transition,logic,monad,point operator,saturation,tics,trace,trace seman-,traced monoidal category,uniform fixed point operator,van glabbeek spectrum,weak bisimulation,weak trace semantics},
month = {feb},
number = {504},
pages = {23},
title = {{On coalgebras with internal moves}},
url = {http://arxiv.org/abs/1402.6281},
year = {2014}
}
@inproceedings{Kiselyov2015,
abstract = {We present a rational reconstruction of extensible effects, the recently proposed alternative to monad transformers, as the confluence of efforts to make effectful computations compose. Free monads and then extensible effects emerge from the straightforward term representation of an effectful computation, as more and more boilerplate is abstracted away. The generalization process further leads to freer monads, constructed without the Functor constraint. The continuation exposed in freer monads can then be represented as an efficient type-aligned data structure. The end result is the algorithmically efficient extensible effects library, which is not only more comprehensible but also faster than earlier implementations. As an illustration of the new library, we show three surprisingly simple applications: non-determinism with committed choice (LogicT), catching IO exceptions in the presence of other effects, and the semi-automatic management of file handles and other resources through monadic regions. We extensively use and promote the new sort of `laziness', which underlies the left Kan extension: instead of performing an operation, keep its operands and pretend it is done.},
address = {New York, New York, USA},
author = {Kiselyov, Oleg and Ishii, Hiromi},
booktitle = {Proceedings of the 8th ACM SIGPLAN Symposium on Haskell - Haskell 2015},
doi = {10.1145/2804302.2804319},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov, Ishii - 2015 - Freer monads, more extensible effects.pdf:pdf},
isbn = {9781450338080},
issn = {03621340},
keywords = {coroutine,effect handler,effect interaction,free monad,kan extension,open union,type and effect system},
pages = {94--105},
publisher = {ACM Press},
title = {{Freer monads, more extensible effects}},
url = {http://dl.acm.org/citation.cfm?doid=2804302.2804319},
year = {2015}
}
@article{Sipos2015,
archivePrefix = {arXiv},
arxivId = {1409.1370},
author = {Sipos, Andrei},
eprint = {1409.1370},
file = {:Users/liang-tingchen/Dropbox/References/Sipos - 2015 - Codensity and Stone spaces.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {codensity,frame,monad,sober space,stone space,ultrafilter},
pages = {1--18},
title = {{Codensity and Stone spaces}},
year = {2015}
}
@article{Pippenger1997,
author = {Pippenger, Nicholas},
doi = {10.1007/BF02679444},
file = {:Users/liang-tingchen/Dropbox/References/Pippenger - 1997 - Regular languages and stone duality.pdf:pdf},
issn = {1432-4350},
journal = {Theory of Computing Systems},
month = {jul},
number = {2},
pages = {121--134},
title = {{Regular languages and stone duality}},
url = {http://link.springer.com/10.1007/BF02679444},
volume = {30},
year = {1997}
}
@inproceedings{Gaboardi2016,
abstract = {Effects and coeffects are two general, complementary aspects of program behaviour. They roughly correspond to computations which change the execution context (effects) versus computations which make demands on the context (coeffects). Effectful features include partiality, non-determinism, input-output, state, and exceptions. Coeffectful features include resource demands, variable access, notions of linearity, and data input requirements. The effectful or coeffectful behaviour of a program can be captured and described via type-based analyses, with fine grained information provided by monoidal effect annotations and semiring coeffects. Various recent work has proposed models for such typed calculi in terms of graded (strong) monads for effects and graded (monoidal) comonads for coeffects. Effects and coeffects have been studied separately so far, but in practice many computations are both effectful and coeffectful, e.g., possibly throwing exceptions but with resource requirements. To remedy this, we introduce a new general calculus with a combined effect-coeffect system. This can describe both the changes and requirements that a program has on its context, as well as interactions between these effectful and coeffectful features of computation. The effect-coeffect system has a denotational model in terms of effect-graded monads and coeffect-graded comonads where interaction is expressed via the novel concept of graded distributive laws. This graded semantics unifies the syntactic type theory with the denotational model. We show that our calculus can be instantiated to describe in a natural way various different kinds of interaction between a program and its evaluation context.},
address = {New York, New York, USA},
author = {Gaboardi, Marco and Katsumata, Shin-ya and Orchard, Dominic and Breuvart, Flavien and Uustalu, Tarmo},
booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming - ICFP 2016},
doi = {10.1145/2951913.2951939},
file = {:Users/liang-tingchen/Dropbox/References/Gaboardi et al. - 2016 - Combining effects and coeffects via grading.pdf:pdf},
isbn = {9781450342193},
keywords = {categorical semantics,coeffects,comonads,distributive,effects,grading,laws,monads,types},
pages = {476--489},
publisher = {ACM Press},
title = {{Combining effects and coeffects via grading}},
url = {http://dl.acm.org/citation.cfm?doid=2951913.2951939},
year = {2016}
}
@inproceedings{Kavvos2017,
abstract = {We show how to derive natural deduction systems for the necessity fragment of various constructive modal logics by exploiting a pattern found in sequent calculi. The resulting systems are dual-context systems, in the style pioneered by Girard, Barber, Plotkin, Pfenning, Davies, and others. This amounts to a full extension of the Curry-Howard-Lambek correspondence to the necessity fragments of a constructive variant of the modal logics K, K4, GL, T, and S4. We investigate the metatheory of these calculi, as well as their categorical semantics. Finally, we speculate on their computational interpretation.},
archivePrefix = {arXiv},
arxivId = {1602.04860},
author = {Kavvos, G. Alex},
booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2017.8005089},
eprint = {1602.04860},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2017 - Dual-context calculi for modal logic.pdf:pdf},
isbn = {978-1-5090-3018-7},
issn = {10436871},
month = {jun},
pages = {1--12},
publisher = {IEEE},
title = {{Dual-context calculi for modal logic}},
url = {http://ieeexplore.ieee.org/document/8005089/},
volume = {4},
year = {2017}
}
@incollection{Kurz2002,
author = {Kurz, Alexander and Pattinson, Dirk},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/S1571-0661(04)80363-3},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Pattinson - 2002 - Definability, canonical models, compactness for finitary coalgebraic modal logic.pdf:pdf},
issn = {15710661},
month = {oct},
number = {1},
pages = {135--155},
title = {{Definability, canonical models, compactness for finitary coalgebraic modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104803633},
volume = {65},
year = {2002}
}
@incollection{McBride2016,
author = {McBride, Conor},
booktitle = {A List of Successes That Can Change the World},
doi = {10.1007/978-3-319-30936-1_12},
editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2016 - I Got Plenty o' Nuttin'.pdf:pdf},
isbn = {9783319309354},
issn = {16113349},
pages = {207--233},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{I Got Plenty o' Nuttin'}},
url = {http://link.springer.com/10.1007/978-3-319-30936-1{\_}12},
volume = {9600},
year = {2016}
}
@article{Chang2017,
abstract = {We present TURNSTILE, a metalanguage for creating typed embedded languages. To implement the type system, pro-grammers write type checking rules resembling traditional judgment syntax. To implement the semantics, they incorpo-rate elaborations into these rules. TURNSTILE critically de-pends on the idea of linguistic reuse. It exploits a macro sys-tem in a novel way to simultaneously type check and rewrite a surface program into a target language. Reusing a macro system also yields modular implementations whose rules may be mixed and matched to create other languages. Com-bined with typical compiler and runtime reuse, TURNSTILE produces performant typed languages with little effort.},
author = {Chang, Stephen and Ballantyne, Michael and Turner, Milo and Bowman, William J.},
doi = {10.1145/3371071},
file = {:Users/liang-tingchen/Dropbox/References/Chang et al. - 2020 - Dependent type systems as macros.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {dependent types,macros,proof assistants,type systems},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Dependent type systems as macros}},
url = {http://dl.acm.org/citation.cfm?doid=3093333.3009886 http://dl.acm.org/doi/10.1145/3371071},
volume = {4},
year = {2020}
}
@article{Ward1977,
abstract = {It is shown that, for the discrete space X of positive integers, V$\omega$;X (= V$\beta$X) is not naturally homeomorphic either to $\backslash$$\backslash$aeVX or to $\beta$VX (V, $\omega$ and $\beta$ denoting the Vietoris, Wallman and Stone- $\backslash$$\backslash$v Cech operators respectively). The example gives a negative answer to two problems recently posed by A. G. Hitchcock, and also disproves a statement attributed by him to V. M. lvanova.},
author = {Ward, A. J.},
doi = {10.1112/jlms/s2-16.3.539},
file = {:Users/liang-tingchen/Dropbox/References/Ward - 1977 - The Stone-{\v{C}}ech and Vietoris Operators are not Commutative.pdf:pdf},
journal = {Journal of the London Mathematical Society},
number = {3},
pages = {539--540},
title = {{The Stone-{\v{C}}ech and Vietoris Operators are not Commutative}},
type = {Journal article},
url = {http://jlms.oxfordjournals.org/content/s2-16/3/539.abstract},
volume = {s2-16},
year = {1977}
}
@article{Furber2015,
abstract = {This paper presents a categorical account of conditional probability, covering both the classical and the quantum case. Classical conditional probabilities are expressed as a certain "triangle-fill-in" condition, connecting marginal and joint probabilities, in the Kleisli category of the distribution monad. The conditional probabilities are induced by a map together with a predicate (the condition). The latter is a predicate in the logic of effect modules on this Kleisli category. This same approach can be transferred to the category of C*-algebras (with positive unital maps), whose predicate logic is also expressed in terms of effect modules. Conditional probabilities can again be expressed via a triangle-fill-in property. In the literature, there are several proposals for what quantum conditional probability should be, and also there are extra difficulties not present in the classical case. At this stage, we only describe quantum systems with classical parameterization.},
archivePrefix = {arXiv},
arxivId = {1306.0831},
author = {Furber, Robert and Jacobs, Bart},
doi = {10.4204/EPTCS.195.14},
eprint = {1306.0831},
file = {:Users/liang-tingchen/Dropbox/References/Furber, Jacobs - 2015 - Towards a Categorical Account of Conditional Probability.pdf:pdf},
issn = {20752180},
journal = {Quantum Physics and Logic},
number = {Qpl 2015},
pages = {179--195},
title = {{Towards a Categorical Account of Conditional Probability}},
year = {2015}
}
@article{Alpern1985,
abstract = {A formal definition for liveness properties is proposed. It is argued that this definition captures the intuition that liveness properties stipulate that 'something good' eventually happens during execution. A topological characterization of safety and liveness is given. Every property is shown to be the intersection of a safety property and a liveness property. ?? 1985.},
author = {Alpern, Bowen and Schneider, Fred B.},
doi = {10.1016/0020-0190(85)90056-0},
file = {:Users/liang-tingchen/Dropbox/References/Alpern, Schneider - 1985 - Defining liveness.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
keywords = {Liveness,absolute liveness,concurrency,property,safety,semantics,topology,uniform liveness},
month = {oct},
number = {4},
pages = {181--185},
title = {{Defining liveness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0020019085900560},
volume = {21},
year = {1985}
}
@article{Krivine2001,
author = {Krivine, Jean-Louis},
doi = {10.1007/s001530000057},
file = {:Users/liang-tingchen/Dropbox/References/Krivine - 2001 - Typed lambda-calculus in classical Zermelo-Fr{\ae}nkel set theory.pdf:pdf},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
month = {apr},
number = {3},
pages = {189--205},
title = {{Typed lambda-calculus in classical Zermelo-Fr{\ae}nkel set theory}},
url = {http://link.springer.com/10.1007/s001530000057},
volume = {40},
year = {2001}
}
@incollection{Coquand2010,
author = {Coquand, Thierry},
booktitle = {Logical Frameworks},
doi = {10.1017/CBO9780511569807.011},
file = {:Users/liang-tingchen/Dropbox/References/Coquand - 1991 - An algorithm for testing conversion in type theory.pdf:pdf},
month = {sep},
pages = {255--279},
publisher = {Cambridge University Press},
title = {{An algorithm for testing conversion in type theory}},
url = {https://www.cambridge.org/core/product/identifier/CBO9780511569807A020/type/book{\_}part},
year = {1991}
}
@article{Speed1972,
author = {Speed, T.P.},
doi = {10.1017/S0004972700044415},
file = {:Users/liang-tingchen/Dropbox/References/Speed - 1972 - Profinite posets.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
pages = {177},
title = {{Profinite posets}},
volume = {6},
year = {1972}
}
@inproceedings{Paredes2006,
abstract = {Let A be a set of size m. Obtaining the first k ≤ m elements of A in ascending order can be done in optimal O(m+k log k) time. We present an algorithm (online on k) which incrementally gives the next smallest element of the set, so that the first k elements are obtained in optimal time for any k. We also give a practical version of the algorithm, with the same complexity on average, which performs better in practice than the best existing online algorithm. As a direct application, we use our technique to implement Kruskal's Minimum Spanning Tree algorithm, where our solution is competitive with the best current implementations. We finally show that our technique can be applied to several other problems, such as obtaining an interval of the sorted sequence and implementing heaps.},
address = {Philadelphia, PA},
author = {Paredes, Rodrigo and Navarro, Gonzalo},
booktitle = {2006 Proceedings of the Eighth Workshop on Algorithm Engineering and Experiments (ALENEX)},
doi = {10.1137/1.9781611972863.16},
file = {:Users/liang-tingchen/Dropbox/References/Paredes, Navarro - 2006 - Optimal Incremental Sorting.pdf:pdf},
isbn = {978-1-61197-286-3},
month = {jan},
pages = {171--182},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Optimal Incremental Sorting}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972863.16 https://epubs.siam.org/doi/10.1137/1.9781611972863.16},
year = {2006}
}
@article{Pearl1990,
abstract = {An earlier position paper has examined the applicability of belief-functions methodology in three reasoning tasks: (1) representation of incomplete knowledge, (2) belief-updating, and (3) evidence pooling. My conclusions were that the use of belief functions encounters basic difficulties along all three tasks, and that extensive experimental and theoretical studies should be undertaken before belief functions could be applied safely. This article responds to the discussion, in this issue, of my conclusions and the degree to which they affect the applicability of belief functions in automated reasoning tasks. {\textcopyright} 1992.},
author = {Pearl, Judea},
doi = {10.1016/0888-613X(90)90013-R},
file = {:Users/liang-tingchen/Dropbox/References/Pearl - 1990 - Reasoning with belief functions An analysis of compatibility.pdf:pdf},
isbn = {0888-613X},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Belief functions,Dempster-Shafer theory,conditional information,knowledge representation nonmonotonic reasoning},
month = {sep},
number = {5-6},
pages = {363--389},
title = {{Reasoning with belief functions: An analysis of compatibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0888613X9090013R},
volume = {4},
year = {1990}
}
@incollection{Abel2014a,
abstract = {We consider a simplified version of Nakano's guarded fixed-point types in a representation by infinite type expressions, defined coinductively. Smallstep reduction is parametrized by a natural number “depth” that expresses under how many guards we may step during evaluation. We prove that reduction is strongly normalizing for any depth. The proof involves a typed inductive notion of strong normalization and a Kripke model of types in two dimensions: depth and typing context. Our results have been formalized in Agda and serve as a case study of reasoning about a language with coinductive type expressions.},
author = {Abel, Andreas and Vezzosi, Andrea},
booktitle = {Programming Languages and Systems. APLAS 2014},
doi = {10.1007/978-3-319-12736-1_8},
editor = {Garrigue, Jacques},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Vezzosi - 2014 - A Formalized Proof of Strong Normalization for Guarded Recursive Types.pdf:pdf},
isbn = {9783319127354},
issn = {16113349},
pages = {140--158},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Formalized Proof of Strong Normalization for Guarded Recursive Types}},
url = {http://link.springer.com/10.1007/978-3-319-12736-1{\_}8},
volume = {8858},
year = {2014}
}
@article{Allais2018,
abstract = {Almost every programming language's syntax includes a notion of binder and corresponding bound occurrences , along with the accompanying notions of $\alpha$-equivalence, capture avoiding substitution, typing contexts, runtime environments, and so on. In the past, implementing and reasoning about programming languages required careful handling to maintain the correct behaviour of bound variables. Modern programming languages include features that enable constraints like scope safety to be expressed in types. Nevertheless, the programmer is still forced to write the same boilerplate over again for each new implementation of a scope safe operation (e.g., renaming, substitution, desugaring, printing, etc.), and then again for correctness proofs. We present an expressive universe of syntaxes with binding and demonstrate how to (1) implement scope safe traversals once and for all by generic programming; and (2) how to derive properties of these traversals by generic proving. Our universe description, generic traversals and proofs, and our examples have all been formalised in Agda and are available in the accompanying material.},
author = {Allais, Guillaume and Atkey, Robert and Chapman, James and McBride, Conor and McKinna, James},
doi = {10.1145/3236785},
file = {:Users/liang-tingchen/Dropbox/References/Allais et al. - 2018 - A type and scope safe universe of syntaxes with binding their semantics and proofs.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--30},
title = {{A type and scope safe universe of syntaxes with binding: their semantics and proofs}},
url = {http://dl.acm.org/citation.cfm?doid=3243631.3236785},
volume = {2},
year = {2018}
}
@misc{TheMendeleySupportTeam2011c,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/liang-tingchen/Dropbox/References/The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Kokkinis2016,
author = {Lurie, Joseph},
doi = {10.3390/philosophies3010002},
file = {:Users/liang-tingchen/Dropbox/References/Lurie - 2018 - Probabilistic Justification Logic.pdf:pdf},
issn = {2409-9287},
journal = {Philosophies},
keywords = {epistemic logic,epistemology,evidentialism,fuzzy logic,justification,justification logic,logic,probabilistic},
month = {feb},
number = {1},
pages = {2},
title = {{Probabilistic Justification Logic}},
url = {http://link.springer.com/10.1007/978-3-319-27683-0{\_}13 http://www.mdpi.com/2409-9287/3/1/2},
volume = {3},
year = {2018}
}
@article{Wainer2006,
author = {Wainer, Stan S.},
doi = {10.2178/bsl/1146620064},
file = {:Users/liang-tingchen/Dropbox/References/Wainer - 2006 - 2005 Summer Meeting of the Association for Symbolic Logic. Logic Colloquium '05.pdf:pdf},
issn = {1079-8986},
journal = {Bulletin of Symbolic Logic},
month = {jun},
number = {2},
pages = {310--361},
title = {{2005 Summer Meeting of the Association for Symbolic Logic. Logic Colloquium '05}},
url = {https://www.cambridge.org/core/product/identifier/S1079898600002808/type/journal{\_}article},
volume = {12},
year = {2006}
}
@book{Burris1981,
author = {Burris, Stanley and Sankappanavar, H. P.},
file = {:Users/liang-tingchen/Dropbox/References/Burris, Sankappanavar - 1981 - A Course in Universal Algebra.pdf:pdf},
isbn = {3-540-90578-2},
issn = {00029890},
month = {jan},
pages = {276},
publisher = {Springer},
title = {{A Course in Universal Algebra}},
url = {ww.math.uwaterloo.ca/{~}snburris},
year = {1981}
}
@article{Goldwasser1982,
abstract = {This paper proposes an Encryption Scheme that possess the following property : An adversary, who knows the encryption algorithm and is given the cyphertext, cannot obtain any information about the clear-text. Any implementation of a Public Key Cryptosystem, as proposed by Diffie and Hellman in 8, should possess this property. Our Encryption Scheme follows the ideas in the number theoretic implementations of a Public Key Cryptosystem due to Rivest, Shamir and Adleman 13, and Rabin 12.},
author = {Goldwasser, Shaft and Micali, Silvio},
doi = {10.1145/800070.802212},
file = {:Users/liang-tingchen/Dropbox/References/Goldwasser, Micali - 1982 - Probabilistic encryption {\&} how to play mental poker keeping secret all partial information.pdf:pdf},
isbn = {0897910672},
journal = {STOC '82 Proceedings of the fourteenth annual ACM symposium on Theory of computing},
pages = {365--377},
title = {{Probabilistic encryption {\&} how to play mental poker keeping secret all partial information}},
url = {http://dl.acm.org/citation.cfm?id=802212},
year = {1982}
}
@article{Adamek2004a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Porst, Hans-E.},
doi = {10.1016/S0304-3975(03)00378-5},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Porst - 2004 - On tree coalgebras and coalgebra presentations.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebras},
month = {jan},
number = {1-3},
pages = {257--283},
title = {{On tree coalgebras and coalgebra presentations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397503003785},
volume = {311},
year = {2004}
}
@article{Gehrke2014,
author = {Gehrke, Mai and Krebs, Andreas and Pin, Jean-{\'{E}}ric},
doi = {10.1016/j.tcs.2015.08.007},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke, Krebs, Pin - 2014 - Ultrafilters on words for a fragment of logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {1--29},
publisher = {Elsevier B.V.},
title = {{Ultrafilters on words for a fragment of logic}},
url = {http://dx.doi.org/10.1016/j.tcs.2015.08.007},
volume = {610},
year = {2014}
}
@inproceedings{Diab2009,
address = {New York, New York, USA},
author = {Wadler, P.},
booktitle = {Proceedings of the 14th ACM SIGACT-SIGPLAN symposium on Principles of programming languages - POPL '87},
doi = {10.1145/41625.41653},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 1987 - Views a way for pattern matching to cohabit with data abstraction.pdf:pdf},
isbn = {0897912152},
keywords = {CRTP,E2E security,Fast authentication,Fmipv6,IMS,IPHC,IPSEC,Seamless handover,VoIP},
pages = {307--313},
publisher = {ACM Press},
title = {{Views: a way for pattern matching to cohabit with data abstraction}},
url = {http://portal.acm.org/citation.cfm?doid=41625.41653},
year = {1987}
}
@article{Meng2005,
abstract = {This paper introduces a generic semantic framework for component-based development, expressed in the unified modelling language UML. The principles of a coalgebraic semantics for class, object and statechart diagrams as well as for use cases, are developed. It is also discussed how to formalize the refinement steps in the development process based upon a suitable notion of behavior refinement. In this way, a formal basis for component-based development in UML is studied, which allows the construction of more complex and specific systems from independent components. {\textcopyright} 2005 Published by Elsevier B.V.},
author = {Meng, Sun and Aichernig, Bernhard K. and Barbosa, Lu{\'{i}}s S. and Naixiao, Zhang},
doi = {10.1016/j.entcs.2004.06.051},
file = {:Users/liang-tingchen/Dropbox/References/Meng et al. - 2005 - A coalgebraic semantic framework for component-based development in UML.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Coalgebras,Refinement,UML,Unified modeling language},
month = {mar},
pages = {229--245},
title = {{A coalgebraic semantic framework for component-based development in UML}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105000411},
volume = {122},
year = {2005}
}
@article{Maurice2006,
author = {Maurice, K. and {Celestin Nkuimi}, J.},
doi = {10.1155/IJMMS/2006/56786},
file = {:Users/liang-tingchen/Dropbox/References/Maurice, Celestin Nkuimi - 2006 - A simplification functor for coalgebras.pdf:pdf},
journal = {International Journal of Mathematics and Mathematical Sciences},
pages = {9},
publisher = {Hindawi Publishing Corporation},
title = {{A simplification functor for coalgebras}},
type = {Journal article},
volume = {2006},
year = {2006}
}
@incollection{Gorin2012,
abstract = {Modal languages are well-known for their robust decidability and relatively low complexity. However, as soon as one adds a self-referencing construct, like hybrid logic's down-arrow binder, to the basic modal language, decidability is lost, even if one restricts binding to a single variable. Here, we concentrate on the latter case and investigate the logics obtained by restricting the nesting depth of modalities between binding and use. In particular, for distances strictly below 3 we obtain well-behaved logics with a relatively high descriptive power. We investigate the fragment with distance 1 in the framework of coalgebraic modal logic, for which we provide very general decidability and complexity results. For the fragment with distance 2 we focus on the case of Kripke semantics and obtain optimum complexity bounds (no harder than the base logic). We show that this fragment is expressive enough to accommodate the guarded fragment over the correspondence language.},
annote = {10.1007/978-3-642-28729-9{\_}16},
author = {Gor{\'{i}}n, Daniel and Schr{\"{o}}der, Lutz},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Gor{\'{i}}n, Schr{\"{o}}der - 2012 - Narcissists are easy, stepmothers are hard.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {240--254},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Narcissists are easy, stepmothers are hard}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}16},
volume = {7213},
year = {2012}
}
@article{Cirstea2010,
author = {C{\^{i}}rstea, Corina},
doi = {10.1016/j.entcs.2010.07.015},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2010 - Generic infinite traces and path-based coalgebraic temporal logics.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coalgebra,nondeterminism,probability,temporal logic,trace semantics},
number = {2},
pages = {83--103},
publisher = {Elsevier B.V.},
title = {{Generic infinite traces and path-based coalgebraic temporal logics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066110000745},
volume = {264},
year = {2010}
}
@inproceedings{Petricek2014,
abstract = {The notion of context in functional languages no longer refers just to variables in scope. Context can capture additional properties of variables (usage patterns in linear logics; caching requirements in dataflow languages) as well as additional resources or properties of the execution environment (rebindable resources; platform version in a cross-platform application). The recently introduced notion of coeffects captures the latter, whole-context properties, but it failed to capture fine-grained per-variable properties. We remedy this by developing a generalized coeffect system with annotations indexed by a coeffect shape. By instantiating a concrete shape, our system captures previously studied flat (whole-context) coeffects, but also structural (per-variable) coeffects, making coeffect analyses more useful. We show that the structural system enjoys desirable syntactic properties and we give a categorical semantics using extended notions of indexed comonad. The examples presented in this paper are based on analysis of established language features (liveness, linear logics, dataflow, dynamic scoping) and we argue that such context-aware properties will also be useful for future development of languages for increasingly heterogeneous and distributed platforms.},
address = {New York, NY, USA},
author = {Petricek, Tomas and Orchard, Dominic and Mycroft, Alan},
booktitle = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming},
doi = {10.1145/2628136.2628160},
file = {:Users/liang-tingchen/Dropbox/References/Petricek, Orchard, Mycroft - 2014 - Coeffects(2).pdf:pdf},
isbn = {9781450328739},
issn = {0362-1340},
keywords = {a key feature and,coeffects,context,contribution of,for capturing various no-,in this paper,indexed comonads,programming,tions of context in,types,we develop a calculus},
month = {aug},
pages = {123--135},
publisher = {ACM},
title = {{Coeffects}},
url = {http://dl.acm.org/citation.cfm?doid=2628136.2628160 https://dl.acm.org/doi/10.1145/2628136.2628160},
year = {2014}
}
@misc{Coquand2012,
author = {Coquand, Thierry},
file = {:Users/liang-tingchen/Dropbox/References/Coquand - 2012 - Presheaf model.pdf:pdf},
pages = {1--4},
title = {{Presheaf model}},
year = {2012}
}
@article{Power2000,
abstract = {Given a class F of weights, one can consider the construction that takes a small category to the free cocompletion of under weighted colimits, for which the weight lies in F. Provided these free F-cocompletions are small, this construction generates a 2-monad on Cat, or more generally on -Cat for monoidal biclosed complete and cocomplete . We develop the notion of a dense 2-monad on -Cat and characterise free F-cocompletions by dense KZ-monads on -Cat. We prove various corollaries about the structure of such 2-monads and their Kleisli 2-categories, as needed for the use of open maps in giving an axiomatic study of bisimulation in concurrency. This requires the introduction of the concept of a pseudo-commutativity for a strong 2-monad on a symmetric monoidal 2-category, and a characterisation of it in terms of structure on the Kleisli 2-category.},
author = {Power, A. John and Cattani, Gian Luca and Winskel, Glynn},
doi = {10.1016/S0022-4049(99)00063-8},
file = {:Users/liang-tingchen/Dropbox/References/Power, Cattani, Winskel - 2000 - A representation result for free cocompletions.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
pages = {273--286},
title = {{A representation result for free cocompletions}},
url = {http://dx.doi.org/10.1016/S0022-4049(99)00063-8},
volume = {151},
year = {2000}
}
@inproceedings{espritosanto:LIPIcs:2015:5162,
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (Curry-Howard for Sequent Calculus at Last! - Santo, Jos{\'{e}} Esp{\'{i}}rito)

Keywords: co-control, co-continuation, vector notation, let-expression, formal sub- stitution, context substitution, computational lambda-calculus, classical lo},
author = {{Esp{\'{i}}rito Santo}, Jos{\'{e}}},
booktitle = {13th International Conference on Typed Lambda Calculi and Applications (TLCA 2015)},
doi = {10.4230/LIPIcs.TLCA.2015.165},
editor = {Altenkirch, Thorsten},
file = {:Users/liang-tingchen/Dropbox/References//Esp{\'{i}}rito Santo - 2015 - Curry-Howard for Sequent Calculus at Last!.pdf:pdf},
isbn = {978-3-939897-87-3},
issn = {1868-8969},
keywords = {165,2015,4230,and phrases co-control,classical logic,co-continuation,computational lambda-calculus,context substitution,de morgan duality,digital object identifier 10,formal sub-,let-expression,lipics,stitution,tlca,vector notation},
pages = {165--179},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Curry-Howard for Sequent Calculus at Last!}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5162},
volume = {38},
year = {2015}
}
@incollection{Brotherston2005,
abstract = {We consider a cyclic approach to inductive reasoning in the setting of first-order logic with inductive definitions. We present a proof system for this language in which proofs are represented as finite, locally sound derivation trees with a "repeat function" identifying cyclic proof sections. Soundness is guaranteed by a well-foundedness condition formulated globally in terms of traces over the proof tree, following an idea due to Sprenger and Dam. However, in contrast to their work, our proof system does not require an extension of logical syntax by ordinal variables. A fundamental question in our setting is the strength of the cyclic proof system compared to the more familiar use of a non-cyclic proof system using explicit induction rules. We show that the cyclic proof system subsumes the use of explicit induction rules. In addition, we provide machinery for manipulating and analysing the structure of cyclic proofs, based primarily on viewing them as generating regular infinite trees, and also formulate a finitary trace condition sufficient (but not necessary) for soundness, that is computationally and combinatorially simpler than the general trace condition. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Brotherston, James},
booktitle = {Automated Reasoning with Analytic Tableaux and Related Methods. TABLEAUX 2005},
doi = {10.1007/11554554_8},
editor = {Beckert, Bernhard},
file = {:Users/liang-tingchen/Dropbox/References/Brotherston - 2005 - Cyclic Proofs for First-Order Logic with Inductive Definitions.pdf:pdf},
isbn = {3540289313},
issn = {03029743},
pages = {78--92},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Cyclic Proofs for First-Order Logic with Inductive Definitions}},
url = {http://link.springer.com/10.1007/11554554{\_}8},
volume = {3702},
year = {2005}
}
@incollection{Abramsky2013,
abstract = {Our aim in this paper is to point out a surprising formal connection, between two topics which seem on face value to have nothing to do with each other: relational database theory, and the study of non-locality and contextuality in the foundations of quantum mechanics. We shall show that there is a remarkably direct correspondence between central results such as Bell's theorem in the foundations of quantum mechanics, and questions which arise naturally and have been well-studied in relational database theory.},
archivePrefix = {arXiv},
arxivId = {1208.6416},
author = {Abramsky, Samson},
booktitle = {In Search of Elegance in the Theory and Practice of Computation},
doi = {10.1007/978-3-642-41660-6_2},
editor = {Tannen, Val and Wong, Limsoon and Libkin, Leonid and Fan, Wenfei and Tan, Wang-Chiew and Fourman, Michael},
eprint = {1208.6416},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 2013 - Relational Databases and {\{}B{\}}ell's Theorem.pdf:pdf},
pages = {13--35},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Relational Databases and {\{}B{\}}ell's Theorem}},
url = {http://arxiv.org/abs/1208.6416 http://link.springer.com/10.1007/978-3-642-41660-6{\_}2},
volume = {8000},
year = {2013}
}
@article{Fagin1991,
author = {Fagin, Ronald and Halpern, Joseph Y.},
doi = {10.1111/j.1467-8640.1991.tb00391.x},
file = {:Users/liang-tingchen/Dropbox/References/Fagin, Halpern - 1991 - Uncertainty, belief, and probability.pdf:pdf},
issn = {0824-7935},
journal = {Computational Intelligence},
month = {aug},
number = {3},
pages = {160--173},
title = {{Uncertainty, belief, and probability}},
url = {http://doi.wiley.com/10.1111/j.1467-8640.1991.tb00391.x 1},
volume = {7},
year = {1991}
}
@article{Eilenberg1976a,
author = {Eilenberg, Samuel and Sch{\"{u}}tzenb{\'{e}}rger, Marcel P.},
file = {:Users/liang-tingchen/Dropbox/References/Eilenberg, Sch{\"{u}}tzenb{\'{e}}rger - 1976 - On pseudovarieties.pdf:pdf},
journal = {Advances in Mathematics},
number = {3},
pages = {413--418},
title = {{On pseudovarieties}},
volume = {19},
year = {1976}
}
@article{Kuich1991,
abstract = {We generalize the following two language- and automata-theoretic results to ??-continuous semirings. {\&}{\#}x02022; (i) The family of languages accepted by finite automata is the smallest class containing all finite languages and closed under union, product and star (Kleene's Theorem). {\&}{\#}x02022; (ii) The family of languages accepted by pushdown automata is the family ofcontext-free languages. ?? 1991.},
author = {Kuich, Werner},
doi = {10.1016/0304-3975(91)90147-T},
file = {:Users/liang-tingchen/Dropbox/References/Kuich - 1991 - Automata and languages generalized to $\omega$-continuous semirings.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {feb},
number = {1},
pages = {137--150},
title = {{Automata and languages generalized to $\omega$-continuous semirings}},
url = {http://linkinghub.elsevier.com/retrieve/pii/030439759190147T},
volume = {79},
year = {1991}
}
@incollection{Gonthier2013,
author = {Gonthier, Georges and Asperti, Andrea and Avigad, Jeremy and Bertot, Yves and Cohen, Cyril and Garillot, Fran{\c{c}}ois and {Le Roux}, St{\'{e}}phane and Mahboubi, Assia and O'Connor, Russell and {Ould Biha}, Sidi and Pasca, Ioana and Rideau, Laurence and Solovyev, Alexey and Tassi, Enrico and Th{\'{e}}ry, Laurent},
booktitle = {Interactive Theorem Proving. ITP 2013},
doi = {10.1007/978-3-642-39634-2_14},
editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
pages = {163--179},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Machine-Checked Proof of the Odd Order Theorem}},
url = {http://link.springer.com/10.1007/978-3-642-39634-2{\_}14},
volume = {7998},
year = {2013}
}
@article{Beeri1984,
abstract = {Given a universal relation scheme, presented as a set of attributes and a set of dependencies, it may be advantageous to decompose it into a collection of schemes, each with its own sets of attributes and dependencies, that has some desired properties. A basic requirement for such a decomposition to be useful is that the corresponding decomposition map on universal relations be injective. A central problem in database theory is to find the reconstruction map, i.e., the inverse map of an injective decomposition map. It is proved here that when the decomposition, viewed as a hypergraph, is acyclic and the given dependencies are full implicational dependencies, then the reconstruction map is the natural join. Based on this, it is shown that there is a polynomial time algorithm to test for injectiveness of decompositions. {\textcopyright} 1984 Academic Press, Inc. All rights reserved.},
author = {Beeri, Catriel and Vardi, Moshe Y.},
doi = {10.1016/S0019-9958(84)80051-0},
file = {:Users/liang-tingchen/Dropbox/References/Beeri, Vardi - 1984 - On acyclic database decompositions.pdf:pdf},
issn = {00199958},
journal = {Information and Control},
month = {may},
number = {2},
pages = {75--84},
title = {{On acyclic database decompositions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0019995884800510},
volume = {61},
year = {1984}
}
@inproceedings{Arkor2020,
abstract = {We develop algebraic models of simple type theories, laying out a framework that extends universal algebra to incorporate both algebraic sorting and variable binding. Examples of simple type theories include the unityped and simply-typed $\lambda$-calculi, the computational $\lambda$-calculus, and predicate logic. Simple type theories are given models in presheaf categories, with structure specified by algebras of polynomial endofunctors that correspond to natural deduction rules. Initial models, which we construct, abstractly describe the syntax of simple type theories. Taking substitution structure into consideration, we further provide sound and complete semantics in structured cartesian multicategories. This development generalises Lambek's correspondence between the simply-typed $\lambda$-calculus and cartesian-closed categories, to arbitrary simple type theories.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2006.16949},
author = {Arkor, Nathanael and Fiore, Marcelo},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394771},
eprint = {2006.16949},
file = {:Users/liang-tingchen/Dropbox/References/Arkor, Fiore - 2020 - Algebraic models of simple type theories.pdf:pdf},
isbn = {9781450371049},
keywords = {Lambek correspondence,algebraic theory,cartesian multicategory,categorical semantics,category theory,classifying category,polynomial functor,simple type theory},
month = {jul},
pages = {88--101},
publisher = {ACM},
title = {{Algebraic models of simple type theories}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394771},
year = {2020}
}
@inproceedings{Rhiger2012,
abstract = {We present a simple core type system, $\lambda$ [ ] - pronounced "lambda open box" - for a statically typed, hygienic, and multi-stage lambda-calculus supporting evaluation under future-stage binders, open-code manipulation, a first-class eval function, and mutable state. The type system provides one type of lexically scoped code that precisely accounts for the contexts in which code values can be inserted. In particular, this type can distinguish between open and closed code. We show how to extend $\lambda$ [ ] with subtype polymorphism over program contexts. The soundness and simplicity of $\lambda$ [ ] demonstrate that the notion of staging is orthogonal to features that have been presented as instrumental in existing type systems for staged computation, such as polymorphism, nameless term representations, explicit substitutions, and delimited continuations. {\textcopyright} 2012 Springer-Verlag.},
author = {Rhiger, Morten},
booktitle = {Programming Languages and Systems. ESOP 2012},
doi = {10.1007/978-3-642-28869-2_28},
editor = {Seidl, Helmut},
file = {:Users/liang-tingchen/Dropbox/References/Rhiger - 2012 - Staged computation with staged lexical scope.pdf:pdf},
isbn = {9783642288685},
issn = {03029743},
pages = {559--578},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Staged computation with staged lexical scope}},
volume = {7211},
year = {2012}
}
@incollection{Chen2015a,
abstract = {Profinite equations are an indispensable tool for the algebraic classification of formal languages. Reiterman's theorem states that they precisely specify pseudovarieties, i.e. classes of finite algebras closed under finite products, subalgebras and quotients. In this paper Reiterman's theorem is generalised to finite Eilenberg-Moore algebras for a monad T on a variety D of (ordered) algebras: a class of finite T-algebras is a pseudovariety iff it is presentable by profinite (in-)equations. As an application, quasivarieties of finite algebras are shown to be presentable by profinite implications. Other examples include finite ordered algebras, finite categories, finite infinity-monoids, etc.},
archivePrefix = {arXiv},
arxivId = {1511.02147},
author = {Chen, Liang-Ting and Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Urbat, Henning},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Software Sciences and Computer Structures},
doi = {10.1007/978-3-662-49630-5_31},
editor = {Jacobs, Bart and L{\"{o}}ding, Christof},
eprint = {1511.02147},
file = {:Users/liang-tingchen/Dropbox/References/Chen et al. - 2016 - Profinite monads, profinite equations, and Reiterman's theorem.pdf:pdf},
pages = {531--547},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Profinite monads, profinite equations, and Reiterman's theorem}},
url = {http://arxiv.org/abs/1511.02147 http://link.springer.com/10.1007/978-3-662-49630-5{\_}31},
volume = {9634},
year = {2016}
}
@article{Haghverdi2006,
abstract = {We consider the multiplicative and exponential fragment of linear logic (MELL) and give a geometry of interaction (GoI) semantics for it based on unique decomposition categories. We prove a soundness and finiteness theorem for this interpretation. We show that Girard's original approach to GoI 1 via operator algebras is exactly captured in this categorical framework. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Haghverdi, Esfandiar and Scott, Philip J.},
doi = {10.1016/j.tcs.2005.10.028},
file = {:Users/liang-tingchen/Dropbox/References/Haghverdi, Scott - 2006 - A categorical model for the geometry of interaction.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Geometry of interaction,Linear logic,Partially additive categories,Traced monoidal categories,Unique decomposition categories},
month = {feb},
number = {2-3},
pages = {252--274},
title = {{A categorical model for the geometry of interaction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397505006808},
volume = {350},
year = {2006}
}
@inproceedings{Ahrens2015a,
abstract = {We prove a conjecture about the constructibility of coinductive types - in the principled form of indexed M-types - in Homotopy Type Theory. The conjecture says that in the presence of inductive types, coinductive types are derivable. Indeed, in this work, we construct coinductive types in a subsystem of Homotopy Type Theory; this subsystem is given by Intensional Martin-L$\backslash$"of type theory with natural numbers and Voevodsky's Univalence Axiom. Our results are mechanized in the computer proof assistant Agda.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Non-Wellfounded Trees in Homotopy Type Theory - Ahrens, Benedikt; Capriotti, Paolo; Spadotti, R{\'{e}}gis)

Keywords: Homotopy Type Theory, coinductive types, computer theorem proving, Agda},
archivePrefix = {arXiv},
arxivId = {1504.02949},
author = {Ahrens, Benedikt and Capriotti, Paolo and Spadotti, R{\'{e}}gis},
booktitle = {13th International Conference on Typed Lambda Calculi and Applications (TLCA 2015)},
doi = {10.4230/LIPIcs.TLCA.2015.17},
editor = {Altenkirch, Thorsten},
eprint = {1504.02949},
file = {:Users/liang-tingchen/Dropbox/References//Ahrens, Capriotti, Spadotti - 2015 - Non-Wellfounded Trees in Homotopy Type Theory.pdf:pdf},
isbn = {978-3-939897-87-3},
issn = {1868-8969},
keywords = {and phrases homotopy type,coinductive types,computer theorem proving,theory},
pages = {17--30},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Non-Wellfounded Trees in Homotopy Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5152 http://arxiv.org/abs/1504.02949},
volume = {38},
year = {2015}
}
@article{Caires2016,
abstract = {Throughout the years, several typing disciplines for the $\pi$-calculus have been proposed. Arguably, the most widespread of these typing disciplines consists of session types. Session types describe the input/output behaviour of processes and traditionally provide strong guarantees about this behaviour (i.e. deadlock-freedom and fidelity). While these systems exploit a fundamental notion of linearity, the precise connection between linear logic and session types has not been well understood.},
author = {CAIRES, LU{\'{I}}S and PFENNING, FRANK and TONINHO, BERNARDO},
doi = {10.1017/S0960129514000218},
file = {:Users/liang-tingchen/Dropbox/References/CAIRES, PFENNING, TONINHO - 2016 - Linear logic propositions as session types(2).pdf:pdf},
isbn = {0093-691X},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {03},
pages = {367--423},
title = {{Linear logic propositions as session types}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129514000218},
volume = {26},
year = {2016}
}
@inproceedings{Krivine2016,
address = {Dagstuhl, Germany},
annote = {Keywords: lambda-calculus, Curry-Howard correspondence, set theory},
author = {Krivine, Jean-Louis},
booktitle = {25th EACSL Annual Conference on Computer Science Logic (CSL 2016)},
doi = {10.4230/LIPIcs.CSL.2016.25},
editor = {Talbot, Jean-Marc and Regnier, Laurent},
file = {:Users/liang-tingchen/Dropbox/References/Krivine - 2016 - Bar Recursion in Classical Realisability Dependent Choice and Continuum Hypothesis.pdf:pdf},
isbn = {978-3-95977-022-4},
issn = {1868-8969},
pages = {25:1----25:11},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Bar Recursion in Classical Realisability: Dependent Choice and Continuum Hypothesis}},
url = {http://drops.dagstuhl.de/opus/volltexte/2016/6565},
volume = {62},
year = {2016}
}
@incollection{Atkey2012,
abstract = {This paper provides several induction rules that can be used to prove properties of effectful data types. Our results are semantic in nature and build upon Hermida and Jacobs' fibrational formulation of induction for polynomial data types and its extension to all inductive data types by Ghani, Johann, and Fumex. An effectful data type $\mu$ ( TF ) is built from a functor F that describes data, and a monad T that computes effects. Our main contribution is to derive induction rules that are generic over all functors F and monads T such that $\mu$ ( TF ) exists. Along the way, we also derive a principle of definition by structural recursion for effectful data types that is similarly generic. Our induction rule is also generic over the kinds of properties to be proved: like the work on which we build, we work in a general fibrational setting and so can accommodate very general notions of properties, rather than just those of particular syntactic forms. We give examples exploiting the generality of our results, and show how our results specialize to those in the literature, particularly those of Filinski and St{\o}vring.},
annote = {10.1007/978-3-642-28729-9{\_}3},
author = {Atkey, Robert and Ghani, Neil and Jacobs, Bart and Johann, Patricia},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Atkey et al. - 2012 - Fibrational induction meets effects.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {42--57},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Fibrational induction meets effects}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}3},
volume = {7213},
year = {2012}
}
@article{Kavvos2020a,
abstract = {The main way of analysing the complexity of a program is that of extracting and solving a recurrence that expresses its running time in terms of the size of its input. We develop a method that automatically extracts such recurrences from the syntax of higher-order recursive functional programs. The resulting recurrences, which are programs in a call-by-name language with recursion, explicitly compute the running time in terms of the size of the input. In order to achieve this in a uniform way that covers both call-by-name and call-by-value evaluation strategies, we use Call-by-Push-Value (CBPV) as an intermediate language. Finally, we use domain theory to develop a denotational cost semantics for the resulting recurrences.},
author = {Kavvos, G. A. and Morehouse, Edward and Licata, Daniel R. and Danner, Norman},
doi = {10.1145/3371083},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos et al. - 2020 - Recurrence extraction for functional programs through call-by-push-value.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Call by push value,Cost semantics,Denotational semantics,General recursion,Higher order recurrences,Recurrence extraction,Resource analysis},
month = {jan},
number = {POPL},
pages = {1--31},
title = {{Recurrence extraction for functional programs through call-by-push-value}},
url = {https://dl.acm.org/doi/10.1145/3371083},
volume = {4},
year = {2020}
}
@book{Howes1995,
author = {Howes, Norman R.},
doi = {10.1007/978-1-4612-0833-4},
file = {:Users/liang-tingchen/Dropbox/References/Howes - 1995 - Modern Analysis and Topology.pdf:pdf},
isbn = {0387979867},
publisher = {Springer New York},
series = {Universitext},
title = {{Modern Analysis and Topology}},
year = {1995}
}
@article{HARLAND1994,
author = {HARLAND, JAMES},
doi = {10.1093/logcom/4.1.69},
file = {:Users/liang-tingchen/Dropbox/References/HARLAND - 1994 - A Proof-theoretic Analysis of Goal-directed Provability.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {logic programming,proof theory,uniform proofs},
number = {1},
pages = {69--88},
title = {{A Proof-theoretic Analysis of Goal-directed Provability}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/4.1.69},
volume = {4},
year = {1994}
}
@incollection{Pavlovic2014,
author = {Pavlovi{\'{c}}, Dusko},
booktitle = {Categories and Types in Logic, Language, and Physics},
doi = {10.1007/978-3-642-54789-8_19},
editor = {Casadio, Claudia and Coecke, Bob and Moortgat, Michael and Scott, Philip},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} - 2014 - Chasing Diagrams in Cryptography.pdf:pdf},
pages = {353--367},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Chasing Diagrams in Cryptography}},
url = {http://link.springer.com/10.1007/978-3-642-54789-8{\_}19},
year = {2014}
}
@article{Hofmann2006,
author = {Hofmann, M. and van Oosten, J. and Streicher, T.},
doi = {10.1007/s00153-006-0003-5},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann, van Oosten, Streicher - 2006 - Well-foundedness in Realizability.pdf:pdf},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
month = {oct},
number = {7},
pages = {795--805},
title = {{Well-foundedness in Realizability}},
url = {http://link.springer.com/10.1007/s00153-006-0003-5},
volume = {45},
year = {2006}
}
@article{Hermida2014,
author = {Hermida, Claudio and Reddy, Uday S. and Robinson, Edmund P.},
doi = {10.1016/j.entcs.2014.02.008},
file = {:Users/liang-tingchen/Dropbox/References/Hermida, Reddy, Robinson - 2014 - Logical Relations and Parametricity – A Reynolds Programme for Category Theory and Programming Langu.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {category theory,data abstraction,definability,fibrations,hiding,homomorphisms,information,logical relations,natural,parametric polymorphism,reflexive graphs,relation lifting,relational parametricity,transformations,universal algebra},
month = {mar},
pages = {149--180},
publisher = {Elsevier B.V.},
title = {{Logical Relations and Parametricity – A Reynolds Programme for Category Theory and Programming Languages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066114000346},
volume = {303},
year = {2014}
}
@article{Guitart2013,
author = {Guitart, Ren{\'{e}}},
file = {:Users/liang-tingchen/Dropbox/References/Guitart - 2013 - TRIJUNCTIONS AND TRIADIC GALOIS CONNECTIONS.pdf:pdf},
journal = {Cahiers de topologie et g{\'{e}}om{\'{e}}trie diff{\'{e}}rentielle cat{\'{e}}goriques},
keywords = {06a15,18a40,18b10,2010,adjunction,algebraic universes,bi-adjunction,bration,galois connection,mathematics subject classification,topos,trifi-,trijunction},
pages = {13--27},
title = {{TRIJUNCTIONS AND TRIADIC GALOIS CONNECTIONS}},
volume = {LIV-1},
year = {2013}
}
@article{Sozeau2020a,
author = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Th{\'{e}}o},
doi = {10.1145/3371076},
file = {:Users/liang-tingchen/Dropbox/References/Sozeau et al. - 2020 - Coq Coq correct! verification of type checking and erasure for Coq, in Coq.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {certification,proof assistants,type checker},
month = {jan},
number = {POPL},
pages = {1--28},
title = {{Coq Coq correct! verification of type checking and erasure for Coq, in Coq}},
url = {https://dl.acm.org/doi/10.1145/3371076},
volume = {4},
year = {2020}
}
@article{Harrenstein2003,
abstract = {Multi-agent systems comprise entities whose individual decision making behavior may depend on one another's. Game-theory provides apposite concepts to reason in a mathematically precise fashion about such interactive and interdependent situations. This paper concerns a logical analysis of the game-theoretical notions of Nash equilibrium and its subgame perfect variety as they apply to a particular class of extensive games of perfect information. Extensive games are defined as a special type of labelled graph and we argue that modal languages can be employed in their description. We propose a logic for a multi-modal language and prove its completeness with respect to a class of frames that correspond with a particular class of extensive games. In this multimodal language (subgame perfect) Nash equilibria can be characterized. Finally, we show how this approach can formally be refined by using Prepositional Dynamic Logic (PDL), though we leave completeness as an open question.},
author = {Harrenstein, Paul and Meyer, John Jules and {Van der Hoek}, Wiebe and Witteveen, Cees},
file = {:Users/liang-tingchen/Dropbox/References/Harrenstein et al. - 2003 - A Modal Characterization of Nash Equilibrium.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
keywords = {Dynamic Logic,Game Theory,Modal Logic,Nash Equilibrium},
number = {2-4},
pages = {281--321},
title = {{A Modal Characterization of Nash Equilibrium}},
volume = {57},
year = {2003}
}
@phdthesis{Zsido2010,
author = {Zsido, Julianna},
file = {:Users/liang-tingchen/Dropbox/References/Zsido - 2010 - Typed Abstract Syntax.pdf:pdf},
school = {Université Nice Sophia Antipolis},
title = {{Typed Abstract Syntax}},
type = {PhD},
url = {https://tel.archives-ouvertes.fr/tel-00535944},
year = {2010}
}
@book{Vickers1996a,
author = {Vickers, Steven},
doi = {10.2277/0521576512},
file = {:Users/liang-tingchen/Dropbox/References/Vickers - 1996 - Topology via Logic.pdf:pdf},
isbn = {0521576512},
month = {sep},
publisher = {Cambridge University Press},
title = {{Topology via Logic}},
type = {Book},
year = {1996}
}
@article{Brady2017,
abstract = {Modern software systems rely on communication; for example, mobile applications communicating with a central server, distributed systems coordinating a telecommunications network, or concurrent systems handling events and processes in a desktop application. However, reasoning about concurrent programs is hard since we must reason about each process and the order in which communication might happen between processes. In this paper, I describe a type-driven approach to implementing communicating concurrent programs using the dependently typed programming language Idris. I show how the type system can be used to describe resource access protocols (such as controlling access to a file handle) and verify that the programs correctly follow those protocols. Finally, I show how to use the type system to reason about the order of communication between concurrent processes, ensuring that each end of a communication channel follows a defined protocol.},
author = {Brady, Edwin},
doi = {10.7494/csci.2017.18.3.1413},
file = {:Users/liang-tingchen/Dropbox/References/Brady - 2017 - TYPE-DRIVEN DEVELOPMENT OF CONCURRENT COMMUNICATING SYSTEMS.pdf:pdf},
issn = {1508-2806},
journal = {Computer Science},
keywords = {concurrency,dependent types,domain specific languages,verification},
number = {3},
pages = {219},
title = {{TYPE-DRIVEN DEVELOPMENT OF CONCURRENT COMMUNICATING SYSTEMS}},
url = {https://journals.agh.edu.pl/csci/article/view/1413},
volume = {18},
year = {2017}
}
@incollection{Dennielou2012,
abstract = {For many application-level distributed protocols and parallel algorithms, the set of participants, the number of messages or the interaction structure are only known at run-time. This paper proposes a dependent type theory for multiparty sessions which can statically guarantee type-safe, deadlock-free multiparty interactions among processes whose specifications are parameterised by indices. We use the primitive recursion operator from G{\"{o}}del's System T to express a wide range of communication patterns while keeping type checking decidable. To type individual distributed processes, a parameterised global type is projected onto a generic generator which represents a class of all possible end-point types. We prove the termination of the type-checking algorithm in the full system with both multiparty session types and recursive types. We illustrate our type theory through non-trivial programming and verification examples taken from parallel algorithms and web services usecases.},
author = {Yoshida, Nobuko and Deni{\'{e}}lou, Pierre-Malo and Bejleri, Andi and Hu, Raymond},
booktitle = {Foundations of Software Science and Computational Structures. FoSSaCS 2010.},
doi = {10.1007/978-3-642-12032-9_10},
editor = {Ong, Luke},
file = {:Users/liang-tingchen/Dropbox/References/Yoshida et al. - 2010 - Parameterised Multiparty Session Types.pdf:pdf},
pages = {128--145},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Parameterised Multiparty Session Types}},
url = {http://link.springer.com/10.1007/978-3-642-12032-9{\_}10},
volume = {6014},
year = {2010}
}
@book{Ahrens2021,
abstract = {The Univalence Principle is the statement that equivalent mathematical structures are indistinguishable. We prove a general version of this principle that applies to all set-based, categorical, and higher-categorical structures defined in a non-algebraic and space-based style, as well as models of higher-order theories such as topological spaces. In particular, we formulate a general definition of indiscernibility for objects of any such structure, and a corresponding univalence condition that generalizes Rezk's completeness condition for Segal spaces and ensures that all equivalences of structures are levelwise equivalences. Our work builds on Makkai's First-Order Logic with Dependent Sorts, but is expressed in Voevodsky's Univalent Foundations (UF), extending previous work on the Structure Identity Principle and univalent categories in UF. This enables indistinguishability to be expressed simply as identification, and yields a formal theory that is interpretable in classical homotopy theory, but also in other higher topos models. It follows that Univalent Foundations is a fully equivalence-invariant foundation for higher-categorical mathematics, as intended by Voevodsky.},
archivePrefix = {arXiv},
arxivId = {2102.06275},
author = {Ahrens, Benedikt and North, Paige Randall and Shulman, Michael and Tsementzis, Dimitris},
eprint = {2102.06275},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2021 - The Univalence Principle.pdf:pdf},
title = {{The Univalence Principle}},
url = {http://arxiv.org/abs/2102.06275},
year = {2021}
}
@article{Freyd2008,
author = {Freyd, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Freyd - 2008 - Algebraic real analysis.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Algebraic real analysis,Chromatic scale,Closed interval,Closed midpoint algebra,Coalgebraic real analysis,Complete scale,Finitely presented scale,Free scale,Harmonic scale,Injective scale,Lattice-ordered abelian group,Linear logic,Lipschitz extension},
number = {10},
pages = {215--306},
title = {{Algebraic real analysis}},
volume = {20},
year = {2008}
}
@article{Ebner2017,
abstract = {We describe the metaprogramming framework currently used in Lean, an interactive theorem prover based on dependent type theory. This framework extends Lean's object language with an API to some of Lean's internal structures and procedures, and provides ways of reflecting object-level expressions into the metalanguage. We provide evidence to show that our implementation is performant, and that it provides a convenient and flexible way of writing not only small-scale interactive tactics, but also more substantial kinds of automation.},
author = {Ebner, Gabriel and Ullrich, Sebastian and Roesch, Jared and Avigad, Jeremy and de Moura, Leonardo},
doi = {10.1145/3110278},
file = {:Users/liang-tingchen/Dropbox/References/Ebner et al. - 2017 - A metaprogramming framework for formal verification.pdf:pdf},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {theorem proving, dependent type theory, tactic lan},
number = {ICFP},
pages = {1--29},
title = {{A metaprogramming framework for formal verification}},
volume = {1},
year = {2017}
}
@article{Stolpe2015,
abstract = {This paper provides a semantics for input/input output logic based on formal concept analysis. The central result shows that an input/output logic axiomatised by a relation R is the same as the logic induced by deriving pairs from the concept lattice generated by R using a ∧- and ∨-classical Scott consequence relation. This correspondence offers powerful analytical techniques for classifying, visualising and analysing input/output relations, revealing implicit hierarchical structure and/or natural clusterings and dependencies. The application of all formal developments are illustrated by a worked example towards the end.},
author = {Stolpe, Audun},
doi = {10.1016/j.jal.2015.04.002},
file = {:Users/liang-tingchen/Dropbox/References/Stolpe - 2015 - A concept approach to inputoutput logic.pdf:pdf},
issn = {15708683},
journal = {Journal of Applied Logic},
keywords = {Formal concept analysis,Generation relations,Input/output logic,Production inference},
month = {sep},
number = {3},
pages = {239--258},
publisher = {Elsevier B.V.},
title = {{A concept approach to input/output logic}},
url = {http://dx.doi.org/10.1016/j.jal.2015.04.002 https://linkinghub.elsevier.com/retrieve/pii/S157086831500049X},
volume = {13},
year = {2015}
}
@article{Tasistro2015,
abstract = {In [25] Alley Stoughton proposed a notion of (simultaneous) substitution for the Lambda calculus as formulated in its original syntax -i.e. with only one sort of symbols (names) for variables- and without identifying $\alpha$-convertible terms. According to such formulation, the action of substitution on terms is defined by simple structural recursion and an interesting theory arises concerning the connection to $\alpha$-conversion. In this paper we present a formalisation of Stoughton's work in Constructive Type Theory using the language Agda, which reaches up to the Substitution Lemma for $\alpha$-conversion. The development has been quite inexpensive e.g. in labour cost, and we are able to formulate some improvements over the original presentation. For instance, our definition of $\alpha$-conversion is just syntax directed and we prove it to be an equivalence relation in an easy way, whereas in [25] the latter was included as part of the definition and then proven to be equivalent to an only nearly structural definition as corollary of a lengthier development. As a result of this work we are inclined to assert that Stoughton's is the right way to formulate the Lambda calculus in its original, conventional syntax and that it is a formulation amenable to fully formal treatment.},
author = {Tasistro, {\'{A}}lvaro and Copello, Ernesto and Szasz, Nora},
doi = {10.1016/j.entcs.2015.04.013},
file = {:Users/liang-tingchen/Dropbox/References/Tasistro, Copello, Szasz - 2015 - Formalisation in Constructive Type Theory of Stoughton's Substitution for the Lambda Calculus.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Constructive Type Theory,Formal Metatheory,Lambda Calculus},
month = {apr},
pages = {215--230},
publisher = {Elsevier B.V.},
title = {{Formalisation in Constructive Type Theory of Stoughton's Substitution for the Lambda Calculus}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.04.013 https://linkinghub.elsevier.com/retrieve/pii/S1571066115000171},
volume = {312},
year = {2015}
}
@book{Nachbin1965a,
author = {Nachbin, Leopoldo},
isbn = {978-0882753874},
publisher = {Van Nostrand, Princeton, N.J.},
series = {Van Nostrand Mathematical Studies},
title = {{Topology and order}},
type = {Book},
volume = {296},
year = {1965}
}
@incollection{Sheard2001,
author = {Sheard, Tim},
booktitle = {Semantics, Applications, and Implementation of Program Generation. SAIG 2001},
doi = {10.1007/3-540-44806-3_2},
editor = {Taha, Walid},
file = {:Users/liang-tingchen/Dropbox/References/Sheard - 2001 - Accomplishments and Research Challenges in Meta-programming.pdf:pdf},
isbn = {3540425586},
issn = {16113349},
pages = {2--44},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Accomplishments and Research Challenges in Meta-programming}},
url = {http://link.springer.com/10.1007/3-540-44806-3{\_}2},
volume = {2196},
year = {2001}
}
@incollection{Adamek2011b,
abstract = {An algebra is called corecursive if from every coalgebra a unique coalgebra-to-algebra homomorphism exists into it. We prove that free corecursive algebras are obtained as a coproduct of the final coalgebra (considered as an algebra) and with free algebras. The monad of free corecursive algebras is proved to be the free corecursive monad, where the concept of corecursive monad is a generalization of Elgot's iterative monads, analogous to corecursive algebras generalizing completely iterative algebras. We also characterize the Eilenberg-Moore algebras for the free corecursive monad and call them Bloom algebras.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Haddadi, Mahdie and Milius, Stefan},
booktitle = {Proceeding CALCO'11 Proceedings of the 4th international conference on Algebra and coalgebra in computer science},
doi = {10.1007/978-3-642-22944-2_5},
editor = {Corradini, Andrea and Klin, Bartek and C{\^{i}}rstea, Corina},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Haddadi, Milius - 2011 - From corecursive algebras to corecursive Monads.pdf:pdf},
pages = {55--69},
publisher = {Springer Berlin Heidelberg},
title = {{From corecursive algebras to corecursive Monads}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-22944-2{\_}5},
year = {2011}
}
@phdthesis{Oliveira2014,
author = {de Oliveira, Henrique Roscoe},
file = {:Users/liang-tingchen/Dropbox/References/Oliveira - 2014 - Attention and Information Acquisition.pdf:pdf},
number = {June},
school = {Northwestern University},
title = {{Attention and Information Acquisition}},
year = {2014}
}
@phdthesis{Kavvos2017c,
archivePrefix = {arXiv},
arxivId = {1602.01365},
author = {Kavvos, G. Alex},
doi = {10.1007/978-3-662-54458-7_32},
eprint = {1602.01365},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2017 - On the semantics of intensionality and intensional recursion.pdf:pdf},
isbn = {9783662544570},
issn = {16113349},
school = {University of Oxford},
title = {{On the semantics of intensionality and intensional recursion}},
type = {DPhil},
year = {2017}
}
@inproceedings{Abel2009,
abstract = {We present a normalization-by-evaluation (NbE) algorithm for System F $\omega$ with $\beta$$\eta$-equality, the simplest impredicative type theory with computation on the type level. Values are kept abstract and requirements on values are kept to a minimum, allowing many different implementations of the algorithm. The algorithm is verified through a general model construction using typed applicative structures, called type and object structures. Both soundness and completeness of NbE are conceived as an instance of a single fundamental theorem. {\textcopyright} 2009 Springer Berlin Heidelberg.},
author = {Abel, Andreas},
booktitle = {Computer Science Logic. CSL 2009},
doi = {10.1007/978-3-642-04027-6_6},
editor = {Gr{\"{a}}del, Erich and Kahle, Reinhard},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2009 - Typed applicative structures and normalization by evaluation for system F$\omega$.pdf:pdf},
isbn = {3642040268},
issn = {03029743},
pages = {40--54},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Typed applicative structures and normalization by evaluation for system F$\omega$}},
volume = {5771},
year = {2009}
}
@article{Martin-Lof1987,
author = {Martin-L{\"{o}}f, Per},
file = {:Users/liang-tingchen/Dropbox/References/Martin-L{\"{o}}f - 1987 - Truth of a Proposition, Evidence of a Judgement, Validity of a Proof.pdf:pdf},
journal = {Synthese},
number = {3},
pages = {407--420},
title = {{Truth of a Proposition, Evidence of a Judgement, Validity of a Proof}},
volume = {73},
year = {1987}
}
@article{Bartels2003,
abstract = {We introduce the $\lambda$-coiteration schema for a distributive law $\lambda$ of a functor T over a functor F. Under certain conditions it can be shown to uniquely characterise functions into the carrier of a final F-coalgebra, generalising the basic coiteration schema as given by finality. The duals of primitive recursion and course-of-value iteration, which are known extensions of coiteration, arise as instances of our framework. One can furthermore obtain schemata justifying recursive specifications that involve operators such as addition of power series, regular operators on languages, or parallel and sequential composition of processes. Next, the same type of distributive law $\lambda$ is used to generalise coinductive proof techniques. To this end, we introduce the notion of a $\lambda$-bisimulation relation. It specialises to what could be called bisimulation up-to-equality or bisimulation up-to-context for contexts built from operators of the type mentioned above. We state that every such relation is contained in some larger conventional bisimulation and demonstrate that this principle leads to simpler bisimilarity proofs using less complex relations. {\textcopyright}2001 Published by Elsevier Science B.V.},
author = {Bartels, Falk},
doi = {10.1017/S0960129502003900},
file = {:Users/liang-tingchen/Dropbox/References/Bartels - 2003 - Generalised coinduction.pdf:pdf},
isbn = {0960129502},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
month = {apr},
number = {2},
pages = {321--348},
title = {{Generalised coinduction}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129502003900},
volume = {13},
year = {2003}
}
@inproceedings{Ferreira2015,
address = {New York, New York, USA},
author = {Ferreira, Francisco and Pientka, Brigitte},
booktitle = {Proceedings of the 16th International Symposium on Principles and Practice of Declarative Programming - PPDP '14},
doi = {10.1145/2643135.2643153},
file = {:Users/liang-tingchen/Dropbox/References/Ferreira, Pientka - 2014 - Bidirectional Elaboration of Dependently Typed Programs.pdf:pdf},
isbn = {9781450329477},
keywords = {dependent types,type reconstruction},
pages = {161--174},
publisher = {ACM Press},
title = {{Bidirectional Elaboration of Dependently Typed Programs}},
url = {http://dl.acm.org/citation.cfm?doid=2643135.2643153},
year = {2014}
}
@article{Gumm2001,
author = {Gumm, H. Peter and Schr{\"{o}}der, Tobias},
doi = {10.1016/S1571-0661(04)80908-3},
file = {:Users/liang-tingchen/Dropbox/References/Gumm, Schr{\"{o}}der - 2001 - Monoid-labeled transition systems.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {bisimulation,coalgebra,distributive lattice,fuzzy transition,monoid,multiset,refinable,transition system,weak pullback preservation},
month = {may},
number = {1},
pages = {185--204},
title = {{Monoid-labeled transition systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104809083},
volume = {44},
year = {2001}
}
@article{Ki1984,
author = {Imieli{\'{n}}ski, Tomasz and Lipski, Witold},
doi = {10.1016/0022-0000(84)90077-1},
file = {:Users/liang-tingchen/Dropbox/References/Imieli{\'{n}}ski, Lipski - 1984 - The relational model of data and cylindric algebras.pdf:pdf},
isbn = {9780080465210},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {feb},
number = {1},
pages = {80--102},
title = {{The relational model of data and cylindric algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022000084900771},
volume = {28},
year = {1984}
}
@incollection{Chen2012,
abstract = {Probabilistic bisimilarity is a fundamental notion of equivalence on labelled Markov chains. It has a natural generalisation to a probabilistic bisimilarity pseudometric, whose definition involves the Kantorovich metric on probability distributions. The pseudometric has discounted and undiscounted variants, according to whether one discounts the future in observing discrepancies between states. This paper is concerned with the complexity of computing probabilistic bisimilarity and the probabilistic bisimilarity pseudometric on labelled Markov chains. We show that the problem of computing probabilistic bisimilarity is P -hard by reduction from the monotone circuit value problem. We also show that the discounted pseudometric is rational and can be computed exactly in polynomial time using the network simplex algorithm and the continued fraction algorithm. In the undiscounted case we show that the pseudometric is again rational and can be computed exactly in polynomial time using the ellipsoid algorithm. Finally, using the notion of couplings on Markov chains, we show that the pseudometric can be used to compute bounds on the variational distance of trace distributions, which is NP -hard to compute directly.},
annote = {10.1007/978-3-642-28729-9{\_}29},
author = {Chen, Di and van Breugel, Franck and Worrell, James},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Chen, van Breugel, Worrell - 2012 - On the Complexity of Computing Probabilistic Bisimilarity.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {437--451},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On the Complexity of Computing Probabilistic Bisimilarity}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}29},
volume = {7213},
year = {2012}
}
@incollection{Johnstone1985a,
address = {New York},
author = {Johnstone, Peter T.},
booktitle = {Continuous lattices and their applications},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone - 1985 - Vietoris locales and localic semilattices.pdf:pdf},
pages = {155--180},
publisher = {Marcel Dekker},
series = {Lecture Notes in Pure and Applied Mathematics},
title = {{Vietoris locales and localic semilattices}},
type = {Book part (with own title)},
year = {1985}
}
@book{Comon2007,
author = {Comon, Hubert and Dauchet, Max and Gilleron, R{\'{e}}mi and Jacquemard, Florent and Lugiez, Denis and L{\"{o}}ding, Christof and Tison, Sophie and Tommasi, Marc},
file = {:Users/liang-tingchen/Dropbox/References/Comon et al. - 2007 - Tree Automata Techniques and Applications.pdf:pdf},
pages = {262},
publisher = {Available on: $\backslash$url{\{}http://www.grappa.univ-lille3.fr/tata{\}}},
title = {{Tree Automata Techniques and Applications}},
year = {2007}
}
@techreport{Chong2016,
abstract = {Report on the NSF Workshop on Formal Methods for Security, held 19-20 November 2015.},
archivePrefix = {arXiv},
arxivId = {1608.00678},
author = {Chong, Stephen and Guttman, Joshua and Datta, Anupam and Myers, Andrew and Pierce, Benjamin and Schaumont, Patrick and Sherwood, Tim and Zeldovich, Nickolai},
eprint = {1608.00678},
file = {:Users/liang-tingchen/Dropbox/References/Chong et al. - 2016 - Report on the NSF Workshop on Formal Methods for Security.pdf:pdf},
month = {aug},
title = {{Report on the NSF Workshop on Formal Methods for Security}},
url = {http://arxiv.org/abs/1608.00678},
year = {2016}
}
@article{Coquand2021,
abstract = {We provide a constructive version of the notion of sheaf models of univalent type theory. We start by relativizing existing constructive models of univalent type theory to presheaves over a base category. Any Grothendieck topology of the base category then gives rise to a family of left-exact modalities, and we recover a model of type theory by localizing the presheaf model with respect to this family of left-exact modalities. We provide then some examples.},
archivePrefix = {arXiv},
arxivId = {1912.10407},
author = {Coquand, Thierry and Ruch, Fabian and Sattler, Christian},
doi = {10.1017/S0960129521000359},
eprint = {1912.10407},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Ruch, Sattler - 2021 - Constructive sheaf models of type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {Dependent type theory,constructive models of univalence,homotopy type theory,left-exact modalities,sheaf models},
month = {nov},
number = {2021},
pages = {1--24},
title = {{Constructive sheaf models of type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129521000359/type/journal{\_}article},
year = {2021}
}
@book{Johnstone2002,
author = {Johnstone, Peter T.},
isbn = {978-0-19-853425-9},
pages = {562},
publisher = {Oxford University Press},
title = {{Sketches of an Elephant: A Topos Theory Compendium}},
volume = {1},
year = {2002}
}
@article{Denning1976,
abstract = {This paper investigates mechanisms that guarantee secure information flow in a computer system. These mechanisms are examined within a mathematical framework suitable for formulating the requirements of secure information flow among security classes. The central component of the model is a lattice structure derived from the security classes and justified by the semantics of information flow. The lattice properties permit concise formulations of the security requirements of different existing systems and facilitate the construction of mechanisms that enforce security. The model provides a unifying view of all systems that restrict information flow, enables a classification of them according to security objectives, and suggests some new approaches. It also leads to the construction of automatic program certification mechanisms for verifying the secure flow of information through a program.},
author = {Denning, Dorothy E.},
doi = {10.1145/360051.360056},
file = {:Users/liang-tingchen/Dropbox/References/Denning - 1976 - A lattice model of secure information flow.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {and phrases,information flow,lattice,program,protection,security,security class},
month = {may},
number = {5},
pages = {236--243},
title = {{A lattice model of secure information flow}},
url = {http://portal.acm.org/citation.cfm?doid=360051.360056},
volume = {19},
year = {1976}
}
@article{Antwerpen2018,
author = {van Antwerpen, Hendrik and {Bach Poulsen}, Casper and Rouvoet, Arjen and Visser, Eelco},
doi = {10.1145/3276484},
file = {:Users/liang-tingchen/Dropbox/References/van Antwerpen et al. - 2018 - Scopes as types.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {domain-specific language,name resolution,scope graphs,static semantics,type checker,type system},
month = {oct},
number = {OOPSLA},
pages = {1--30},
title = {{Scopes as types}},
url = {http://dl.acm.org/citation.cfm?doid=3288538.3276484},
volume = {2},
year = {2018}
}
@article{Street2012,
abstract = {This is a report on aspects of the theory and use of monoidal categories. The first section introduces the main concepts through the example of the category of vector spaces. String notation is explained and shown to lead naturally to a link between knot theory and monoidal categories. The second section reviews the light thrown on aspects of representation theory by the machinery of monoidal category theory, such as braidings and convolution. The category theory of Mackey functors is reviewed in the third section. Some recent material and a conjecture concerning monoidal centres is included. The fourth and final section looks at ways in which monoidal categories are, and might, be used for new invariants of low-dimensional manifolds and for the field theory of theoretical physics.},
archivePrefix = {arXiv},
arxivId = {1201.2991},
author = {Street, Ross},
eprint = {1201.2991},
file = {:Users/liang-tingchen/Dropbox/References/Street - 2012 - Monoidal categories in, and linking, geometry and algebra.pdf:pdf},
issn = {13701444},
journal = {Bulletin of the Belgian Mathematical Society},
keywords = {and phrases,braiding,day convolution,duoidal category,enriched category,finite,functor,green functor,joyal species,mackey,manifold invariant,monoidal category,string diagram,topological quantum field theory},
month = {jan},
number = {5},
pages = {769--820},
title = {{Monoidal categories in, and linking, geometry and algebra}},
url = {http://arxiv.org/abs/1201.2991 http://projecteuclid.org/euclid.bbms/1354031551{\#}info},
volume = {19},
year = {2012}
}
@incollection{Rutten1995a,
author = {Rutten, Jan J.M.M.},
booktitle = {Modal Logic and Process Algebra},
editor = {Ponse, Alban and de Rijke, Maarten and Venema, Yde},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 1995 - A calculus of transition systems (towards universal coalgebra).pdf:pdf},
pages = {231--256},
publisher = {Center for the Study of Language and Information, Stanford},
title = {{A calculus of transition systems (towards universal coalgebra)}},
type = {Book chapter/section},
year = {1995}
}
@article{Dreyer2011,
author = {Dreyer, Derek and Ahmed, Amal and Birkedal, Lars},
doi = {10.2168/LMCS-7(2:16)2011},
editor = {Pitts, Andrew},
file = {:Users/liang-tingchen/Dropbox/References/Dreyer, Ahmed, Birkedal - 2011 - Logical Step-Indexed Logical Relations.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {jun},
number = {2},
pages = {1--37},
title = {{Logical Step-Indexed Logical Relations}},
url = {https://lmcs.episciences.org/698},
volume = {7},
year = {2011}
}
@incollection{Scott1970,
author = {Scott, Dana S.},
booktitle = {Philosophical Problems in Logic},
doi = {10.1007/978-94-010-3272-8_7},
editor = {Lamber, Karel},
isbn = {978-94-010-3274-2},
pages = {143--173},
publisher = {Springer Netherlands},
series = {Synthese Library},
title = {{Advice on Modal Logic}},
volume = {29},
year = {1970}
}
@article{Bonsangue2012,
abstract = {Coalgebras provide a uniform framework to study dynamical systems, including several types of automata. In this paper, we make use of the coalgebraic view on systems to investigate, in a uniform way, under which conditions calculi that are sound and complete with respect to behavioral equivalence can be extended to a coarser coalgebraic language equivalence, which arises from a generalised powerset construction that determinises coalgebras. We show that soundness and completeness are established by proving that expressions modulo axioms of a calculus form the rational fixpoint of the given type functor. Our main result is that the rational fixpoint of the functor {\$}FT{\$}, where {\$}T{\$} is a monad describing the branching of the systems (e.g. non-determinism, weights, probability etc.), has as a quotient the rational fixpoint of the "determinised" type functor {\$}\backslashbar F{\$}, a lifting of {\$}F{\$} to the category of {\$}T{\$}-algebras. We apply our framework to the concrete example of weighted automata, for which we present a new sound and complete calculus for weighted language equivalence. As a special case, we obtain non-deterministic automata, where we recover Rabinovich's sound and complete calculus for language equivalence.},
archivePrefix = {arXiv},
arxivId = {1104.2803},
author = {Bonsangue, Marcello M. and Milius, Stefan and Silva, Alexandra},
doi = {10.1145/0000000.0000000},
eprint = {1104.2803},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Milius, Silva - 2012 - Sound and complete axiomatizations of coalgebraic language equivalence.pdf:pdf},
journal = {ArXiv e-prints},
month = {apr},
title = {{Sound and complete axiomatizations of coalgebraic language equivalence}},
url = {http://arxiv.org/abs/1104.2803},
year = {2012}
}
@article{PierangelaSamarati2001,
author = {Samarati, P.},
doi = {10.1109/69.971193},
file = {:Users/liang-tingchen/Dropbox/References/Samarati - 2001 - Protecting respondents identities in microdata release.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {6},
pages = {1010--1027},
title = {{Protecting respondents identities in microdata release}},
url = {http://ieeexplore.ieee.org/document/971193/},
volume = {13},
year = {2001}
}
@inproceedings{Fiore2013,
abstract = {—We formalise and study the notion of polymorphic algebraic theory, as understood in the mathematical vernacular as a theory presented by equations between polymorphically-typed terms with both type and term variable binding. The prototypical example of a polymorphic algebraic theory is Sys-tem F, but our framework applies more widely. The extra generality stems from a mathematical analysis that has led to a unified theory of polymorphic algebraic theories with the following ingredients: -polymorphic signatures that specify arbitrary polymorphic opera-tors (e.g. as in extended $\lambda$-calculi and algebraic theories of effects); -metavariables, both for types and terms, that enable the generic description of meta-theories; -multiple type universes that allow a notion of translation between theories that is parametric over possibly different type universes; -polymorphic structures that provide a general notion of algebraic model (including the PL-category semantics of System F); and -a Polymorphic Equational Logic that constitutes a sound and complete logical framework for equational reasoning. Our work is semantically driven, being based on a hierarchical two-levelled algebraic modelling of abstract syntax with variable binding. As such, the development requires a sophisticated blend of math-ematical tools: presheaf categories, the Grothendieck construction, discrete generalised polynomial functors, and aspects of categorical universal algebra.},
author = {Fiore, Marcelo and Hamana, Makoto},
booktitle = {2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.59},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Hamana - 2013 - Multiversal Polymorphic Algebraic Theories Syntax, Semantics, Translations, and Equational Logic.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
keywords = {categorical semantics,equational logic,polymorphism,presheaves,the Grothendieck construction},
month = {jun},
pages = {520--529},
publisher = {IEEE},
title = {{Multiversal Polymorphic Algebraic Theories: Syntax, Semantics, Translations, and Equational Logic}},
url = {http://ieeexplore.ieee.org/document/6571585/},
year = {2013}
}
@article{Balan2011,
author = {Balan, Adriana and Kurz, Alexander},
doi = {10.1016/j.tcs.2011.03.021},
file = {:Users/liang-tingchen/Dropbox/References/Balan, Kurz - 2011 - On coalgebras over algebras.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {sep},
number = {38},
pages = {4989--5005},
publisher = {Elsevier B.V.},
title = {{On coalgebras over algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397511002519},
volume = {412},
year = {2011}
}
@article{Rosicky1994a,
author = {Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/0022-4049(94)90023-X},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}} - 1994 - Models of Horn theories revisited.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {mar},
number = {2},
pages = {185--190},
title = {{Models of Horn theories revisited}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499490023X},
volume = {92},
year = {1994}
}
@incollection{Zhang2013,
abstract = {Publication of the private set-valued data will provide enormous opportunities for counting queries and various data mining tasks. Compared to those previous methods based on partition-based privacy models (e.g., k-anonymity), differential privacy provides strong privacy guarantees against adversaries with arbitrary background knowledge. However, the existing solutions based on differential privacy for data publication are currently limited to static datasets, and do not adequately address today's demand for up-to-date information. In this paper, we address the problem of differentially private set-valued data release on an incremental scenario in which the data need to be transformed are not static. Motivated by this, we propose an efficient algorithm, called IncTDPart, to incrementally generate a series of differentially private releases. The proposed algorithm is based on top-down partitioning model with the help of item-free taxonomy tree and update-bounded mechanism. Extensive experiments on real datasets confirm that our approach maintains high utility and scalability for counting query.},
author = {Zhang, Xiaojian and Meng, Xiaofeng and Chen, Rui},
booktitle = {Database Systems for Advanced Applications. DASFAA 2013},
doi = {10.1007/978-3-642-37487-6_30},
editor = {Meng, Weiyi and Feng, Ling and Bressan, St{\'{e}}phane and Winiwarter, Werner and Song, Wei},
file = {:Users/liang-tingchen/Dropbox/References/Zhang, Meng, Chen - 2013 - Differentially Private Set-Valued Data Release against Incremental Updates.pdf:pdf},
isbn = {9783642374869},
issn = {03029743},
keywords = {Differential privacy,Incremental updates,Set-valued data},
pages = {392--406},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Differentially Private Set-Valued Data Release against Incremental Updates}},
url = {http://link.springer.com/10.1007/978-3-642-37487-6{\_}30},
volume = {7825},
year = {2013}
}
@article{Barr1992,
author = {Barr, Michael},
doi = {10.1016/0022-4049(92)90169-G},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1992 - Algebraically compact functors.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {oct},
number = {3},
pages = {211--231},
title = {{Algebraically compact functors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499290169G},
volume = {82},
year = {1992}
}
@article{Lucyshyn-wright2016,
author = {Lucyshyn-wright, Rory B. B.},
file = {:Users/liang-tingchen/Dropbox/References/Lucyshyn-wright - 2016 - Enriched Algebraic Theories and Monads for a System of Arities.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {2016,algebraic theory,and phrases,b,c rory b,enriched cate-,free cocompletion,gory theory,lawvere theory,lucyshyn-wright,monad,permission to copy for,private use granted,universal algebra},
number = {5},
pages = {101--137},
title = {{Enriched Algebraic Theories and Monads for a System of Arities}},
volume = {31},
year = {2016}
}
@article{Mostrous2015,
abstract = {This paper proposes a session typing system for the higher-order $\pi$-calculus (the HO$\pi$-calculus) with asynchronous communication subtyping, which allows partial commutativity of actions in higher-order processes. The system enables two complementary kinds of optimisation, mobile code and asynchronous permutation of session actions, within processes that utilise structured, typed communications. Our first contribution is a session typing system for the HO$\pi$-calculus using techniques from the linear $\lambda$-calculus. Integration of arbitrary higher-order code mobility and sessions leads to technical difficulties in type soundness, because linear usage of session channels and completion of sessions are required. Our second contribution is to introduce an asynchronous subtyping system which uniformly deals with type-manifested asynchrony and linear functions. The most technical challenge for subtyping is to prove the transitivity of the subtyping relation. We also demonstrate the expressiveness of our typing system with an e-commerce example, where optimised processes can interact respecting the expected sessions.},
author = {Mostrous, Dimitris and Yoshida, Nobuko},
doi = {10.1016/j.ic.2015.02.002},
file = {:Users/liang-tingchen/Dropbox/References/Mostrous, Yoshida - 2015 - Session typing and asynchronous subtyping for the higher-order $\pi$-calculus.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Asynchronous subtyping,Code mobility,Communication optimisation,Linear typing,Session types,The higher-order $\pi$-calculus},
month = {apr},
pages = {227--263},
publisher = {Elsevier Inc.},
title = {{Session typing and asynchronous subtyping for the higher-order $\pi$-calculus}},
url = {http://dx.doi.org/10.1016/j.ic.2015.02.002 https://linkinghub.elsevier.com/retrieve/pii/S0890540115000139},
volume = {241},
year = {2015}
}
@inproceedings{OConnor2016,
address = {New York, New York, USA},
author = {O'Connor, Liam},
booktitle = {Proceedings of the 1st International Workshop on Type-Driven Development - TyDe 2016},
doi = {10.1145/2976022.2976030},
file = {:Users/liang-tingchen/Dropbox/References/O'Connor - 2016 - Applications of applicative proof search.pdf:pdf},
isbn = {9781450344357},
keywords = {agda,answer,are at-,au-,but actual evidence to,concurrency,critical section,ensures,model checking,proof,properties,support the proposition they,tempting to automatically prove,testing,the type system already,tomation},
pages = {43--55},
publisher = {ACM Press},
title = {{Applications of applicative proof search}},
url = {http://dl.acm.org/citation.cfm?doid=2976022.2976030},
year = {2016}
}
@inproceedings{Pin2009,
author = {Pin, Jean-{\'{E}}ric},
booktitle = {26th International Symposium on Theoretical Aspects of Computer Science},
doi = {10.4230/LIPIcs.STACS.2009.1856},
editor = {Albers, Susanne and Marion, Jean-Yves},
file = {:Users/liang-tingchen/Dropbox/References/Pin - 2009 - Profinite methods in automata theory.pdf:pdf},
isbn = {9783939897095},
issn = {18688969},
pages = {31--50},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{Profinite methods in automata theory}},
volume = {3},
year = {2009}
}
@article{Venema2012,
abstract = {This paper introduces an endofunctor {\$}\backslashVT{\$} on the category of frames, parametrized by an endofunctor {\$}\backslashT{\$} on the category {\$}\backslashSet{\$} that satisfies certain constraints. This generalizes Johnstone's construction of the Vietoris powerlocale, in the sense that his construction is obtained by taking for {\$}\backslashT{\$} the finite covariant power set functor. Our construction of the {\$}\backslashT{\$}-powerlocale {\$}\backslashVT \backslashbbL{\$} out of a frame {\$}\backslashbbL{\$} is based on ideas from coalgebraic logic and makes explicit the connection between the Vietoris construction and Moss's coalgebraic cover modality. We show how to extend certain natural transformations between set functors to natural transformations between {\$}\backslashT{\$}-powerlocale functors. Finally, we prove that the operation {\$}\backslashVT{\$} preserves some properties of frames, such as regularity, zero-dimensionality, and the combination of zero-dimensionality and compactness.},
archivePrefix = {arXiv},
arxivId = {1202.3264},
author = {Venema, Yde and Vickers, Steven and Vosmaer, Jacob},
doi = {10.1017/S0960129512000229},
eprint = {1202.3264},
file = {:Users/liang-tingchen/Dropbox/References/Venema, Vickers, Vosmaer - 2012 - Generalised powerlocales via relation lifting.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {coalgebra,cover modality,frames,locales,modal logic,vietoris construction},
month = {aug},
number = {01},
pages = {142--199},
title = {{Generalised powerlocales via relation lifting}},
url = {http://arxiv.org/abs/1202.3264 http://www.journals.cambridge.org/abstract{\_}S0960129512000229},
volume = {23},
year = {2012}
}
@article{Kock2012,
abstract = {The theory of commutative monads on cartesian closed categories provides a framework where aspects of the theory of distributions and other extensive quantities can be formulated and some results proved. We make explicit a link between our theory and the theory of Schwartz distributions of compact support. We also discuss probability distributions.},
archivePrefix = {arXiv},
arxivId = {1108.5952},
author = {Kock, Anders},
eprint = {1108.5952},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 2012 - Commutative monads as a theory of distributions.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Distributions,Extensive quantities,Monads},
number = {4},
pages = {97--131},
title = {{Commutative monads as a theory of distributions}},
url = {http://www.tac.mta.ca/tac/volumes/26/4/26-04abs.html},
volume = {26},
year = {2012}
}
@article{Halmos1981,
author = {Halmos, Paul R.},
file = {:Users/liang-tingchen/Dropbox/References/Halmos - 1981 - Applied Mathematics is Bad Mathematics.pdf:pdf},
journal = {Mathematics Tomorrow},
pages = {9--20},
title = {{Applied Mathematics is Bad Mathematics}},
year = {1981}
}
@incollection{Street1996,
abstract = {This chapter discusses category theory, with emphasis on categorical structures. Innovative categorical concepts in category theory include homological algebra, universal algebra, set theory, and enumerative combinatorics. The chapter emphasizes categories as vital mathematical structures. It also explores some fundamental interconnections involving rewrite systems, free higher-order categories, cubes and simplexes, and homotopy theory. A (directed) graph G consists of two sets G0, G1 and an ordered pair of functions. The elements of G0 are called “objects,” “vertices,” or “0-cells.” The elements of G1 are called “arrows,” “edges,” or “1-cells.” Repeated horizontal and vertical composition in a 2-category K determines a more general operation called “pasting.” Each free 2-category A has a length 2-functor ℓ: A →M induced by the unique computed morphism between the generating computads. The connection between categories and the Bazhanov–Stroganov d-simplex equations arisen in statistical and quantum mechanics are also presented.},
author = {Street, Ross},
booktitle = {Handbook of Algebra},
doi = {10.1016/S1570-7954(96)80019-2},
editor = {Hazewinkel, M.},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1996 - Categorical structures.pdf:pdf},
isbn = {978-0-444-82212-3},
issn = {15707954},
pages = {529--577},
publisher = {North-Holland},
title = {{Categorical structures}},
volume = {1},
year = {1996}
}
@article{Hinze2013b,
abstract = {Folds and unfolds are at the heart of the algebra of programming. They allow the cognoscenti to derive and manipulate programs rigorously and effectively. However, most, if not all, programs require some tweaking to be given the form of an (un)fold. In this article, we remedy the situation by introducing adjoint (un)folds. We demonstrate that most programs are already of the required form and thus are directly amenable to formal manipulation. Central to the development is the categorical notion of an adjunction, which links adjoint (un)folds to standard (un)folds. We discuss a multitude of basic adjunctions and ways of combining adjunctions and show that they are directly relevant to programming. Furthermore, we develop the calculational properties of adjoint (un)folds, providing several fusion laws, which codify basic optimisation principles. We give a novel proof of type fusion based on adjoint folds and discuss several applications - type fusion states conditions for fusing a left adjoint with an initial algebra to form another initial algebra. The formal development is complemented by a series of examples in Haskell. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
author = {Hinze, Ralf},
doi = {10.1016/j.scico.2012.07.011},
file = {:Users/liang-tingchen/Dropbox/References/Hinze - 2013 - Adjoint folds and unfolds—An extended study.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
keywords = {Adjunction,Final coalgebra,Fold,Fusion,Haskell,Initial algebra,Kan extension,Unfold},
month = {nov},
number = {11},
pages = {2108--2159},
publisher = {Elsevier B.V.},
title = {{Adjoint folds and unfolds—An extended study}},
url = {http://dx.doi.org/10.1016/j.scico.2012.07.011 https://linkinghub.elsevier.com/retrieve/pii/S0167642312001396},
volume = {78},
year = {2013}
}
@article{Makkai1987,
author = {Makkai, Michael},
doi = {10.1016/0001-8708(87)90020-X},
file = {:Users/liang-tingchen/Dropbox/References/Makkai - 1987 - Stone duality for first order logic.pdf:pdf},
issn = {00018708},
journal = {Advances in Mathematics},
month = {aug},
number = {2},
pages = {97--170},
title = {{Stone duality for first order logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/000187088790020X},
volume = {65},
year = {1987}
}
@phdthesis{Chen2013,
author = {Chen, Liang-Ting},
file = {:Users/liang-tingchen/Dropbox/References/Chen - 2013 - On a Purely Categorical Framework for Coalgebraic Modal Logic.pdf:pdf},
school = {University of Birmingham},
title = {{On a Purely Categorical Framework for Coalgebraic Modal Logic}},
url = {http://etheses.bham.ac.uk/4882/},
year = {2013}
}
@book{Emerson2001,
abstract = {In this paper, we consider the model checking problem for the $\mu$-calculus and show that it is succinctly equivalent to the non-emptiness problem of finite-state automata on infinite binary trees with the parity acceptance condition. We also present efficient model checking algorithms for two rich subclasses of the $\mu$-calculus formulas and relate their expressive power to well-known extensions of branching time temporal logics. {\textcopyright} 2001 Elsevier Science B.V. All rights reserved.},
author = {Emerson, E. Allen and Jutla, Charanjit S. and Sistla, A. Prasad},
booktitle = {Theoretical Computer Science},
doi = {10.1016/S0304-3975(00)00034-7},
file = {:Users/liang-tingchen/Dropbox/References/Emerson, Jutla, Sistla - 2001 - On model checking for the $\mu$-calculus and its fragments.pdf:pdf},
isbn = {0036580650199},
issn = {03043975},
keywords = {Expressiveness,Model checking,Temporal logic,Tree automata,$\mu$-calculus},
number = {1-2},
pages = {491--522},
title = {{On model checking for the $\mu$-calculus and its fragments}},
volume = {258},
year = {2001}
}
@article{Ahrens2012,
abstract = {We give an algebraic characterization of the syntax and operational semantics of a class of simply-typed languages, such as the language PCF: we characterize simply-typed syntax with variable binding and equipped with reduction rules via a universal property, namely as the initial object of some category of models. For this purpose, we employ techniques developed in two previous works: in the first work we model syntactic translations between languages over different sets of types as initial morphisms in a category of models. In the second work we characterize untyped syntax with reduction rules as initial object in a category of models. In the present work, we combine the techniques used earlier in order to characterize simply-typed syntax with reduction rules as initial object in a category. The universal property yields an operator which allows to specify translations---that are semantically faithful by construction---between languages over possibly different sets of types. As an example, we upgrade a translation from PCF to the untyped lambda calculus, given in previous work, to account for reduction in the source and target. Specifically, we specify a reduction semantics in the source and target language through suitable rules. By equipping the untyped lambda calculus with the structure of a model of PCF, initiality yields a translation from PCF to the lambda calculus, that is faithful with respect to the reduction semantics specified by the rules. This paper is an extended version of an article published in the proceedings of WoLLIC 2012.},
author = {Ahrens, Benedikt},
doi = {10.23638/LMCS-15(1:28)2019},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens - 2019 - Initial Semantics for Reduction Rules.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {Computer Science - Logic in Computer Science,F.3.2,F.4.3,Mathematics - Logic},
number = {1},
pages = {1--28},
title = {{Initial Semantics for Reduction Rules}},
url = {https://lmcs.episciences.org/5299},
volume = {15},
year = {2019}
}
@inproceedings{Mitchell2012,
address = {New York, New York, USA},
author = {Mitchell, Neil},
booktitle = {Proceedings of the 17th ACM SIGPLAN international conference on Functional programming - ICFP '12},
doi = {10.1145/2364527.2364538},
file = {:Users/liang-tingchen/Dropbox/References/Mitchell - 2012 - Shake before building.pdf:pdf},
isbn = {9781450310543},
pages = {55},
publisher = {ACM Press},
title = {{Shake before building}},
url = {http://dl.acm.org/citation.cfm?doid=2364527.2364538},
year = {2012}
}
@article{Hyland2002,
author = {Hyland, Martin and Power, A. John},
doi = {10.1016/S0022-4049(02)00133-0},
file = {:Users/liang-tingchen/Dropbox/References/Hyland, Power - 2002 - Pseudo-commutative monads and pseudo-closed 2-categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-3},
pages = {141--185},
title = {{Pseudo-commutative monads and pseudo-closed 2-categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404902001330},
volume = {175},
year = {2002}
}
@incollection{Dwork2008b,
abstract = {We briefly survey several privacy compromises in published datasets, some historical and some on paper. An inspection of these suggests that the problem lies with the nature of the privacy-motivated promises in question. These are typically syntactic, rather than semantic. They are also ad hoc , with insufficient argument that fulfilling these syntactic and ad hoc conditions yields anything like what most people would regard as privacy. We examine two comprehensive, or ad omnia , guarantees for privacy in statistical databases discussed in the literature, note that one is unachievable, and describe implementations of the other.},
address = {Berlin, Heidelberg},
author = {Dwork, Cynthia},
booktitle = {Privacy, Security, and Trust in KDD},
doi = {10.1007/978-3-540-78478-4_1},
file = {:Users/liang-tingchen/Dropbox/References/Dwork - 2008 - An Ad Omnia Approach to Defining and Achieving Private Data Analysis.pdf:pdf},
isbn = {978-3-540-78477-7},
issn = {03029743},
keywords = {cryptography,differential,privacy},
pages = {1--13},
publisher = {Springer Berlin Heidelberg},
title = {{An Ad Omnia Approach to Defining and Achieving Private Data Analysis}},
url = {http://dx.doi.org/10.1007/978-3-540-78478-4{\_}1 http://link.springer.com/10.1007/978-3-540-78478-4{\_}1},
volume = {4890},
year = {2008}
}
@article{Okasaki1995,
abstract = {We present purely functional implementations of queues and double-ended queues (deques) requiring only O (1) time per operation in the worst case. Our algorithms are considerably simpler than previous designs with the same bounds. The inspiration for our approach is the incremental behaviour of certain functions on lazy lists.},
author = {Okasaki, Chris},
doi = {10.1017/S0956796800001489},
file = {:Users/liang-tingchen/Dropbox/References/Okasaki - 1995 - Simple and efficient purely functional queues and deques.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {oct},
number = {04},
pages = {583--592},
publisher = {Swansea University Libraries},
title = {{Simple and efficient purely functional queues and deques}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796800001489},
volume = {5},
year = {1995}
}
@inproceedings{Chen2022a,
address = {Dagstuhl, Germany},
annote = {Keywords: provability, guarded recursion, realisability, modal types, metaprogramming},
author = {Chen, Liang-Ting and Ko, Hsiang-Shang},
booktitle = {30th EACSL Annual Conference on Computer Science Logic (CSL 2022)},
doi = {10.4230/LIPIcs.CSL.2022.14},
editor = {Manea, Florin and Simpson, Alex},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Ko - 2022 - Realising Intensional S4 and GL Modalities.pdf:pdf},
isbn = {978-3-95977-218-1},
issn = {1868-8969},
pages = {14:1----14:17},
publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Realising Intensional S4 and GL Modalities}},
url = {https://drops.dagstuhl.de/opus/volltexte/2022/15734},
volume = {216},
year = {2022}
}
@incollection{Gehrke2009,
abstract = {This is a theoretical paper giving the extended Stone duality perspective on the recently discovered connection between duality theory as studied in non-classical logic and theoretical computer science and the algebraic theory of finite state automata. As a bi-product we obtain a general result about profinite completion, namely, that it is the dual under extended Stone duality of the recognisable languages over the original algebra equipped with certain residuation operations.},
author = {Gehrke, Mai},
booktitle = {3rd Conference on Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-03741-2_17},
editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke - 2009 - Stone Duality and the Recognisable Languages over an Algebra.pdf:pdf},
isbn = {3642037402},
issn = {03029743},
pages = {236--250},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Stone Duality and the Recognisable Languages over an Algebra}},
url = {http://link.springer.com/10.1007/978-3-642-03741-2{\_}17},
year = {2009}
}
@inproceedings{Urabe2016,
address = {Dagstuhl, Germany},
annote = {Keywords: coalgebra, Buechi automaton, parity automaton, probabilistic automaton, tree automaton},
author = {Urabe, Natsuki and Shimizu, Shunsuke and Hasuo, Ichiro},
booktitle = {27th International Conference on Concurrency Theory (CONCUR 2016)},
doi = {http://dx.doi.org/10.4230/LIPIcs.CONCUR.2016.24},
editor = {Desharnais, Jos{\'{e}}e and Jagadeesan, Radha},
file = {:Users/liang-tingchen/Dropbox/References/Urabe, Shimizu, Hasuo - 2016 - Coalgebraic trace semantics for B{\"{u}}chi and parity automata.pdf:pdf},
isbn = {978-3-95977-017-0},
issn = {1868-8969},
pages = {24:1----24:15},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Coalgebraic trace semantics for B{\"{u}}chi and parity automata}},
url = {http://drops.dagstuhl.de/opus/volltexte/2016/6186},
volume = {59},
year = {2016}
}
@inproceedings{Pickering2019,
abstract = {Cross-stage persistence is an essential aspect of multi-stage programming that allows a value defined in one stage to be available in another. However, difficulty arises when implicit information held in types, type classes and implicit parameters needs to be persisted. Without a careful treatment of such implicit information-which are pervasive in Haskell-subtle yet avoidable bugs lurk beneath the surface. This paper demonstrates that in multi-stage programming care must be taken when representing quoted terms so that important implicit information is kept in context and not discarded. The approach is formalised with a type-system, and an implementation in GHC is presented that fixes problems of the previous incarnation.},
address = {New York, New York, USA},
author = {Pickering, Matthew and Wu, Nicolas and Kiss, Csongor},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Symposium on Haskell - Haskell 2019},
doi = {10.1145/3331545.3342597},
file = {:Users/liang-tingchen/Dropbox/References/Pickering, Wu, Kiss - 2019 - Multi-stage programs in context.pdf:pdf},
isbn = {9781450368131},
keywords = {Implicits,Metaprogramming,Staging},
number = {Section 2},
pages = {71--84},
publisher = {ACM Press},
title = {{Multi-stage programs in context}},
url = {http://dl.acm.org/citation.cfm?doid=3331545.3342597},
year = {2019}
}
@article{Jones1996,
abstract = {The last decade has seen two methodological advances of particular direct import for the theory of finite monoids and indirect import for that of rational languages. The first has been the use of categories (considered as "algebras over graphs") as a framework in which to study monoids and their homomorphisms, the second has been the use of implicit operations to study pseudovarieties of monoids. Still more recent work has emphasized the role of profiniteness in finite monoid theory. This paper fuses these three topics by means of a general study of profinite categories, with applications to C-varieties (pseudovarieties of categories) in general, to those C-varieties arising from M-varieties (pseudovarieties of monoids) in particular, to implicit operations on categories and to recognizable languages over graphs.},
author = {Jones, Peter R.},
doi = {10.1016/0022-4049(95)00074-7},
file = {:Users/liang-tingchen/Dropbox/References/Jones - 1996 - Profinite categories, implicit operations and pseudovarieties of categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {1},
pages = {61--95},
title = {{Profinite categories, implicit operations and pseudovarieties of categories}},
volume = {109},
year = {1996}
}
@phdthesis{Kurz2000,
author = {Kurz, Alexander},
file = {:Users/liang-tingchen/Dropbox/References/Kurz - 2000 - Logics for Coalgebras and Applications to Computer Science.pdf:pdf},
month = {jul},
school = {University of Munich},
title = {{Logics for Coalgebras and Applications to Computer Science}},
url = {http://www.cs.le.ac.uk/people/akurz/works.html},
year = {2000}
}
@article{Andreoli1992,
abstract = {The deep symmetry of linear logic [18] makes it suitable for providing abstract models of computation, free from implementation details which are, by nature, oriented and non-symmetrical. I propose here one such model, in the area of logic programming, where the basic computational priciple is. Computation = Proof search. Proofs cinsidered here are those of the Gentzen style sequent calculus for linear logic. However, proofs in this system may be redundant, in that two proofs canbe syntactically different although identical up to some irrelevant reordering or simplification of the applications of the inferences rules. This leads to an untractable proof search where the search procedure is forced to make costly choices whch turn out to be irrelevant. To overcome this problem, a subclass of proofs, called the 'focusing' proofs, which is both complete (any derivable formla in linear logic has a focusing proof) and tractable (many irrelevant choices in the search are eliminated when aimed at focusing proofs) is identified. The main constraint underlying the specificatuon of focusing proofs has been to preserve the symmetry of linear logic, which is its most salient feature. In particular, dual connectives have dual properties with respect to focusing proofs. Then, a progrmming language, called LinLog, consisting of a fragment of linear logic, in which focussing proofs have a more compact form, is presented. Linlog deals with formulae which have a syntax similar to the of the definite clauses and goals of Horn logic, but the crucial difference here is that it allows clauses with multiple atoms in the head, connected by the 'par' (multiplicative disjuction). It is then shown that the syntyactic restriction induced by LinLog is not performed at the cost of any expressive power: a mapping from full linear logic to LinLog, preserving focusing proofs, and analogous to the normalization to clausal form for classical logic, is presented. {\textcopyright} 1992 Oxford University Press.},
author = {ANDREOLI, JEAN-MARC},
doi = {10.1093/logcom/2.3.297},
file = {:Users/liang-tingchen/Dropbox/References/ANDREOLI - 1992 - Logic Programming with Focusing Proofs in Linear Logic.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Concurrency.,Linear logic,Logic programming,Parallelism,Proof normalization,Sequent systems},
number = {3},
pages = {297--347},
title = {{Logic Programming with Focusing Proofs in Linear Logic}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/2.3.297},
volume = {2},
year = {1992}
}
@incollection{Manes2003,
author = {Manes, Ernie},
booktitle = {Handbook of Algebra},
doi = {10.1016/S1570-7954(03)80059-1},
editor = {Hazewinkel, M.},
file = {:Users/liang-tingchen/Dropbox/References/Manes - 2003 - Monads of sets.pdf:pdf},
isbn = {978-0444512642},
pages = {67--153},
publisher = {North Holland},
title = {{Monads of sets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1570795403800591},
volume = {3},
year = {2003}
}
@article{Brady2000,
author = {Brady, Geraldine and {Todd Trimble}},
file = {:Users/liang-tingchen/Dropbox/References/Brady, Todd Trimble - 2000 - A string diagram calculus for predicate logic and C. S. Peirce's System Beta.pdf:pdf},
title = {{A string diagram calculus for predicate logic and C. S. Peirce's System Beta}},
year = {2000}
}
@article{Palmgren2019a,
abstract = {First-order logic with dependent sorts, such as Makkai's first-order logic with dependent sorts (FOLDS), or Aczel's and Belo's dependently typed (intuitionistic) first-order logic (DFOL), may be regarded as logic enriched dependent type theories. Categories with families (cwfs) is an established semantical structure for dependent type theories, such as Martin-L{\"{o}}f type theory. We introduce in this article a notion of hyperdoctrine over a cwf, and show how FOLDS and DFOL fit in this semantical framework. A soundness and completeness theorem is proved for DFOL. The semantics is functorial in the sense of Lawvere, and uses a dependent version of the Lindenbaum-Tarski algebra for a DFOL theory. Agreement with standard first-order semantics is established. Applications of DFOL to constructive mathematics and categorical foundations are given. A key feature is a local propositions-as-types principle.},
archivePrefix = {arXiv},
arxivId = {1605.01586},
author = {Palmgren, Erik},
doi = {10.1016/j.apal.2019.102715},
eprint = {1605.01586},
file = {:Users/liang-tingchen/Dropbox/References/Palmgren - 2019 - Categories with families and first-order logic with dependent sorts(2).pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Categorical logic,Dependent types,Intuitionistic first-order logic,Models of type theory},
month = {dec},
number = {12},
pages = {102715},
publisher = {Elsevier B.V.},
title = {{Categories with families and first-order logic with dependent sorts}},
url = {https://doi.org/10.1016/j.apal.2019.102715 https://linkinghub.elsevier.com/retrieve/pii/S0168007219300727},
volume = {170},
year = {2019}
}
@article{Goncharov2014,
abstract = {Strong bisimulation for labelled transition systems is one of the most fundamental equivalences in process algebra, and has been generalised to numerous classes of systems that exhibit richer transition behaviour. Nearly all of the ensuing notions are instances of the more general notion of coalgebraic bisimulation. Weak bisimulation, however, has so far been much less amenable to a coalgebraic treatment. Here we attempt to close this gap by giving a coalgebraic treatment of (parametrized) weak equivalences, including weak bisimulation. Our analysis requires that the functor defining the transition type of the system is based on a suitable order-enriched monad, which allows us to capture weak equivalences by least fixpoints of recursive equations. Our notion is in agreement with existing notions of weak bisimulations for labelled transition systems, probabilistic and weighted systems, and simple Segala systems.},
archivePrefix = {arXiv},
arxivId = {1404.1215},
author = {Goncharov, Sergey and Pattinson, Dirk},
eprint = {1404.1215},
file = {:Users/liang-tingchen/Dropbox/References/Goncharov, Pattinson - 2014 - Coalgebraic Weak Bisimulation from Recursive Equations over Monads.pdf:pdf},
journal = {ArXiv e-prints},
month = {apr},
number = {1},
pages = {1--25},
title = {{Coalgebraic Weak Bisimulation from Recursive Equations over Monads}},
url = {http://arxiv.org/abs/1404.1215v1},
year = {2014}
}
@article{Matthes2007,
author = {Kunc, Michal},
doi = {10.1051/ita:2003018},
file = {:Users/liang-tingchen/Dropbox/References/Kunc - 2003 - Equational description of pseudovarieties of homomorphisms.pdf:pdf},
issn = {0988-3754},
journal = {RAIRO - Theoretical Informatics and Applications},
keywords = {and phrases,implicit operation,languages,pseudoidentity,pseudovariety,syntactic homomorphism,variety of regular},
number = {3},
pages = {243--254},
title = {{Equational description of pseudovarieties of homomorphisms}},
volume = {37},
year = {2003}
}
@inproceedings{Barak2007,
abstract = {The contingency table is a work horse of official statistics, the format of reported data for the US Census, Bureau of Labor Statistics, and the Internal Revenue Service. In many settings such as these privacy is not only ethically mandated, but frequently legally as well. Consequently there is an extensive and diverse literature dedicated to the problems of statistical disclosure control in contingency table release. However, all current techniques for reporting contingency tables fall short on at leas one of privacy, accuracy, and consistency (among multiple released tables). We propose a solution that provides strong guarantees for all three desiderata simultaneously. Our approach can be viewed as a special case of a more general approach for producing synthetic data: Any privacy-preserving mechanism for contingency table release begins with raw data and produces a (possibly inconsistent) privacy-preserving set of marginals. From these tables alone-and hence without weakening privacy--we will find and output the "nearest" consistent set of marginals. Interestingly, this set is no farther than the tables of the raw data, and consequently the additional error introduced by the imposition of consistency is no more than the error introduced by the privacy mechanism itself. The privacy mechanism of [20] gives the strongest known privacy guarantees, with very little error. Combined with the techniques of the current paper, we therefore obtain excellent privacy, accuracy, and consistency among the tables. Moreover, our techniques are surprisingly efficient. Our techniques apply equally well to the logical cousin of the contingency table, the OLAP cube.},
address = {New York, New York, USA},
author = {Barak, Boaz and Chaudhuri, Kamalika and Dwork, Cynthia and Kale, Satyen and McSherry, Frank and Talwar, Kunal},
booktitle = {Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems - PODS '07},
doi = {10.1145/1265530.1265569},
file = {:Users/liang-tingchen/Dropbox/References/Barak et al. - 2007 - Privacy, accuracy, and consistency too.pdf:pdf},
isbn = {9781595936851},
keywords = {OLAP,contingency table,privacy},
pages = {273},
publisher = {ACM Press},
title = {{Privacy, accuracy, and consistency too}},
url = {http://doi.acm.org/10.1145/1265530.1265569 http://portal.acm.org/citation.cfm?doid=1265530.1265569},
year = {2007}
}
@article{Kelly2009,
author = {Kelly, Gregory Maxwell},
doi = {10.1017/S0004972700005724},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1982 - Two addenda to the author's ‘Transfinite constructions'.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
pages = {221--237},
title = {{Two addenda to the author's ‘Transfinite constructions'}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700005724},
volume = {26},
year = {1982}
}
@article{Hunter2010,
abstract = {There are relatively few proposals for inconsistency measures for propositional belief bases. However inconsistency measures are potentially as important as information measures for artificial intelligence, and more generally for computer science. In particular, they can be useful to define various operators for belief revision, belief merging, and negotiation. The measures that have been proposed so far can be split into two classes. The first class of measures takes into account the number of formulae required to produce an inconsistency: the more formulae required to produce an inconsistency, the less inconsistent the base. The second class takes into account the proportion of the language that is affected by the inconsistency: the more propositional variables affected, the more inconsistent the base. Both approaches are sensible, but there is no proposal for combining them. We address this need in this paper: our proposal takes into account both the number of variables affected by the inconsistency and the distribution of the inconsistency among the formulae of the base. Our idea is to use existing inconsistency measures in order to define a game in coalitional form, and then to use the Shapley value to obtain an inconsistency measure that indicates the responsibility/contribution of each formula to the overall inconsistency in the base. This allows us to provide a more reliable image of the belief base and of the inconsistency in it.},
author = {Hunter, Anthony and Konieczny, S{\'{e}}bastien},
doi = {10.1016/j.artint.2010.06.001},
file = {:Users/liang-tingchen/Dropbox/References/Hunter, Konieczny - 2010 - On the measure of conflicts Shapley Inconsistency Values.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Conflict resolution,Inconsistency management,Inconsistency measures,Inconsistency tolerance,Paraconsistency,Shapley values},
month = {sep},
number = {14},
pages = {1007--1026},
publisher = {Elsevier B.V.},
title = {{On the measure of conflicts: Shapley Inconsistency Values}},
url = {http://dx.doi.org/10.1016/j.artint.2010.06.001 http://linkinghub.elsevier.com/retrieve/pii/S000437021000086X},
volume = {174},
year = {2010}
}
@article{Moss2008,
author = {Moss, Lawrence S.},
doi = {10.1093/logcom/exn095},
file = {:Users/liang-tingchen/Dropbox/References/Moss - 2008 - A note on expressive coalgebraic logics for finitary Set functors.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
month = {dec},
number = {5},
pages = {1101--1111},
title = {{A note on expressive coalgebraic logics for finitary Set functors}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exn095},
volume = {20},
year = {2008}
}
@article{Hansoul2012,
author = {Hansoul, Georges and Teheux, Bruno},
doi = {10.1007/s11225-012-9396-9},
file = {:Users/liang-tingchen/Dropbox/References/Hansoul, Teheux - 2013 - Extending {\L}ukasiewicz Logics with a Modality Algebraic Approach to Relational Semantics.pdf:pdf},
isbn = {1122501293},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {03b45,03b50,canon-,ical model,kripke semantic,many-valued logic,mathematics subject classification,modal logic,mv-algebras,relational semantic},
month = {jun},
number = {3},
pages = {505--545},
title = {{Extending {\L}ukasiewicz Logics with a Modality: Algebraic Approach to Relational Semantics}},
url = {http://www.springerlink.com/index/10.1007/s11225-012-9396-9 http://link.springer.com/10.1007/s11225-012-9396-9},
volume = {101},
year = {2013}
}
@book{Awodey2010a,
author = {Awodey, Steve},
edition = {2},
isbn = {978-0-19-923718-0},
pages = {336},
publisher = {Oxford University Press},
series = {Oxford Logic Guides},
title = {{Category Theory}},
year = {2010}
}
@article{Reiterman1978,
author = {Reiterman, Jan},
doi = {10.1017/S0004972700008923},
file = {:Users/liang-tingchen/Dropbox/References/Reiterman - 1978 - Large algebraic theories with small algebras.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {dec},
number = {03},
pages = {371},
title = {{Large algebraic theories with small algebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700008923},
volume = {19},
year = {1978}
}
@article{Giunti2016,
abstract = {We present a type system based on session types that works on a conventional pi calculus. Types are equipped with a constructor that describes the two ends of a single communication channel, this being the only type available for describing the behaviour of channels. Session types, in turn, describe the behaviour of each individual channel end, as usual. A novel notion of typing context split allows for typing processes not typable with extant type systems. We show that our system guarantees that typed processes do not engage in races for linear resources. We assess the expressiveness of the type system by providing three distinct encodings – from the pi calculus with polarized variables, from the pi calculus with accept and request primitives, and from the linear pi calculus – into our system. For each language we present operational and typing correspondences, showing that our system effectively subsumes foregoing works on linear and session types. In the case of the linear pi calculus we also provide a completeness result.},
author = {GIUNTI, MARCO and VASCONCELOS, VASCO THUDICHUM},
doi = {10.1017/S0960129514000176},
file = {:Users/liang-tingchen/Dropbox/References/GIUNTI, VASCONCELOS - 2016 - Linearity, session types and the Pi calculus.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {02},
pages = {206--237},
title = {{Linearity, session types and the Pi calculus}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129514000176},
volume = {26},
year = {2016}
}
@article{Kennison1968,
author = {Kennison, John F.},
file = {:Users/liang-tingchen/Dropbox/References/Kennison - 1968 - Full reflective subcategories and generalized covering spaces.pdf:pdf},
journal = {Illinois Journal of Mathematics},
number = {3},
pages = {353--365},
title = {{Full reflective subcategories and generalized covering spaces}},
url = {http://projecteuclid.org/euclid.ijm/1256054104},
volume = {12},
year = {1968}
}
@book{Jech2003,
author = {Jech, Thomas},
doi = {10.1007/3-540-44761-X},
edition = {3rd rev.},
file = {:Users/liang-tingchen/Dropbox/References/Jech - 2003 - Set Theory.pdf:pdf},
isbn = {978-3-540-44085-7},
publisher = {Springer Berlin Heidelberg},
series = {Springer Monographs in Mathematics},
title = {{Set Theory}},
url = {http://www.springerlink.com/index/10.1007/3-540-44761-X},
year = {2003}
}
@article{Mardare2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.03843v1},
author = {Mio, Matteo},
doi = {10.2168/LMCS-8(4:18)2012},
editor = {Gr{\"{a}}del, Erich},
eprint = {arXiv:1506.03843v1},
file = {:Users/liang-tingchen/Dropbox/References/Mio - 2012 - Probabilistic modal $\mu$-calculus with independent product.pdf:pdf},
isbn = {2111201200},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,axiomatization,logics,markov processes,probabilistic and stochastic modal},
month = {nov},
number = {4},
pages = {1--39},
title = {{Probabilistic modal $\mu$-calculus with independent product}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1199},
volume = {8},
year = {2012}
}
@incollection{Kurz2012b,
abstract = {Gabbay and Pitts proved that lambda-terms up to alpha-equivalence constitute an initial algebra for a certain endofunctor on the category of nominal sets. We show that the terms of the infinitary lambda-calculus form the final coalgebra for the same functor. This allows us to give a corecursion principle for alpha-equivalence classes of finite and infinite terms. As an application, we give corecursive definitions of substitution and of infinite normal forms (B{\"{o}}hm, L{\'{e}}vy-Longo and Berarducci trees). {\textcopyright} 2012 IFIP International Federation for Information Processing.},
author = {Kurz, Alexander and Petrişan, Daniela and Severi, Paula and de Vries, Fer-Jan},
booktitle = {Coalgebraic Methods in Computer Science. CMCS 2012},
doi = {10.1007/978-3-642-32784-1_8},
editor = {Pattinson, Dirk and Schr{\"{o}}der, Lutz},
file = {:Users/liang-tingchen/Dropbox/References/Kurz et al. - 2012 - An Alpha-Corecursion Principle for the Infinitary Lambda Calculus.pdf:pdf},
isbn = {9783642327834},
issn = {03029743},
pages = {130--149},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{An Alpha-Corecursion Principle for the Infinitary Lambda Calculus}},
url = {http://link.springer.com/10.1007/978-3-642-32784-1{\_}8},
volume = {7399},
year = {2012}
}
@article{Harper1993,
author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon D.},
doi = {10.1145/138027.138060},
file = {:Users/liang-tingchen/Dropbox/References/Harper, Honsell, Plotkin - 1993 - A framework for defining logics.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
month = {jan},
number = {1},
pages = {143--184},
title = {{A framework for defining logics}},
url = {http://portal.acm.org/citation.cfm?doid=138027.138060},
volume = {40},
year = {1993}
}
@inproceedings{Blum2005,
abstract = {We consider a statistical database in which a trusted administrator introduces noise to the query responses with the goal of maintaining privacy of individual database entries. In such a database, a query consists of a pair (S, f) where S is a set of rows in the database and f is a function mapping database rows to {\{}0, 1{\}}. The true answer is $\Sigma$i$\epsilon$S f(di), and a noisy version is released as the response to the query. Results of Dinur, Dwork, and Nissim show that a strong form of privacy can be maintained using a surprisingly small amount of noise -- much less than the sampling error -- provided the total number of queries is sublinear in the number of database rows. We call this query and (slightly) noisy reply the SuLQ (Sub-Linear Queries) primitive. The assumption of sublinearity becomes reasonable as databases grow increasingly large.We extend this work in two ways. First, we modify the privacy analysis to real-valued functions f and arbitrary row types, as a consequence greatly improving the bounds on noise required for privacy. Second, we examine the computational power of the SuLQ primitive. We show that it is very powerful indeed, in that slightly noisy versions of the following computations can be carried out with very few invocations of the primitive: principal component analysis, k means clustering, the Perceptron Algorithm, the ID3 algorithm, and (apparently!) all algorithms that operate in the in the statistical query learning model [11].},
address = {New York, New York, USA},
author = {Blum, Avrim and Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi},
booktitle = {Proceedings of the twenty-fourth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems - PODS '05},
doi = {10.1145/1065167.1065184},
file = {:Users/liang-tingchen/Dropbox/References/Blum et al. - 2005 - Practical privacy.pdf:pdf},
isbn = {1595930620},
pages = {128},
publisher = {ACM Press},
title = {{Practical privacy}},
url = {http://doi.acm.org/10.1145/1065167.1065184 http://portal.acm.org/citation.cfm?doid=1065167.1065184},
volume = {2},
year = {2005}
}
@article{Davey2015,
abstract = {We clarify what it means for two full dualities based on the same algebra to be different. Our main theorem gives conditions on two different alter egos of a finite algebra under which, if one yields a full duality, then the other does too. We use this theorem to obtain a better understanding of several important examples from the theory of natural dualities. Throughout the paper, a fundamental role is played by the universal Horn theory of the dual classes.},
archivePrefix = {arXiv},
arxivId = {1511.03001},
author = {Davey, Brian A. and Pitkethly, Jane G. and Willard, Ross},
eprint = {1511.03001},
file = {:Users/liang-tingchen/Dropbox/References/Davey, Pitkethly, Willard - 2015 - New-from-old full dualities via axiomatisation.pdf:pdf},
pages = {1--25},
title = {{New-from-old full dualities via axiomatisation}},
url = {http://arxiv.org/abs/1511.03001},
year = {2015}
}
@incollection{Benton2002,
abstract = {A tension in language design has been between simple semantics on the one hand, and rich possibilities for side-effects, exception handling and so on on the other. The introduction of monads has made a large step towards reconciling these alternatives. First proposed by Moggi as a way of structuring semantic descriptions, they were adopted by Wadler to structure Haskell programs. Monads have been used to solve long-standing problems such as adding pointers and assignment, inter-language working, and exception handling to Haskell, without compromising its purely functional semantics. The course introduces monads, effects, and exemplifies their applications in programming (Haskell) and in compilation (MLj). The course presents typed metalanguages for monads and related categorical notions, and then describes how they can be further refined by introducing effects.},
author = {Benton, Nick and Hughes, John and Moggi, Eugenio},
booktitle = {Applied Semantics},
doi = {10.1007/3-540-45699-6_2},
editor = {Barthe, Gilles and Dybjer, Peter and Pinto, Lu{\'{i}}s and Saraiva, Jo{\~{a}}o},
file = {:Users/liang-tingchen/Dropbox/References/Benton, Hughes, Moggi - 2002 - Monads and Effects.pdf:pdf},
isbn = {978-3-540-44044-4},
pages = {923--952},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Monads and Effects}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/3-540-45699-6{\_}2},
volume = {2395},
year = {2002}
}
@incollection{Dubuco1968,
author = {Dubuc, Eduardo J.},
booktitle = {Reports of the Midwest Category Seminar II},
doi = {10.1007/BFb0077113},
editor = {{Mac Lane}, Saunders},
file = {:Users/liang-tingchen/Dropbox/References/Dubuc - 1968 - Adjoint triangles.pdf:pdf},
isbn = {978-3-540-04231-0},
pages = {69--91},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Adjoint triangles}},
url = {http://www.springerlink.com/index/10.1007/BFb0077113},
volume = {61},
year = {1968}
}
@article{Calude2017,
abstract = {**medianamente t{\'{e}}cnico** La efectividad de las herramientas de analisis de datos es usada para apoyar la filosofia que va en contra del m{\'{e}}todo cient{\'{i}}fico. Siendo as{\'{i}}, los auotres, prueban que las bases de datos muy grandes contienen correlaciones arbitrarias. Los autores argumentan que demasiada informaci{\'{o}}n tiende a comportarse como muy poca informaci{\'{o}}n, por lo cual el paper afirma que el m{\'{e}}todo cientifico puede ser enriquecido por la computadora pero no reemplazado por ella.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Calude, Cristian S. and Longo, Giuseppe},
doi = {10.1007/s10699-016-9489-4},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/Calude, Longo - 2017 - The Deluge of Spurious Correlations in Big Data.pdf:pdf},
isbn = {9788578110796},
issn = {1233-1821},
journal = {Foundations of Science},
keywords = {Algorithmic information theory,Big data,Correlation,Ergodic theory,Ramsey theory},
month = {sep},
number = {3},
pages = {595--612},
pmid = {25246403},
publisher = {Springer Netherlands},
title = {{The Deluge of Spurious Correlations in Big Data}},
url = {http://link.springer.com/10.1007/s10699-016-9489-4},
volume = {22},
year = {2017}
}
@article{Nogina2014,
abstract = {In 1933, G$\backslash$"odel considered two modal approaches to describing provability. One captured formal provability and resulted in the logic GL and Solovay's Completeness Theorem. The other was based on the modal logic S4 and led to Artemov's Logic of Proofs LP. In this paper, we study introduced by the author logic GLA, which is a fusion of GL and LP in the union of their languages. GLA is supplied with a Kripke-style semantics and the corresponding completeness theorem. Soundness and completeness of GLA with respect to the arithmetical provability semantics is established.},
archivePrefix = {arXiv},
arxivId = {1405.2559},
author = {Nogina, Elena},
eprint = {1405.2559},
file = {:Users/liang-tingchen/Dropbox/References/Nogina - 2014 - On Logic of Formal Provability and Explicit Proofs.pdf:pdf},
month = {may},
pages = {1--15},
title = {{On Logic of Formal Provability and Explicit Proofs}},
url = {http://arxiv.org/abs/1405.2559},
year = {2014}
}
@article{Seely2008,
author = {Seely, Robert A. G.},
doi = {10.1017/S0305004100061284},
file = {:Users/liang-tingchen/Dropbox/References/Seely - 2008 - Locally cartesian closed categories and type theory.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {oct},
number = {01},
pages = {33},
title = {{Locally cartesian closed categories and type theory}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004100061284},
volume = {95},
year = {2008}
}
@article{Leinster2013,
abstract = {Even a functor without an adjoint induces a monad, namely, its codensity monad; this is subject only to the existence of certain limits. We clarify the sense in which codensity monads act as substitutes for monads induced by adjunctions. We also expand on an undeservedly ignored theorem of Kennison and Gildenhuys: that the codensity monad of the inclusion of (finite sets) into (sets) is the ultrafilter monad. This result is analogous to the correspondence between measures and integrals. So, for example, we can speak of integration against an ultrafilter. Using this language, we show that the codensity monad of the inclusion of (finite-dimensional vector spaces) into (vector spaces) is double dualization. From this it follows that compact Hausdorff spaces have a linear analogue: linearly compact vector spaces. Extension of this analogy to other theories is left as an open question.},
archivePrefix = {arXiv},
arxivId = {1209.3606},
author = {Leinster, Tom},
eprint = {1209.3606},
file = {:Users/liang-tingchen/Dropbox/References/Leinster - 2013 - Codensity and the ultrafilter monad.pdf:pdf},
journal = {Theory and Applications of Categories},
month = {sep},
number = {13},
pages = {26},
title = {{Codensity and the ultrafilter monad}},
url = {http://arxiv.org/abs/1209.3606},
volume = {28},
year = {2013}
}
@article{Freyd1973,
author = {Freyd, Peter},
doi = {10.1016/0022-4049(73)90031-5},
file = {:Users/liang-tingchen/Dropbox/References/Freyd - 1973 - Concreteness.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jun},
number = {2},
pages = {171--191},
title = {{Concreteness}},
url = {http://dx.doi.org/10.1016/0022-4049(73)90031-5},
volume = {3},
year = {1973}
}
@article{Futamura1999,
abstract = {This paper reports the relationship between formal description of semantics (i.e., intepreter) of a programming language and an actual compiler. The paper also describes a method to automatically generate an actual compiler froma a formal description which is, in some sense, the partial evaluation of a computation process. The compiler-compiler inspired by this method differs from conventional ones in that the compiler-compiler based on our method can describe an evaluation procedure (interpreter) in defining the semantics of a programming language, while the conventional one describes a translation process.},
author = {Futamura, Yoshihiko},
doi = {10.1023/A:1010095604496},
file = {:Users/liang-tingchen/Dropbox/References/Futamura - 1999 - Partial evaluation of computation process--an approach to a compiler-compiler.pdf:pdf},
issn = {13883690},
journal = {Higher-Order and Symbolic Computation},
keywords = {compiler,futamura projections,interpreter,partial evaluation,program transformation},
number = {4},
pages = {381--391},
title = {{Partial evaluation of computation process--an approach to a compiler-compiler}},
url = {http://link.springer.com/article/10.1023/A:1010095604496},
volume = {12},
year = {1999}
}
@article{Lawvere1973,
author = {Lawvere, F. William},
doi = {10.1007/BF02924844},
file = {:Users/liang-tingchen/Dropbox/References/Lawvere - 1973 - Metric spaces, generalized logic, and closed categories.pdf:pdf},
issn = {0370-7377},
journal = {Rendiconti del Seminario Matematico e Fisico di Milano},
month = {dec},
number = {1},
pages = {135--166},
title = {{Metric spaces, generalized logic, and closed categories}},
url = {http://www.springerlink.com/index/10.1007/BF02924844},
volume = {43},
year = {1973}
}
@article{Richardson2006,
abstract = {We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation. A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1103.0398},
author = {Richardson, Matthew and Domingos, Pedro},
doi = {10.1007/s10994-006-5833-1},
eprint = {arXiv:1103.0398},
file = {:Users/liang-tingchen/Dropbox/References/Richardson, Domingos - 2006 - Markov logic networks.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {First-order logic,Graphical models,Inductive logic programming,Knowledge-based model construction,Log-linear models,Markov chain Monte Carlo,Markov networks,Markov random fields,Pseudo-likelihood,Satisfiability,Statistical relational learning},
month = {feb},
number = {1-2},
pages = {107--136},
pmid = {20958249},
title = {{Markov logic networks}},
url = {http://link.springer.com/10.1007/s10994-006-5833-1},
volume = {62},
year = {2006}
}
@article{Hodas1994,
author = {Hodas, J.S. and Miller, D.},
doi = {10.1006/inco.1994.1036},
file = {:Users/liang-tingchen/Dropbox/References/Hodas, Miller - 1994 - Logic Programming in a Fragment of Intuitionistic Linear Logic.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {may},
number = {2},
pages = {327--365},
title = {{Logic Programming in a Fragment of Intuitionistic Linear Logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540184710364},
volume = {110},
year = {1994}
}
@article{Adamek2005,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2005 - Introduction to coalgebra.pdf:pdf},
journal = {Theory and Applications of Categories},
number = {8},
pages = {157--199},
title = {{Introduction to coalgebra}},
url = {http://www.emis.ams.org/journals/TAC/volumes/14/8/14-08.pdf},
volume = {14},
year = {2005}
}
@article{Hashimoto2001,
abstract = {This paper develops a typed calculus for contexts i.e., lambda terms with "holes". In addition to ordinary lambda terms, the calculus contains labeled holes, hole abstraction and context application for manipulating first-class contexts. The primary operation for contexts is hole-filling, which captures free variables. This operation conflicts with substitution of the lambda calculus, and a straightforward mixture of the two results in an inconsistent system. We solve this problem by defining a type system that precisely specifies the variable-capturing nature of contexts and that keeps track of bound variable renaming. These mechanisms enable us to define a reduction system that properly integrates $\beta$-reduction and hole-filling. The resulting calculus is Church-Rosser and the type systehas the subject reduction property. We believe that the context calculus will serve as a basis for developing a programming language with advanced features that call for manipulation of open terms. {\textcopyright} 20 01 Elsevier Science B.V. All rights reserved.},
author = {Hashimoto, Masatomo and Ohori, Atsushi},
doi = {10.1016/S0304-3975(00)00174-2},
file = {:Users/liang-tingchen/Dropbox/References/Hashimoto, Ohori - 2001 - A typed context calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Alpha-renaming,Context,Lambda-calculus,Type system},
month = {sep},
number = {1-2},
pages = {249--272},
title = {{A typed context calculus}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397500001742},
volume = {266},
year = {2001}
}
@article{Plotkin2008,
abstract = {We present a logic for algebraic effects, based on the algebraic representation of computational effects by operations and equations. We begin with the a-calculus, a minimal calculus which separates values, effects, and computations and thereby canonises the order of evaluation. This is extended to obtain the logic, which is a classical first-order multi-sorted logic with higher-order value and computation types, as in Levy's call-by-push-value, a principle of induction over computations, a free algebra principle, and predicate fixed points. This logic embraces Moggi's computational lambda-calculus, and also, via definable modalities, Hennessy-Milner logic, and evaluation logic, though Hoare logic presents difficulties.},
author = {Plotkin, Gordon D. and Pretnar, Matija},
doi = {10.1109/LICS.2008.45},
file = {:Users/liang-tingchen/Dropbox/References/Plotkin, Pretnar - 2008 - A logic for algebraic effects.pdf:pdf},
isbn = {9780769531830},
issn = {10436871},
journal = {Proceedings - Symposium on Logic in Computer Science},
pages = {118--129},
title = {{A logic for algebraic effects}},
year = {2008}
}
@inproceedings{Bhat,
author = {Bhat, G. and Cleaveland, Rance},
booktitle = {Proceedings 11th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1996.561358},
file = {:Users/liang-tingchen/Dropbox/References/Bhat, Cleaveland - 1996 - Efficient model checking via the equational $\mu$-calculus.pdf:pdf},
isbn = {0-8186-7463-6},
pages = {304--312},
publisher = {IEEE Comput. Soc. Press},
title = {{Efficient model checking via the equational $\mu$-calculus}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=561358 http://ieeexplore.ieee.org/document/561358/},
year = {1996}
}
@incollection{Brady2010,
abstract = {We consider the problem of efficient representation of dependently typed data. In particular, we consider a language TT based on Dybjer's notion of inductive families [10] and reanalyse their general form with a view to optimising the storage associated with their use. We introduce an execution language, ExTT, which allows the commenting out of computationally irrelevant subterms and show how to use properties of elimination rules to elide constructor arguments and tags in ExTT. We further show how some types can be collapsed entirely at run-time. Several examples are given, including a representation of the simply typed $\alpha$-calculus for which our analysis yields an 80{\%} reduction in run - time storage requirements. {\textcopyright} Springer - Verlag 2004.},
author = {Brady, Edwin and McBride, Conor and McKinna, James},
booktitle = {Types for Proofs and Programs. TYPES 2003},
doi = {10.1007/978-3-540-24849-1_8},
editor = {Berardi, Stefano and Coppo, Mario and Damiani, Ferruccio},
file = {:Users/liang-tingchen/Dropbox/References/Brady, McBride, McKinna - 2004 - Inductive Families Need Not Store Their Indices.pdf:pdf},
pages = {115--129},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Inductive Families Need Not Store Their Indices}},
url = {http://link.springer.com/10.1007/978-3-540-24849-1{\_}8},
volume = {3085},
year = {2004}
}
@inproceedings{10.1145/3425898.3426953,
abstract = {Object-oriented programming, functional programming, and metaprogramming each offer a unique axis of abstraction that enables modular code. Macros, a common technique for metaprogramming, capture ASTs as quotes to let users manipulate them in the host language. However, macros are often at odds with other programming techniques since they can only process code written at the call-site and cannot analyze code behind abstraction boundaries such as variables and methods. Furthermore, the quotes generated for macro expansion exist only at compile-time and cannot be passed around in user code. Multi-stage programming treats quotes as runtime values to address this problem, but introduces the cost of running the compiler when splicing quotes. This forces developers to choose between low runtime overhead and modularity. What if we could have the best of both worlds? We introduce fluid quotes, a new technique that uses dependent types to let users pass quotes through abstraction boundaries in runtime code while splicing them ahead-of-time. This technique enables new metaprogramming capabilities by eliminating the traditional requirement of co-locating parameter expressions with call-sites. Fluid quotes capture not only source code but also associated runtime context to ensure correctness. In addition, they can be composed into larger expressions without any macro code. We demonstrate the capabilities of fluid quotes through two specific applications: optimizing data processing pipelines and making language integrated queries more flexible.},
address = {New York, NY, USA},
author = {Laddad, Shadaj and Sen, Koushik},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
doi = {10.1145/3425898.3426953},
file = {:Users/liang-tingchen/Dropbox/References/Laddad, Sen - 2020 - Fluid Quotes Metaprogramming across Abstraction Boundaries with Dependent Types.pdf:pdf},
isbn = {9781450381741},
keywords = {dependent types,functional programming,inlining,is granted without fee,metaprogramming,or hard copies of,part or all of,permission to make digital,personal or classroom use,provided that copies are,this work for},
pages = {98--110},
publisher = {Association for Computing Machinery},
series = {GPCE 2020},
title = {{Fluid Quotes: Metaprogramming across Abstraction Boundaries with Dependent Types}},
url = {https://doi.org/10.1145/3425898.3426953},
year = {2020}
}
@book{Bridges1994,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bridges, Douglas S.},
doi = {10.1007/978-1-4612-0863-1},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/Bridges - 1994 - Computability.pdf:pdf},
isbn = {978-1-4612-6925-0},
issn = {1098-6596},
pmid = {25246403},
publisher = {Springer New York},
series = {Graduate Texts in Mathematics},
title = {{Computability}},
url = {http://link.springer.com/10.1007/978-1-4612-0863-1},
volume = {146},
year = {1994}
}
@incollection{Pare1978,
author = {Par{\'{e}}, Robert and Schumacher, Dietmar},
booktitle = {Indexed Categories and Their Applications},
doi = {10.1007/BFb0061361},
file = {:Users/liang-tingchen/Dropbox/References/Par{\'{e}}, Schumacher - 1978 - Abstract families and the adjoint functor theorems.pdf:pdf},
isbn = {978-3-540-08914-8},
pages = {1--125},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Abstract families and the adjoint functor theorems}},
url = {http://dx.doi.org/10.1007/BFb0061361},
year = {1978}
}
@article{Science1987,
author = {Girard, Jean-Yves},
doi = {10.1016/0304-3975(87)90045-4},
file = {:Users/liang-tingchen/Dropbox/References/Girard - 1987 - Linear logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {1--101},
title = {{Linear logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397587900454},
volume = {50},
year = {1987}
}
@incollection{Backes2004,
abstract = {Enterprise privacy enforcement allows enterprises to internally enforce a privacy policy that the enterprise has decided to comply to. To facilitate the compliance with different privacy policies when several parts of an organization or different enterprises cooperate, it is crucial to have tools at hand that allow for a practical management of varying privacy requirements. We propose an algebra providing various types of operators for composing and restricting enterprise privacy policies like conjunction, disjunction, and scoping, together with its formal semantics. We base our work on a superset of the syntax and semantics of IBM's Enterprise Privacy Authorization Language (EPAL), which recently has been submitted to W3C for standardization. However, a detailed analysis of the expressiveness of EPAL reveals that, somewhat surprisingly, EPAL is not closed under conjunction and disjunction. To circumvent this problem, we identified the subset of well-founded privacy policies which enjoy the property that the result of our algebraic operations can be turned into a coherent privacy policy again. This enables existing privacy policy enforcement mechanisms to deal with our algebraic expressions. We further show that our algebra fits together with the existing notions of privacy policy refinement and sequential composition of privacy policies in a natural way.},
author = {Backes, Michael and D{\"{u}}rmuth, Markus and Steinwandt, Rainer},
booktitle = {Computer Security – ESORICS 2004. ESORICS 2004},
doi = {10.1007/978-3-540-30108-0_3},
editor = {Samarati, Pierangela and Ryan, Peter and Gollmann, Dieter and Molva, Refik},
file = {:Users/liang-tingchen/Dropbox/References/Backes, D{\"{u}}rmuth, Steinwandt - 2004 - An Algebra for Composing Enterprise Privacy Policies.pdf:pdf},
isbn = {3-540-22987-6},
issn = {0302-9743},
pages = {33--52},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{An Algebra for Composing Enterprise Privacy Policies}},
url = {http://link.springer.com/10.1007/978-3-540-30108-0{\_}3},
volume = {3193},
year = {2004}
}
@article{Capriotti2014,
abstract = {Applicative functors are a generalisation of monads. Both allow the expression of effectful computations into an otherwise pure language, like Haskell. Applicative functors are to be preferred to monads when the structure of a computation is fixed a priori. That makes it possible to perform certain kinds of static analysis on applicative values. We define a notion of free applicative functor, prove that it satisfies the appropriate laws, and that the construction is left adjoint to a suitable forgetful functor. We show how free applicative functors can be used to implement embedded DSLs which can be statically analysed.},
archivePrefix = {arXiv},
arxivId = {1403.0749},
author = {Capriotti, Paolo and Kaposi, Ambrus},
doi = {10.4204/EPTCS.153.2},
eprint = {1403.0749},
file = {:Users/liang-tingchen/Dropbox/References/Capriotti, Kaposi - 2014 - Free Applicative Functors.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {jun},
number = {section 10},
pages = {2--30},
title = {{Free Applicative Functors}},
url = {http://arxiv.org/abs/1403.0749{\%}0Ahttp://dx.doi.org/10.4204/EPTCS.153.2 http://arxiv.org/abs/1403.0749v3},
volume = {153},
year = {2014}
}
@book{Halpern2003,
author = {Halpern, Joseph Y.},
edition = {1},
pages = {497},
publisher = {The MIT Press},
series = {Computer Science and Intelligent Systems},
title = {{Reasoning about Uncertainty}},
year = {2003}
}
@incollection{Venema2014,
author = {Venema, Yde},
booktitle = {Johan van Benthem on Logic and Information Dynamics},
doi = {10.1007/978-3-319-06025-5_2},
editor = {Baltag, Alexandru and Smets, Sonja},
file = {:Users/liang-tingchen/Dropbox/References/Venema - 2014 - Expressiveness Modulo Bisimilarity A Coalgebraic Perspective.pdf:pdf},
isbn = {978-3-319-06024-8},
pages = {33--65},
publisher = {Springer International Publishing},
series = {Outstanding Contributions to Logic},
title = {{Expressiveness Modulo Bisimilarity: A Coalgebraic Perspective}},
url = {http://link.springer.com/10.1007/978-3-319-06025-5{\_}2},
volume = {5},
year = {2014}
}
@inproceedings{Kaiser2018a,
author = {Kaiser, Jan-oliver and Ziliani, Beta},
booktitle = {the 4th International Workshop on Coq for Programming Languages, CoqPL '18},
file = {:Users/liang-tingchen/Dropbox/References/Kaiser, Ziliani - 2018 - A “destruct” Tactic for Mtac2.pdf:pdf},
isbn = {0956796815000},
pages = {2--3},
title = {{A “destruct” Tactic for Mtac2}},
year = {2018}
}
@book{Gierz2003,
abstract = {Information content and programming semantics are just two of the applications of the mathematical concepts of order, continuity and domains. This authoritative and comprehensive account of the subject will be an essential handbook for all those working in the area. An extensive index and bibliography make this an ideal sourcebook for all those working in domain theory.},
address = {Cambridge},
author = {Gierz, Gerhard and Hofmann, Karl H. and Keimel, Klaus and Lawson, Jimmie D. and Mislove, Michael W. and Scott, Dana S.},
doi = {10.1017/CBO9780511542725},
file = {:Users/liang-tingchen/Dropbox/References/Gierz et al. - 2003 - Continuous Lattices and Domains.pdf:pdf},
isbn = {9780511542725},
month = {apr},
publisher = {Cambridge University Press},
title = {{Continuous Lattices and Domains}},
type = {Book},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511542725},
year = {2003}
}
@article{Kurz2013a,
abstract = {We characterise quasivarieties and varieties of ordered algebras categorically in terms of regularity, exactness and the existence of a suitable generator. The notions of regularity and exactness need to be understood in the sense of category theory enriched over posets. We also prove that finitary varieties of ordered algebras are cocompletions of their theories under sifted colimits (again, in the enriched sense).},
author = {Kurz, Alexander and Velebil, Jiř{\'{i}}},
doi = {10.1017/S096012951500050X},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Velebil - 2016 - Quasivarieties and varieties of ordered algebras regularity and exactness.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jan},
number = {1983},
pages = {1--42},
title = {{Quasivarieties and varieties of ordered algebras: regularity and exactness}},
url = {http://www.journals.cambridge.org/abstract{\_}S096012951500050X},
year = {2016}
}
@inproceedings{Accattoli2022,
address = {Dagstuhl, Germany},
annote = {Keywords: lambda calculus, call-by-need, operational semantics, sharing, cost models},
author = {Accattoli, Beniamino and Leberle, Maico},
booktitle = {30th EACSL Annual Conference on Computer Science Logic (CSL 2022)},
doi = {10.4230/LIPIcs.CSL.2022.4},
editor = {Manea, Florin and Simpson, Alex},
file = {:Users/liang-tingchen/Dropbox/References/Accattoli, Leberle - 2022 - Useful Open Call-By-Need.pdf:pdf},
isbn = {978-3-95977-218-1},
issn = {1868-8969},
pages = {4:1----4:21},
publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Useful Open Call-By-Need}},
url = {https://drops.dagstuhl.de/opus/volltexte/2022/15724},
volume = {216},
year = {2022}
}
@article{Hartonas1998,
author = {Hartonas, Chrysafis},
doi = {10.1016/S0304-3975(97)00233-8},
file = {:Users/liang-tingchen/Dropbox/References/Hartonas - 1998 - Duality for modal $\mu$-logics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jul},
number = {1-2},
pages = {193--222},
title = {{Duality for modal $\mu$-logics}},
type = {Journal article},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397597002338},
volume = {202},
year = {1998}
}
@article{Johnsson1998,
author = {JOHNSSON, THOMAS},
file = {:Users/liang-tingchen/Dropbox/References/JOHNSSON - 1998 - Efficient graph algorithms using lazy monolithic arrays.pdf:pdf},
journal = {Journal of Functional Programming},
month = {jul},
number = {4},
pages = {323--333},
title = {{Efficient graph algorithms using lazy monolithic arrays}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796898003062},
volume = {8},
year = {1998}
}
@inproceedings{Altenkirch1996,
abstract = {We give a semantical proof that every term of a combinator version of system F has a normal form. As the argument is entirely formalizable in an impredicative constructive type theory a reduction-free normalization algorithm can be extracted from this. The proof is presented as the construction of a model of the calculus inside a category of presheaves. Its definition is given entirely in terms of the internal language.},
author = {Altenkirch, Thorsten and Hofmann, Martin and Streicher, Thomas},
booktitle = {Proceedings 11th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1996.561309},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Hofmann, Streicher - 1996 - Reduction-free normalisation for a polymorphic system.pdf:pdf},
isbn = {0-8186-7463-6},
issn = {10436871},
pages = {98--106},
publisher = {IEEE Comput. Soc. Press},
title = {{Reduction-free normalisation for a polymorphic system}},
url = {http://ieeexplore.ieee.org/document/561309/},
year = {1996}
}
@incollection{Danielsson2011,
abstract = {A simple grammar scheme for expressions containing mixfix operators is presented. The scheme is parameterised by a precedence relation which is only restricted to be a directed acyclic graph; this makes it possible to build up precedence relations in a modular way. Efficient and simple implementations of parsers for languages with user-defined mixfix operators, based on the grammar scheme, are also discussed. In the future we plan to replace the support for mixfix operators in the language Agda with a grammar scheme and an implementation based on this work.},
author = {Danielsson, Nils Anders and Norell, Ulf},
booktitle = {Implementation and Application of Functional Languages. IFL 2008},
doi = {10.1007/978-3-642-24452-0_5},
editor = {Scholz, Sven-Bodo and Chitil, Olaf},
file = {:Users/liang-tingchen/Dropbox/References/Danielsson, Norell - 2011 - Parsing Mixfix Operators.pdf:pdf},
isbn = {9783642244513},
issn = {03029743},
pages = {80--99},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Parsing Mixfix Operators}},
url = {http://link.springer.com/10.1007/978-3-642-24452-0{\_}5},
volume = {5836},
year = {2011}
}
@article{Coquand2020,
abstract = {Normalization fails in type theory with an impredicative universe of propositions and a proof-irrelevant propositional equality. The counterexample to normalization is adapted from Girard's counterexample against normalization of System F equipped with a decider for type equality. It refutes Werner's normalization conjecture [LMCS 2008].},
author = {Coquand, Thierry and Abel, Andreas},
doi = {10.23638/LMCS-16(2:14)2020},
file = {:Users/liang-tingchen/Dropbox/References/Coquand, Abel - 2020 - Failure of Normalization in Impredicative Type Theory with Proof-Irrelevant Propositional Equality.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {Computer Science - Logic in Computer Science,Computer Science - Programming Languages,Mathematics - Logic},
number = {2},
pages = {14:1--14:5},
title = {{Failure of Normalization in Impredicative Type Theory with Proof-Irrelevant Propositional Equality}},
url = {https://lmcs.episciences.org/6606},
volume = {16},
year = {2020}
}
@inproceedings{Bonchi2014a,
author = {Bonchi, Filippo and Petrişan, Daniela and Pous, Damien and Rot, Jurriaan},
booktitle = {Proceedings of the Joint Meeting of the Twenty-Third Annual Conference on Computer Science Logic and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/2603088.2603149},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi et al. - 2014 - Coinduction up-to in a fibrational setting.pdf:pdf},
isbn = {9781450328869},
keywords = {bialgebras,bisimulation up-to,coinductive predicates,fibrations,gsos,nominal automata,similarity,up-to techniques},
title = {{Coinduction up-to in a fibrational setting}},
url = {http://dl.acm.org/citation.cfm?doid=2603088.2603149},
year = {2014}
}
@article{Selinger2001,
abstract = {We give a categorical semantics to the call-by-name and call-by-value versions of Parigot's $\lambda$µ-calculus with disjunction types.We introduce the class of control categories, which combine a cartesian-closed structure with a premonoidal structure in the sense of Power and Robinson.We prove, via a categorical structure theorem, that the categorical semantics is equivalent to a CPS semantics in the style of Hofmann and Streicher.We show that the call-by-name $\lambda$µ-calculus forms an internal language for control categories, and that the call-by-value $\lambda$µ-calculus forms an internal language for the dual co-control categories. As a corollary, we obtain a syntactic duality result: there exist syntactic translations between call-by-name and call-by-value which are mutually inverse and which preserve the operational semantics. This answers a question of Streicher and Reus.},
author = {Selinger, Peter},
doi = {10.1017/S096012950000311X},
file = {:Users/liang-tingchen/Dropbox/References/Selinger - 2001 - Control categories and duality on the categorical semantics of the lambda-mu calculus.pdf:pdf},
isbn = {1469-8072},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
month = {apr},
number = {2},
pages = {S096012950000311X},
publisher = {Swansea University Libraries},
title = {{Control categories and duality: on the categorical semantics of the lambda-mu calculus}},
url = {http://www.journals.cambridge.org/abstract{\_}S096012950000311X},
volume = {11},
year = {2001}
}
@article{Hur2012,
abstract = {There has been great progress in recent years on developing effective techniques for reasoning about program equivalence in ML-like languages - that is, languages that combine features like higher-order functions, recursive types, abstract types, and general mutable references. Two of the most prominent types of techniques to have emerged are bisimulations and Kripke logical relations (KLRs). While both approaches are powerful, their complementary advantages have led us and other researchers to wonder whether there is an essential tradeoff between them. Furthermore, both approaches seem to suffer from fundamental limitations if one is interested in scaling them to inter-language reasoning. In this paper, we propose relation transition systems (RTSs), which marry together some of the most appealing aspects of KLRs and bisimulations. In particular, RTSs show how bisimulations' support for reasoning about recursive features via coinduction can be synthesized with KLRs' support for reasoning about local state via state transition systems. Moreover, we have designed RTSs to avoid the limitations of KLRs and bisimulations that preclude their generalization to inter-language reasoning. Notably, unlike KLRs, RTSs are transitively composable. {\textcopyright} 2012 ACM.},
author = {Hur, Chung-Kil and Dreyer, Derek and Neis, Georg and Vafeiadis, Viktor},
doi = {10.1145/2103621.2103666},
file = {:Users/liang-tingchen/Dropbox/References/Hur et al. - 2012 - The marriage of bisimulations and Kripke logical relations.pdf:pdf},
isbn = {9781450310833},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {Abstract types,Bisimulations,Contextual equivalence,Global vs. local knowledge,Higher-order state,Kripke logical relations,Recursive types,Relation transition systems,Transitivity},
month = {jan},
number = {1},
pages = {59},
title = {{The marriage of bisimulations and Kripke logical relations}},
url = {http://dl.acm.org/citation.cfm?doid=2103621.2103666},
volume = {47},
year = {2012}
}
@article{Rosicky2002,
author = {Rosick{\'{y}}, Jiř{\'{i}} and Tholen, Walter},
doi = {10.1016/S0022-4049(02)00141-X},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}}, Tholen - 2002 - Lax factorization algebras.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-3},
pages = {355--382},
title = {{Lax factorization algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002240490200141X},
volume = {175},
year = {2002}
}
@article{DeMontjoye2013,
abstract = {We study fifteen months of human mobility data for one and a half million individuals and find that human mobility traces are highly unique. In fact, in a dataset where the location of an individual is specified hourly, and with a spatial resolution equal to that given by the carrier's antennas, four spatio-temporal points are enough to uniquely identify 95{\%} of the individuals. We coarsen the data spatially and temporally to find a formula for the uniqueness of human mobility traces given their resolution and the available outside information. This formula shows that the uniqueness of mobility traces decays approximately as the 1/10 power of their resolution. Hence, even coarse datasets provide little anonymity. These findings represent fundamental constraints to an individual's privacy and have important implications for the design of frameworks and institutions dedicated to protect the privacy of individuals.},
author = {de Montjoye, Yves-Alexandre and Hidalgo, C{\'{e}}sar A. and Verleysen, Michel and Blondel, Vincent D.},
doi = {10.1038/srep01376},
file = {:Users/liang-tingchen/Dropbox/References/de Montjoye et al. - 2013 - Unique in the Crowd The privacy bounds of human mobility.pdf:pdf},
isbn = {2045-2322 (Electronic)$\backslash$r2045-2322 (Linking)},
issn = {2045-2322},
journal = {Scientific Reports},
month = {dec},
number = {1},
pages = {1376},
pmid = {23524645},
title = {{Unique in the Crowd: The privacy bounds of human mobility}},
url = {http://www.nature.com/articles/srep01376},
volume = {3},
year = {2013}
}
@incollection{Troelstra1998,
author = {Troelstra, A.S.},
booktitle = {Studies in Logic and the Foundations of Mathematics},
doi = {10.1016/S0049-237X(98)80021-9},
file = {:Users/liang-tingchen/Dropbox/References/Troelstra - 1998 - Realizability.pdf:pdf},
isbn = {9780444898401},
issn = {0049237X},
number = {C},
pages = {407--473},
title = {{Realizability}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0049237X98800219},
volume = {137},
year = {1998}
}
@incollection{Bilkova2008,
author = {B{\'{i}}lkov{\'{a}}, Marta and Palmigiano, Alessandra and Venema, Yde},
booktitle = {Advances in Modal Logic},
editor = {Areces, Carlos and Goldblatt, Robert},
file = {:Users/liang-tingchen/Dropbox/References/B{\'{i}}lkov{\'{a}}, Palmigiano, Venema - 2008 - Proof systems for the coalgebraic cover modality.pdf:pdf},
isbn = {978-1904987680},
keywords = {coalgebra,coalgebraic modal-,completeness,derivation system,gentzen calculus,ity,modal logic},
number = {2},
pages = {1--21},
publisher = {College Publications},
title = {{Proof systems for the coalgebraic cover modality}},
volume = {7},
year = {2008}
}
@article{McLean1985,
author = {McLean, John},
doi = {10.1016/0020-0190(85)90065-1},
file = {:Users/liang-tingchen/Dropbox/References/McLean - 1985 - A comment on the ‘basic security theorem' of Bell and LaPadula.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
month = {feb},
number = {2},
pages = {67--70},
title = {{A comment on the ‘basic security theorem' of Bell and LaPadula}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0020019085900651},
volume = {20},
year = {1985}
}
@article{Botta2018,
abstract = {Abstract. We apply a computational framework for specifying and solving sequential decision problems to study the impact of three kinds of uncertainties on optimal emission policies in a stylized sequential emission problem.We find that uncertainties about the implementability of decisions on emission reductions (or increases) have a greater impact on optimal policies than uncertainties about the availability of effective emission reduction technologies and uncertainties about the implications of trespassing critical cumulated emission thresholds. The results show that uncertainties about the implementability of decisions on emission reductions (or increases) call for more precautionary policies. In other words, delaying emission reductions to the point in time when effective technologies will become available is suboptimal when these uncertainties are accounted for rigorously. By contrast, uncertainties about the implications of exceeding critical cumulated emission thresholds tend to make early emission reductions less rewarding.},
author = {Botta, Nicola and Jansson, Patrik and Ionescu, Cezar},
doi = {10.5194/esd-9-525-2018},
file = {:Users/liang-tingchen/Dropbox/References/Botta, Jansson, Ionescu - 2018 - The impact of uncertainty on optimal emission policies.pdf:pdf},
issn = {2190-4987},
journal = {Earth System Dynamics},
month = {may},
number = {2},
pages = {525--542},
title = {{The impact of uncertainty on optimal emission policies}},
url = {https://www.earth-syst-dynam.net/9/525/2018/},
volume = {9},
year = {2018}
}
@article{Cockx2020,
abstract = {In a dependently typed language, we can guarantee correctness of our programmes by providing formal proofs. To check them, the typechecker elaborates these programs and proofs into a low-level core language. However, this core language is by nature hard to understand by mere humans, so how can we know we proved the right thing? This question occurs in particular for dependent copattern matching, a powerful language construct for writing programmes and proofs by dependent case analysis and mixed induction/coinduction. A definition by copattern matching consists of a list of clauses that are elaborated to a case tree , which can be further translated to primitive eliminators . In previous work this second step has received a lot of attention, but the first step has been mostly ignored so far. We present an algorithm elaborating definitions by dependent copattern matching to a core language with inductive data types, coinductive record types, an identity type, and constants defined by well-typed case trees. To ensure correctness, we prove that elaboration preserves the first-match semantics of the user clauses. Based on this theoretical work, we reimplement the algorithm used by Agda to check left-hand sides of definitions by pattern matching. The new implementation is at the same time more general and less complex, and fixes a number of bugs and usability issues with the old version. Thus, we take another step towards the formally verified implementation of a practical dependently typed language.},
author = {Cockx, Jesper and Abel, Andreas M.},
doi = {10.1017/S0956796819000182},
file = {:Users/liang-tingchen/Dropbox/References/Cockx, Abel - 2020 - Elaborating dependent (co)pattern matching No pattern left behind.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
pages = {e2},
title = {{Elaborating dependent (co)pattern matching: No pattern left behind}},
url = {https://www.cambridge.org/core/product/identifier/S0956796819000182/type/journal{\_}article},
volume = {30},
year = {2020}
}
@article{Goldblatt2006a,
author = {Goldblatt, Robert},
doi = {doi:%20DOI:%2010.1016/j.apal.2005.06.006},
file = {:Users/liang-tingchen/Dropbox/References/Goldblatt - 2006 - Final coalgebras and the Hennessy-Milner property.pdf:pdf},
issn = {0168-0072},
journal = {Annals of Pure and Applied Logic},
month = {mar},
number = {1-3},
pages = {77--93},
title = {{Final coalgebras and the Hennessy-Milner property}},
type = {Journal article},
volume = {138},
year = {2006}
}
@inproceedings{Pirog2014,
abstract = {Resumptions appear in many forms as a convenient abstraction, such as in semantics of concurrency and as a programming pattern. In this paper we introduce generalised resumptions in a category-theoretic, coalgebraic context and show their basic properties: they form a monad, they come equipped with a corecursion scheme in the sense of Ad{\'{a}}mek et al.'s notion of completely iterative monads (cims), and they enjoy a certain universal property, which specialises to the coproduct with a free cim in the category of cims.},
author = {Pir{\'{o}}g, Maciej and Gibbons, Jeremy},
booktitle = {Proceedings of the 30th Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1016/j.entcs.2014.10.015},
file = {:Users/liang-tingchen/Dropbox/References/Pir{\'{o}}g, Gibbons - 2014 - The coinductive resumption monad.pdf:pdf},
issn = {15710661},
keywords = {coalgebra,completely iterative monads,resumptions},
pages = {273--288},
publisher = {Elsevier B.V.},
title = {{The coinductive resumption monad}},
url = {http://dx.doi.org/10.1016/j.entcs.2014.10.015},
volume = {308},
year = {2014}
}
@article{Nanz2006,
abstract = {We present a framework for specification and security analysis of communication protocols for mobile wireless networks. This setting introduces new challenges which are not being addressed by classical protocol analysis techniques. The main complication stems from the fact that the actions of intermediate nodes and their connectivity can no longer be abstracted into a single unstructured adversarial environment as they form an inherent part of the system's security. In order to model this scenario faithfully, we present a broadcast calculus which makes a clear distinction between the protocol processes and the network's connectivity graph, which may change independently from protocol actions. We identify a property characterising an important aspect of security in this setting and express it using behavioural equivalences of the calculus. We complement this approach with a control flow analysis which enables us to automatically check this property on a given network and attacker specification. ?? 2006 Elsevier B.V. All rights reserved.},
author = {Nanz, Sebastian and Hankin, Chris},
doi = {10.1016/j.tcs.2006.08.036},
file = {:Users/liang-tingchen/Dropbox/References/Nanz, Hankin - 2006 - A framework for security analysis of mobile wireless networks.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Control flow analysis,Mobile ad hoc networks,Process calculi,Security analysis},
month = {nov},
number = {1-2},
pages = {203--227},
title = {{A framework for security analysis of mobile wireless networks}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506005792},
volume = {367},
year = {2006}
}
@inproceedings{Nuyts2018,
address = {New York, NY, USA},
author = {Nuyts, Andreas and Devriese, Dominique},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3209108.3209119},
file = {:Users/liang-tingchen/Dropbox/References/Nuyts, Devriese - 2018 - Degrees of Relatedness.pdf:pdf},
isbn = {9781450355834},
keywords = {2018,Parametricity,a,acm reference format,algebra in type theory,andreas nuyts and dominique,cubical type theory,degrees of relatedness,devriese,erasure,intersections,irrelevance,parametricity,presheaf semantics,unions},
month = {jul},
pages = {779--788},
publisher = {ACM},
title = {{Degrees of Relatedness}},
url = {http://dl.acm.org/citation.cfm?doid=3209108.3209119 https://dl.acm.org/doi/10.1145/3209108.3209119},
year = {2018}
}
@article{Odintsov2012,
author = {Odintsov, Sergei P. and Latkin, E. I.},
doi = {10.1007/s11225-012-9380-4},
file = {:Users/liang-tingchen/Dropbox/References/Odintsov, Latkin - 2012 - BK-lattices. Algebraic Semantics for Belnapian Modal Logics.pdf:pdf},
isbn = {1122501293},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {belnapian modal logic,bk-lattice,lattice of subvarieties,twist-structure},
month = {feb},
number = {1-2},
pages = {319--338},
title = {{BK-lattices. Algebraic Semantics for Belnapian Modal Logics}},
url = {http://www.springerlink.com/index/10.1007/s11225-012-9380-4},
volume = {100},
year = {2012}
}
@article{Erwig1998,
abstract = {The effective use of visual languages requires a precise understanding of their meaning. Moreover, it is impossible to prove properties of visual languages like soundness of transformation rules or correctness results without having a formal language definition. Although this sounds obvious, it is surprising that only little work has been done about the semantics of visual languages, and even worse, there is no general framework available for the semantics specification of different visual languages. We present such a framework that is based on a rather general notion of abstract visual syntax. This framework allows a logical as well as a denotational approach to visual semantics, and it facilitates the formal reasoning about visual languages and their properties. We illustrate the concepts of the proposed approach by defining abstract syntax and semantics for the visual languages VEX, Show and Tell and Euler circles. We demonstrate the semantics in action by proving a rule for visual reasoning with Euler circles and by showing the correctness of a Show and Tell program. {\textcopyright} 1998 Academic Press.},
author = {ERWIG, MARTIN},
doi = {10.1006/jvlc.1998.0098},
file = {:Users/liang-tingchen/Dropbox/References/ERWIG - 1998 - Abstract Syntax and Semantics of Visual Languages.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages {\&} Computing},
month = {oct},
number = {5},
pages = {461--483},
title = {{Abstract Syntax and Semantics of Visual Languages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1045926X98900982},
volume = {9},
year = {1998}
}
@article{Lack2009,
abstract = {Categorical universal algebra can be developed either using Lawvere theories (single-sorted finite product theories) or using monads, and the category of Lawvere theories is equivalent to the category of finitary monads on Set. We show how this equivalence, and the basic results of universal algebra, can be generalized in three ways: replacing Set by another category, working in an enriched setting, and by working with another class of limits than finite products. An important special case involves working with sifted-colimit-preserving monads rather than filtered-colimit-preserving ones.},
archivePrefix = {arXiv},
arxivId = {0810.2578},
author = {Lack, Stephen and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1007/s10485-009-9215-2},
eprint = {0810.2578},
file = {:Users/liang-tingchen/Dropbox/References/Lack, Rosick{\'{y}} - 2009 - Notions of Lawvere Theory.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
month = {nov},
number = {1},
pages = {363--391},
title = {{Notions of Lawvere Theory}},
url = {http://arxiv.org/abs/0810.2578 http://www.springerlink.com/index/10.1007/s10485-009-9215-2},
volume = {19},
year = {2009}
}
@inproceedings{Ghani2016,
abstract = {We introduce open games as a compositional foundation of economic game theory. A compositional approach potentially allows methods of game theory and theoretical computer science to be applied to large-scale economic models for which standard economic tools are not practical. An open game represents a game played relative to an arbitrary environment and to this end we introduce the concept of coutility, which is the utility generated by an open game and returned to its environment. Open games are the morphisms of a symmetric monoidal category and can therefore be composed by categorical composition into sequential move games and by monoidal products into simultaneous move games. Open games can be represented by string diagrams which provide an intuitive but formal visualisation of the information flows. We show that a variety of games can be faithfully represented as open games in the sense of having the same Nash equilibria and off-equilibrium best responses.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1603.04641},
author = {Ghani, Neil and Hedges, Jules and Winschel, Viktor and Zahn, Philipp},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '18},
doi = {10.1145/3209108.3209165},
eprint = {1603.04641},
file = {:Users/liang-tingchen/Dropbox/References/Ghani et al. - 2018 - Compositional Game Theory.pdf:pdf},
isbn = {9781450355834},
pages = {472--481},
publisher = {ACM Press},
title = {{Compositional Game Theory}},
url = {http://arxiv.org/abs/1603.04641 http://dl.acm.org/citation.cfm?doid=3209108.3209165},
year = {2018}
}
@incollection{Pavlovic2012a,
abstract = {Formal Concept Analysis (FCA) begins froma context, given as a binary relation between some objects and some attributes, and derives a lattice of concepts, where each concept is given as a set of objects and a set of attributes, such that the first set consists of all objects that satisfy all attributes in the second, and vice versa. Many applications, though, provide contexts with quantitative information, telling not justwhether an object satisfies an attribute, but also quantifying this satisfaction. Contexts in this form arise as rating matrices in recommender systems, as occurrence matrices in text analysis, as pixel intensitymatrices in digital image processing, etc. Such applications have attracted a lot of attention, and several numeric extensions of FCA have been proposed. We propose the framework of proximity sets (proxets), which subsume partially ordered sets (posets) as well as metric spaces. One feature of this approach is that it extracts from quantified contexts quantified concepts, and thus allows full use of the available information. Another feature is that the categorical approach allows analyzing any universal properties that the classical FCA and the new versions may have, and thus provides structural guidance for aligning and combining the approaches.},
archivePrefix = {arXiv},
arxivId = {arXiv:1204.5802v1},
author = {Pavlovi{\'{c}}, Dusko},
booktitle = {Proceedings of the 10th International Conference on Formal Concept Analysis},
doi = {10.1007/978-3-642-29892-9_24},
editor = {Domenach, Florent and Ignatov, Dmitry I. and Poelmans, Jonas},
eprint = {arXiv:1204.5802v1},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} - 2012 - Quantitative Concept Analysis.pdf:pdf},
isbn = {9783642298912},
issn = {03029743},
keywords = {concept analysis,enriched category,semantic completion,universal property},
pages = {260--277},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Quantitative Concept Analysis}},
url = {http://link.springer.com/10.1007/978-3-642-29892-9{\_}24},
year = {2012}
}
@inproceedings{Fiore2002,
abstract = {This paper studies normalisation by evaluation for typed lambda calculus from a categorical and algebraic viewpoint. The first part of the paper analyses the lambda definability result of Jung and Tiuryn via Kripke logical relations and shows how it can be adapted to unify definability and normalisation, yielding an extensional normalisation result. In the second part of the paper the analysis is refined further by considering intensional Kripke relations (in the form of glueing) and shown to provide a function for normalising terms, casting normalisation by evaluation in the context of categorical glueing. The technical development includes an algebraic treatment of the syntax and semantics of the typed lambda calculus that allows the definition of the normalisation function to be given within a simply typed metatheory.},
address = {New York, New York, USA},
author = {Fiore, Marcelo},
booktitle = {Proceedings of the 4th ACM SIGPLAN international conference on Principles and practice of declarative programming - PPDP '02},
doi = {10.1145/571157.571161},
file = {:Users/liang-tingchen/Dropbox/References/Fiore - 2002 - Semantic analysis of normalisation by evaluation for typed lambda calculus.pdf:pdf},
isbn = {1581135289},
keywords = {Categorical glueing,Initial algebra semantics,Lambda definability,Logical relations,Normalisation by evaluation,Typed abstract syntax with variable binding,Typed lambda calculus},
pages = {26--37},
publisher = {ACM Press},
title = {{Semantic analysis of normalisation by evaluation for typed lambda calculus}},
url = {http://portal.acm.org/citation.cfm?doid=571157.571161},
year = {2002}
}
@article{Karazeris2011a,
abstract = {We give conditions on a finitary endofunctor of a finitely accessible category to admit a final coalgebra. Our conditions always apply to the case of a finitary endofunctor of a locally finitely presentable (l.f.p.) category and they bring an explicit construction of the final coalgebra in this case. On the other hand, there are interesting examples of final coalgebras beyond the realm of l.f.p. categories to which our results apply. We rely on ideas developed by Tom Leinster for the study of self-similar objects in topology.},
archivePrefix = {arXiv},
arxivId = {0905.4883},
author = {Karazeris, Panagis and Matzaris, Apostolos and Velebil, Jiř{\'{i}}},
doi = {10.1017/S0960129511000351},
eprint = {0905.4883},
file = {:Users/liang-tingchen/Dropbox/References/Karazeris, Matzaris, Velebil - 2011 - Final coalgebras in accessible categories.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jul},
number = {05},
pages = {1067--1108},
title = {{Final coalgebras in accessible categories}},
url = {http://arxiv.org/abs/0905.4883 http://www.journals.cambridge.org/abstract{\_}S0960129511000351},
volume = {21},
year = {2011}
}
@article{Abbott2005a,
abstract = {This paper and our conference paper (Abbott, Altenkirch, Ghani, and McBride, 2003b) explain and analyse the notion of the derivative of a data structure as the type of its one-hole contexts based on the central observation made by McBride (2001). To make the idea precise we need a generic notion of a data type, which leads to the notion of a container, introduced in (Abbott, Altenkirch, and Ghani, 2003a) and investigated extensively in (Abbott, 2003). Using containers we can provide a notion of linear map which is the concept missing from McBride's first analysis. We verify the usual laws of differential calculus including the chain rule and establish laws for initial algebras and terminal coalgebras.},
author = {Abbott, Michael and Altenkirch, Thorsten and McBride, Conor and Ghani, Neil},
file = {:Users/liang-tingchen/Dropbox/References/Abbott et al. - 2005 - ∂ for Data Differentiating Data Structures.pdf:pdf},
isbn = {0169-2968},
issn = {0169-2968},
journal = {Fundamenta Informaticae},
number = {1-2},
pages = {1--28},
title = {{∂ for Data: Differentiating Data Structures}},
url = {http://iospress.metapress.com/index/JJ599WW44R90MAA0.pdf},
volume = {65},
year = {2005}
}
@inproceedings{Fredrikson2014,
abstract = {Describes how inverse model attacks can use a model with a high epsilon value for epislon-differential privacy in order to find out the value of one of the predictor variables. This is much more possible for large value of epsilons ({\textgreater}5) than smallvalues ({\textless}1).},
author = {Fredrikson, Matt and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
booktitle = {Proceedings of the 23rd {\{}USENIX{\}} Security Symposium},
file = {:Users/liang-tingchen/Dropbox/References/Fredrikson et al. - 2014 - Privacy in Pharmacogenetics An End-to-End Case Study of Personalized Warfarin Dosing.pdf:pdf},
isbn = {9781931971157},
pages = {17--32},
pmid = {27077138},
publisher = {{\{}USENIX{\}} Association},
title = {{Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing}},
url = {http://www.biostat.wisc.edu/{~}page/WarfarinUsenix2014.pdf},
year = {2014}
}
@article{Hackett2018,
author = {Hackett, Jennifer and Hutton, Graham},
doi = {10.1145/3236763},
file = {:Users/liang-tingchen/Dropbox/References/Hackett, Hutton - 2018 - Parametric polymorphism and operational improvement.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--24},
title = {{Parametric polymorphism and operational improvement}},
url = {https://dl.acm.org/doi/10.1145/3236763},
volume = {2},
year = {2018}
}
@article{Olkhovikov2012,
abstract = {Notions of k-asimulation and asimulation are introduced as asymmetric counterparts to k-bisimulation and bisimulation, respectively. It is proved that a first-order formula is equivalent to a standard translation of an intuitionistic propositional formula iff it is invariant with respect to k-asimulations for some k, and then that a first-order formula is equivalent to a standard translation of an intuitionistic propositional formula iff it is invariant with respect to asimulations. Finally, it is proved that a first-order formula is intuitionistically equivalent to a standard translation of an intuitionistic propositional formula iff it is invariant with respect to asimulations between intuitionistic models.},
archivePrefix = {arXiv},
arxivId = {1207.4414},
author = {Olkhovikov, Grigory K},
eprint = {1207.4414},
file = {:Users/liang-tingchen/Dropbox/References/Olkhovikov - 2012 - Model-theoretic characterization of intuitionistic propositional formulas.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {a modal,a standard translation of,bisimu-,formula is equivalent to,intuitionistic logic,lation,model theory,propositional logic,s theorem,s well-known modal characterization,states that a first-order,theorem,theorem 3 below,van benthem},
month = {jul},
pages = {16},
title = {{Model-theoretic characterization of intuitionistic propositional formulas}},
url = {http://arxiv.org/abs/1207.4414},
year = {2012}
}
@incollection{Bizjak2016,
author = {Bizjak, Ale{\v{s}} and Grathwohl, Hans Bugge and Clouston, Ranald and M{\o}gelberg, Rasmus Ejlers and Birkedal, Lars},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2016},
doi = {10.1007/978-3-662-49630-5_2},
editor = {Jacobs, Bart and L{\"{o}}ding, Christof},
file = {:Users/liang-tingchen/Dropbox/References/Bizjak et al. - 2016 - Guarded Dependent Type Theory with Coinductive Types.pdf:pdf},
isbn = {9783662496305},
pages = {20--35},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Guarded Dependent Type Theory with Coinductive Types}},
url = {http://link.springer.com/10.1007/978-3-662-49630-5{\_}2},
volume = {9634},
year = {2016}
}
@article{Josang2002,
abstract = {The consensus operator provides a method for combining possibly conflicting beliefs within the Dempster-Shafer belief theory, and represents an alternative to the traditional Dempster's rule. This paper describes how the consensus operator can be applied to dogmatic conflicting opinions, i.e., when the degree of conflict is very high. It overcomes shortcomings of Dempster's rule and other operators that have been proposed for combining possibly conflicting beliefs. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Josang, Audun},
doi = {10.1016/S0004-3702(02)00259-X},
file = {:Users/liang-tingchen/Dropbox/References/Josang - 2002 - The consensus operator for combining beliefs.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Belief,Conflict,Consensus operator,Dempster's rule,Subjective logic},
number = {1-2},
pages = {157--170},
title = {{The consensus operator for combining beliefs}},
volume = {141},
year = {2002}
}
@incollection{Orchard2013,
author = {Orchard, Dominic and Mycroft, Alan},
booktitle = {Implementation and Application of Functional Languages. IFL 2012},
doi = {10.1007/978-3-642-41582-1},
editor = {Hinze, Ralf},
file = {:Users/liang-tingchen/Dropbox/References/Orchard, Mycroft - 2013 - A Notation for Comonads.pdf:pdf},
isbn = {978-3-642-41581-4},
pages = {1--17},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Notation for Comonads}},
url = {https://doi.org/10.1007/978-3-642-41582-1 http://link.springer.com/10.1007/978-3-642-41582-1},
volume = {8241},
year = {2013}
}
@article{Kelly1980,
abstract = {Many problems lead to the consideration of “algebras”, given by an object A of a category A together with “actions” TkA → A on A of one or more endofunctors of A, subjected to equational axioms. Such problems include those of free monads and free monoids, of cocompleteness in categories of monads and of monoids, of orthogonal subcategories (= generalized sheaf-categories), of categories of continuous functors, and so on; apart from problems involving the algebras for their own sake. Desirable properties of the category of algebras - existence of free ones, cocompleteness, existence of adjoints to algebraic functors - all follow if this category can be proved reflective in some well-behaved category: for which we choose a certain comma-category T/A We show that the reflexion exists and is given as the colimit of a simple transfinite sequence, if A is cocomplete and the Tk preserve either colimits or unions of suitably-long chains of subobjects. The article draws heavily on the work of earlier authors, unifies and simplifies this, and extends it to new problems. Moreover the reflectivity in T/A is stronger than any earlier result, and will be applied in forthcoming articles, in an enriched version, to the study of categories with structure.},
author = {Kelly, Gregory Maxwell},
doi = {10.1017/S0004972700006353},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1980 - A unified treatment of transfinite constructions for free algebras, free monoids, colimits, associated sheaves, and so on.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
number = {01},
pages = {1},
title = {{A unified treatment of transfinite constructions for free algebras, free monoids, colimits, associated sheaves, and so on}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700006353},
volume = {22},
year = {1980}
}
@article{Ghani2015a,
author = {Ghani, Neil and {Nordvall Forsberg}, Fredrik and Malatesta, Lorenzo},
doi = {10.2168/LMCS-11(1:13)2015},
editor = {Milius, Stefan},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Nordvall Forsberg, Malatesta - 2015 - Positive Inductive-Recursive Definitions.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,data types,induction-recursion,initial-algebra,martin-l,of type theory},
month = {mar},
number = {1},
pages = {1--21},
title = {{Positive Inductive-Recursive Definitions}},
url = {https://lmcs.episciences.org/1154},
volume = {11},
year = {2015}
}
@incollection{Lindley2016a,
author = {{Peyton Jones}, Simon and Weirich, Stephanie and Eisenberg, Richard A. and Vytiniotis, Dimitrios},
booktitle = {A List of Successes That Can Change the World},
doi = {10.1007/978-3-319-30936-1_16},
editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
file = {:Users/liang-tingchen/Dropbox/References/Peyton Jones et al. - 2016 - A Reflection on Types.pdf:pdf},
isbn = {978-3-319-30935-4},
issn = {16113349},
pages = {292--317},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Reflection on Types}},
url = {http://link.springer.com/10.1007/978-3-319-30936-1 http://link.springer.com/10.1007/978-3-319-30936-1{\_}16},
volume = {9600},
year = {2016}
}
@article{Fiore2006,
abstract = {We study three operational models of name-passing process calculi: coalgebras on (pre)sheaves, indexed labelled transition systems, and history dependent automata. The coalgebraic model is considered both for presheaves over the category of finite sets and injections, and for its subcategory of atomic sheaves known as the Schanuel topos. Each coalgebra induces an indexed labelled transition system. Such transition systems are characterised, relating the coalgebraic approach to an existing model of name-passing. Further, we consider internal labelled transition systems within the sheaf topos, and axiomatise a class that is in precise correspondence with the coalgebraic and the indexed labelled transition system models. By establishing and exploiting the equivalence of the Schanuel topos with a category of named-sets, these internal labelled transition systems are also related to the theory of history dependent automata. ?? 2006 Elsevier Inc. All rights reserved.},
annote = {NULL},
author = {Fiore, Marcelo P. and Staton, Sam},
doi = {10.1016/j.ic.2005.08.004},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Staton - 2006 - Comparing operational models of name-passing process calculi.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {4},
pages = {524--560},
title = {{Comparing operational models of name-passing process calculi}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540106000058},
volume = {204},
year = {2006}
}
@inproceedings{Licata2017a,
abstract = {We define a general framework that abstracts the common features of many intuitionistic sub-structural and modal logics / type theories. The framework is a sequent calculus / normal-form type theory parametrized by a mode theory, which is used to describe the structure of contexts and the structural properties they obey. In this sequent calculus, the context itself obeys standard structural properties, while a term, drawn from the mode theory, constrains how the context can be used. Product types, implications, and modalities are defined as instances of two general con-nectives, one positive and one negative, that manipulate these terms. Specific mode theories can express a range of substructural and modal connectives, including non-associative, ordered, linear, affine, relevant, and cartesian products and implications; monoidal and non-monoidal functors, (co)monads and adjunctions; n-linear variables; and bunched implications. We prove cut (and identity) admissibility independently of the mode theory, obtaining it for many different logics at once. Further, we give a general equational theory on derivations / terms that, in addition to the usual $\beta$$\eta$-rules, characterizes when two derivations differ only by the placement of structural rules. Additionally, we give an equivalent semantic presentation of these ideas, in which a mode theory corresponds to a 2-dimensional cartesian multicategory, the framework corresponds to another such multicategory with a functor to the mode theory, and the logical connectives make this into a bifibration. Finally, we show how the framework can be used both to encode existing existing logics / type theories and to design new ones.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (A Fibrational Framework for Substructural and Modal Logics - Licata, Daniel R; Shulman, Michael; Riley, Mitchell)

Keywords: type theory, modal logic, substructural logic, homotopy type theory},
author = {Licata, Daniel R and Shulman, Michael and Riley, Mitchell},
booktitle = {2nd International Conference on Formal Structures for Computation and Deduction (FSCD 2017)},
doi = {10.4230/LIPIcs.FSCD.2017.25},
editor = {Miller, Dale},
file = {:Users/liang-tingchen/Dropbox/References//Licata, Shulman, Riley - 2017 - A Fibrational Framework for Substructural and Modal Logics.pdf:pdf},
isbn = {978-3-95977-047-7},
issn = {1868-8969},
keywords = {1998 ACM,Classification F41,Logic,Mathematical,Subject},
number = {25},
pages = {25:1----25:22},
pmid = {2309541},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{A Fibrational Framework for Substructural and Modal Logics}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/7740 http://dlicata.web.wesleyan.edu/pubs/lsr17multi/lsr17multi-ex.pdf},
volume = {84},
year = {2017}
}
@article{Coecke2016,
abstract = {Many fields of science investigate states and processes as resources. Chemistry, thermodynamics, Shannon's theory of communication channels, and the theory of quantum entanglement are prominent examples. Questions addressed by these theories include: Which resources can be converted into which others? At what rate can many copies of one resource be converted into many copies of another? Can a catalyst enable a conversion? How to quantify a resource? We propose a general mathematical definition of resource theory. We prove general theorems about how resource theories can be constructed from theories of processes with a subclass of processes that are freely implementable. These define the means by which costly states and processes can be interconverted. We outline how various existing resource theories fit into our framework, which is a first step in a project of identifying universal features and principles of resource theories. We develop a few general results concerning resource convertibility.},
archivePrefix = {arXiv},
arxivId = {1409.5531},
author = {Coecke, Bob and Fritz, Tobias and Spekkens, Robert W.},
doi = {10.1016/j.ic.2016.02.008},
eprint = {1409.5531},
file = {:Users/liang-tingchen/Dropbox/References/Coecke, Fritz, Spekkens - 2016 - A mathematical theory of resources.pdf:pdf},
isbn = {0252725484},
issn = {08905401},
journal = {Information and Computation},
month = {oct},
pages = {59--86},
pmid = {9230594},
publisher = {Elsevier Inc.},
title = {{A mathematical theory of resources}},
url = {http://dx.doi.org/10.1016/j.ic.2016.02.008 https://linkinghub.elsevier.com/retrieve/pii/S0890540116000353},
volume = {250},
year = {2016}
}
@article{Pitts2016,
author = {Pitts, Andrew},
doi = {10.1145/2893582.2893594},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2016 - Nominal Techniques.pdf:pdf},
issn = {2372-3491},
journal = {ACM SIGLOG News},
number = {1},
pages = {57--72},
title = {{Nominal Techniques}},
url = {http://doi.acm.org/10.1145/2893582.2893594},
volume = {3},
year = {2016}
}
@book{Hatcher2002,
author = {{Allen Hatcher}},
file = {:Users/liang-tingchen/Dropbox/References/Allen Hatcher - 2002 - Algebraic Topology.pdf:pdf},
pages = {556},
publisher = {Cambridge University Press},
title = {{Algebraic Topology}},
url = {https://www.cambridge.org/gb/academic/subjects/mathematics/geometry-and-topology/algebraic-topology-1?format=PB{\&}isbn=9780521795401},
year = {2002}
}
@inproceedings{Filinski2007,
address = {New York, New York, USA},
author = {Filinski, Andrzej and St{\o}vring, Kristian},
booktitle = {Proceedings of the 2007 ACM SIGPLAN international conference on Functional programming - ICFP '07},
doi = {10.1145/1291151.1291168},
file = {:Users/liang-tingchen/Dropbox/References/Filinski, St{\o}vring - 2007 - Inductive reasoning about effectful data types.pdf:pdf},
isbn = {9781595938152},
issn = {03621340},
keywords = {abstract effects,backtracking,cons,equational reasoning,for l 1,for t,h,logical,monads,nil and l 1,recursive types,relations,streams,t,that the equation holds,with the induction hypothesis},
month = {oct},
number = {9},
pages = {97},
publisher = {ACM Press},
title = {{Inductive reasoning about effectful data types}},
url = {http://portal.acm.org/citation.cfm?doid=1291220.1291168 http://portal.acm.org/citation.cfm?doid=1291151.1291168},
volume = {42},
year = {2007}
}
@incollection{Levy1999,
author = {Levy, Paul Blain},
booktitle = {Typed Lambda Calculi and Applications. TLCA 1999},
doi = {10.1007/3-540-48959-2_17},
editor = {Girard, Jean-Yves},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 1999 - Call-by-Push-Value A Subsuming Paradigm.pdf:pdf},
pages = {228--243},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Call-by-Push-Value: A Subsuming Paradigm}},
url = {http://link.springer.com/10.1007/3-540-48959-2{\_}17},
volume = {1581},
year = {1999}
}
@article{Johann1994,
abstract = {Let R be a convergent term rewriting system, and let CR-equality on (simply typed) combinatory logic terms be the equality induced by $\beta$$\eta$R- equality on terms of the (simply typed) lambda calculus under any of the standard translations between these two frameworks for higher-order reasoning. We generalize the classical notion of strong reduction to a reduction relation which generates CR-equality and whose irreducibles are exactly the translates of long $\beta$R-normal forms. The classical notion of strong normal form in combinatory logic is also generalized, yielding yet another description of these translates. Their resulting tripartite characterization extends to the combined first-order algebraic and higher-order setting the classical combinatory logic descriptions of the translates of long $\beta$-normal forms in the lambda calculus. As a consequence, the translates of long $\beta$R-normal forms are easily seen to serve as canonical representatives for CR-equivalence classes of combinatory logic terms for nonempty, as well as for empty, R. {\textcopyright} 1994, Duke University Press. All Rights Reserved.},
author = {Johann, Patricia},
doi = {10.1305/ndjfl/1040408614},
file = {:Users/liang-tingchen/Dropbox/References/Johann - 1994 - Normal Forms in Combinatory Logic.pdf:pdf},
issn = {0029-4527},
journal = {Notre Dame Journal of Formal Logic},
month = {oct},
number = {4},
pages = {573--594},
title = {{Normal Forms in Combinatory Logic}},
url = {https://projecteuclid.org/journals/notre-dame-journal-of-formal-logic/volume-35/issue-4/Normal-Forms-in-Combinatory-Logic/10.1305/ndjfl/1040408614.full},
volume = {35},
year = {1994}
}
@article{Worrell2002,
author = {Worrell, James},
doi = {10.1016/S1571-0661(04)80373-6},
file = {:Users/liang-tingchen/Dropbox/References/Worrell - 2002 - A Note on Coalgebras and Presheaves.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {oct},
number = {1},
pages = {358--364},
title = {{A Note on Coalgebras and Presheaves}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104803736},
volume = {65},
year = {2002}
}
@article{Danielsson2010,
abstract = {A monadic parser combinator library which guarantees termination of parsing, while still allowing many forms of left recursion, is described. The library's interface is similar to those of many other parser combinator libraries, with two important differences: one is that the interface clearly specifies which parts of the constructed parsers may be infinite, and which parts have to be finite, using dependent types and a combination of induction and coinduction; and the other is that the parser type is unusually informative. The library comes with a formal semantics, using which it is proved that the parser combinators are as expressive as possible. The implementation is supported by a machine-checked correctness proof.},
author = {Danielsson, Nils Anders},
doi = {10.1145/1932681.1863585},
file = {:Users/liang-tingchen/Dropbox/References/Danielsson - 2010 - Total parser combinators.pdf:pdf},
isbn = {9781605587943},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {dependent types,mixed induction and coinduction,parser combinators,productivity,termination},
month = {sep},
number = {9},
pages = {285},
title = {{Total parser combinators}},
url = {http://portal.acm.org/citation.cfm?doid=1932681.1863585},
volume = {45},
year = {2010}
}
@article{BachPoulsen2018,
abstract = {A definitional interpreter defines the semantics of an object language in terms of the (well-known) semantics of a host language, enabling understanding and validation of the semantics through execution. Combining a definitional interpreter with a separate type system requires a separate type safety proof. An alternative approach, at least for pure object languages, is to use a dependently-typed language to encode the object language type system in the definition of the abstract syntax. Using such intrinsically-typed abstract syntax definitions allows the host language type checker to verify automatically that the interpreter satisfies type safety. Does this approach scale to larger and more realistic object languages, and in particular to languages with mutable state and objects? In this paper, we describe and demonstrate techniques and libraries in Agda that successfully scale up intrinsically-typed definitional interpreters to handle rich object languages with non-trivial binding structures and mutable state. While the resulting interpreters are certainly more complex than the simply-typed $\lambda$-calculus interpreter we start with, we claim that they still meet the goals of being concise, comprehensible, and executable, while guaranteeing type safety for more elaborate object languages. We make the following contributions: (1) A dependent-passing style technique for hiding the weakening of indexed values as they propagate through monadic code. (2) An Agda library for programming with scope graphs and frames, which provides a uniform approach to dealing with name binding in intrinsically-typed interpreters. (3) Case studies of intrinsically-typed definitional interpreters for the simply-typed $\lambda$-calculus with references (STLC+Ref) and for a large subset of Middleweight Java (MJ).},
author = {{Bach Poulsen}, Casper and Rouvoet, Arjen and Tolmach, Andrew and Krebbers, Robbert and Visser, Eelco},
doi = {10.1145/3158104},
file = {:Users/liang-tingchen/Dropbox/References/Bach Poulsen et al. - 2018 - Intrinsically-typed definitional interpreters for imperative languages.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Agda,Java,definitional interpreters,dependent types,mechanized semantics,scope graphs,type safety},
month = {jan},
number = {POPL},
pages = {1--34},
title = {{Intrinsically-typed definitional interpreters for imperative languages}},
url = {https://dl.acm.org/doi/10.1145/3158104},
volume = {2},
year = {2018}
}
@article{Milius2010,
author = {Milius, Stefan},
doi = {10.1109/LICS.2010.11},
file = {:Users/liang-tingchen/Dropbox/References/Milius - 2010 - A Sound and Complete Calculus for Finite Stream Circuits.pdf:pdf},
isbn = {978-1-4244-7588-9},
journal = {25th Annual IEEE Symposium on Logic in Computer Science},
keywords = {-kleene algebra,coalgebra,regular ex-,streams},
month = {jul},
pages = {421--430},
publisher = {Ieee},
title = {{A Sound and Complete Calculus for Finite Stream Circuits}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5571746},
year = {2010}
}
@article{McBride2018,
abstract = {The key to any nameless representation of syntax is how it indicates the variables we choose to use and thus, implicitly, those we discard. Standard de Bruijn representations delay discarding maxi-mally till the leaves of terms where one is chosen from the variables in scope at the expense of the rest. Consequently, introducing new but unused variables requires term traversal. This paper introduces a nameless 'co-de-Bruijn' representation which makes the opposite canonical choice, delaying discarding minimally, as near as possible to the root. It is literate Agda: dependent types make it a practical joy to express and be driven by strong intrinsic invariants which ensure that scope is aggressively whittled down to just the support of each subterm, in which every remaining variable occurs somewhere. The construction is generic, delivering a universe of syntaxes with higher-order metavariables, for which the appropriate notion of substitution is hereditary. The implementation of simultaneous substitution exploits tight scope control to avoid busywork and shift terms without traversal. Surprisingly, it is also intrinsically terminating, by structural recursion alone.},
author = {McBride, Conor},
doi = {10.4204/EPTCS.275.6},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2018 - Everybody's Got To Be Somewhere.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {jul},
number = {Msfp},
pages = {53--69},
title = {{Everybody's Got To Be Somewhere}},
url = {http://arxiv.org/abs/1807.04085v1},
volume = {275},
year = {2018}
}
@article{Lack2002,
author = {Lack, Stephen and Street, Ross},
doi = {10.1016/S0022-4049(02)00137-8},
file = {:Users/liang-tingchen/Dropbox/References/Lack, Street - 2002 - The formal theory of monads II.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-3},
pages = {243--265},
title = {{The formal theory of monads II}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404902001378},
volume = {175},
year = {2002}
}
@article{Narayanan2010,
author = {Narayanan, Arvind and Shmatikov, Vitaly},
doi = {10.1145/1743546.1743558},
file = {:Users/liang-tingchen/Dropbox/References/Narayanan, Shmatikov - 2010 - Myths and fallacies of personally identifiable information.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {6},
pages = {24},
title = {{Myths and fallacies of "personally identifiable information"}},
url = {http://portal.acm.org/citation.cfm?doid=1743546.1743558},
volume = {53},
year = {2010}
}
@incollection{Alimarine2004,
abstract = {Generic functions are defined by induction on the structural representation of types. As a consequence, by defining just a single generic operation, one acquires this operation over any particular type. An instance on a specific type is generated by interpretation of the type's structure. A direct translation leads to extremely inefficient code that involves many conversions between types and their structural representations. In this paper we present an optimization technique based on compile-time symbolic evaluation. We prove that the optimization removes the overhead of the generated code for a considerable class of generic functions. The proof uses typing to identify intermediate data structures that should be eliminated. In essence, the output after optimization is similar to hand-written code. {\textcopyright} Springer-Verlag 2004.},
author = {Alimarine, Artem and Smetsers, Sjaak},
booktitle = {Mathematics of Program Construction. MPC 2004},
doi = {10.1007/978-3-540-27764-4_3},
editor = {Kozen, Dexter},
file = {:Users/liang-tingchen/Dropbox/References/Alimarine, Smetsers - 2004 - Optimizing Generic Functions.pdf:pdf},
isbn = {3540223800},
issn = {16113349},
pages = {16--31},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Optimizing Generic Functions}},
url = {http://link.springer.com/10.1007/978-3-540-27764-4{\_}3},
volume = {3125},
year = {2004}
}
@article{Kingdom2015a,
abstract = {Writing formal specifications for distributed systems is difficult. Even simple consistency requirements often turn out to be unrealizable because of the complicated information flow in the distributed system: not all information is available in every component, and information transmitted from other components may arrive with a delay or not at all, especially in the presence of faults. The problem of checking the distributed realizability of a temporal specification is, in general, undecidable. Semi-algorithms for synthesis, such as bounded synthesis, are only useful in the positive case, where they construct an implementation for a realizable specification, but not in the negative case: if the specification is unrealizable, the search for the implementation never terminates. In this paper, we introduce counterexamples to distributed realizability and present a method for the detection of such counterexamples for specifications given in linear-time temporal logic (LTL). A counterexample consists of a set of paths, each representing a different sequence of inputs from the environment, such that, no matter how the components are implemented, the specification is violated on at least one of these paths. We present a method for finding such counterexamples both for the classic distributed realizability problem and for the fault-tolerant realizability problem. Our method considers, incrementally, larger and larger sets of paths until a counterexample is found. For safety specifications in weakly ordered architectures we obtain a decision procedure, while counterexamples for full LTL and arbitrary architectures may consist of infinitely many paths. Experimental results, obtained with a QBF-based prototype implementation, show that our method finds simple errors very quickly, and even problems with high combinatorial complexity, like the Byzantine Generals' Problem, are tractable.},
archivePrefix = {arXiv},
arxivId = {1505.06862},
author = {Bonchi, Filippo and Zanasi, Fabio},
doi = {10.2168/LMCS-11(1:14)2015},
editor = {Milius, Stefan},
eprint = {1505.06862},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi, Zanasi - 2015 - Bialgebraic Semantics for Logic Programming.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {algebraic techniques in automata,and phrases,probabilistic automata,value 1 problem},
month = {mar},
number = {1},
pages = {1--50},
title = {{Bialgebraic Semantics for Logic Programming}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1571},
volume = {11},
year = {2015}
}
@article{Hirschowitz2010,
abstract = {Inspired by the classical theory of modules over a monoid, we introduce the natural notion of module over a monad. The associated notion of morphism of left modules ("linear" natural transformations) captures an important property of compatibility with substitution, not only in the so-called homogeneous case but also in the heterogeneous case where "terms" and variables therein could be of different types. In this paper, we present basic constructions of modules and we show how modules allow a new point of view concerning higher-order syntax and semantics. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Hirschowitz, Andr{\'{e}} and Maggesi, Marco},
doi = {10.1016/j.ic.2009.07.003},
file = {:Users/liang-tingchen/Dropbox/References/Hirschowitz, Maggesi - 2010 - Modules over monads and initial semantics.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {may},
number = {5},
pages = {545--564},
publisher = {Elsevier Inc.},
title = {{Modules over monads and initial semantics}},
url = {http://dx.doi.org/10.1016/j.ic.2009.07.003 https://linkinghub.elsevier.com/retrieve/pii/S0890540109002405},
volume = {208},
year = {2010}
}
@book{MacLane1978,
author = {{Mac Lane}, Saunders},
doi = {10.1007/978-1-4757-4721-8},
isbn = {978-1-4419-3123-8},
publisher = {Springer New York, NY},
series = {Graduate Texts in Mathematics},
title = {{Categories for the Working Mathematician}},
url = {http://link.springer.com/10.1007/978-1-4757-4721-8},
volume = {5},
year = {1978}
}
@incollection{Italiano2015,
address = {Berlin, Heidelberg},
author = {{\'{E}}sik, Zolt{\'{a}}n},
booktitle = {Proceedings of the 40th Mathematical Foundations of Computer Science},
doi = {10.1007/978-3-662-48057-1_2},
editor = {Italiano, Giuseppe F and Pighizzini, Giovanni and Sannella, Donald T.},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 2015 - Equational properties of fixed point operations in cartesian categories An overview.pdf:pdf},
isbn = {978-3-662-48056-4},
issn = {16113349},
pages = {18--37},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Equational properties of fixed point operations in cartesian categories: An overview}},
url = {http://link.springer.com/10.1007/978-3-662-48057-1{\_}2},
volume = {9234},
year = {2015}
}
@incollection{VanBreugel2005a,
abstract = {Metric labelled transition systems are labelled transition systems whose states and actions form (pseudo)metric spaces. These systems can capture a large class of timed transition systems, including systems with uncountably many states and uncountable nondeterminism. In this paper a behavioural pseudometric is introduced for metric labelled transition systems. The behavioural distance between states, a nonnegative real number, captures the similarity of the behaviour of those states. The smaller the distance, the more alike the states are. In particular, the distance between states is 0 iff they are bisimilar. Three different characterisations of this pseudometric are given: a fixed point, a logical and a coinductive characterisation. These generalise the fixed point, logical and coinductive characterisations of bisimilarity. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {van Breugel, Franck},
booktitle = {International Conference on Concurrency Theory},
doi = {10.1007/11539452_14},
editor = {Abadi, Mart{\'{i}}n and de Alfaro, Luca},
file = {:Users/liang-tingchen/Dropbox/References/van Breugel - 2005 - A behavioural pseudometric for metric labelled transition systems.pdf:pdf},
isbn = {978-3-540-28309-6},
issn = {03029743},
pages = {141--155},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A behavioural pseudometric for metric labelled transition systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-27244457559{\&}partnerID=40{\&}md5=f367c4395507c446b8dbb5ab61efee9f http://link.springer.com/10.1007/11539452{\_}14},
volume = {3653},
year = {2005}
}
@article{Longley2014,
abstract = {We generalise the standard construction of realizability models (specifically, of categories of assemblies) to a wide class of computability structures , which is broad enough to embrace models of computation such as labelled transition systems and process algebras. We consider a general notion of simulation between such computability structures, and show how these simulations correspond precisely to certain functors between the realizability models. Furthermore, we show that our class of computability structures has good closure properties – in particular, it is ‘cartesian closed' in a slightly relaxed sense. Finally, we investigate some important subclasses of computability structures and of simulations between them. We suggest that our 2-category of computability structures and simulations may offer a useful framework for investigating questions of computational power, abstraction and simulability for a wide range of models.},
author = {Longley, John},
doi = {10.1017/S0960129513000182},
file = {:Users/liang-tingchen/Dropbox/References/Longley - 2014 - Computability structures, simulations and realizability.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {apr},
number = {2},
pages = {e240201},
title = {{Computability structures, simulations and realizability}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129513000182 https://www.cambridge.org/core/product/identifier/S0960129513000182/type/journal{\_}article},
volume = {24},
year = {2014}
}
@misc{Riehl2009,
author = {Riehl, Emily},
file = {:Users/liang-tingchen/Dropbox/References/Riehl - 2009 - Weighted Limits and Colimits.pdf:pdf},
title = {{Weighted Limits and Colimits}},
url = {http://www.math.harvard.edu/{~}eriehl/weighted.pdf},
year = {2009}
}
@misc{Day1978,
author = {Day, Brian J.},
booktitle = {Bulletin of the Australian Mathematical Society},
doi = {10.1017/S0004972700008613},
file = {:Users/liang-tingchen/Dropbox/References/Day - 1978 - Duality in topological algebra.pdf:pdf},
issn = {0004-9727},
number = {03},
pages = {475--480},
title = {{Duality in topological algebra}},
volume = {18},
year = {1978}
}
@inproceedings{Jay2018,
abstract = {Intensional lambda-calculus adds intensional combinators to lambda-calculus to facilitate analysis. In particular, they are used to factorise data structures and programs into their components, which can be used to convert abstractions into combinators. This paper shows how to type an intensional lambda-calculus using no more than the types of System F. Even the quotation function used to access program syntax can be defined and typed, as can its inverse: the calculus supports typed self-quotation. Thus, one may freely alternate between program analysis and program execution. Proofs of all results have been verified in Coq.},
author = {Jay, Barry},
booktitle = {The Thirty-third Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXIII)},
doi = {10.1016/j.entcs.2018.03.024},
file = {:Users/liang-tingchen/Dropbox/References/Jay - 2018 - Self-Quotation in a Typed, Intensional Lambda-Calculus.pdf:pdf},
issn = {15710661},
keywords = {combinators,lambda-calculus,self-interpretation,type theory},
month = {apr},
pages = {207--222},
publisher = {Elsevier B.V.},
title = {{Self-Quotation in a Typed, Intensional Lambda-Calculus}},
url = {https://doi.org/10.1016/j.entcs.2018.03.024 https://linkinghub.elsevier.com/retrieve/pii/S1571066118300276},
volume = {336},
year = {2018}
}
@article{Adamek2011d,
abstract = {B. Courcelle studied algebraic trees as precisely the solutions of all recursive program schemes for a given signature in Set. He proved that the corresponding monad is iterative. We generalize this to recursive program schemes over a given finitary endofunctor H of a "suitable" category. A monad is called second-order iterative if every guarded recursive program scheme has a unique solution in it. We construct two second-order iterative monads: one, called the second-order rational monad, SH, is proved to be the initial second-order iterative monad. The other one, called the context-free monad, CH, is a quotient of SH and in the original case of a polynomial endofunctor H of Set we prove that CH is the monad studied by B. Courcelle. The question whether these two monads are equal is left open. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Velebil, Jiř{\'{i}}},
doi = {10.1016/j.tcs.2011.04.027},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Velebil - 2011 - On second-order iterative monads.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Algebraic trees,Ideal theory,Monads,Recursive program schemes},
number = {38},
pages = {4969--4988},
publisher = {Elsevier B.V.},
title = {{On second-order iterative monads}},
url = {http://dx.doi.org/10.1016/j.tcs.2011.04.027},
volume = {412},
year = {2011}
}
@inproceedings{Marlow2016,
abstract = {Monads have taken the world by storm, and are supported by do-notation (at least in Haskell). Programmers are increasingly waking up to the usefulness and ubiquity of Applicatives, but they have so far been hampered by the absence of supporting notation. In this paper we show how to re-use the very same do-notation to work for Applicatives as well, providing efficiency benefits for some types that are both Monad and Applicative, and syntactic convenience for those that are merely Applicative. The result is fully implemented in GHC, and is in use at Facebook to make it easy to write highly-parallel queries in a distributed system.},
address = {New York, New York, USA},
author = {Marlow, Simon and {Peyton Jones}, Simon and Kmett, Edward and Mokhov, Andrey},
booktitle = {Proceedings of the 9th International Symposium on Haskell - Haskell 2016},
doi = {10.1145/2976002.2976007},
file = {:Users/liang-tingchen/Dropbox/References/Marlow et al. - 2016 - Desugaring Haskell's do-notation into applicative operations.pdf:pdf},
isbn = {9781450344340},
issn = {03621340},
keywords = {14,16,a functor and,a monad lies an,al,applicative,haskell,marlow et,monad,s insight that between,showed how to exploit,syntax,this parallelism by,to be concrete,using mcbride and paterson,we can rewrite},
month = {sep},
number = {12},
pages = {92--104},
publisher = {ACM Press},
title = {{Desugaring Haskell's do-notation into applicative operations}},
url = {http://dl.acm.org/citation.cfm?doid=3241625.2976007 http://dl.acm.org/citation.cfm?doid=2976002.2976007},
volume = {51},
year = {2016}
}
@article{Bunge1977,
author = {Bunge, Marta C.},
file = {:Users/liang-tingchen/Dropbox/References/Bunge - 1977 - Internal presheaves toposes.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {3},
pages = {291--330},
title = {{Internal presheaves toposes}},
url = {http://www.numdam.org/item/?id=CTGDC{\_}1977{\_}{\_}18{\_}3{\_}291{\_}0},
volume = {8},
year = {1977}
}
@article{Kerstan2013,
archivePrefix = {arXiv},
arxivId = {1310.7417},
author = {Jacobs, Bart},
doi = {10.2168/LMCS-9(3:23)2013},
editor = {Klin, Bartek},
eprint = {1310.7417},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2013 - Bases as Coalgebras.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Coalgebra,Markov processes,Probabilistic transition systems,Trace semantics},
month = {sep},
number = {3},
pages = {1--21},
title = {{Bases as Coalgebras}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1133},
volume = {9},
year = {2013}
}
@article{Brown1993,
abstract = {We define a relational quantale to be a quantale whose elements are relations on a set A, ordered by inclusion and forming a monoid under relational composition. Such quantales have been studied in several areas of theoretical computer science, and constitute a sound and complete class of models for non-commutative linear logic. We show that every quantale is isomorphic to a relational quantale, and investigate the classification of quantales according to properties of their representations as relational quantales. {\textcopyright} 1993.},
author = {Brown, Carolyn and Gurr, Doug},
doi = {10.1016/0022-4049(93)90169-T},
file = {:Users/liang-tingchen/Dropbox/References/Brown, Gurr - 1993 - A representation theorem for quantales.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {mar},
number = {1},
pages = {27--42},
title = {{A representation theorem for quantales}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499390169T},
volume = {85},
year = {1993}
}
@incollection{Altenkirch1995,
author = {Altenkirch, Thorsten and Hofmann, Martin and Streicher, Thomas},
booktitle = {Category Theory and Computer Science. CTCS 1995},
doi = {10.1007/3-540-60164-3_27},
editor = {Pitt, David and Rydeheard, David E. and Johnstone, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Hofmann, Streicher - 1995 - Categorical reconstruction of a reduction free normalization proof.pdf:pdf},
isbn = {3540601643},
issn = {16113349},
number = {January},
pages = {182--199},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Categorical reconstruction of a reduction free normalization proof}},
url = {http://link.springer.com/10.1007/3-540-60164-3{\_}27},
volume = {953},
year = {1995}
}
@incollection{Altenkirch2010,
address = {Berlin, Heidelberg},
author = {Altenkirch, Thorsten and Chapman, James and Uustalu, Tarmo},
booktitle = {Proceedings of the 13th International Conference on Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-642-12032-9},
editor = {Ong, Luke},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Chapman, Uustalu - 2010 - Monads need not be endofunctors.pdf:pdf},
isbn = {978-3-642-12031-2},
issn = {0302-9743},
pages = {297--311},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Monads need not be endofunctors}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-12032-9},
year = {2010}
}
@article{Narens2016,
abstract = {The focus of this article is on probability theories based on non-boolean event spaces that have potential for scientific and philosophical applications. Since the early 1930s, such an alternative probability theory has been systematically used to provide a mathematical foundation for quantum physics. This article investigates in a general way feasible alternatives to boolean event algebras as bases for probability theories. Such alternatives permit new kinds of logical relationships among events that are not expressible in boolean event algebras. In psychology, these relationships allow for kinds of modeling methods that help account for various puzzling phenomena found throughout psychology, particularly in cognitive decision theory. The alternative probability theories presented are investigated through algebraic characterizations of their event spaces and probability functions. This is done using results from a well-developed area of mathematics known as “lattice theory”. This article describes the basics of lattice theory and how the interpretation of a few of its results indicates that generalizations of boolean event spaces are severely limited for useful application in scientific modeling. The overall conclusion is that two types of event spaces appear especially promising for generalization: One that captures key concepts of the logic inherent in quantum mechanics, “quantum logic”, and another that captures key concepts inherent in a generalization of classical logic that is used in the foundations of mathematics, “intuitionistic logic”. Both of these types of logical structures are useful for constructing unorthodox models of troublesome findings in behavioral economics. One theme of this article is the use of intuitionistic logic to model probabilistic judgments and decision making.},
author = {Narens, Louis},
doi = {10.1016/j.jmp.2016.04.013},
file = {:Users/liang-tingchen/Dropbox/References/Narens - 2016 - An introduction to lattice based probability theories.pdf:pdf},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
keywords = {Foundations of probability,Intuitionistic logic,Lattice theory,Quantum probability theory},
month = {oct},
pages = {66--81},
publisher = {Elsevier Inc.},
title = {{An introduction to lattice based probability theories}},
url = {http://dx.doi.org/10.1016/j.jmp.2016.04.013 http://linkinghub.elsevier.com/retrieve/pii/S0022249616300232},
volume = {74},
year = {2016}
}
@article{YAGER1983,
author = {Yager, Ronald R.},
doi = {10.1080/03081078308960825},
file = {:Users/liang-tingchen/Dropbox/References/Yager - 1983 - ENTROPY AND SPECIFICITY IN A MATHEMATICAL THEORY OF EVIDENCE.pdf:pdf},
issn = {0308-1079},
journal = {International Journal of General Systems},
month = {jan},
number = {4},
pages = {249--260},
title = {{ENTROPY AND SPECIFICITY IN A MATHEMATICAL THEORY OF EVIDENCE}},
url = {http://www.tandfonline.com/doi/abs/10.1080/03081078308960825},
volume = {9},
year = {1983}
}
@article{Jung2012,
author = {Jung, Achim and Rivieccio, Umberto},
doi = {10.1007/s11225-012-9376-0},
file = {:Users/liang-tingchen/Dropbox/References/Jung, Rivieccio - 2012 - Priestley Duality for Bilattices.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {bilattices,bilattices with,bilattices with conflation,brouwerian bilattices,implication,priestley duality theory},
month = {feb},
number = {1-2},
pages = {223--252},
title = {{Priestley Duality for Bilattices}},
url = {http://www.cs.bham.ac.uk/{~}rivieccu/pub/dua.pdf http://www.springerlink.com/index/10.1007/s11225-012-9376-0},
volume = {100},
year = {2012}
}
@article{Mu2009,
abstract = {Relational program derivation is the technique of stepwise refining a relational specification to a program by algebraic rules. The program thus obtained is correct by construction. Meanwhile, dependent type theory is rich enough to express various correctness properties to be verified by the type checker. We have developed a library, AoPA (Algebra of Programming in Agda), to encode relational derivations in the dependently typed programming language Agda. A program is coupled with an algebraic derivation whose correctness is guaranteed by the type system. Two non-trivial examples are presented: an optimisation problem and a derivation of quicksort in which well-founded recursion is used to model terminating hylomorphisms in a language with inductive types.},
author = {MU, SHIN-CHENG and KO, HSIANG-SHANG and JANSSON, PATRIK},
doi = {10.1017/S0956796809007345},
file = {:Users/liang-tingchen/Dropbox/References/MU, KO, JANSSON - 2009 - Algebra of programming in Agda Dependent types for relational program derivation.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {5},
pages = {545--579},
title = {{Algebra of programming in Agda: Dependent types for relational program derivation}},
url = {https://www.cambridge.org/core/product/identifier/S0956796809007345/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Qu2019,
author = {Qu, Weihao and Gaboardi, Marco and Garg, Deepak},
doi = {10.1145/3341696},
file = {:Users/liang-tingchen/Dropbox/References/Qu, Gaboardi, Garg - 2019 - Relational cost analysis for functional-imperative programs.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {refinement types,relational type systems,type-and-effect systems},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Relational cost analysis for functional-imperative programs}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341696},
volume = {3},
year = {2019}
}
@inproceedings{Paterson2001,
abstract = {The categorical notion of monad, used by Moggi to structure denotational descriptions, has proved to be a powerful tool for structuring combinator libraries. Moreover, the monadic programming style provides a convenient syntax for many kinds of computation, so that each library defines a new sublanguage. Recently, several workers have proposed a generalization of monads, called variously "arrows" or Freyd-categories. The extra generality promises to increase the power, expressiveness and efficiency of the embedded approach, but does not mesh as well with the native abstraction and application. Definitions are typically given in a point-free style, which is useful for proving general properties, but can be awkward for programming specific instances. In this paper we define a simple extension to the functional language Haskell that makes these new notions of computation more convenient to use. Our language is similar to the monadic style, and has similar reasoning properties. Moreover, it is extensible, in the sense that new combining forms can be defined as expressions in the host language.},
address = {New York, New York, USA},
author = {Paterson, Ross},
booktitle = {Proceedings of the sixth ACM SIGPLAN international conference on Functional programming - ICFP '01},
doi = {10.1145/507635.507664},
file = {:Users/liang-tingchen/Dropbox/References/Paterson - 2001 - A new notation for arrows.pdf:pdf},
isbn = {1581134150},
issn = {03621340},
month = {oct},
number = {10},
pages = {229},
publisher = {ACM Press},
title = {{A new notation for arrows}},
url = {http://portal.acm.org/citation.cfm?doid=507669.507664 http://portal.acm.org/citation.cfm?doid=507635.507664},
volume = {36},
year = {2001}
}
@inproceedings{Berger1991,
author = {Berger, U. and Schwichtenberg, H.},
booktitle = {Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1991.151645},
file = {:Users/liang-tingchen/Dropbox/References/Berger, Schwichtenberg - 1991 - An inverse of the evaluation functional for typed lambda calculus.pdf:pdf},
isbn = {0-8186-2230-X},
pages = {203--211},
publisher = {IEEE Comput. Sco. Press},
title = {{An inverse of the evaluation functional for typed lambda calculus}},
url = {http://ieeexplore.ieee.org/document/151645/},
year = {1991}
}
@article{Michael1951,
author = {Michael, Ernest},
file = {:Users/liang-tingchen/Dropbox/References/Michael - 1951 - Topologies on spaces of subsets.pdf:pdf},
journal = {Transactions of the American Mathematical Society},
number = {1},
pages = {152--182},
publisher = {American Mathematical Society},
title = {{Topologies on spaces of subsets}},
type = {Journal article},
url = {http://www.jstor.org/stable/1990864 http://www.ams.org/journals/tran/1951-071-01/S0002-9947-1951-0042109-4/S0002-9947-1951-0042109-4.pdf},
volume = {71},
year = {1951}
}
@book{Borceux1994,
author = {Borceux, Francis},
isbn = {9780521441797},
pages = {443},
publisher = {Cambridge University Press},
series = {Encyclopedia of Mathematics and its Applications},
title = {{Handbook of Categorical Algebra 1: Basic Category Theory}},
type = {Book},
url = {http://dx.doi.org/10.2277/052144179X},
year = {1994}
}
@inproceedings{Luu2016,
abstract = {Cryptocurrencies record transactions in a decentralized data structure called a blockchain. Two of the most popular cryptocurrencies, Bitcoin and Ethereum, support the fea-ture to encode rules or scripts for processing transactions. This feature has evolved to give practical shape to the ideas of smart contracts, or full-fledged programs that are run on blockchains. Recently, Ethereum's smart contract system has seen steady adoption, supporting tens of thousands of contracts, holding millions dollars worth of virtual coins. In this paper, we investigate the security of running smart contracts based on Ethereum in an open distributed network like those of cryptocurrencies. We introduce several new se-curity problems in which an adversary can manipulate smart contract execution to gain profit. These bugs suggest subtle gaps in the understanding of the distributed semantics of the underlying platform. As a refinement, we propose ways to enhance the operational semantics of Ethereum to make con-tracts less vulnerable. For developers writing contracts for the existing Ethereum system, we build a symbolic execution tool called Oyente to find potential security bugs. Among 19, 366 existing Ethereum contracts, Oyente flags 8, 833 of them as vulnerable, including the TheDAO bug which led to a 60 million US dollar loss in June 2016. We also discuss the severity of other attacks for several case studies which have source code available and confirm the attacks (which target only our accounts) in the main Ethereum network.},
address = {New York, New York, USA},
author = {Luu, Loi and Chu, Duc-Hiep and Olickel, Hrishi and Saxena, Prateek and Hobor, Aquinas},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security - CCS'16},
doi = {10.1145/2976749.2978309},
file = {:Users/liang-tingchen/Dropbox/References/Luu et al. - 2016 - Making Smart Contracts Smarter.pdf:pdf},
isbn = {9781450341394},
issn = {15437221},
pages = {254--269},
publisher = {ACM Press},
title = {{Making Smart Contracts Smarter}},
url = {http://dl.acm.org/citation.cfm?doid=2976749.2978309},
year = {2016}
}
@article{Kouzapas2007,
author = {Kouzapas, Dimitrios and Philippou, Anna},
doi = {10.23638/LMCS-13(4:27)2017},
file = {:Users/liang-tingchen/Dropbox/References/Kouzapas, Philippou - 2007 - PRIVACY BY TYPING IN THE $\pi$-CALCULUS DIMITRIOS.pdf:pdf},
journal = {Logical Methods in Computer Science},
number = {4:27},
pages = {1----42},
title = {{PRIVACY BY TYPING IN THE $\pi$-CALCULUS DIMITRIOS}},
url = {https://lmcs.episciences.org/4152},
volume = {13},
year = {2007}
}
@article{Heunen2009,
abstract = {The aim of this paper is to relate algebraic quantum mechanics to topos theory, so as to construct new foundations for quantum logic and quantum spaces. Motivated by Bohr's idea that the empirical content of quantum physics is accessible only through classical physics, we show how a C*-algebra of observables A induces a topos T(A) in which the amalgamation of all of its commutative subalgebras comprises a single commutative C*-algebra. According to the constructive Gelfand duality theorem of Banaschewski and Mulvey, the latter has an internal spectrum S(A) in T(A), which in our approach plays the role of a quantum phase space of the system. Thus we associate a locale (which is the topos-theoretical notion of a space and which intrinsically carries the intuitionistic logical structure of a Heyting algebra) to a C*-algebra (which is the noncommutative notion of a space). In this setting, states on A become probability measures (more precisely, valuations) on S(A), and self-adjoint elements of A define continuous functions (more precisely, locale maps) from S(A) to Scott's interval domain. Noting that open subsets of S(A) correspond to propositions about the system, the pairing map that assigns a (generalized) truth value to a state and a proposition assumes an extremely simple categorical form. Formulated in this way, the quantum theory defined by A is essentially turned into a classical theory, internal to the topos T(A).},
archivePrefix = {arXiv},
arxivId = {0709.4364},
author = {Heunen, Chris and Landsman, Nicolaas P. and Spitters, Bas},
doi = {10.1007/s00220-009-0865-6},
eprint = {0709.4364},
file = {:Users/liang-tingchen/Dropbox/References/Heunen, Landsman, Spitters - 2009 - A Topos for Algebraic Quantum Theory.pdf:pdf},
issn = {0010-3616},
journal = {Communications in Mathematical Physics},
month = {jul},
number = {1},
pages = {63--110},
title = {{A Topos for Algebraic Quantum Theory}},
url = {http://arxiv.org/abs/0709.4364 http://link.springer.com/10.1007/s00220-009-0865-6},
volume = {291},
year = {2009}
}
@inproceedings{Protzenko2018,
abstract = {We present the proof search monad, a set of combinators that allows one to write a proof search engine in a style that resembles the formal rules closely. The user calls functions such as premise, prove or choice; the library then takes care of generating a derivation tree. Proof search engines written in this style enjoy: first, a one-to-one correspondence between the implementation and the derivation rules, which makes manual inspection easier; second, proof witnesses “for free”, which makes a verified, independent validation approach easier too.},
author = {Protzenko, Jonathan},
booktitle = {IWIL-2015. 11th International Workshop on the Implementation of Logics},
doi = {10.29007/cfdq},
editor = {Konev, Boris and Schulz, Stephan and Simon, Laurent},
file = {:Users/liang-tingchen/Dropbox/References/Protzenko - 2018 - Functional Pearl the Proof Search Monad.pdf:pdf},
number = {1},
pages = {91--75},
publisher = {EasyChair},
series = {EPiC Series in Computing},
title = {{Functional Pearl: the Proof Search Monad}},
url = {https://easychair.org/publications/paper/HzFg},
volume = {40},
year = {2018}
}
@inproceedings{Adamek2015,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Myers, Robert Samuel Ralph and Urbat, Henning and Milius, Stefan},
booktitle = {30th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2015.46},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2015 - Varieties of Languages in a Category.pdf:pdf},
isbn = {978-1-4799-8875-4},
month = {jul},
pages = {414--425},
publisher = {IEEE},
title = {{Varieties of Languages in a Category}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7174900},
year = {2015}
}
@article{Erwig2001,
abstract = {We propose a new style of writing graph algorithms in functional languages which is based on an alternative view of graphs as inductively defined data types. We show how this graph model can be implemented efficiently, and then we demonstrate how graph algorithms can be succinctly given by recursive function definitions based on the inductive graph view. We also regard this as a contribution to the teaching of algorithms and data structures in functional languages since we can use the functional-style graph algorithms instead of the imperative algorithms that are dominant today. Keywords: Graphs in Functional Languages, Recursive Graph Algorithms, Teaching Graph Algorithms in Functional Languages},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {ERWIG, MARTIN},
doi = {10.1017/S0956796801004075},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/ERWIG - 2001 - Inductive graphs and functional graph algorithms.pdf:pdf},
isbn = {9781450338103},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {05},
pages = {467--492},
pmid = {21675331},
publisher = {Swansea University Libraries},
title = {{Inductive graphs and functional graph algorithms}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796801004075},
volume = {11},
year = {2001}
}
@incollection{Simpson2017,
abstract = {Cyclic proof provides a style of proof for logics with inductive (and coinductive) definitions, in which proofs are cyclic graphs representing a form of argument by infinite descent. It is easily shown that cyclic proof subsumes proof by (co)induction. So cyclic proof systems are at least as powerful as the corresponding proof systems with explicit (co)induction rules. Whether or not the converse inclusion holds is a nontrivial question. In this paper, we resolve this question in one interesting case. We show that a cyclic formulation of first-order arithmetic is equivalent in power to Peano Arithmetic. The proof involves formalising the meta-theory of cyclic proof in a subsystem of second-order arithmetic.},
author = {Simpson, Alex},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2017},
doi = {10.1007/978-3-662-54458-7_17},
editor = {Esparza, Javier and Murawski, Andrzej S.},
file = {:Users/liang-tingchen/Dropbox/References/Simpson - 2017 - Cyclic Arithmetic Is Equivalent to Peano Arithmetic.pdf:pdf},
isbn = {9783662544570},
issn = {16113349},
pages = {283--300},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Cyclic Arithmetic Is Equivalent to Peano Arithmetic}},
url = {http://link.springer.com/10.1007/978-3-662-54458-7{\_}17},
volume = {10203},
year = {2017}
}
@inproceedings{Kaposi2019b,
abstract = {The relationship between categorical gluing and proofs using the logical relation technique is folklore. In this paper we work out this relationship for Martin-L{\"{o}}f type theory and show that parametricity and canonicity arise as special cases of gluing. The input of gluing is two models of type theory and a pseudomorphism between them and the output is a displayed model over the first model. A pseudomorphism preserves the categorical structure strictly, the empty context and context extension up to isomorphism, and there are no conditions on preservation of type formers. We look at three examples of pseudomorphisms: the identity on the syntax, the interpretation into the set model and the global section functor. Gluing along these result in syntactic parametricity, semantic parametricity and canonicity, respectively.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Gluing for Type Theory - Kaposi, Ambrus; Huber, Simon; Sattler, Christian)

Keywords: Martin-L{\"{o}}f type theory, logical relations, parametricity, canonicity, quotient inductive types},
author = {Kaposi, Ambrus and Huber, Simon and Sattler, Christian},
booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
doi = {10.4230/LIPIcs.FSCD.2019.25},
editor = {Geuvers, Herman},
file = {:Users/liang-tingchen/Dropbox/References/Kaposi, Huber, Sattler - 2019 - Gluing for Type Theory.pdf:pdf},
isbn = {978-3-95977-107-8},
issn = {1868-8969},
keywords = {Canonicity,Logical relations,Martin-L{\"{o}}f type theory,Parametricity,Quotient inductive types},
number = {25},
pages = {25:1----25:19},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Gluing for Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2019/10532},
volume = {131},
year = {2019}
}
@article{Milius2017,
abstract = {Motivated by the recent interest in models of guarded (co-)recursion, we study their equational properties. We formulate axioms for guarded fixpoint operators generalizing the axioms of iteration theories of Bloom and {\'{E}}sik. Models of these axioms include both standard (e.g., cpo-based) models of iteration theories and models of guarded recursion such as complete metric spaces or the topos of trees studied by Birkedal et al. We show that the standard result on the satisfaction of all Conway axioms by a unique dagger operation generalizes to the guarded setting. We also introduce the notion of guarded trace operator on a category, and we prove that guarded trace and guarded fixpoint operators are in one-to-one correspondence. Our results are intended as first steps leading, hopefully, towards future description of classifying theories for guarded recursion.},
archivePrefix = {arXiv},
arxivId = {1603.05214},
author = {Milius, Stefan and Litak, Tadeusz},
doi = {10.3233/FI-2017-1475},
eprint = {1603.05214},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Litak - 2017 - Guard Your Daggers and Traces Properties of Guarded (Co-)recursion.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
number = {3-4},
pages = {407--419},
title = {{Guard Your Daggers and Traces: Properties of Guarded (Co-)recursion}},
volume = {150},
year = {2017}
}
@inproceedings{Turi,
abstract = {We present a categorical theory of `well-behaved' operational semantics which aims at complementing the established theory of domains and denotational semantics to form a coherent whole. It is shown that, if the operational rules of a programming language can be modelled as a natural transformation of a suitable general form, depending on functorial notions of syntax and behaviour, then one gets the following for free: an operational model satisfying the rules and a canonical, internally fully abstract denotational model which satisfies the operational rules. The theory is based on distributive laws and bialgebras; it specialises to the known classes of well-behaved rules for structural operational semantics, such as GSOS.},
author = {Turi, Daniele and Plotkin, Gordon D.},
booktitle = {Proceedings of Twelfth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1997.614955},
file = {:Users/liang-tingchen/Dropbox/References/Turi, Plotkin - 1997 - Towards a mathematical operational semantics.pdf:pdf},
isbn = {0-8186-7925-5},
pages = {280--291},
publisher = {IEEE Comput. Soc},
title = {{Towards a mathematical operational semantics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=614955},
year = {1997}
}
@phdthesis{Ionescu2008,
author = {Ionescu, Cezar (Universidad de Berl{\'{i}}n)},
file = {:Users/liang-tingchen/Dropbox/References/Ionescu - 2008 - Vulnerability Modeling and Monadic Dynamical Systems.pdf:pdf},
number = {November},
pages = {149},
school = {Freie Universit{\"{a}}t Berlin},
title = {{Vulnerability Modeling and Monadic Dynamical Systems}},
year = {2008}
}
@inproceedings{Calcagno2003,
abstract = {The paper addresses theoretical and practical aspects of implementing multi-stage languages using abstract syntax trees (ASTs), gensym, and reflection. We present an operational account of the correctness of this approach, and report on our experience with a bytecode compiler called MetaOCaml that is based on this strategy. Current performance measurements reveal interesting characteristics of the underlying OCaml compiler, and illustrate why this strategy can be particularly useful for implementing domain-specific languages in a typed, functional setting. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
author = {Calcagno, Cristiano and Taha, Walid and Huang, Liwen and Leroy, Xavier},
booktitle = {Generative Programming and Component Engineering. GPCE 2003},
doi = {10.1007/978-3-540-39815-8_4},
editor = {Pfenning, Frank and Smaragdakis, Yannis},
file = {:Users/liang-tingchen/Dropbox/References/Calcagno et al. - 2003 - Implementing multi-stage languages using ASTs, gensym, and reflection.pdf:pdf},
isbn = {3540201025},
issn = {16113349},
pages = {57--76},
publisher = {Springer, Berlin, Heidelberg},
title = {{Implementing multi-stage languages using ASTs, gensym, and reflection}},
volume = {2830},
year = {2003}
}
@article{Aizpuru2006,
abstract = {In this paper we study how some classic properties in measure theory, valid on Boolean algebras, still hold in quantum logic, mainly, on quantum logic of sets. We obtain some results about the Vitali-Hahn-Saks property and the Nikodym property for sequences of real valued, $\sigma$-additive measures. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Aizpuru, A. and Tamayo, M.},
doi = {10.1016/j.fss.2006.03.010},
file = {:Users/liang-tingchen/Dropbox/References/Aizpuru, Tamayo - 2006 - Classical properties of measure theory on effect algebras.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Effect algebras,Measure},
month = {aug},
number = {15},
pages = {2139--2143},
title = {{Classical properties of measure theory on effect algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165011406001047},
volume = {157},
year = {2006}
}
@article{Hofmann2002,
abstract = {We study the expressive power of non-size increasing recursive definitions over lists. This notion of computation is such that the size of all intermediate results will automatically be bounded by the size of the input so that the interpretation in a finite model is sound with respect to the standard semantics. Many well-known algorithms with this property such as the usual sorting algorithms are definable in the system in the natural way. The main result is that a characteristic function is definable if and only if it is computable in time O(2p(n)) for some polynomial p. The method used to establish the lower bound on the expressive power also shows that the complexity becomes polynomial time if we allow primitive recursion only. This settles an open question posed in [1, 7]. The key tool for establishing upper bounds on the complexity of derivable functions is an interpretation in a finite relational model whose correctness with respect to the standard interpretation is shown using a semantic technique.},
author = {Hofmann, Martin},
doi = {10.1145/565816.503297},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann - 2002 - The strength of non-size increasing computation.pdf:pdf},
isbn = {1581134509},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {Computational complexity,Finite model,Higher-order functions,Semantics},
month = {jan},
number = {1},
pages = {260--269},
title = {{The strength of non-size increasing computation}},
url = {http://portal.acm.org/citation.cfm?doid=565816.503297},
volume = {37},
year = {2002}
}
@incollection{Kokke2015,
author = {Kokke, Pepijn and Swierstra, Wouter},
booktitle = {Mathematics of Program Construction. MPC 2015},
doi = {10.1007/978-3-319-19797-5_14},
editor = {Hinze, Ralf and Voigtl{\"{a}}nder, Janis},
file = {:Users/liang-tingchen/Dropbox/References/Kokke, Swierstra - 2015 - Auto in Agda.pdf:pdf},
isbn = {9783319197968},
issn = {16113349},
pages = {276--301},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Auto in Agda}},
url = {http://link.springer.com/10.1007/978-3-319-19797-5{\_}14},
volume = {9129},
year = {2015}
}
@article{Pouillard2010a,
abstract = {Abstract A wide range of computer programs, including compilers and theorem provers, manipulate data structures that involve and binding. However, the design of idioms which allow performing these manipulations in a safe and natural style has, to a large},
author = {Pouillard, Nicolas and Pottier, Fran{\c{c}}ois},
doi = {10.1145/1932681.1863575},
file = {:Users/liang-tingchen/Dropbox/References/Pouillard, Pottier - 2010 - A fresh look at programming with names and binders(2).pdf:pdf},
isbn = {9781605587943},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {3,binders,cannot be mixed,equivalent,higher-order abstract syntax,in increasing,meta-programming,name abstraction,names,names with different scopes,these slogans are not,we have listed them},
month = {sep},
number = {9},
pages = {217},
title = {{A fresh look at programming with names and binders}},
url = {http://portal.acm.org/citation.cfm?doid=1932681.1863575},
volume = {45},
year = {2010}
}
@article{Curien2005a,
abstract = {A calculation of dynamic polarizabilities of rovibrational states with vibrational quantum number {\$}v=0-7{\$} and rotational quantum number {\$}J=0,1{\$} in the 1s{\$}\backslashsigma{\_}g{\$} ground-state potential of HD{\$}{\^{}}+{\$} is presented. Polarizability contributions by transitions involving other 1s{\$}\backslashsigma{\_}g{\$} rovibrational states are explicitly calculated, whereas contributions by electronic transitions are treated quasi-statically and partially derived from existing data [R.E. Moss and L. Valenzano, $\backslash$textit{\{}Molec. Phys.{\}}, 2002, $\backslash$textbf{\{}100{\}}, 1527]. Our model is valid for wavelengths {\$}{\textgreater}4{\~{}}\backslashmu{\$}m and is used to to assess level shifts due to the blackbody radiation (BBR) electric field encountered in experimental high-resolution laser spectroscopy of trapped HD{\$}{\^{}}+{\$} ions. Polarizabilities of 1s{\$}\backslashsigma{\_}g{\$} rovibrational states obtained here agree with available existing accurate $\backslash$textit{\{}ab initio{\}} results. It is shown that the Stark effect due to BBR is dynamic and cannot be treated quasi-statically, as is often done in the case of atomic ions. Furthermore it is pointed out that the dynamic Stark shifts have tensorial character and depend strongly on the polarization state of the electric field. Numerical results of BBR-induced Stark shifts are presented, showing that Lamb-Dicke spectroscopy of narrow vibrational optical lines ({\$}\backslashsim 10{\$} Hz natural linewidth) in HD{\$}{\^{}}+{\$} will become affected by BBR shifts only at the {\$}10{\^{}}{\{}-16{\}}{\$} level.},
archivePrefix = {arXiv},
arxivId = {1106.1305},
author = {Curien, Pierre-Louis},
doi = {10.1039/C1CP21204D},
eprint = {1106.1305},
file = {:Users/liang-tingchen/Dropbox/References/Curien - 2005 - Introduction to linear logic and ludics, part II.pdf:pdf},
issn = {1463-9076},
keywords = {03b70,03f05,03f52,68n15,68q10,68q55,cut-elimination,in-,linear logic,logic in computer science,programming languages,semantics,teractive modes of computation},
pages = {1--49},
title = {{Introduction to linear logic and ludics, part II}},
url = {http://arxiv.org/abs/cs/0501039},
year = {2005}
}
@inproceedings{Wilkinson2012,
author = {Wilkinson, Toby},
booktitle = {Proceedings of the 11th International Workshop on Coalgebraic Methods in Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Wilkinson - 2012 - Internal Models for Coalgebraic Modal Logics.pdf:pdf},
title = {{Internal Models for Coalgebraic Modal Logics}},
year = {2012}
}
@article{Mitchell1991a,
author = {Mitchell, John C and Moggi, Eugenio},
doi = {10.1016/0168-0072(91)90067-V},
file = {:Users/liang-tingchen/Dropbox/References/Mitchell, Moggi - 1991 - Kripke-style models for typed lambda calculus.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
month = {mar},
number = {1-2},
pages = {99--124},
title = {{Kripke-style models for typed lambda calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/016800729190067V},
volume = {51},
year = {1991}
}
@article{Abbott2005,
abstract = {We introduce the notion of a Martin-L{\"{o}}f category - a locally cartesian closed category with disjoint coproducts and initial algebras of container functors (the categorical analogue of W-types) - and then establish that nested strictly positive inductive and coinductive types, which we call strictly positive types, exist in any Martin-L{\"{o}}f category. Central to our development are the notions of containers and container functors. These provide a new conceptual analysis of data structures and polymorphic functions by exploiting dependent type theory as a convenient way to define constructions in Martin-L{\"{o}}f categories. We also show that morphisms between containers can be full and faithfully interpreted as polymorphic functions (i.e. natural transformations) and that, in the presence of W-types, all strictly positive types (including nested inductive and coinductive types) give rise to containers. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Abbott, Michael and Altenkirch, Thorsten and Ghani, Neil},
doi = {10.1016/j.tcs.2005.06.002},
file = {:Users/liang-tingchen/Dropbox/References/Abbott, Altenkirch, Ghani - 2005 - Containers Constructing strictly positive types.pdf:pdf},
isbn = {03043975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Category theory,Coinduction,Container functors,Final coalgebras,Induction,Initial algebras,Type theory,W-Types},
month = {sep},
number = {1},
pages = {3--27},
title = {{Containers: Constructing strictly positive types}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397505003373},
volume = {342},
year = {2005}
}
@article{VanOosten2016,
abstract = {We show that every abstract Krivine structure in the sense of Streicher can be obtained, up to equivalence of the resulting tripos, from a filtered opca (A, Aʹ) and a subobject of 1 in the relative realizability topos RT(Aʹ, A); the topos is always a Boolean subtopos of RT(Aʹ, A). We exhibit a range of non-localic Boolean subtriposes of the Kleene-Vesley tripos.},
author = {van Oosten, Jaap and Zou, Tingxiang},
file = {:Users/liang-tingchen/Dropbox/References/van Oosten, Zou - 2016 - Classical and relative realizability.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Abstract Krivine structures,Geometric morphisms,Local operators,Non-Localic Boolean toposes,Partial combinatory algebras,Realizability toposes},
number = {22},
pages = {571--593},
title = {{Classical and relative realizability}},
volume = {31},
year = {2016}
}
@article{Jain2016,
abstract = {Report to the President of USA},
author = {Jain, Priyank and Gyanchandani, Manasi and Khare, Nilay},
doi = {10.1186/s40537-016-0059-y},
file = {:Users/liang-tingchen/Dropbox/References/Jain, Gyanchandani, Khare - 2016 - Big data privacy a technological perspective and review.pdf:pdf},
isbn = {9781633213982},
issn = {2196-1115},
journal = {Journal of Big Data},
keywords = {Big data,FADS,HybrEx,L-diversity,PPDP,Privacy and security,Privacy preserving: k-anonymity: T-closeness},
month = {dec},
number = {1},
pages = {25},
pmid = {2094938},
publisher = {Springer International Publishing},
title = {{Big data privacy: a technological perspective and review}},
url = {http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0059-y},
volume = {3},
year = {2016}
}
@book{Pitts2013,
author = {Pitts, Andrew M.},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 2013 - Nominal Sets.pdf:pdf},
isbn = {9781107017788},
month = {jul},
pages = {287},
publisher = {Cambridge University Press},
series = {Cambridge Tracts in Theoretical Computer Science},
title = {{Nominal Sets}},
year = {2013}
}
@article{Bonneau2015,
abstract = {Bitcoin has emerged as the most successful cryptographic currency in history. Within two years of its quiet launch in 2009, Bitcoin grew to comprise billions of dollars of economic value despite only cursory analysis of the system's design. Since then a growing literature has identified hidden-but-important properties of the system, discovered attacks, proposed promising alternatives, and singled out difficult future challenges. Meanwhile a large and vibrant open-source community has proposed and deployed numerous modifications and extensions. We provide the first systematic exposition Bitcoin and the many related cryptocurrencies or ‘altcoins.' Drawing from a scattered body of knowledge, we identify three key components of Bitcoin's design that can be decoupled. This enables a more insightful analysis of Bitcoin's properties and future stability. We map the design space for numerous proposed modifications, providing comparative analyses for alternative consensus mechanisms, currency allocation mechanisms, computational puzzles, and key management tools. We survey anonymity issues in Bitcoin and provide an evaluation framework for analyzing a variety of privacy-enhancing proposals. Finally we provide new insights on what we term disintermediation protocols, which absolve the need for trusted intermediaries in an interesting set of applications. We identify three general disintermediation strategies and provide a detailed comparison.},
author = {Bonneau, Joseph and Miller, Andrew and Clark, Jeremy and Narayanan, Arvind and Kroll, Joshua A. and Felten, Edward W.},
doi = {10.1109/SP.2015.14},
file = {:Users/liang-tingchen/Dropbox/References/Bonneau et al. - 2015 - SoK Research perspectives and challenges for bitcoin and cryptocurrencies.pdf:pdf},
isbn = {9781467369497},
issn = {10816011},
journal = {Proceedings - IEEE Symposium on Security and Privacy},
pages = {104--121},
title = {{SoK: Research perspectives and challenges for bitcoin and cryptocurrencies}},
volume = {2015-July},
year = {2015}
}
@article{Kupke2012,
abstract = {We study the finitary version of the coalgebraic logic introduced by L.{\~{}}Moss. The syntax of this logic, which is introduced uniformly with respect to a coalgebraic type functor, required to preserve weak pullbacks, extends that of classical propositional logic with a so-called coalgebraic cover modality depending on the type functor. Its semantics is defined in terms of a categorically defined relation lifting operation. As the main contributions of our paper we introduce a derivation system, and prove that it provides a sound and complete axiomatization for the collection of coalgebraically valid inequalities. Our soundness and completeness proof is algebraic, and we employ Pattinson's stratification method, showing that our derivation system can be stratified in countably many layers, corresponding to the modal depth of the formulas involved. In the proof of our main result we identify some new concepts and obtain some auxiliary results of independent interest. We survey properties of the notion of relation lifting, induced by an arbitrary but fixed set functor. We introduce a category of Boolean algebra presentations, and establish an adjunction between it and the category of Boolean algebras. Given the fact that our derivation system involves only formulas of depth one, it can be encoded as a endo-functor on Boolean algebras. We show that this functor is finitary and preserves embeddings, and we prove that the Lindenbaum-Tarski algebra of our logic can be identified with the initial algebra for this functor.},
author = {Kupke, Clemens and Kurz, Alexander and Venema, Yde},
doi = {10.2168/LMCS-8(3:2)2012},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Kurz, Venema - 2012 - Completeness for the coalgebraic cover modality.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,coalgebra,completeness,cover modality,modal logic,presenta-,relation lifting,relations,tions by generators and},
pages = {1--76},
title = {{Completeness for the coalgebraic cover modality}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=828{\&}layout=abstract{\&}sa=1{\&}cu=1},
volume = {8},
year = {2012}
}
@article{Jay1988,
abstract = {The concept of a local adjunction between bicategories A and B focuses on a family of adjunctions. B(FA, B)???A(A, GB) between hom-categories; hence the name local adjunction. When bicategories of spans, or (bi-)modules for some monoidal category are created, ordinary adjunctions induce local adjunctions between the resulting bicategories. Other examples include bi-adjunctions, lax adjunctions, strict quasi-adjunctions and monoidal adjunctions. ?? 1988.},
author = {Jay, C. Barry},
doi = {10.1016/0022-4049(88)90124-7},
file = {:Users/liang-tingchen/Dropbox/References/Jay - 1988 - Local adjunctions.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {sep},
number = {3},
pages = {227--238},
title = {{Local adjunctions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404988901247},
volume = {53},
year = {1988}
}
@article{Jirousek2018,
abstract = {We propose a new definition of entropy of basic probability assignments (BPAs) in the Dempster–Shafer (DS) theory of belief functions, which is interpreted as a measure of total uncertainty in the BPA. Our definition is different from those proposed by H{\"{o}}hle, Smets, Yager, Nguyen, Dubois–Prade, Lamata–Moral, Klir–Ramer, Klir–Parviz, Pal et al., Maeda–Ichihashi, Harmanec–Klir, Abell{\'{a}}n–Moral, Jousselme et al., Pouly et al., and Deng. We state a list of six desired properties of entropy for DS belief functions theory, four of which are motivated by Shannon's definition of entropy of probability functions, and the remaining two are requirements that adapt this measure to the philosophy of the DS theory. Three of our six desired properties are different from the five properties proposed by Klir and Wierman. We demonstrate that our definition satisfies all six properties in our list, whereas none of the existing definitions do. Our new definition has two components. The first component is Shannon's entropy of an equivalent probability mass function obtained using the plausibility transform, which constitutes the conflict measure of entropy. The second component is Dubois–Prade's definition of entropy of basic probability assignments in the DS theory, which constitutes the non-specificity measure of entropy. Our new definition is the sum of these two components. Our definition does not satisfy the subadditivity property. Whether there exists a definition that satisfies our six properties plus subadditivity remains an open question.},
author = {Jirou{\v{s}}ek, Radim and Shenoy, Prakash P.},
doi = {10.1016/j.ijar.2017.10.010},
file = {:Users/liang-tingchen/Dropbox/References/Jirou{\v{s}}ek, Shenoy - 2018 - A new definition of entropy of belief functions in the Dempster–Shafer theory.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Dempster's rule of combination,Dempster–Shafer theory of belief functions,Dempster–Shafer theory semantics,Maximum entropy property,Plausibility transform of a belief function},
month = {jan},
pages = {49--65},
publisher = {Elsevier Inc.},
title = {{A new definition of entropy of belief functions in the Dempster–Shafer theory}},
url = {https://doi.org/10.1016/j.ijar.2017.10.010 http://linkinghub.elsevier.com/retrieve/pii/S0888613X17300786},
volume = {92},
year = {2018}
}
@article{Altenkirch2015,
abstract = {We introduce a generalization of monads, called relative monads, allowing for underlying functors between different categories. Examples include finite-dimensional vector spaces, untyped and typed $\lambda$-calculus syntax and indexed containers. We show that the Kleisli and Eilenberg-Moore constructions carry over to relative monads and are related to relative adjunctions. Under reasonable assumptions, relative monads are monoids in the functor category concerned and extend to monads, giving rise to a coreflection between relative monads and monads. Arrows are also an instance of relative monads.},
author = {Altenkirch, Thorsten and Chapman, James and Uustalu, Tarmo},
doi = {10.2168/LMCS-11(1:3)2015},
editor = {Ong, Luke},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Chapman, Uustalu - 2015 - Monads need not be endofunctors.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Adjunctions,Hughes's arrows,Monads,Monoids,Skew-monoidal categories},
month = {mar},
number = {1},
pages = {1--40},
title = {{Monads need not be endofunctors}},
url = {https://lmcs.episciences.org/928},
volume = {11},
year = {2015}
}
@inproceedings{Kupke2004a,
author = {Kupke, Clemens and Kurz, Alexander and Pattinson, Dirk},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/j.entcs.2004.02.037},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Kurz, Pattinson - 2004 - Algebraic Semantics for Coalgebraic Logics.pdf:pdf},
issn = {15710661},
month = {dec},
pages = {219--241},
title = {{Algebraic Semantics for Coalgebraic Logics}},
type = {Journal article},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104051771},
volume = {106},
year = {2004}
}
@inproceedings{pitts:LIPIcs:2015:5498,
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Nominal Presentation of Cubical Sets Models of Type Theory - Pitts, Andrew M)

Keywords: models of dependent type theory, homotopy type theory, cubical sets, nominal sets, monoids},
author = {Pitts, Andrew M},
booktitle = {20th International Conference on Types for Proofs and Programs (TYPES 2014)},
doi = {10.4230/LIPIcs.TYPES.2014.202},
editor = {Herbelin, Hugo and Letouzey, Pierre and Sozeau, Matthieu},
file = {:Users/liang-tingchen/Dropbox/References//Pitts - 2014 - Nominal Presentation of Cubical Sets Models of Type Theory.pdf:pdf},
isbn = {978-3-939897-88-0},
issn = {1868-8969},
keywords = {4230,and phrases models of,cubical sets,dependent type theory,digital object identifier 10,homotopy type theory,lipics,monoids,nominal sets,p,xxx,yyy},
number = {September},
pages = {202--220},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Nominal Presentation of Cubical Sets Models of Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5498},
volume = {39},
year = {2014}
}
@article{Sterling2021b,
abstract = {The theory of program modules is of interest to language designers not only for its practical importance to programming, but also because it lies at the nexus of three fundamental concerns in language design: the phase distinction , computational effects , and type abstraction . We contribute a fresh “synthetic” take on program modules that treats modules as the fundamental constructs, in which the usual suspects of prior module calculi (kinds, constructors, dynamic programs) are rendered as derived notions in terms of a modal type-theoretic account of the phase distinction. We simplify the account of type abstraction (embodied in the generativity of module functors) through a lax modality that encapsulates computational effects, placing projectibility of module expressions on a type-theoretic basis.},
archivePrefix = {arXiv},
arxivId = {2010.08599},
author = {Sterling, Jonathan and Harper, Robert},
doi = {10.1145/3474834},
eprint = {2010.08599},
file = {:Users/liang-tingchen/Dropbox/References/Sterling, Harper - 2021 - Logical Relations as Types Proof-Relevant Parametricity for Program Modules.pdf:pdf},
issn = {0004-5411},
journal = {Journal of the ACM},
month = {dec},
number = {6},
pages = {1--47},
title = {{Logical Relations as Types: Proof-Relevant Parametricity for Program Modules}},
url = {https://dl.acm.org/doi/10.1145/3474834},
volume = {68},
year = {2021}
}
@article{Porst2011,
abstract = {We show that subobjects and quotients respectively of any object K in a locally finitely presentable category form an algebraic lattice. The same holds for the internal equivalence relations on K. In fact, these results turn out to be—at least in the case of subobjects—nothing but simple consequences of well known closure properties of the classes of locally finitely presentable categories and accessible categories, respectively. We thus get a completely categorical explanation of the well known fact that the subobject- and congruence lattices of algebras in finitary varieties are algebraic. Moreover we also obtain new natural examples: in particular, for any (not necessarily finitary) polynomial set-functor F, the subcoalgebras of an F-coalgebra form an algebraic lattice; the same holds for the lattices of regular congruences and quotients of these F-coalgebras.},
author = {Porst, Hans-E.},
doi = {10.1007/s00012-011-0129-0},
file = {:Users/liang-tingchen/Dropbox/References/Porst - 2011 - Algebraic lattices and locally finitely presentable categories.pdf:pdf},
issn = {0002-5240},
journal = {Algebra universalis},
keywords = {algebraic lattice,and phrases,congruence,hospitality of tshwane university,internal equivalence relation,is gratefully acknowledged,locally finitely presentable category,of technology,pretoria,quo-,subobject,tient},
month = {apr},
number = {3},
pages = {285--298},
title = {{Algebraic lattices and locally finitely presentable categories}},
url = {http://www.springerlink.com/index/10.1007/s00012-011-0129-0},
volume = {65},
year = {2011}
}
@article{Mellies2015,
abstract = {Any refinement system (= functor) has a fully faithful representation in the refinement system of presheaves, by interpreting types as relative slice categories, and refinement types as presheaves over those categories. Motivated by an analogy between side effects in programming and *context effects* in linear logic, we study logical aspects of this "positive" (covariant) representation, as well as of an associated "negative" (contravariant) representation. We establish several preservation properties for these representations, including a generalization of Day's embedding theorem for monoidal closed categories. Then we establish that the positive and negative representations satisfy an Isbell-style duality. As corollaries, we derive two different formulas for the positive representation of a pushforward (inspired by the classical negative translations of proof theory), which express it either as the dual of a pullback of a dual, or as the double dual of a pushforward. Besides explaining how these constructions on refinement systems generalize familiar category-theoretic ones (by viewing categories as special refinement systems), our main running examples involve representations of Hoare Logic and linear sequent calculus.},
archivePrefix = {arXiv},
arxivId = {1501.05115},
author = {Melli{\`{e}}s, Paul-Andr{\'{e}} and Zeilberger, Noam},
eprint = {1501.05115},
file = {:Users/liang-tingchen/Dropbox/References/Melli{\`{e}}s, Zeilberger - 2015 - An Isbell Duality Theorem for Type Refinement Systems.pdf:pdf},
journal = {ArXiv e-prints},
month = {jan},
pages = {1--35},
title = {{An Isbell Duality Theorem for Type Refinement Systems}},
url = {http://arxiv.org/abs/1501.05115},
year = {2015}
}
@article{Germane2014,
author = {GERMANE, KIMBALL and MIGHT, MATTHEW},
doi = {10.1017/S0956796814000227},
file = {:Users/liang-tingchen/Dropbox/References/GERMANE, MIGHT - 2014 - Deletion The curse of the red-black tree.pdf:pdf},
isbn = {8750122010},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {04},
pages = {423--433},
title = {{Deletion: The curse of the red-black tree}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796814000227},
volume = {24},
year = {2014}
}
@article{Pfenning2001a,
abstract = {We reconsider the foundations of modal logic, following Martin-Lof's methodology of distinguishing judgments from propositions. We give constructive meaning explanations for necessity and possibility, which yields a simple and uniform system of natural deduction for intuitionistic modal logic that does not exhibit anomalies found in other proposals. We also give a new presentation of lax logic and find that the lax modality is already expressible using possibility and necessity. Through a computational interpretation of proofs in modal logic we further obtain a new formulation of Moggi's monadic metalanguage. {\textcopyright} 2001, Cambridge University Press. All rights reserved.},
author = {Pfenning, Frank and Davies, Rowan},
doi = {10.1017/S0960129501003322},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning, Davies - 2001 - A judgmental reconstruction of modal logic(2).pdf:pdf},
isbn = {0960129501003},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {aug},
number = {04},
pages = {511--540},
title = {{A judgmental reconstruction of modal logic}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129501003322},
volume = {11},
year = {2001}
}
@article{ZILIANI2015a,
abstract = {Effective support for custom proof automation is essential for large-scale interactive proof development. However, existing languages for automation via tactics either (a) provide no way to specify the behavior of tactics within the base logic of the accompanying theorem prover, or (b) rely on advanced type-theoretic machinery that is not easily integrated into established theorem provers. We present Mtac, a lightweight but powerful extension to Coq that supports dependently typed tactic programming. Mtac tactics have access to all the features of ordinary Coq programming, as well as a new set of typed tactical primitives. We avoid the need to touch the trusted kernel typechecker of Coq by encapsulating uses of these new tactical primitives in a monad , and instrumenting Coq so that it executes monadic tactics during type inference.},
address = {New York, New York, USA},
author = {Ziliani, Beta and Dreyer, Derek and Krishnaswami, Neelakantan R. and Nanevski, Aleksandar and Vafeiadis, Viktor},
doi = {10.1145/2544174.2500579},
file = {:Users/liang-tingchen/Dropbox/References/Ziliani et al. - 2013 - Mtac A Monad for Typed Tactic Programming in Coq.pdf:pdf},
isbn = {9781450308656},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {coq,custom proof automation,interactive theorem proving,monads,tactics,typed meta-programming},
month = {nov},
number = {9},
pages = {87--100},
publisher = {ACM Press},
title = {{Mtac: A Monad for Typed Tactic Programming in Coq}},
url = {http://dl.acm.org/citation.cfm?doid=2034773.2034798 http://dl.acm.org/citation.cfm?doid=2544174.2500579},
volume = {48},
year = {2013}
}
@incollection{Rosebrugh1978,
author = {Rosebrugh, Robert},
booktitle = {Indexed Categories and Their Applications},
doi = {10.1007/BFb0061364},
file = {:Users/liang-tingchen/Dropbox/References/Rosebrugh - 1978 - Coequalizers in algebras for an internal type.pdf:pdf},
pages = {243--260},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Coequalizers in algebras for an internal type}},
year = {1978}
}
@article{Vardi2007,
author = {Vardi, Moshe Y},
doi = {10.1007/978-3-642-01702-5_2},
file = {:Users/liang-tingchen/Dropbox/References/Vardi - 2007 - Automata-theoretic model checking revisited.pdf:pdf},
isbn = {978-3-540-69735-0},
issn = {03029743},
journal = {Hardware and Software: Verification and Testing},
pages = {137--150},
title = {{Automata-theoretic model checking revisited}},
volume = {5394},
year = {2007}
}
@article{Ganz2001,
abstract = {With few exceptions, macros have traditionally been viewed as operations on syntax trees or even on plain strings. This view makes macros seem ad hoc, and is at odds with two desirable features of contemporary typed functional languages: static typing and static scoping. At a deeper level, there is a need for a simple, usable semantics for macros. This paper argues that these problems can be addressed by formally viewing macros as multi-stage computations. This view eliminates the need for freshness conditions and tests on variable names, and provides a compositional interpretation that can serve as a basis for designing a sound type system for languages supporting macros, or even for compilation. To illustrate our approach, we develop and present MacroML, an extension of ML that supports inlining, recursive macros, and the definition of new binding constructs. The latter is subtle, and is the most novel addition in a statically typed setting. The semantics of a core subset of MacroML is given by an interpretation into MetaML, a statically-typed multi-stage programming language. It is then easy to show that MacroML is stage- and type-safe: macro expansion does not depend on runtime evaluation, and both stages do not "go wrong.},
author = {Ganz, Steven E. and Sabry, Amr and Taha, Walid},
doi = {10.1145/507669.507646},
file = {:Users/liang-tingchen/Dropbox/References/Ganz, Sabry, Taha - 2001 - Macros as multi-stage computations.pdf:pdf},
isbn = {1581134150},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
month = {oct},
number = {10},
pages = {74--85},
title = {{Macros as multi-stage computations}},
url = {https://dl.acm.org/doi/10.1145/507669.507646},
volume = {36},
year = {2001}
}
@article{Bergner2006,
abstract = {In this paper we give a summary of the comparisons between different definitions of so-called ($\backslash$infty,1)-categories, which are considered to be models for $\backslash$infty-categories whose n-morphisms are all invertible for n{\textgreater}1. They are also, from the viewpoint of homotopy theory, models for the homotopy theory of homotopy theories. The four different structures, all of which are equivalent, are simplicial categories, Segal categories, complete Segal spaces, and quasi-categories.},
archivePrefix = {arXiv},
arxivId = {math/0610239},
author = {Bergner, Julia E},
eprint = {0610239},
file = {:Users/liang-tingchen/Dropbox/References/Bergner - 2006 - A survey of (infty, 1)-categories.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {13},
primaryClass = {math},
title = {{A survey of ($\backslash$infty, 1)-categories}},
url = {http://arxiv.org/abs/math/0610239},
year = {2006}
}
@incollection{Bun2016,
abstract = {“Concentrated differential privacy” was recently introduced by Dwork and Rothblum as a relaxation of differential privacy, which permits sharper analyses of many privacy-preserving computations. We present an alternative formulation of the concept of concentrated differential privacy in terms of the R{\'{e}}nyi divergence between the distributions obtained by running an algorithm on neighboring inputs. With this reformulation in hand, we prove sharper quantitative results, establish lower bounds, and raise a few new questions. We also unify this approach with approximate differential privacy by giving an appropriate definition of “approximate concentrated differential privacy”.},
author = {Bun, Mark and Steinke, Thomas},
booktitle = {Theory of Cryptography. TCC 2016},
doi = {10.1007/978-3-662-53641-4_24},
editor = {Hirt, Martin and Smith, Adam},
file = {:Users/liang-tingchen/Dropbox/References/Bun, Steinke - 2016 - Concentrated Differential Privacy Simplifications, Extensions, and Lower Bounds.pdf:pdf},
pages = {635--658},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds}},
url = {http://link.springer.com/10.1007/978-3-662-53641-4{\_}24},
volume = {9985},
year = {2016}
}
@inproceedings{Li2011,
abstract = {This paper aims at answering the following two questions in privacy-preserving data analysis and publishing: What formal privacy guarantee (if any) does {\$}k{\$}-anonymization provide? How to benefit from the adversary's uncertainty about the data? We have found that random sampling provides a connection that helps answer these two questions, as sampling can create uncertainty. The main result of the paper is that {\$}k{\$}-anonymization, when done "safely", and when preceded with a random sampling step, satisfies {\$}(\backslashepsilon,\backslashdelta){\$}-differential privacy with reasonable parameters. This result illustrates that "hiding in a crowd of {\$}k{\$}" indeed offers some privacy guarantees. This result also suggests an alternative approach to output perturbation for satisfying differential privacy: namely, adding a random sampling step in the beginning and pruning results that are too sensitive to change of a single tuple. Regarding the second question, we provide both positive and negative results. On the positive side, we show that adding a random-sampling pre-processing step to a differentially-private algorithm can greatly amplify the level of privacy protection. Hence, when given a dataset resulted from sampling, one can utilize a much large privacy budget. On the negative side, any privacy notion that takes advantage of the adversary's uncertainty likely does not compose. We discuss what these results imply in practice.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1101.2604},
author = {Li, Ninghui and Qardaji, Wahbeh and Su, Dong},
booktitle = {Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security - ASIACCS '12},
doi = {10.1145/2414456.2414474},
eprint = {1101.2604},
file = {:Users/liang-tingchen/Dropbox/References/Li, Qardaji, Su - 2012 - On sampling, anonymization, and differential privacy or, {\$}k{\$}-anonymization meets differential privacy.pdf:pdf},
isbn = {9781450316484},
keywords = {all or part of,anonymization,data privacy,differential privacy,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
pages = {32},
publisher = {ACM Press},
title = {{On sampling, anonymization, and differential privacy or, {\$}k{\$}-anonymization meets differential privacy}},
url = {http://arxiv.org/abs/1101.2604 http://dl.acm.org/citation.cfm?doid=2414456.2414474},
year = {2012}
}
@incollection{Kraus2013,
author = {Kraus, Nicolai and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel and Coquand, Thierry and Altenkirch, Thorsten},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2013},
doi = {10.1007/978-3-642-38946-7_14},
editor = {Hasegawa, Masahito},
file = {:Users/liang-tingchen/Dropbox/References/Kraus et al. - 2013 - Generalizations of Hedberg's Theorem.pdf:pdf},
keywords = {anonymous existence,bracket types,constant endofunctions,equality,hedberg,homotopy type theory,propositional,s theorem,squash types,truncation},
pages = {173--188},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generalizations of Hedberg's Theorem}},
url = {http://link.springer.com/10.1007/978-3-642-38946-7{\_}14},
volume = {7941},
year = {2013}
}
@article{Paulson1989,
author = {Paulson, Lawrence C.},
doi = {10.1007/BF00248324},
file = {:Users/liang-tingchen/Dropbox/References/Paulson - 1989 - The foundation of a generic theorem prover.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {higher-order logic,higher-order unification,isabelle,lcf,logical frameworks,meta-reasoning},
month = {sep},
number = {3},
pages = {363--397},
title = {{The foundation of a generic theorem prover}},
url = {http://link.springer.com/10.1007/BF00248324},
volume = {5},
year = {1989}
}
@incollection{Kinoshita1989,
author = {Kinoshita, Y. and Power, A. John},
booktitle = {Proceedings of the International Workshop on Extensions of Logic Programming},
doi = {10.1007/3-540-60983-0_12},
file = {:Users/liang-tingchen/Dropbox/References/Kinoshita, Power - 1989 - A fibrational semantics for logic programs.pdf:pdf},
isbn = {978-3-540-60983-4},
pages = {177--191},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A fibrational semantics for logic programs}},
year = {1989}
}
@incollection{Day1969,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Day, Brian J.},
booktitle = {Reports of the Midwest Category Seminar IV},
doi = {10.1007/BFb0060438},
editor = {{Mac Lane}, Saunders and Appelgate, Harry Wesley and Barr, Michael and Day, Brian J. and Dubuc, Eduardo J. and Phreilambud and Pultr, Ale{\v{s}} and Street, Ross and Tierney, Myles and {\'{S}}wierczkowski, Stanis{\l}aw},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/Day - 1970 - On closed categories of functors.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {1--38},
pmid = {25246403},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{On closed categories of functors}},
url = {http://link.springer.com/10.1007/BFb0060438},
volume = {137},
year = {1970}
}
@article{Leroy2009,
abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: The verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
author = {Leroy, Xavier},
doi = {10.1145/1538788.1538814},
file = {:Users/liang-tingchen/Dropbox/References/Leroy - 2009 - Formal verification of a realistic compiler.pdf:pdf},
issn = {0001-0782},
journal = {Communications of the ACM},
month = {jul},
number = {7},
pages = {107--115},
title = {{Formal verification of a realistic compiler}},
url = {https://dl.acm.org/doi/10.1145/1538788.1538814},
volume = {52},
year = {2009}
}
@book{MacKay2003,
abstract = {This book is aimed at senior undergraduates and graduate students in Engineering, Science, Mathematics, and Computing. It expects familiarity with calculus, probability theory, and linear algebra as taught in a rst- or secondyear undergraduate course on mathematics for scientists and engineers. Conventional courses on information theory cover not only the beautiful theoretical ideas of Shannon, but also practical solutions to communication problems. This book goes further, bringing in Bayesian data modelling, Monte Carlo methods, variational methods, clustering algorithms, and neural networks. Why unify information theory and machine learning? Because they are two sides of the same coin. In the 1960s, a single eld, cybernetics, was populated by information theorists, computer scientists, and neuroscientists, all studying common problems. Information theory and machine learning still belong together. Brains are the ultimate compression and communication systems. And the state-of-the-art algorithms for both data compression and error-correcting codes use the same tools as machine learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {MacKay, David J. C.},
doi = {10.1198/jasa.2005.s54},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/MacKay - 2003 - Information Theory, Inference {\&} Learning Algorithms.pdf:pdf},
isbn = {9780521642989},
issn = {01621459},
pages = {640},
pmid = {13217055},
publisher = {Cambridge University Press},
title = {{Information Theory, Inference {\&} Learning Algorithms}},
url = {http://pubs.amstat.org/doi/abs/10.1198/jasa.2005.s54{\%}5Cnhttp://www.cambridge.org/0521642981},
year = {2003}
}
@inproceedings{Schroder2010,
author = {Schr{\"{o}}der, Lutz and Pattinson, Dirk},
booktitle = {Proceedings of the Foundations of Software Science and Computational Structures},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Pattinson - 2010 - Coalgebraic correspondence theory.pdf:pdf},
pages = {328--342},
publisher = {Springer},
title = {{Coalgebraic correspondence theory}},
url = {http://www.springerlink.com/index/e78h061v0777l368.pdf},
year = {2010}
}
@inproceedings{Kesner2022,
address = {Dagstuhl, Germany},
annote = {Keywords: Call-by-Push-Value, Call-by-Name, Call-by-Value, Intersection Types},
author = {Kesner, Delia and Viso, Andr{\'{e}}s},
booktitle = {30th EACSL Annual Conference on Computer Science Logic (CSL 2022)},
doi = {10.4230/LIPIcs.CSL.2022.27},
editor = {Manea, Florin and Simpson, Alex},
file = {:Users/liang-tingchen/Dropbox/References/Kesner, Viso - 2022 - Encoding Tight Typing in a Unified Framework.pdf:pdf},
isbn = {978-3-95977-218-1},
issn = {1868-8969},
pages = {27:1----27:20},
publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Encoding Tight Typing in a Unified Framework}},
url = {https://drops.dagstuhl.de/opus/volltexte/2022/15747},
volume = {216},
year = {2022}
}
@article{Jaziri2014,
author = {Jaziri, Samy and Larsen, Kim G. and Mardare, Radu and Xue, Bingtian},
doi = {10.1016/j.entcs.2014.10.011},
file = {:Users/liang-tingchen/Dropbox/References/Jaziri et al. - 2014 - Adequacy and Complete Axiomatization for Timed Modal Logic.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {complete axiomatization,non-compact modal logics,timed modal logic},
pages = {183--210},
publisher = {Elsevier B.V.},
title = {{Adequacy and Complete Axiomatization for Timed Modal Logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066114000784},
volume = {308},
year = {2014}
}
@book{Aceto2007,
abstract = {Formal methods is the term used to describe the specification and verification of software and software systems using mathematical logic. Various methodologies have been developed and incorporated into software tools. An important subclass is distributed systems. There are many books that look at particular methodologies for such systems, e.g. CSP, process algebra. This book offers a more balanced introduction for graduate students that describes the various approaches, their strengths and weaknesses, and when they are best used. Milner's CCS and its operational semantics are introduced, together with notions of behavioural equivalence based on bisimulation techniques and with variants of Hennessy-Milner modal logics. Later in the book, the presented theories are extended to take timing issues into account. The book has arisen from various courses taught in Iceland and Denmark and is designed to give students a broad introduction to the area, with exercises throughout.},
annote = {NULL},
author = {Aceto, Luca and Ing{\'{o}}lfsd{\'{o}}ttir, Anna and Larsen, Kim Guldstrand and Srba, Jiri},
file = {:Users/liang-tingchen/Dropbox/References/Aceto et al. - 2007 - Reactive Systems Modelling, Specification and Verification.pdf:pdf},
isbn = {9780521875462},
pages = {302},
publisher = {Cambridge University Press},
title = {{Reactive Systems: Modelling, Specification and Verification}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Ju0HM-2RIwgC{\&}oi=fnd{\&}pg=PA261{\&}dq=Reactive+Systems+:+Modelling+,+Specification+and+Verification{\&}ots=zXDcdGJmcC{\&}sig=MlfuHOaGLK-tfgY74kaa{\_}8VTzoQ},
year = {2007}
}
@article{Allais2021,
abstract = {The syntax of almost every programming language includes a notion of binder and corresponding bound occurrences, along with the accompanying notions of $\alpha$-equivalence, capture-avoiding substitution, typing contexts, runtime environments, and so on. In the past, implementing and reasoning about programming languages required careful handling to maintain the correct behaviour of bound variables. Modern programming languages include features that enable constraints like scope safety to be expressed in types. Nevertheless, the programmer is still forced to write the same boilerplate over again for each new implementation of a scope-safe operation (e.g., renaming, substitution, desugaring, printing), and then again for correctness proofs. We present an expressive universe of syntaxes with binding and demonstrate how to (1) implement scope-safe traversals once and for all by generic programming; and (2) how to derive properties of these traversals by generic proving. Our universe description, generic traversals and proofs, and our examples have all been formalised in Agda and are available in the accompanying material available online at https://github.com/gallais/generic-syntax .},
archivePrefix = {arXiv},
arxivId = {2001.11001},
author = {Allais, Guillaume and Atkey, Robert and Chapman, James and McBride, Conor and McKinna, James},
doi = {10.1017/S0956796820000076},
eprint = {2001.11001},
file = {:Users/liang-tingchen/Dropbox/References/Allais et al. - 2021 - A type- and scope-safe universe of syntaxes with binding their semantics and proofs.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {oct},
number = {1996},
pages = {e22},
title = {{A type- and scope-safe universe of syntaxes with binding: their semantics and proofs}},
url = {https://www.cambridge.org/core/product/identifier/S0956796820000076/type/journal{\_}article},
volume = {31},
year = {2021}
}
@article{Weirich2017,
author = {Weirich, Stephanie and Voizard, Antoine and de Amorim, Pedro Henrique Azevedo and Eisenberg, Richard A.},
doi = {10.1145/3110275},
file = {:Users/liang-tingchen/Dropbox/References/Weirich et al. - 2017 - A specification for dependent types in Haskell.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Dependent Types,Haskell},
month = {aug},
number = {ICFP},
pages = {1--29},
title = {{A specification for dependent types in Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=3136534.3110275},
volume = {1},
year = {2017}
}
@incollection{Komendantskaya2016a,
author = {Komendantskaya, Ekaterina and Power, John},
booktitle = {Coalgebraic Methods in Computer Science. CMCS 2016},
doi = {10.1007/978-3-319-40370-0_7},
editor = {Hasuo, Ichiro},
file = {:Users/liang-tingchen/Dropbox/References/Komendantskaya, Power - 2016 - Category Theoretic Semantics for Theorem Proving in Logic Programming Embracing the Laxness.pdf:pdf},
isbn = {9783319403700},
keywords = {coalgebra,coinductive derivation tree,kan extensions,lawvere theories,lax transforma-,logic programming,term-matching resolu-,tion,tions},
pages = {94--113},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Category Theoretic Semantics for Theorem Proving in Logic Programming: Embracing the Laxness}},
url = {http://link.springer.com/10.1007/978-3-319-40370-0{\_}7},
volume = {9608},
year = {2016}
}
@phdthesis{Ringer2021,
author = {Ringer, Talia},
file = {:Users/liang-tingchen/Dropbox/References/Ringer - 2021 - Proof Repair.pdf:pdf},
school = {University of Washington},
title = {{Proof Repair}},
year = {2021}
}
@book{Bramer2005,
author = {Bramer, Max},
file = {:Users/liang-tingchen/Dropbox/References/Bramer - 2005 - Logic Programming with Prolog.pdf:pdf},
isbn = {9781852339388},
pages = {223},
publisher = {Springer},
title = {{Logic Programming with Prolog}},
year = {2005}
}
@incollection{Gehrke2011a,
abstract = {We put forward a zero-knowledge based definition of privacy. Our$\backslash$nnotion is strictly stronger than the notion of differential$\backslash$nprivacy and is particularly attractive when modeling privacy in$\backslash$nsocial networks. We furthermore demonstrate that it can be$\backslash$nmeaningfully achieved for tasks such as computing averages,$\backslash$nfractions, histograms, and a variety of graph parameters and$\backslash$nproperties, such as average degree and distance to connectivity.$\backslash$nOur results are obtained by establishing a connection between$\backslash$nzero-knowledge privacy and sample complexity, and by leveraging$\backslash$nrecent sublinear time algorithms.},
author = {Gehrke, Johannes and Lui, Edward and Pass, Rafael},
booktitle = {Theory of Cryptography. TCC 2011},
doi = {10.1007/978-3-642-19571-6_26},
editor = {Ishai, Yuval},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke, Lui, Pass - 2011 - Towards Privacy for Social Networks A Zero-Knowledge Based Definition of Privacy.pdf:pdf},
isbn = {9783642195709},
issn = {03029743},
pages = {432--449},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Towards Privacy for Social Networks: A Zero-Knowledge Based Definition of Privacy}},
url = {http://link.springer.com/10.1007/978-3-642-19571-6{\_}26},
volume = {6597},
year = {2011}
}
@inproceedings{Veltri2020,
abstract = {Dependent type theories with guarded recursion have shown themselves suitable for the development of denotational semantics of programming languages. In particular Ticked Cubical Type Theory (TCTT) has been used to show that for guarded labelled transition systems (GLTS) interpretation into the denotational semantics maps bisimilar processes to equal values. In fact the two notions are proved equivalent, allowing one to reason about equality in place of bisimilarity. We extend that result to the $\pi$-calculus, picking early congruence as the syntactic notion of equivalence between processes, showing that denotational models based on guarded recursive types can handle the dynamic creation of channels that goes beyond the scope of GLTSs. Hence we present a fully abstract denotational model for the early $\pi$-calculus, formalized as an extended example for Guarded Cubical Agda: a novel implementation of Ticked Cubical Type Theory based on Cubical Agda.},
address = {New York, NY, USA},
author = {Veltri, Niccol{\`{o}} and Vezzosi, Andrea},
booktitle = {Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs},
doi = {10.1145/3372885.3373814},
file = {:Users/liang-tingchen/Dropbox/References/Veltri, Vezzosi - 2020 - Formalizing $\pi$-calculus in guarded cubical Agda.pdf:pdf},
isbn = {9781450370974},
keywords = {Denotational semantics,Guarded recursion,Ticked cubical type theory,$\pi$-Calculus},
month = {jan},
pages = {270--283},
publisher = {ACM},
title = {{Formalizing $\pi$-calculus in guarded cubical Agda}},
url = {https://dl.acm.org/doi/10.1145/3372885.3373814},
year = {2020}
}
@inproceedings{Coull2013,
author = {Coull, Scott E. and Kenneally, Erin},
booktitle = {2013 IEEE International Conference on Technologies for Homeland Security (HST)},
doi = {10.1109/THS.2013.6698982},
file = {:Users/liang-tingchen/Dropbox/References/Coull, Kenneally - 2013 - Toward a comprehensive disclosure control framework for shared data.pdf:pdf},
isbn = {978-1-4799-1535-4},
month = {nov},
pages = {93--98},
publisher = {IEEE},
title = {{Toward a comprehensive disclosure control framework for shared data}},
url = {http://ieeexplore.ieee.org/document/6698982/},
year = {2013}
}
@inproceedings{Lammel2003,
abstract = {We describe a design pattern for writing programs that traverse data structures built from rich mutually-recursive data types. Such programs often have a great deal of "boilerplate" code that simply walks the structure, hiding a small amount of "real" code that constitutes the reason for the traversal.Our technique allows most of this boilerplate to be written once and for all, or even generated mechanically, leaving the programmer free to concentrate on the important part of the algorithm. These generic programs are much more adaptive when faced with data structure evolution because they contain many fewer lines of type-specific code.Our approach is simple to understand, reasonably efficient, and it handles all the data types found in conventional functional programming languages. It makes essential use of rank-2 polymorphism, an extension found in some implementations of Haskell. Further it relies on a simple type-safe cast operator.},
address = {New York, New York, USA},
author = {L{\"{a}}mmel, Ralf and Jones, Simon Peyton},
booktitle = {Proceedings of the 2003 ACM SIGPLAN international workshop on Types in languages design and implementation - TLDI '03},
doi = {10.1145/604174.604179},
file = {:Users/liang-tingchen/Dropbox/References/L{\"{a}}mmel, Jones - 2003 - Scrap your boilerplate.pdf:pdf},
isbn = {1581135262},
issn = {03621340},
keywords = {Generic programming,Rank-2 types,Traversal,Type cast},
month = {mar},
number = {3},
pages = {26},
publisher = {ACM Press},
title = {{Scrap your boilerplate}},
url = {http://portal.acm.org/citation.cfm?doid=640136.604179 http://portal.acm.org/citation.cfm?doid=604174.604179},
volume = {38},
year = {2003}
}
@article{Kelly1982a,
author = {Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1982 - Structures defined by finite limits in the enriched context, I.pdf:pdf},
journal = {Cahiers Topologie G{\'{e}}om. Diff{\'{e}}rentielle},
number = {1},
pages = {3--42},
title = {{Structures defined by finite limits in the enriched context, I}},
url = {https://eudml.org/doc/91287},
volume = {23},
year = {1982}
}
@incollection{Ryan2001,
abstract = {In this chapter I present a process algebraic approach to the modelling of security properties and policies. I will concentrate on the concept of secrecy, also known as confidentiality, and in particular on the notion of non-interference. Non-interference seeks to characterise the absence of information flows through a system and, as such, is a fundamental concept in information security. A central thesis of these lectures is that, viewed from a process algebraic point of view, the problem of characterising non-interference is essentially equivalent to that of characterising the equivalence of processes. The latter is itself a fundamental and delicate question at the heart of process algebra and indeed theoretical computer science: the semantics of a process is intimately linked to the question of which processes should be regarded as equivalent. We start, by way of motivation and to set the context, with a brief historical background. A much fuller exposition of security policies in the wider sense, embracing properties other than secrecy, can be found in the chapter by Pierangela Samarati in this volume. We then cover some elements of process algebra, in particular CSP (Communicating Sequential Processes), that we need and present a formulation of noninterference, along with some more operational presentations of process algebra, including the idea of bi-simulation. I argue that the classical notion of unwinding found in the security literature is really just bisimulation in another guise. Finally, I propose some generalisations of the process algebraic formulations designed to encompass a richer class of policies and examples.},
author = {Ryan, Peter Y. A.},
booktitle = {Foundations of Security Analysis and Design: Tutorial Lectures},
doi = {10.1007/3-540-45608-2_1},
file = {:Users/liang-tingchen/Dropbox/References/Ryan - 2001 - Mathematical models of computer security.pdf:pdf},
isbn = {978-3-540-45608-7},
pages = {1--62},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Mathematical models of computer security}},
url = {http://link.springer.com/10.1007/3-540-45608-2{\_}1},
volume = {2171},
year = {2001}
}
@inproceedings{Renyi1961,
abstract = {We shall investigate the relationships between the thermodynamic entropy and information theory and the implications that can be drawn for the arrow of time. This demands a careful study of classical thermodynamics and a review of its fundamental concepts. The statistical mechanical properties of time-dependent systems will be carefully studied, and the point at which the arrow of time appears will be described.},
archivePrefix = {arXiv},
arxivId = {1101.3070},
author = {R{\'{e}}nyi, Alfr{\'{e}}d},
booktitle = {Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability},
doi = {10.1021/jp106846b},
eprint = {1101.3070},
file = {:Users/liang-tingchen/Dropbox/References/R{\'{e}}nyi - 1961 - On measures of entropy and information.pdf:pdf},
isbn = {0097-0433},
issn = {15205207},
pages = {547--561},
pmid = {20961075},
title = {{On measures of entropy and information}},
url = {https://projecteuclid.org/euclid.bsmsp/1200512181},
volume = {1},
year = {1961}
}
@incollection{Hinze2007,
abstract = {The last decade has seen a number of approaches to datatype-generic programming: PolyP, Functorial ML, 'Scrap Your Boiler-plate', Generic Haskell, 'Generics for the Masses', and so on. The approaches vary in sophistication and target audience: some propose full-blown programming languages, some suggest libraries, some can be seen as categorical programming methods. In these lecture notes we compare the various approaches to datatype-generic programming in Haskell. We introduce each approach by means of example, and we evaluate it along different dimensions (expressivity, ease of use, and so on). {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Hinze, Ralf and Jeuring, Johan and L{\"{o}}h, Andres},
booktitle = {Datatype-Generic Programming. SSDGP 2006},
doi = {10.1007/978-3-540-76786-2_2},
editor = {Backhouse, Roland and Gibbons, Jeremy and Hinze, Ralf and Jeuring, Johan},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Jeuring, L{\"{o}}h - 2007 - Comparing Approaches to Generic Programming in Haskell.pdf:pdf},
isbn = {9783540767855},
issn = {16113349},
pages = {72--149},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Comparing Approaches to Generic Programming in Haskell}},
url = {http://link.springer.com/10.1007/978-3-540-76786-2{\_}2},
volume = {4719},
year = {2007}
}
@article{Hermida1998,
abstract = {We present a categorical logic formulation of induction and coinduction principles for reasoning about inductively and coinductively defined types. Our main results provide sufficient criteria for the validity of such principles: in the presence of comprehension, the induction principle for initial algebras is admissible, and dually, in the presence of quotient types, the coinduction principle for terminal coalgebras is admissible. After giving an alternative formulation of induction in terms of binary relations, we combine both principles and obtain a mixed induction/coinduction principle which allows us to reason about minimal solutionsX≅$\sigma$(X) whereXmay occur both positively and negatively in the type constructor $\sigma$. We further strengthen these logical principles to deal with contexts and prove that such strengthening is valid when the (abstract) logic we consider is contextually/functionally complete. All the main results follow from a basic result about adjunctions between “categories of algebras” (inserters).},
author = {Hermida, Claudio and Jacobs, Bart},
doi = {10.1006/inco.1998.2725},
file = {:Users/liang-tingchen/Dropbox/References/Hermida, Jacobs - 1998 - Structural induction and coinduction in a fibrational setting.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
number = {2},
pages = {107--152},
title = {{Structural induction and coinduction in a fibrational setting}},
url = {http://dx.doi.org/10.1006/inco.1998.2725 http://linkinghub.elsevier.com/retrieve/pii/S0890540198927250},
volume = {145},
year = {1998}
}
@book{Goldblatt1993a,
author = {Goldblatt, Robert},
file = {:Users/liang-tingchen/Dropbox/References/Goldblatt - 1993 - Mathematics of modality.pdf:pdf},
isbn = {1-881526-23-2},
publisher = {Center for the Study of Language and Information, Stanford},
series = {CSLI Lecture Notes},
title = {{Mathematics of modality}},
type = {Book},
year = {1993}
}
@article{Garc??a2010,
author = {{Guti{\'{e}}rrez Garc{\'{i}}a}, Javier and Mardones-P{\'{e}}rez, Iraide and {de Prada Vicente}, Mar{\'{i}}a Angeles and Zhang, Dexue},
doi = {10.1002/malq.200810044},
file = {:Users/liang-tingchen/Dropbox/References/Guti{\'{e}}rrez Garc{\'{i}}a et al. - 2010 - Fuzzy Galois connections categorically.pdf:pdf},
issn = {09425616},
journal = {Mathematical Logic Quarterly},
keywords = {??-adjunction,??-relation,Category enriched over a unital quantale,Contravariant fuzzy galois connection,Covariant fuzzy galois connection,Girard quantale,Unital quantale},
month = {mar},
number = {2},
pages = {131--147},
title = {{Fuzzy Galois connections categorically}},
url = {http://doi.wiley.com/10.1002/malq.200810044},
volume = {56},
year = {2010}
}
@article{Melquiond2012,
abstract = {The process of proving some mathematical theorems can be greatly reduced by relying on numerically-intensive computations with a certified arithmetic. This article presents a formalization of floating-point arithmetic that makes it possible to efficiently compute inside the proofs of the Coq system. This certified library is a multi-radix and multi-precision implementation free from underflow and overflow. It provides the basic arithmetic operators and a few elementary functions. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
author = {Melquiond, Guillaume},
doi = {10.1016/j.ic.2011.09.005},
file = {:Users/liang-tingchen/Dropbox/References/Melquiond - 2012 - Floating-point arithmetic in the Coq system.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Coq system,Floating-point arithmetic,Formal proofs},
month = {jul},
pages = {14--23},
publisher = {Elsevier Inc.},
title = {{Floating-point arithmetic in the Coq system}},
url = {http://dx.doi.org/10.1016/j.ic.2011.09.005 https://linkinghub.elsevier.com/retrieve/pii/S0890540112000739},
volume = {216},
year = {2012}
}
@article{Awodey2018a,
abstract = {It is sometimes convenient or useful in mathematics to treat isomorphic structures as the same. The recently proposed Univalence Axiom for the foundations of mathematics elevates this idea to a foundational principle in the setting of homotopy type theory. It provides a simple and precise way in which isomorphic structures can be identified. We explore the motivations and consequences, both mathematical and philosophical, of making such a new logical postulate.},
author = {Awodey, Steve},
doi = {10.1016/j.indag.2018.01.011},
file = {:Users/liang-tingchen/Dropbox/References/Awodey - 2018 - Univalence as a principle of logic.pdf:pdf},
issn = {00193577},
journal = {Indagationes Mathematicae},
month = {dec},
number = {6},
pages = {1497--1510},
publisher = {Elsevier B.V.},
title = {{Univalence as a principle of logic}},
url = {https://doi.org/10.1016/j.indag.2018.01.011 https://linkinghub.elsevier.com/retrieve/pii/S0019357718303227},
volume = {29},
year = {2018}
}
@article{Klin2016,
abstract = {We use modal logic as a framework for coalgebraic trace semantics, and show the flexibility of the approach with concrete examples such as the language semantics of weighted, alternating and tree automata, and the trace semantics of generative probabilistic systems. We provide a sufficient condition under which a logical semantics coincides with the trace semantics obtained via a given determinization construction. Finally, we consider a condition that guarantees the existence of a canonical determinization procedure that is correct with respect to a given logical semantics. That procedure is closely related to Brzozowski's minimization algorithm.},
archivePrefix = {arXiv},
arxivId = {1611.05183},
author = {Klin, Bartek and Rot, Jurriaan},
doi = {1611.05183},
eprint = {1611.05183},
file = {:Users/liang-tingchen/Dropbox/References/Klin, Rot - 2016 - Coalgebraic trace semantics via forgetful logics.pdf:pdf},
isbn = {9783642548611},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Algebraic theories,Equational logic,Rewriting,Soundness and completeness,Variable binding,$\alpha$-equivalence},
month = {nov},
number = {3},
pages = {1--34},
title = {{Coalgebraic trace semantics via forgetful logics}},
url = {http://arxiv.org/abs/1611.05183},
volume = {7},
year = {2016}
}
@article{Mellies2017,
author = {Melli{\`{e}}s, Paul Andr{\'{e}}},
doi = {10.1017/S0960129515000328},
file = {:Users/liang-tingchen/Dropbox/References/Melli{\`{e}}s - 2017 - The parametric continuation monad.pdf:pdf},
isbn = {0960129515000},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
number = {5},
pages = {651--680},
title = {{The parametric continuation monad}},
volume = {27},
year = {2017}
}
@article{Vytiniotis2010,
abstract = {Propositions that express type equality are a frequent ingredient of modern functional programming – they can encode generic functions, dynamic types, and GADTs. Via the Curry–Howard correspondence, these propositions are ordinary types inhabited by proof terms , computed using runtime type representations. In this paper we show that two examples of type equality propositions actually do reflect type equality; they are only inhabited when their arguments are equal and their proofs are unique (up to equivalence.) We show this result in the context of a strongly normalizing language with higher-order polymorphism and primitive recursion over runtime-type representations by proving Reynolds's abstraction theorem. We then use this theorem to derive “free” theorems about equality types.},
author = {Vytiniotis, Dimitrios and Weirich, Stephanie},
doi = {10.1017/S0956796810000079},
file = {:Users/liang-tingchen/Dropbox/References/Vytiniotis, Weirich - 2010 - Parametricity, type equality, and higher-order polymorphism.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {175--210},
title = {{Parametricity, type equality, and higher-order polymorphism}},
url = {https://www.cambridge.org/core/product/identifier/S0956796810000079/type/journal{\_}article},
volume = {20},
year = {2010}
}
@article{Bloom1983,
author = {Bloom, Stephen L. and Wright, Jesse B.},
doi = {10.1016/0022-4049(83)90080-4},
file = {:Users/liang-tingchen/Dropbox/References/Bloom, Wright - 1983 - P-varieties - a signature independent characterization of varieties of ordered algebras.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jul},
number = {1},
pages = {13--58},
title = {{P-varieties - a signature independent characterization of varieties of ordered algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404983900804},
volume = {29},
year = {1983}
}
@article{Coumans2012a,
abstract = {Canonical extension has proven to be a powerful tool in algebraic study of propositional logics. In this paper we describe a generalisation of the theory of canonical extension to the setting of first order logic. We define a notion of canonical extension for coherent categories. These are the categorical analogues of distributive lattices and they provide categorical semantics for coherent logic, the fragment of first order logic in the connectives ???, ???, 0, 1 and ???. We describe a universal property of our construction and show that it generalises the existing notion of canonical extension for distributive lattices. Our new construction for coherent categories has led us to an alternative description of the topos of types, introduced by Makkai (1981) in [22]. This allows us to give new and transparent proofs of some properties of the action of the topos of types construction on morphisms. Furthermore, we prove a new result relating, for a coherent category C, its topos of types to its category of models (in Set). ?? 2012 Elsevier B.V.},
author = {Coumans, Dion},
doi = {10.1016/j.apal.2012.07.002},
file = {:Users/liang-tingchen/Dropbox/References/Coumans - 2012 - Generalising canonical extension to the categorical setting.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Canonical extension,Coherent categories,Topos of types},
month = {dec},
number = {12},
pages = {1940--1961},
publisher = {Elsevier B.V.},
title = {{Generalising canonical extension to the categorical setting}},
url = {http://dx.doi.org/10.1016/j.apal.2012.07.002 http://linkinghub.elsevier.com/retrieve/pii/S016800721200108X},
volume = {163},
year = {2012}
}
@book{Achten,
address = {Berlin, Heidelberg},
author = {Achten, Peter and Eds, Pieter Koopman and Hutchison, David},
doi = {10.1007/978-3-642-40355-2},
editor = {Achten, Peter and Koopman, Pieter},
file = {:Users/liang-tingchen/Dropbox/References/Achten, Eds, Hutchison - 2013 - The Beauty of Functional Code.pdf:pdf},
isbn = {978-3-642-40354-5},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Beauty of Functional Code}},
url = {http://link.springer.com/10.1007/978-3-642-40355-2},
volume = {8106},
year = {2013}
}
@article{Klin2011,
author = {Klin, Bartek},
doi = {10.1016/j.tcs.2011.03.023},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2011 - Bialgebras for structural operational semantics An introduction.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {structural operational semantics},
month = {sep},
number = {38},
pages = {5043--5069},
publisher = {Elsevier B.V.},
title = {{Bialgebras for structural operational semantics: An introduction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397511002532},
volume = {412},
year = {2011}
}
@article{Urban2004,
author = {Urban, Christian and Pitts, Andrew M. and Gabbay, Murdoch J.},
doi = {10.1016/j.tcs.2004.06.016},
file = {:Users/liang-tingchen/Dropbox/References/Urban, Pitts, Gabbay - 2004 - Nominal unification.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {abstract syntax,alpha-conversion,binding operations,uni{\"{y}}cation},
month = {sep},
number = {1-3},
pages = {473--497},
title = {{Nominal unification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397504004013},
volume = {323},
year = {2004}
}
@article{Flatt2012,
abstract = {Racket is a large language that is built mostly within itself. Unlike the usual approach taken by non-Lisp languages, the self-hosting of Racket is not a matter of bootstrapping one implementation through a previous implementation, but instead a matter of building a tower of languages and libraries via macros. The upper layers of the tower include a class system, a component system, pedagogic variants of Scheme, a statically typed dialect of Scheme, and more. The demands of this language-construction effort require a macro system that is substantially more expressive than previous macro systems. In particular, while conventional Scheme macro systems handle stand-alone syntactic forms adequately, they provide weak support for macros that share information or macros that use existing syntactic forms in new contexts. This paper describes and models features of the Racket macro system, including support for general compile-time bindings, sub-form expansion and analysis, and environment management. The presentation assumes a basic familiarity with Lisp-style macros, and it takes for granted the need for macros that respect lexical scope. The model, however, strips away the pattern and template system that is normally associated with Scheme macros, isolating a core that is simpler, can support pattern and template forms themselves as macros, and generalizes naturally to Racket's other extensions.},
author = {FLATT, MATTHEW and CULPEPPER, RYAN and DARAIS, DAVID and FINDLER, ROBERT BRUCE},
doi = {10.1017/S0956796812000093},
file = {:Users/liang-tingchen/Dropbox/References/FLATT et al. - 2012 - Macros that Work Together.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {181--216},
title = {{Macros that Work Together}},
url = {https://www.cambridge.org/core/product/identifier/S0956796812000093/type/journal{\_}article},
volume = {22},
year = {2012}
}
@article{Wong2009,
abstract = {Data publishing generates much concern over the protection of individual privacy. Recent studies consider cases where the adversary may possess different kinds of knowledge about the data. In this article, we show that knowledge of the mechanism or algorithm of anonymization for data publication can also lead to extra information that assists the adversary and jeopardizes individual privacy. In particular, all known mechanisms try to minimize information loss and such an attempt provides a loophole for attacks. We call such an attack a minimality attack. In this article, we introduce a model called m-confidentiality which deals with minimality attacks, and propose a feasible solution. Our experiments show that minimality attacks are practical concerns on real datasets and that our algorithm can prevent such attacks with very little overhead and information loss.},
author = {Wong, Raymond Chi-wing and Fu, ADA Wai-chee and Wang, KE and Pei, Jian},
doi = {10.1145/1538909.1538910},
file = {:Users/liang-tingchen/Dropbox/References/Wong et al. - 2009 - Anonymization-Based Attacks in Privacy-Preserving Data Publishing.pdf:pdf},
journal = {Journal ACM Transactions on Database Systems},
number = {2},
title = {{Anonymization-Based Attacks in Privacy-Preserving Data Publishing}},
url = {https://dl.acm.org/citation.cfm?doid=1538909.1538910},
volume = {34},
year = {2009}
}
@incollection{Hyland1982,
abstract = {This chapter describes the most accessible of the series of toposes that can be constructed from notions of realizability: it is that based on the original notion of recursive realizability and presents the abstract approach to recursive realizability in some detail. The chapter introduces effective topos and discusses the notion of a negative formula that arises naturally in the theory of sheaves. The chapter presents features of effective topos, where the power-set matters: uniformity principles and properties of j-operators. The chapter recommends that while constructing a topos from a tripos, one must add new subobjects of the sets one has started with to represent the nonstandard predicates and take quotients of these by the nonstandard equivalence relations. {\textcopyright} 1982 North-Holland Publishing Company, Amsterdam},
author = {Hyland, J.M.E.},
booktitle = {Studies in Logic and the Foundations of Mathematics},
doi = {10.1016/S0049-237X(09)70129-6},
file = {:Users/liang-tingchen/Dropbox/References/Hyland - 1982 - The Effective Topos.pdf:pdf},
issn = {0049237X},
number = {C},
pages = {165--216},
publisher = {North-Holland Publishing Company, Amsterdam},
title = {{The Effective Topos}},
url = {http://dx.doi.org/10.1016/S0049-237X(09)70129-6 https://linkinghub.elsevier.com/retrieve/pii/S0049237X09701296},
volume = {110},
year = {1982}
}
@article{Lambek1968,
author = {Lambek, Joachim},
doi = {10.1007/BF01703261},
file = {:Users/liang-tingchen/Dropbox/References/Lambek - 1968 - Deductive systems and categories.pdf:pdf},
issn = {0025-5661},
journal = {Mathematical Systems Theory},
month = {dec},
number = {4},
pages = {287--318},
publisher = {Springer-Verlag},
title = {{Deductive systems and categories}},
url = {http://link.springer.com/10.1007/BF01703261},
volume = {2},
year = {1968}
}
@book{Dalen2004,
address = {Berlin, Heidelberg},
author = {van Dalen, Dirk},
doi = {10.1007/978-3-540-85108-0},
file = {:Users/liang-tingchen/Dropbox/References/Dalen - 2004 - Logic and Structure.pdf:pdf},
isbn = {978-3-540-20879-2},
publisher = {Springer Berlin Heidelberg},
series = {Universitext},
title = {{Logic and Structure}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-85108-0},
year = {2004}
}
@article{Pretnar2015a,
abstract = {This paper is a tutorial on algebraic effects and handlers. In it, we explain what algebraic effects are, give ample examples to explain how handlers work, define an operational semantics and a type {\&} effect system, show how one can reason about effects, and give pointers for further reading.},
author = {Pretnar, Matija},
doi = {10.1016/j.entcs.2015.12.003},
file = {:Users/liang-tingchen/Dropbox/References/Pretnar - 2015 - An Introduction to Algebraic Effects and Handlers. Invited tutorial paper.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {algebraic effects,effect system,handlers,logic,semantics,tutorial},
month = {dec},
pages = {19--35},
publisher = {Elsevier B.V.},
title = {{An Introduction to Algebraic Effects and Handlers. Invited tutorial paper}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.12.003 https://linkinghub.elsevier.com/retrieve/pii/S1571066115000705},
volume = {319},
year = {2015}
}
@incollection{Hennessy1980,
author = {Hennessy, Matthew and Milner, Robin},
booktitle = {Automata, Languages and Programming, 7th Colloquium, Noordweijkerhout, The Netherland, July 14-18, 1980, Proceedings},
doi = {10.1007/3-540-10003-2_79},
editor = {Bakker, Jaco and Leeuwen, Jan},
file = {:Users/liang-tingchen/Dropbox/References/Hennessy, Milner - 1980 - On observing nondeterminism and concurrency.pdf:pdf},
isbn = {978-3-540-10003-4},
pages = {299--309},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On observing nondeterminism and concurrency}},
url = {http://dx.doi.org/10.1007/3-540-10003-2{\_}79},
volume = {85},
year = {1980}
}
@article{Svenningsson2015,
abstract = {We present a technique to combine deep and shallow embedding in the context of compiling embedded languages in order to provide the benefits of both techniques. When compiling embedded languages it is natural to use an abstract syntax tree to represent programs. This is known as a deep embedding and it is a rather cumbersome technique compared to other forms of embedding, typically leading to more code and being harder to extend. In shallow embeddings, language constructs are mapped directly to their semantics which yields more flexible and succinct implementations. But shallow embeddings are not well-suited for compiling embedded languages. Our technique uses a combination of deep and shallow embedding, which helps keeping the deep embedding small and makes extending the embedded language much easier. The technique also has some unexpected but welcome secondary effects. It provides fusion of functions to remove intermediate results for free without any additional effort. It also helps us to give the embedded language a more natural programming interface.},
author = {Svenningsson, Josef and Axelsson, Emil},
doi = {10.1016/j.cl.2015.07.003},
file = {:Users/liang-tingchen/Dropbox/References/Svenningsson, Axelsson - 2015 - Combining deep and shallow embedding of domain-specific languages.pdf:pdf},
issn = {14778424},
journal = {Computer Languages, Systems {\&} Structures},
keywords = {Deep embedding,Domain specific languages,Fusion,Monads,Shallow embedding},
month = {dec},
pages = {143--165},
publisher = {Elsevier},
title = {{Combining deep and shallow embedding of domain-specific languages}},
url = {http://dx.doi.org/10.1016/j.cl.2015.07.003 https://linkinghub.elsevier.com/retrieve/pii/S1477842415000500},
volume = {44},
year = {2015}
}
@article{Abramsky1994b,
author = {Abramsky, Samson and Jagadeesan, R.},
doi = {10.1006/inco.1994.1041},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky, Jagadeesan - 1994 - New Foundations for the Geometry of Interaction.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {may},
number = {1},
pages = {53--119},
title = {{New Foundations for the Geometry of Interaction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540184710418},
volume = {111},
year = {1994}
}
@article{Kurz2010a,
author = {Kurz, Alexander and Palmigiano, Alessandra and Venema, Yde},
doi = {10.1093/logcom/exn094},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Palmigiano, Venema - 2010 - Coalgebra and Logic A Brief Overview.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
month = {sep},
number = {5},
pages = {985--990},
title = {{Coalgebra and Logic: A Brief Overview}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exn094},
volume = {20},
year = {2010}
}
@article{Petricek2012,
abstract = {Sequencing of effectful computations can be neatly captured using monads and elegantly written using do notation. In practice such monads often allow additional ways of composing computations, which have to be written explicitly using combinators. We identify joinads, an abstract notion of computation that is stronger than monads and captures many such ad-hoc extensions. In particular, joinads are monads with three additional operations: one of type m a → m b → m (a,b) captures various forms of parallel composition, one of type m a → m a → m a that is inspired by choice and one of type m a → m (m a) that captures aliasing of computations. Algebraically, the first two operations form a near-semiring with commutative multiplication. We introduce docase notation that can be viewed as a monadic version of case. Joinad laws imply various syntactic equivalences of programs written using docase that are analogous to equiva- lences about case. Examples of joinads that benefit from the nota- tion include speculative parallelism, waiting for a combination of user interface events, but also encoding of validation rules using the intersection of parsers.},
author = {Petricek, Tomas and Mycroft, Alan and Syme, Don},
doi = {10.1145/2096148.2034677},
file = {:Users/liang-tingchen/Dropbox/References/Petricek, Mycroft, Syme - 2012 - Extending monads with pattern matching.pdf:pdf},
isbn = {9781450308601},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {jan},
number = {12},
pages = {1},
title = {{Extending monads with pattern matching}},
url = {http://dl.acm.org/citation.cfm?doid=2096148.2034677},
volume = {46},
year = {2012}
}
@article{Rosicky1981a,
author = {Rosick{\'{y}}, Jiř{\'{i}}},
file = {:Users/liang-tingchen/Dropbox/References/Rosick{\'{y}} - 1981 - Equational categories.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {1},
pages = {85--95},
title = {{Equational categories}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1981{\_}{\_}22{\_}1{\_}85{\_}0},
volume = {22},
year = {1981}
}
@article{Kaposi2020a,
abstract = {Higher inductive-inductive types (HIITs) generalize inductive types of dependent type theories in two ways. On the one hand they allow the simultaneous definition of multiple sorts that can be indexed over each other. On the other hand they support equality constructors, thus generalizing higher inductive types of homotopy type theory. Examples that make use of both features are the Cauchy real numbers and the well-typed syntax of type theory where conversion rules are given as equality constructors. In this paper we propose a general definition of HIITs using a small type theory, named the theory of signatures. A context in this theory encodes a HIIT by listing the constructors. We also compute notions of induction and recursion for HIITs by using variants of syntactic logical relation translations. Building full categorical semantics and constructing initial algebras is left for future work. The theory of HIIT signatures was formalised in Agda together with the syntactic translations. We also provide a Haskell implementation, which takes signatures as input and outputs translation results as valid Agda code.},
archivePrefix = {arXiv},
arxivId = {1902.00297},
author = {Kaposi, Ambrus and Kov{\'{a}}cs, Andr{\'{a}}s},
doi = {10.23638/LMCS-16(1:10)2020},
eprint = {1902.00297},
file = {:Users/liang-tingchen/Dropbox/References/Kaposi, Kov{\'{a}}cs - 2020 - Signatures and induction principles for higher inductive-inductive types.pdf:pdf},
isbn = {1620170000},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Higher inductive types,Homotopy type theory,Inductive types},
number = {1},
pages = {10:1--10:30},
title = {{Signatures and induction principles for higher inductive-inductive types}},
volume = {16},
year = {2020}
}
@incollection{Fiadeiro2018,
author = {Fiadeiro, Jos{\'{e}} and Ţuţu, Ionuţ and Lopes, Ant{\'{o}}nia and Pavlovic, Dusko},
booktitle = {Dynamic Logic. New Trends and Applications. DALI 2017},
doi = {10.1007/978-3-319-73579-5_7},
editor = {Madeira, Alexandre and Benevides, M{\'{a}}rio},
file = {:Users/liang-tingchen/Dropbox/References/Fiadeiro et al. - 2018 - Logics for Actor Networks A Case Study in Constrained Hybridization.pdf:pdf},
isbn = {978-3-319-73578-8},
pages = {98--114},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Logics for Actor Networks: A Case Study in Constrained Hybridization}},
url = {http://link.springer.com/10.1007/978-3-319-73579-5 http://link.springer.com/10.1007/978-3-319-73579-5{\_}7},
volume = {10669},
year = {2018}
}
@article{Stansifer2016,
abstract = {Current systems for safely manipulating values containing names only support simple binding structures for those names. As a result, few tools exist to safely manipulate code in those languages for which name problems are the most challenging. We address this problem with Romeo, a language that respects $\alpha$-equivalence on its values, and which has access to a rich specification language for binding, inspired by attribute grammars. Our work has the complex-binding support of David Herman's $\lambda$ m , but is a full-fledged binding-safe language like Pure FreshML.},
author = {Stansifer, Paul and Wand, Mitchell},
doi = {10.1017/S0956796816000137},
file = {:Users/liang-tingchen/Dropbox/References/Stansifer, Wand - 2016 - Romeo A system for more flexible binding-safe programming.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {c},
pages = {e13},
title = {{Romeo: A system for more flexible binding-safe programming}},
url = {https://www.cambridge.org/core/product/identifier/S0956796816000137/type/journal{\_}article},
volume = {26},
year = {2016}
}
@article{Street1978,
author = {Street, Ross and Walters, Robert},
doi = {10.1016/0021-8693(78)90160-6},
file = {:Users/liang-tingchen/Dropbox/References/Street, Walters - 1978 - Yoneda structures on 2-categories.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
number = {1978},
pages = {350--379},
title = {{Yoneda structures on 2-categories}},
volume = {50},
year = {1978}
}
@article{Milius2018,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Moss, Lawrence S.},
doi = {10.1016/j.jlamp.2017.11.003},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Moss - 2018 - Fixed points of functors.pdf:pdf},
issn = {23522208},
journal = {Journal of Logical and Algebraic Methods in Programming},
keywords = {fixed points of functors},
month = {feb},
pages = {41--81},
title = {{Fixed points of functors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2352220816301201},
volume = {95},
year = {2018}
}
@incollection{Esik2002,
author = {{\'{E}}sik, Zolt{\'{a}}n and Lei$\beta$, Hans},
booktitle = {Computer Science Logic. CSL 2002},
doi = {10.1007/3-540-45793-3_10},
editor = {Bradfield, Julian},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik, Lei$\beta$ - 2002 - Greibach Normal Form in Algebraically Complete Semirings.pdf:pdf},
keywords = {al-,context-free languages,conway algebra,equational theory,gebraically complete semirings,greibach normal form,kleene algebra,point induction,pre-fixed-},
pages = {135--150},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Greibach Normal Form in Algebraically Complete Semirings}},
url = {http://link.springer.com/10.1007/3-540-45793-3{\_}10},
volume = {2471},
year = {2002}
}
@article{Kelly2016,
author = {Kelly, Kevin T. and Genin, Konstantin and Lin, Hanti},
doi = {10.1007/s11229-015-0993-9},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Genin, Lin - 2016 - Realism, rhetoric, and reliability.pdf:pdf},
issn = {15730964},
journal = {Synthese},
keywords = {Epistemic justification,Learning,Ockham's Razor,Simplicity,Testability,Topology},
number = {4},
pages = {1191--1223},
publisher = {Springer Netherlands},
title = {{Realism, rhetoric, and reliability}},
volume = {193},
year = {2016}
}
@article{Dunn1995,
author = {Dunn, J. Michael},
doi = {10.1007/BF01061239},
file = {:Users/liang-tingchen/Dropbox/References/Dunn - 1995 - Positive modal logic.pdf:pdf},
journal = {Studia Logica},
number = {2},
pages = {301--317},
title = {{Positive modal logic}},
url = {http://www.jstor.org/stable/20015820},
volume = {55},
year = {1995}
}
@article{Kelly1989,
author = {Kelly, Gregory Maxwell},
doi = {10.1017/S0004972700002781},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1989 - Elementary observations on 2-categorical limits.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
month = {apr},
number = {02},
pages = {301--317},
title = {{Elementary observations on 2-categorical limits}},
url = {http://www.journals.cambridge.org/abstract{\_}S0004972700002781},
volume = {39},
year = {1989}
}
@incollection{Jacobs1996,
author = {Jacobs, Bart},
booktitle = {Object Orientation with Parallelism and Persistence},
doi = {10.1007/978-1-4613-1437-0_5},
editor = {Freitag, B. and Jones, C.B. and Lengauer, C. and Schek, HJ.},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 1996 - Objects And Classes, Co-Algebraically.pdf:pdf},
pages = {83--103},
publisher = {Springer, Boston, MA},
series = {The Kluwer International Series in Engineering and Computer Science},
title = {{Objects And Classes, Co-Algebraically}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Objects+and+classes,+co-algebraically{\#}0 http://link.springer.com/10.1007/978-1-4613-1437-0{\_}5},
volume = {370},
year = {1996}
}
@incollection{Sheard1999,
author = {Sheard, Tim},
booktitle = {Advanced Functional Programming. AFP 1998},
doi = {10.1007/10704973_5},
editor = {Swierstra, S. Doaitse and Oliveira, Jos{\'{e}} N. and Henriques, Pedro R.},
file = {:Users/liang-tingchen/Dropbox/References/Sheard - 1999 - Using MetaML A Staged Programming Language.pdf:pdf},
pages = {207--239},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Using MetaML: A Staged Programming Language}},
url = {http://link.springer.com/10.1007/10704973{\_}5},
volume = {1608},
year = {1999}
}
@inproceedings{Enqvist2016,
author = {Enqvist, Sebastian and Seifan, Fatemeh and Venema, Yde},
booktitle = {25th EACSL Annual Conference on Computer Science Logic},
doi = {10.4230/LIPIcs.CSL.2016.7},
editor = {Talbot, Jean-Marc and Regnier, Laurent},
file = {:Users/liang-tingchen/Dropbox/References/Enqvist, Seifan, Venema - 2016 - Completeness for coalgebraic fixpoint logic.pdf:pdf},
isbn = {978-3-95977-022-4},
issn = {1868-8969},
keywords = {2016,4230,7,and phrases µ -calculus,automata,coalgebra,coalgebraic modal logic,completeness,csl,digital object identifier 10,lipics},
pages = {7:1--7:19},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{Completeness for coalgebraic fixpoint logic}},
volume = {62},
year = {2016}
}
@inproceedings{kovacs:LIPIcs.CSL.2022.28,
abstract = {In type theories, universe hierarchies are commonly used to increase the expressive power of the theory while avoiding inconsistencies arising from size issues. There are numerous ways to specify universe hierarchies, and theories may differ in details of cumulativity, choice of universe levels, specification of type formers and eliminators, and available internal operations on levels. In the current work, we aim to provide a framework which covers a large part of the design space. First, we develop syntax and semantics for cumulative universe hierarchies, where levels may come from any set equipped with a transitive well-founded ordering. In the semantics, we show that induction-recursion can be used to model transfinite hierarchies, and also support lifting operations on type codes which strictly preserve type formers. Then, we consider a setup where universe levels are first-class types and subject to arbitrary internal reasoning. This generalizes the bounded polymorphism features of Coq and at the same time the internal level computations in Agda.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Generalized Universe Hierarchies and First-Class Universe Levels - Kov{\'{a}}cs, Andr{\'{a}}s)

Keywords: type theory, universes},
archivePrefix = {arXiv},
arxivId = {2103.00223},
author = {Kov{\'{a}}cs, Andr{\'{a}}s},
booktitle = {30th EACSL Annual Conference on Computer Science Logic (CSL 2022)},
doi = {10.4230/LIPIcs.CSL.2022.28},
editor = {Manea, Florin and Simpson, Alex},
eprint = {2103.00223},
file = {:Users/liang-tingchen/Dropbox/References/Kov{\'{a}}cs - 2022 - Generalized Universe Hierarchies and First-Class Universe Levels.pdf:pdf},
isbn = {978-3-95977-218-1},
issn = {1868-8969},
keywords = {1,2022,28,4230,agda,and phrases type theory,andraskovacs,archived at swh,b74a7da080ca804b662e1038e025e76ea202edf3,com,csl,digital object identifier 10,dir,github,https,lipics,master,source code,supplementary material software,tree,type theory,universes},
number = {28},
pages = {28:1----28:17},
publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"{u}}r Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Generalized Universe Hierarchies and First-Class Universe Levels}},
url = {https://drops.dagstuhl.de/opus/volltexte/2022/15748 http://arxiv.org/abs/2103.00223},
volume = {216},
year = {2022}
}
@article{Baier2005,
abstract = {This paper presents various semantics in the branching-time spectrum of discrete-time and continuous-time Markov chains (DTMCs and CTMCs). Strong and weak bisimulation equivalence and simulation pre-orders are covered and are logically characterized in terms of the temporal logics Probabilistic Computation Tree Logic (PCTL) and Continuous Stochastic Logic (CSL). Apart from presenting various existing branching-time relations in a uniform manner, this paper presents the following new results: (i) strong simulation for CTMCs, (ii) weak simulation for CTMCs and DTMCs, (iii) logical characterizations thereof (including weak bisimulation for DTMCs), (iv) a relation between weak bisimulation and weak simulation equivalence, and (v) various connections between equivalences and pre-orders in the continuous- and discrete-time setting. The results are summarized in a branching-time spectrum for DTMCs and CTMCs elucidating their semantics as well as their relationship. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Baier, Christel and Katoen, Joost-Pieter and Hermanns, Holger and Wolf, Verena},
doi = {10.1016/j.ic.2005.03.001},
file = {:Users/liang-tingchen/Dropbox/References/Baier et al. - 2005 - Comparative branching-time semantics for Markov chains.pdf:pdf},
isbn = {08905401},
issn = {08905401},
journal = {Information and Computation},
keywords = {(Weak) Bisimulation,(Weak) Simulation,Comparative semantics,Markov chain,Temporal logic},
number = {2},
pages = {149--214},
title = {{Comparative branching-time semantics for Markov chains}},
volume = {200},
year = {2005}
}
@incollection{Bagwell:52465,
abstract = {Since its inception Functional Programming, J. McCarthy, has almost universally used the Linked List as the underpinning data structure. This paper introduces a new data structure, the VList, that is compact, thread safe and significantly faster to use than Linked Lists for nearly all list operations. Space usage can be reduced by 50{\%} to 90{\%} and in typical list operations speed improved by factors ranging from 4 to 20 or more. Some important operations such as indexing and length are typically changed from O(N) to O(1) and O(lgN) respectively. A language interpreter Visp, using a dialect of Common Lisp, has been implemented using VLists and the benchmark comparison with OCAML reported. It is also shown how to adapt the structure to create variable length arrays, persistent deques and functional hash tables. The VArray requires no resize copying and has an average O(1) random access time. Comparisons are made with previous resizable one dimensional arrays, Hash Array Trees (HAT) Sitarski [1996], and Brodnik, Carlsson, Demaine, Munro, and Sedgewick [1999].},
author = {Bagwell, Phil},
booktitle = {Implementation of Functional Languages. IFL 2002},
doi = {10.1007/3-540-44854-3_3},
editor = {Pe{\~{n}}a, Ricardo and Arts, Thomas},
file = {:Users/liang-tingchen/Dropbox/References/Bagwell - 2003 - Fast Functional Lists.pdf:pdf},
pages = {34--50},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Fast Functional Lists}},
url = {http://infoscience.epfl.ch/record/52465 http://link.springer.com/10.1007/3-540-44854-3{\_}3},
volume = {2670},
year = {2003}
}
@article{Cockx2018,
abstract = {Dependently typed languages such as Agda, Coq, and Idris use a syntactic first-order unification algorithm to check definitions by dependent pattern matching. However, standard unification algorithms implicitly rely on principles such as uniqueness of identity proofs and injectivity of type constructors . These principles are inadmissible in many type theories, particularly in the new and promising branch known as homotopy type theory. As a result, programs and proofs in these new theories cannot make use of dependent pattern matching or other techniques relying on unification, and are as a result much harder to write, modify, and understand. This paper proposes a proof-relevant framework for reasoning formally about unification in a dependently typed setting. In this framework, unification rules compute not just a unifier but also a corresponding soundness proof in the form of an equivalence between two sets of equations. By rephrasing the standard unification rules in a proof-relevant manner, they are guaranteed to preserve soundness of the theory. In addition, it enables us to safely add new rules that can exploit the dependencies between the types of equations, such as rules for eta-equality of record types and higher dimensional unification rules for solving equations between equality proofs. Using our framework, we implemented a complete overhaul of the unification algorithm used by Agda. As a result, we were able to replace previous ad-hoc restrictions with formally verified unification rules, fixing a substantial number of bugs in the process. In the future, we may also want to integrate new principles with pattern matching, for example, the higher inductive types introduced by homotopy type theory. Our framework also provides a solid basis for such extensions to be built on.},
author = {Cockx, Jesper and Devriese, Dominique},
doi = {10.1017/S095679681800014X},
file = {:Users/liang-tingchen/Dropbox/References/Cockx, Devriese - 2018 - Proof-relevant unification Dependent pattern matching with only the axioms of your type theory.pdf:pdf},
isbn = {0956796818},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {may},
number = {May 2019},
pages = {e12},
title = {{Proof-relevant unification: Dependent pattern matching with only the axioms of your type theory}},
url = {https://www.cambridge.org/core/product/identifier/S095679681800014X/type/journal{\_}article},
volume = {28},
year = {2018}
}
@article{Bentzen2022,
abstract = {This article proposes a way of doing type theory informally, assuming a cubical style of reasoning. It can thus be viewed as a first step toward a cubical alternative to the program of informalization of type theory carried out in the homotopy type theory book for dependent type theory augmented with axioms for univalence and higher inductive types. We adopt a cartesian cubical type theory proposed by Angiuli, Brunerie, Coquand, Favonia, Harper, and Licata as the implicit foundation, confining our presentation to elementary results such as function extensionality, the derivation of weak connections and path induction, the groupoid structure of types, and the Eckmman–Hilton duality.},
archivePrefix = {arXiv},
arxivId = {1911.05844},
author = {Bentzen, Bruno},
doi = {10.1017/S096012952200007X},
eprint = {1911.05844},
file = {:Users/liang-tingchen/Dropbox/References/Bentzen - 2022 - Naive cubical type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {cubical type theory,homotopy type theory,informal type theory,naive type theory},
month = {mar},
pages = {1--27},
title = {{Naive cubical type theory}},
url = {https://www.cambridge.org/core/product/identifier/S096012952200007X/type/journal{\_}article},
year = {2022}
}
@article{Cassidy1985,
author = {Cassidy, C. and H{\'{e}}bert, Michel and Kelly, Gregory Maxwell},
doi = {10.1017/S1446788700023624},
file = {:Users/liang-tingchen/Dropbox/References/Cassidy, H{\'{e}}bert, Kelly - 1985 - Reflective subcategories, localizations and factorization systems.pdf:pdf},
issn = {1446-7887},
journal = {Journal of the Australian Mathematical Society},
language = {English},
month = {apr},
number = {03},
pages = {287},
title = {{Reflective subcategories, localizations and factorization systems}},
url = {http://journals.cambridge.org/abstract{\_}S1446788700023624 http://www.journals.cambridge.org/abstract{\_}S1446788700023624},
volume = {38},
year = {1985}
}
@article{Kozen1988,
abstract = {We prove a finite model theorem and infinitary completeness result for the propositional $\mu$-calculus. The construction establishes a link between finite model theorems for propositional program logics and the theory of well-quasi-orders.},
author = {Kozen, Dexter},
doi = {10.1007/BF00370554},
file = {:Users/liang-tingchen/Dropbox/References/Kozen - 1988 - A finite model theorem for the propositional $\mu$-calculus.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
month = {sep},
number = {3},
pages = {233--241},
title = {{A finite model theorem for the propositional $\mu$-calculus}},
url = {http://link.springer.com/10.1007/BF00370554},
volume = {47},
year = {1988}
}
@article{Hofstra2003,
author = {Hofstra, Pieter and van Oosten, Jaap},
doi = {10.1017/S0305004102006424},
file = {:Users/liang-tingchen/Dropbox/References/Hofstra, van Oosten - 2003 - Ordered partial combinatory algebras.pdf:pdf},
issn = {03050041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {may},
number = {3},
title = {{Ordered partial combinatory algebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004102006424},
volume = {134},
year = {2003}
}
@article{Goncharov2016,
abstract = {Monads are extensively used nowadays to abstractly model a wide range of computational effects such as nondeterminism, statefulness, and exceptions. It turns out that equipping a monad with a (uniform) iteration operator satisfying a set of natural axioms allows for modelling iterative computations just as abstractly. The emerging monads are called complete Elgot monads. It has been shown recently that extending complete Elgot monads with free effects (e.g. operations of sending/receiving messages over channels) canonically leads to generalized coalgebraic resumption monads, previously used as semantic domains for non-wellfounded guarded processes. In this paper, we continue the study of the relationship between abstract complete Elgot monads and those that capture coalgebraic resumptions, by comparing the corresponding categories of (Eilenberg-Moore) algebras. To this end we first provide a characterization of the latter category; even more generally, we formulate this characterization in terms of Uustalu's parametrized monads. This is further used for establishing a characterization of complete Elgot monads as precisely those monads whose algebras are coherently equipped with the structure of algebras of coalgebraic resumption monads.},
archivePrefix = {arXiv},
arxivId = {1603.02148},
author = {Goncharov, Sergey and Milius, Stefan and Rauch, Christoph},
eprint = {1603.02148},
file = {:Users/liang-tingchen/Dropbox/References/Goncharov, Milius, Rauch - 2016 - Complete Elgot Monads and Coalgebraic Resumptions.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {Elgot Monads},
month = {mar},
title = {{Complete Elgot Monads and Coalgebraic Resumptions}},
url = {http://arxiv.org/abs/1603.02148},
year = {2016}
}
@article{Barth-Jones2012,
author = {Barth-Jones, Daniel C.},
doi = {10.2139/ssrn.2076397},
file = {:Users/liang-tingchen/Dropbox/References/Barth-Jones - 2012 - The 'Re-Identification' of Governor William Weld's Medical Information A Critical Re-Examination of Health Data Ide.pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {de-identification,hipaa,population,privacy,statistical disclosure},
pages = {1--19},
title = {{The 'Re-Identification' of Governor William Weld's Medical Information: A Critical Re-Examination of Health Data Identification Risks and Privacy Protections, Then and Now}},
url = {http://www.ssrn.com/abstract=2076397},
year = {2012}
}
@incollection{Bonsangue1993a,
author = {Bonsangue, Marcello M. and Kok, Joost N.},
booktitle = {Mathematical Foundations of Computer Science},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Kok - 1993 - Isomorphisms between Predicates and State Transformers.pdf:pdf},
pages = {301--310},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Isomorphisms between Predicates and State Transformers}},
type = {Conference proceedings (article)},
year = {1993}
}
@inproceedings{Staton2013,
author = {Staton, Sam},
booktitle = {28th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.58},
file = {:Users/liang-tingchen/Dropbox/References/Staton - 2013 - Instances of Computational Effects An Algebraic Perspective.pdf:pdf},
isbn = {978-1-4799-0413-6},
month = {jun},
number = {1},
pages = {519--519},
publisher = {IEEE},
title = {{Instances of Computational Effects: An Algebraic Perspective}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6571584},
year = {2013}
}
@incollection{Benabou1967,
author = {Benabou, Jean},
booktitle = {Reports of the Midwest Category Seminar},
doi = {10.1007/BFb0074298},
file = {:Users/liang-tingchen/Dropbox/References/Benabou - 1967 - Introduction to bicategories.pdf:pdf},
isbn = {978-3-540-03918-1},
pages = {1--77},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Introduction to bicategories}},
url = {http://www.springerlink.com/index/10.1007/BFb0074298},
volume = {47},
year = {1967}
}
@article{Haenni2004,
abstract = {The paper presents a generic approach of approximating inference. The method is based on the concept of valuation algebras with its wide range of possible applications in many different domains. We present convenient resource-bounded anytime algorithms, where the maximal time of computation is determined by the user. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {Haenni, Rolf},
doi = {10.1016/j.ijar.2003.10.009},
file = {:Users/liang-tingchen/Dropbox/References/Haenni - 2004 - Ordered valuation algebras a generic framework for approximating inference.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Anytime algorithms,Approximation,Binary join trees,Bucket elimination,Local computation,Mini-buckets,Resource-bounded computation,Valuation algebras},
month = {aug},
number = {1},
pages = {1--41},
title = {{Ordered valuation algebras: a generic framework for approximating inference}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X03001476},
volume = {37},
year = {2004}
}
@incollection{Schroder2010a,
abstract = {Fixed point logics are widely used in computer science, in particular in artificial intelligence and concurrency. The most expressive logics of this type are the $\mu$-calculus and its relatives. However, popular fixed point logics tend to trade expressivity for simplicity and readability, and in fact often live within the single variable fragment of the $\mu$-calculus. The family of such flat fixed point logics includes, e.g., CTL, the *-nesting-free fragment of PDL, and the logic of common knowledge. Here, we extend this notion to the generic semantic framework of coalgebraic logic, thus covering a wide range of logics beyond the standard $\mu$-calculus including, e.g., flat fragments of the graded $\mu$-calculus and the alternating-time $\mu$-calculus (such as ATL), as well as probabilistic and monotone fixed point logics. Our main results are completeness of the Kozen-Park axiomatization and a timed-out tableaux method that matches ExpTime upper bounds inherited from the coalgebraic $\mu$-calculus but avoids using automata.},
author = {Schr{\"{o}}der, Lutz and Venema, Yde},
booktitle = {CONCUR'10 Concurrency Theory},
doi = {10.1007/978-3-642-15375-4_36},
editor = {Gastin, Paul and Laroussinie, Fran{\c{c}}ois},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Venema - 2010 - Flat coalgebraic fixed point logics.pdf:pdf},
pages = {1--15},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Flat coalgebraic fixed point logics}},
year = {2010}
}
@incollection{Kohlas2009,
abstract = {According to Shannon's classical information theory [19] information is measured by the reduction of uncertainty and the latter is measured by entropy. This theory is concerned with the transmission of symbols from a finite alphabet. The uncertainty concerns the question which symbol is sent and the information is given by a probabilistic model of the transmission channel and the symbol observed at the output of the channel. This leads to a statistical communication theory which is still the main subject of communication theory today.},
author = {Kohlas, J{\"{u}}rg and Schneuwly, Cesar},
booktitle = {Formal Theories of Information},
doi = {10.1007/978-3-642-00659-3_5},
editor = {Sommaruga, Giovanni},
file = {:Users/liang-tingchen/Dropbox/References/Kohlas, Schneuwly - 2009 - Information algebra.pdf:pdf},
isbn = {3642006582},
issn = {03029743},
pages = {95--127},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Information algebra}},
url = {http://link.springer.com/10.1007/978-3-642-00659-3{\_}5},
volume = {5363},
year = {2009}
}
@article{Leal2009,
author = {Leal, Raul Andres and Kupke, Clemens},
file = {:Users/liang-tingchen/Dropbox/References/Leal, Kupke - 2009 - Of the Hennessy-Milner property and Other Demons.pdf:pdf},
journal = {ILLC Prepublications/ILLC},
title = {{Of the Hennessy-Milner property and Other Demons}},
type = {Journal article},
url = {http://dare.uva.nl/en/record/301219},
year = {2009}
}
@inproceedings{Ahrens2020,
abstract = {The ordinary Structure Identity Principle states that any property of set-level structures (e.g., posets, groups, rings, fields) definable in Univalent Foundations is invariant under isomorphism: More specifically, identifications of structures coincide with isomorphisms. We prove a version of this principle for a wide range of higher-categorical structures, adapting FOLDS-signatures to specify a general class of structures, and using two-level type theory to treat all categorical dimensions uniformly. As in the previously known case of 1-categories (which is an instance of our theory), the structures themselves must satisfy a local univalence principle, stating that identifications coincide with "isomorphisms" between elements of the structure. Our main technical achievement is a definition of such isomorphisms, which we call "indiscernibilities," using only the dependency structure rather than any notion of composition.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2004.06572},
author = {Ahrens, Benedikt and North, Paige Randall and Shulman, Michael and Tsementzis, Dimitris},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394755},
eprint = {2004.06572},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens et al. - 2020 - A Higher Structure Identity Principle.pdf:pdf},
isbn = {9781450371049},
issn = {21531633},
keywords = {categories,equivalence principle,homotopy type theory,structure identity principle,univalent foundations},
month = {jul},
pages = {53--66},
publisher = {ACM},
title = {{A Higher Structure Identity Principle}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394755},
year = {2020}
}
@article{Kock1971,
abstract = {The notion of commutative monad was defined by the author in [4]. The content of the present paper may briefly be stated: The category of algebras for a commutative monad can in a canonical way be made into a closed category, the two adjoint functors connecting the category of algebras with the base category are in a canonical way closed functors, and the front- and end-adjunctions are closed transformations. (The terms ‘Closed Category' etc. are from the paper [2] by Eilenberg and Kelly). In particular, the monad itself is a ‘closed monad'; this fact was also proved in [4].},
author = {Kock, Anders},
doi = {10.1017/S1446788700010272},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 1971 - Closed categories generated by commutative monads.pdf:pdf},
issn = {0004-9735},
journal = {Journal of the Australian Mathematical Society},
month = {nov},
number = {4},
pages = {405--424},
title = {{Closed categories generated by commutative monads}},
url = {https://www.cambridge.org/core/product/identifier/S1446788700010272/type/journal{\_}article},
volume = {12},
year = {1971}
}
@unpublished{Bertot2016,
address = {Types Summer School, also used at the University of Goteborg, Nice,{\textless}br /{\textgreater}Ecole Jeunes Chercheurs en Programmation,{\textless}br/{\textgreater}Universite de Nice, France},
annote = {From Duplicate 2 (Coq in a Hurry - Bertot, Yves)

Lecture},
author = {Bertot, Yves},
file = {:Users/liang-tingchen/Dropbox/References//Bertot - 2016 - Coq in a Hurry.pdf:pdf},
month = {jun},
pages = {49},
title = {{Coq in a Hurry}},
type = {3rd cycle},
url = {https://cel.archives-ouvertes.fr/inria-00001173},
year = {2016}
}
@article{Wei2019,
author = {Wei, Guannan and Chen, Yuxuan and Rompf, Tiark},
doi = {10.1145/3360552},
file = {:Users/liang-tingchen/Dropbox/References/Wei, Chen, Rompf - 2019 - Staged abstract interpreters fast and modular whole-program analysis via meta-programming.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {abstract interpreters,control-flow analysis,multi-stage programming},
month = {oct},
number = {OOPSLA},
pages = {1--32},
title = {{Staged abstract interpreters: fast and modular whole-program analysis via meta-programming}},
url = {https://dl.acm.org/doi/10.1145/3360552},
volume = {3},
year = {2019}
}
@article{Hyland2017,
abstract = {Recent developments in the categorical foundations of universal algebra have given an impetus to an understanding of the lambda calculus coming from categorical logic: an interpretation is a semi-closed algebraic theory. Scott's representation theorem is then completely natural and leads to a precise Fundamental Theorem showing the essential equivalence between the categorical and more familiar notions.},
archivePrefix = {arXiv},
arxivId = {1211.5762},
author = {HYLAND, J.M.E.},
doi = {10.1017/S0960129515000377},
eprint = {1211.5762},
file = {:Users/liang-tingchen/Dropbox/References/HYLAND - 2017 - Classical lambda calculus in modern dress.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {05},
pages = {762--781},
title = {{Classical lambda calculus in modern dress}},
url = {https://www.cambridge.org/core/product/identifier/S0960129515000377/type/journal{\_}article},
volume = {27},
year = {2017}
}
@incollection{Fu2015,
author = {Fu, Peng and Komendantskaya, Ekaterina},
booktitle = {Logic-Based Program Synthesis and Transformation. LOPSTR 2015.},
doi = {10.1007/978-3-319-27436-2_6},
editor = {Falaschi, Moreno},
file = {:Users/liang-tingchen/Dropbox/References/Fu, Komendantskaya - 2015 - A Type-Theoretic Approach to Resolution.pdf:pdf},
isbn = {9783319274355},
issn = {16113349},
keywords = {logic programming,realizability,reduction systems,structural resolution,transformation,typed lambda calculus},
pages = {91--106},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Type-Theoretic Approach to Resolution}},
url = {http://link.springer.com/10.1007/978-3-319-27436-2{\_}6},
volume = {9527},
year = {2015}
}
@book{Longly2015a,
abstract = {This book offers a self-contained exposition of the theory of computability in a higher-order context, where 'computable operations' may themselves be passed as arguments to other computable operations. The subject originated in the 1950s with the work of Kleene, Kreisel and others, and has since expanded in many different directions under the influence of workers from both mathematical logic and computer science. The ideas of higher-order computability have proved valuable both for elucidating the constructive content of logical systems, and for investigating the expressive power of various higher-order programming languages. In contrast to the well-known situation for first-order functions, it turns out that at higher types there are several different notions of computability competing for our attention, and each of these has given rise to its own strand of research. In this book, the authors offer an integrated treatment that draws together many of these strands within a unifying framework, revealing not only the range of possible computability concepts but the relationships between them. The book will serve as an ideal introduction to the field for beginning graduate students, as well as a reference for advanced researchers. Introduction and Motivation -- Historical Survey -- Theory of Computability Models -- Theory of Lambda Algebras -- Kleene Computability in a Total Setting -- Nested Sequential Procedures -- PCF and Its Models -- Total Continuous Functionals -- Hereditarily Effective Operations -- Partial Continuous Functionals -- Sequentially Realizable Functionals -- Some Intensional Models -- Related and Future Work -- References -- Index.},
address = {Berlin, Heidelberg},
author = {Longley, John and Normann, Dag},
booktitle = {Springer},
doi = {10.1007/978-3-662-47992-6},
file = {:Users/liang-tingchen/Dropbox/References/Longley, Normann - 2015 - Higher-Order Computability.pdf:pdf},
isbn = {978-3-662-47991-9},
publisher = {Springer Berlin Heidelberg},
series = {Theory and Applications of Computability},
title = {{Higher-Order Computability}},
url = {http://link.springer.com/10.1007/978-3-662-47992-6},
year = {2015}
}
@inproceedings{Pavlovic1998,
author = {Pavlovi{\'{c}}, Dusko and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel},
booktitle = {Proceedings. Thirteenth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1998.705675},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}}, Escard{\'{o}} - 1998 - Calculus in coinductive form.pdf:pdf},
isbn = {0-8186-8506-9},
pages = {408--417},
publisher = {IEEE Comput. Soc},
title = {{Calculus in coinductive form}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=705675 http://ieeexplore.ieee.org/document/705675/},
year = {1998}
}
@article{Clarkson2010,
abstract = {Trace properties, which have long been used for reasoning about systems, are sets of execution traces. Hyperproperties, introduced here, are sets of trace properties. Hyperproperties can express security policies, such as secure information flow and service level agreements, that trace properties cannot. Safety and liveness are generalized to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. A verification technique for safety hyperproperties is given and is shown to generalize prior techniques for verifying secure information flow. Refinement is shown to be applicable with safety hyperproperties. A topological characterization of hyperproperties is given. [ABSTRACT FROM AUTHOR]$\backslash$nCopyright of Journal of Computer Security is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Clarkson, Michael R. and Schneider, Fred B.},
doi = {10.3233/JCS-2009-0393},
editor = {Sabelfeld, Andrei},
file = {:Users/liang-tingchen/Dropbox/References/Clarkson, Schneider - 2010 - Hyperproperties.pdf:pdf},
issn = {18758924},
journal = {Journal of Computer Security},
keywords = {Security policies,information flow,liveness,safety},
month = {sep},
number = {6},
pages = {1157--1210},
title = {{Hyperproperties}},
url = {http://www.medra.org/servlet/aliasResolver?alias=iospress{\&}doi=10.3233/JCS-2009-0393},
volume = {18},
year = {2010}
}
@inproceedings{Abel2007a,
abstract = {We present an algorithm for computing normal terms and types in Martin-L{\"{o}}f type theory with one universe and eta-conversion. We prove that two terms or types are equal in the theory iff the normal forms are identical (as de Bruijn terms). It thus follows that our algorithm can be used for deciding equality in Martin-L{\"{o}}f type theory. The algorithm uses the technique of normalization by evaluation; normal forms are computed by first evaluating terms and types in a suitable model. The normal forms are then extracted from the semantic elements. We prove its completeness by a PER model and its soundness by a Kripke logical relation. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Abel, Andreas and Coquand, Thierry and Dybjer, Peter},
booktitle = {22nd Annual IEEE Symposium on Logic in Computer Science (LICS 2007)},
doi = {10.1109/LICS.2007.33},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Coquand, Dybjer - 2007 - Normalization by Evaluation for Martin-Lof Type Theory with Typed Equality Judgements.pdf:pdf},
isbn = {0-7695-2908-9},
issn = {10436871},
number = {510996},
pages = {3--12},
publisher = {IEEE},
title = {{Normalization by Evaluation for Martin-Lof Type Theory with Typed Equality Judgements}},
url = {http://ieeexplore.ieee.org/document/4276546/},
year = {2007}
}
@article{Terrovitis2011,
abstract = {In this paper, we study the problem of protecting privacy in the publication of set-valued data. Consider a collection of supermarket transactions that contains detailed information about items bought together by individuals. Even after removing all personal characteristics of the buyer, which can serve as links to his identity, the publication of such data is still subject to privacy attacks from adversaries who have partial knowledge about the set. Unlike most previous works, we do not distinguish data as sensitive and non-sensitive, but we consider them both as potential quasi-identifiers and potential sensitive data, depending on the knowledge of the adversary. We define a new version of the k-anonymity guarantee, the k (m) -anonymity, to limit the effects of the data dimensionality, and we propose efficient algorithms to transform the database. Our anonymization model relies on generalization instead of suppression, which is the most common practice in related works on such data. We develop an algorithm that finds the optimal solution, however, at a high cost that makes it inapplicable for large, realistic problems. Then, we propose a greedy heuristic, which performs generalizations in an Apriori, level-wise fashion. The heuristic scales much better and in most of the cases finds a solution close to the optimal. Finally, we investigate the application of techniques that partition the database and perform anonymization locally, aiming at the reduction of the memory consumption and further scalability. A thorough experimental evaluation with real datasets shows that a vertical partitioning approach achieves excellent results in practice.},
author = {Terrovitis, Manolis and Mamoulis, Nikos and Kalnis, Panos},
doi = {10.1007/s00778-010-0192-8},
file = {:Users/liang-tingchen/Dropbox/References/Terrovitis, Mamoulis, Kalnis - 2011 - Local and global recoding methods for anonymizing set-valued data.pdf:pdf},
issn = {1066-8888},
journal = {The VLDB Journal},
keywords = {Anonymity,Database privacy,Set-valued data},
month = {feb},
number = {1},
pages = {83--106},
title = {{Local and global recoding methods for anonymizing set-valued data}},
url = {http://link.springer.com/10.1007/s00778-010-0192-8},
volume = {20},
year = {2011}
}
@article{Kiselyov2012a,
abstract = {We describe the first implementation of multi-prompt delimited control operators in OCaml that is direct in that it captures only the needed part of the control stack. The implementation is a library that requires no changes to the OCaml compiler or run-time, so it is perfectly compatible with existing OCaml source and binary code. The library has been in fruitful practical use since 2006. We present the library as an implementation of an abstract machine derived by elaborating the definitional machine. The abstract view lets us distill a minimalistic API, scAPI, sufficient for implementing multi-prompt delimited control. We argue that a language system that supports exception and stack-overflow handling supports scAPI. With byte- and native-code OCaml systems as two examples, our library illustrates how to use scAPI to implement multi-prompt delimited control in a typed language. The approach is general and has been used to add multi-prompt delimited control to other existing language systems. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Kiselyov, Oleg},
doi = {10.1016/j.tcs.2012.02.025},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov - 2012 - Delimited control in OCaml, abstractly and concretely.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Abstract machine,Delimited continuation,Exception,Implementation,Semantics},
month = {jun},
pages = {56--76},
publisher = {Elsevier B.V.},
title = {{Delimited control in OCaml, abstractly and concretely}},
url = {http://dx.doi.org/10.1016/j.tcs.2012.02.025 https://linkinghub.elsevier.com/retrieve/pii/S0304397512001661},
volume = {435},
year = {2012}
}
@inproceedings{Schroder2009,
abstract = {Canonical models are of central importance in modal logic, in particular as they witness strong completeness and hence compactness. While the canonical model construction is well understood for Kripke semantics, non-normal modal logics often present subtle difficulties - up to the point that canonical models may fail to exist, as is the case e.g. in most probabilistic logics. Here, we present a generic canonical model construction in the semantic framework of coalgebraic modal logic, which pinpoints coherence conditions between syntax and semantics of modal logics that guarantee strong completeness. We apply this method to reconstruct canonical model theorems that are either known or folklore, and moreover instantiate our method to obtain new strong completeness results. In particular, we prove strong completeness of graded modal logic with finite multiplicities, and of the modal logic of exact probabilities. {\textcopyright} L. Schr{\"{o}}der and D. Pattinson.},
author = {Schr{\"{o}}der, Lutz and Pattinson, Dirk},
booktitle = {26th International Symposium on Theoretical Aspects of Computer Science},
doi = {10.4230/LIPIcs.STACS.2009.1855},
editor = {Albers, Susanne and Marion, Jean-Yves},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Pattinson - 2009 - Strong completeness of coalgebraic modal logics.pdf:pdf},
isbn = {9783939897095},
issn = {18688969},
keywords = {Coalgebra,Deduction,Logic in computer science,Modal logic,Semantics},
pages = {673--684},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Strong completeness of coalgebraic modal logics}},
volume = {3},
year = {2009}
}
@article{Honda2000,
author = {Honda, Kohei},
file = {:Users/liang-tingchen/Dropbox/References/Honda - 2000 - Elementary structures in process theory (1) Sets with renaming.pdf:pdf},
journal = {Mathematical Structures in Computer Science},
number = {5},
pages = {617--663},
publisher = {Cambridge University Press},
title = {{Elementary structures in process theory (1): Sets with renaming}},
url = {https://www.cambridge.org/core/journals/mathematical-structures-in-computer-science/article/elementary-structures-in-process-theory-1-sets-with-renaming/3FE144ABB1194D35BD6DC8F10EAF7FC5},
volume = {10},
year = {2000}
}
@inproceedings{Barthe2016,
abstract = {The aim of this paper is to provide a new method for learning the relationships between data that have been obtained independently. Unlike existing methods like matching, the proposed technique does not require any contextual information, provided that the dependency between the variables of interest is monotone. It can therefore be easily combined with matching in order to exploit the advantages of both methods. This technique can be described as a mix between quantile matching, and deconvolution. We provide for it a theoretical and an empirical validation.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1601.0504},
author = {Barthe, Gilles and Gaboardi, Marco and Gr{\'{e}}goire, Benjamin and Hsu, Justin and Strub, Pierre-Yves},
booktitle = {Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '16},
doi = {10.1145/2933575.2934554},
eprint = {1601.0504},
file = {:Users/liang-tingchen/Dropbox/References/Barthe et al. - 2016 - Proving differential privacy via probabilistic couplings.pdf:pdf},
isbn = {9781450343916},
issn = {10436871},
number = {212},
pages = {749--758},
publisher = {ACM Press},
title = {{Proving differential privacy via probabilistic couplings}},
url = {http://arxiv.org/abs/1601.0504 http://dl.acm.org/citation.cfm?doid=2933575.2934554},
volume = {1},
year = {2016}
}
@article{Mortberg2021,
abstract = {Cubical methods have played an important role in the development of Homotopy Type Theory and Univalent Foundations (HoTT/UF) in recent years. The original motivation behind these developments was to give constructive meaning to Voevodsky's univalence axiom, but they have since then led to a range of new results. Among the achievements of these methods is the design of new type theories and proof assistants with native support for notions from HoTT/UF, syntactic and semantic consistency results for HoTT/UF, as well as a variety of independence results and establishing that the univalence axiom does not increase the proof theoretic strength of type theory. This paper is based on lecture notes that were written for the 2019 Homotopy Type Theory Summer School at Carnegie Mellon University. The goal of these lectures was to give an introduction to cubical methods and provide sufficient background in order to make the current research in this very active area of HoTT/UF more accessible to newcomers. The focus of these notes is hence on both the syntactic and semantic aspects of these methods, in particular on cubical type theory and the various cubical set categories that give meaning to these theories.},
author = {M{\"{o}}rtberg, Anders},
doi = {10.1017/S0960129521000311},
file = {:Users/liang-tingchen/Dropbox/References/M{\"{o}}rtberg - 2021 - Cubical methods in homotopy type theory and univalent foundations.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {Homotopy type theory,cubical set models,cubical type theory,univalent foundations},
month = {dec},
pages = {1--38},
title = {{Cubical methods in homotopy type theory and univalent foundations}},
url = {https://www.cambridge.org/core/product/identifier/S0960129521000311/type/journal{\_}article},
year = {2021}
}
@inproceedings{Dolan2017,
abstract = {We present a type system combining subtyping and ML-style para-metric polymorphism. Unlike previous work, our system supports type inference and has compact principal types. We demonstrate this system in the minimal language MLsub, which types a strict superset of core ML programs. This is made possible by keeping a strict separation between the types used to describe inputs and those used to describe out-puts, and extending the classical unification algorithm to handle subtyping constraints between these input and output types. Prin-cipal types are kept compact by type simplification, which exploits deep connections between subtyping and the algebra of regular lan-guages. An implementation is available online.},
address = {New York, New York, USA},
author = {Dolan, Stephen and Mycroft, Alan},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
doi = {10.1145/3009837.3009882},
file = {:Users/liang-tingchen/Dropbox/References/Dolan, Mycroft - 2017 - Polymorphism, subtyping, and type inference in MLsub.pdf:pdf},
isbn = {9781450346603},
keywords = {Algebra,Applicative (Functional) Programming,F33 [Logics and Meanings of Programs],Polymorphism,Type Inference},
pages = {60--72},
publisher = {ACM Press},
title = {{Polymorphism, subtyping, and type inference in MLsub}},
url = {https://www.cl.cam.ac.uk/{~}sd601/papers/mlsub-preprint.pdf http://dl.acm.org/citation.cfm?doid=3009837.3009882},
year = {2017}
}
@article{Acclavio2017,
abstract = {The original idea of proof nets can be formulated by means of interaction nets syntax. Additional machinery as switching, jumps and graph connectivity is needed in order to ensure correspondence between a proof structure and a correct proof in sequent calculus. In this paper we give an interpretation of proof nets in the syntax of string diagrams. Even though we lose standard proof equivalence, our construction allows to define a framework where soundness and well-typeness of a diagram can be verified in linear time.},
author = {Acclavio, Matteo},
doi = {10.1007/s10817-018-9466-4},
file = {:Users/liang-tingchen/Dropbox/References/Acclavio - 2018 - Proof Diagrams for Multiplicative Linear Logic Syntax and Semantics.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {()},
month = {may},
pages = {11--23},
publisher = {Springer Netherlands},
title = {{Proof Diagrams for Multiplicative Linear Logic: Syntax and Semantics}},
url = {https://arxiv.org/pdf/1606.09016.pdf http://arxiv.org/abs/1606.09016v3 http://link.springer.com/10.1007/s10817-018-9466-4},
volume = {238},
year = {2018}
}
@article{Taha2003,
abstract = {This paper proposes and develops the basic theory for a new approach to typing multi-stage languages based a notion of environment classifiers . This approach involves explicit but lightweight tracking -- at type-checking time -- of the origination environment for future-stage computations. Classification is less restrictive than the previously proposed notions of closedness, and allows for both a more expressive typing of the "run" construct and for a unifying account of typed multi-stage programmin.The proposed approach to typing requires making cross-stage persistence (CSP) explicit in the language. At the same time, it offers concrete new insights into the notion of levels and in turn into CSP itself. Type safety is established in the simply-typed setting. As a first step toward introducing classifiers to the Hindley-Milner setting, we propose an approach to integrating the two, and prove type preservation in this setting.},
author = {Taha, Walid and Nielsen, Michael Florentin},
doi = {10.1145/640128.604134},
file = {:Users/liang-tingchen/Dropbox/References/Taha, Nielsen - 2003 - Environment classifiers.pdf:pdf},
isbn = {1581136285},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
keywords = {Linear temporal logic,Modal logic,Multi-stage programming,Type safety,Type systems},
month = {jan},
number = {1},
pages = {26--37},
title = {{Environment classifiers}},
url = {https://dl.acm.org/doi/10.1145/640128.604134},
volume = {38},
year = {2003}
}
@incollection{Johnstone1978,
author = {Johnstone, Peter T. and Wraith, Gavin C.},
booktitle = {Indexed Categories and Their Applications},
doi = {10.1007/BFb0061360},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone, Wraith - 1978 - Algebraic theories in toposes.pdf:pdf},
isbn = {978-3-540-08914-8},
pages = {141--242},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Algebraic theories in toposes}},
url = {http://www.springerlink.com/index/10.1007/BFb0061360},
year = {1978}
}
@inproceedings{Kupke2008a,
abstract = {We give a sound and complete derivation system for the valid formulas in the ﬁnitary version of Moss' coalgebraic logic, for coalgebras of arbitrary type},
author = {Kupke, Clemens and Kurz, Alexander},
booktitle = {Advances in Modal Logic},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Kurz - 2008 - Completeness of the finitary Moss logic.pdf:pdf},
keywords = {coalgebra,coalgebraic logic,completeness,modal logic},
pages = {193--217},
publisher = {College Publications},
title = {{Completeness of the finitary Moss logic}},
url = {http://dare.uva.nl/document/130019},
volume = {7},
year = {2008}
}
@article{Yavorskaya2001,
abstract = {In the paper the joint Logic of Proofs and Provability LPP is presented that incorporates both the modality □ for provability (Israel J. Math. 25 (1976) 287-304) and the proof operator tF representing the proof predicate "t is a proof of F" (Technical Report No. CFIS 95-29, Cornell University, 1995). The obtained system LPP naturally includes both the modal logic of provability GL and Artemov's Logic of Proofs LP. The presence of the modality □ requires two new operations on proofs that together with operations of LP allow to realize all the invariant operations on proofs admitting description in the modal propositional language. Logic LPP is proved to be decidable and complete with the intended provability semantics. {\textcopyright} 2002 Elsevier Science B.V.},
author = {{Yavorskaya (Sidon)}, Tatiana},
doi = {10.1016/S0168-0072(01)00066-5},
file = {:Users/liang-tingchen/Dropbox/References/Yavorskaya (Sidon) - 2001 - Logic of proofs and provability.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Logic of proofs,Operations on proofs,Provability logic},
month = {dec},
number = {1-3},
pages = {345--372},
title = {{Logic of proofs and provability}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0168007201000665},
volume = {113},
year = {2001}
}
@incollection{Kopotek1998,
abstract = {{\textcopyright} Springer-Verlag Berlin Heidelberg 1998. The paper presents a novel view of the Dempster-Shafer belief function as a measure of diversity in relational data bases. The Dempster rule of evidence combination corresponds to the join operator of the relational database theory. This rough-set based interpretation is qualitative in nature and can represent a number of belief function operators.},
author = {K{\l}opotek, Mieczys{\l}aw A. and Wierzcho{\'{n}}, S{\l}awomir T.},
booktitle = {Rough Sets and Current Trends in Computing},
doi = {10.1007/3-540-69115-4_47},
editor = {Polkowski, Lech and Skowron, Andrzej},
file = {:Users/liang-tingchen/Dropbox/References/K{\l}opotek, Wierzcho{\'{n}} - 1998 - A New Qualitative Rough-Set Approach to Modeling Belief Functions.pdf:pdf},
pages = {346--354},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A New Qualitative Rough-Set Approach to Modeling Belief Functions}},
url = {http://www.springerlink.com/index/CEX5RED84KFPXW1P.pdf http://link.springer.com/10.1007/3-540-69115-4{\_}47},
volume = {1424},
year = {1998}
}
@misc{Riehl2008,
address = {Chicago},
author = {Riehl, Emily},
file = {:Users/liang-tingchen/Dropbox/References/Riehl - 2008 - Factorization systems.pdf:pdf},
title = {{Factorization systems}},
year = {2008}
}
@inproceedings{Borthelle2020,
abstract = {We introduce a categorical framework for operational semantics, in which we define substitution-closed bisimilarity, an abstract analogue of the open extension of Abramsky's applicative bisimilarity. We furthermore prove a congruence theorem for substitution-closed bisimilarity, following Howe's method. We finally demonstrate that the framework covers the call-by-name and call-by-value variants of $\lambda$-calculus in big-step style. As an intermediate result, we generalise the standard framework of Fiore et al. for syntax with variable binding to the skew-monoidal case.},
address = {New York, NY, USA},
author = {Borthelle, Peio and Hirschowitz, Tom and Lafont, Ambroise},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394738},
file = {:Users/liang-tingchen/Dropbox/References/Borthelle, Hirschowitz, Lafont - 2020 - A Cellular Howe Theorem.pdf:pdf},
isbn = {9781450371049},
keywords = {Howe's method,bisimilarity,category theory,congruence,operational semantics},
month = {jul},
pages = {273--286},
publisher = {ACM},
title = {{A Cellular Howe Theorem}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394738},
year = {2020}
}
@article{Marmolejo2010,
author = {Marmolejo, F. and Wood, R. J.},
file = {:Users/liang-tingchen/Dropbox/References/Marmolejo, Wood - 2010 - Monads as extension systems - No iteration is necessary.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Distributive laws,Extension systems,Monads,Profunctors,Wreaths},
number = {4},
pages = {84--113},
title = {{Monads as extension systems - No iteration is necessary}},
url = {http://www.tac.mta.ca/tac/volumes/24/4/24-04abs.html},
volume = {24},
year = {2010}
}
@incollection{Vardi2001a,
abstract = {The discussion of the relative merits of linear- versus branching-time frameworks goes back to early 1980s. One of the beliefs dominating this discussion has been that "while specifying is easier in LTL (linear-temporal logic), verification is easier for CTL (branching-temporal logic)". Indeed, the restricted syntax of CTL limits its expressive power and many important behaviors (e.g., strong fairness) can not be specified in CTL. On the other hand, while model checking for CTL can be done in time that is linear in the size of the specification, it takes time that is exponential in the specification for LTL. Because of these arguments, and for historical reasons, the dominant temporal specification language in industrial use is CTL.},
author = {Vardi, Moshe Y},
booktitle = {Proceedings of the 7th International Conference, Tools and Algorithms for the Construction and Analysis of Systems},
doi = {10.1007/3-540-45319-9_1},
editor = {Margaria, Tiziana and Yi, Wang},
file = {:Users/liang-tingchen/Dropbox/References/Vardi - 2001 - Branching vs. linear time final showdown.pdf:pdf},
isbn = {3540418652},
issn = {16113349},
pages = {1--22},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Branching vs. linear time: final showdown}},
url = {http://www.springerlink.com/index/6jtk6mgaa0exhxer.pdf http://link.springer.com/10.1007/3-540-45319-9{\_}1},
volume = {2031},
year = {2001}
}
@inproceedings{Rahli2016a,
address = {New York, New York, USA},
author = {Rahli, Vincent and Bickford, Mark},
booktitle = {Proceedings of the 5th ACM SIGPLAN Conference on Certified Programs and Proofs - CPP 2016},
doi = {10.1145/2854065.2854077},
file = {:Users/liang-tingchen/Dropbox/References/Rahli, Bickford - 2016 - A nominal exploration of intuitionism.pdf:pdf},
isbn = {9781450341271},
keywords = {Continuity,Coq,Exceptions,Intuitionistic Type Theory,Nominal Type Theory,Nuprl,Squashing,Truncation,continuity,coq,exceptions,intuitionistic type theory,nominal type theory,nuprl,squashing,truncation},
pages = {130--141},
publisher = {ACM Press},
title = {{A nominal exploration of intuitionism}},
url = {http://dl.acm.org/citation.cfm?doid=2854065.2854077},
year = {2016}
}
@incollection{Cohen2013,
abstract = {In intensional type theory, it is not always possible to form the quotient of a type by an equivalence relation. However, quotients are extremely useful when formalizing mathematics, especially in algebra. We provide a Coq library with a pragmatic approach in two complementary components. First, we provide a framework to work with quotient types in an axiomatic manner. Second, we program construction mechanisms for some specific cases where it is possible to build a quotient type. This library was helpful in implementing the types of rational fractions, multivariate polynomials, field extensions and real algebraic numbers.},
author = {Cohen, Cyril},
booktitle = {4th International Conference, Interactive Theorem Proving, 2013},
doi = {10.1007/978-3-642-39634-2_17},
editor = {Blazy, Sandrine and Paulin-Mohring, Christine and Pichardie, David},
file = {:Users/liang-tingchen/Dropbox/References/Cohen - 2013 - Pragmatic quotient types in Coq.pdf:pdf},
isbn = {9783642396335},
issn = {03029743},
keywords = {Coq,Formalization of mathematics,Quotient types},
pages = {213--228},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Pragmatic quotient types in Coq}},
year = {2013}
}
@article{Murray1993,
author = {Murray, B.S. and McDaid, E.},
doi = {10.1006/imms.1993.1003},
file = {:Users/liang-tingchen/Dropbox/References/Murray, McDaid - 1993 - Visualizing and representing knowledge for the end user a review.pdf:pdf},
issn = {00207373},
journal = {International Journal of Man-Machine Studies},
month = {jan},
number = {1},
pages = {23--49},
title = {{Visualizing and representing knowledge for the end user: a review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020737383710035},
volume = {38},
year = {1993}
}
@article{VanOosten2015,
abstract = {We define a notion of homotopy in the effective topos.},
author = {{VAN OOSTEN}, JAAP},
doi = {10.1017/S096012951400053X},
file = {:Users/liang-tingchen/Dropbox/References/VAN OOSTEN - 2015 - A notion of homotopy for the effective topos.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {5},
pages = {1132--1146},
title = {{A notion of homotopy for the effective topos}},
url = {https://www.cambridge.org/core/product/identifier/S096012951400053X/type/journal{\_}article},
volume = {25},
year = {2015}
}
@incollection{Parigot1992,
abstract = {The paper presents a way of extending the paradigm proofs as programs to classical proofs. The system is derived from the general free deduction system. The system is a natural deduction system with multiple conclusions, called classical natural deduction (the one with the absurdity rule being called usual natural deduction). It is a particular subsystem of free deduction (FD) with inputs fixed to the left, chosen for its simplicity: it can be seen as a simple extension of intuitionistic natural deduction, whose algorithmic interpretation is very well known. In this context, the contribution of classical constructs to programming appears clearly: they correspond to control operators added to functional languages, like call/cc in Scheme. In both contexts, the role of the classical constructs is the same: they allow to take shorter routes in the construction of a proof/program.},
author = {Parigot, Michel},
booktitle = {Logic Programming and Automated Reasoning},
doi = {10.1007/BFb0013061},
editor = {Voronkov, Andrei},
file = {:Users/liang-tingchen/Dropbox/References/Parigot - 1992 - $\lambda$$\mu$-Calculus An algorithmic interpretation of classical natural deduction.pdf:pdf},
isbn = {9783540557272},
issn = {16113349},
pages = {190--201},
pmid = {17059516},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science (Lecture Notes in Artificial Intelligence)},
title = {{$\lambda$$\mu$-Calculus: An algorithmic interpretation of classical natural deduction}},
url = {http://www.springerlink.com/index/10.1007/BFb0013061},
volume = {624},
year = {1992}
}
@article{Goris2009,
abstract = {We establish the bi-modal forgetful projection of the Logic of Proofs and Formal Provability GLA. That is to say, we present a normal bi-modal provability logic with modalities □ and {\{}squared times{\}} whose theorems are precisely those formulas for which the implicit provability assertions represented by the {\{}squared times{\}} modality can be realized by explicit proof terms. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Goris, Evan},
doi = {10.1016/j.apal.2009.07.020},
file = {:Users/liang-tingchen/Dropbox/References/Goris - 2009 - A modal provability logic of explicit and implicit proofs.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Justification logic,Provability logic,Realization theorem},
month = {dec},
number = {3},
pages = {388--403},
publisher = {Elsevier B.V.},
title = {{A modal provability logic of explicit and implicit proofs}},
url = {http://dx.doi.org/10.1016/j.apal.2009.07.020 https://linkinghub.elsevier.com/retrieve/pii/S0168007209001481},
volume = {161},
year = {2009}
}
@article{Rioul2014,
abstract = {In the information theory community, the following ``historical'' statements are generally well accepted: (1) Hartley did put forth his rule twenty years before Shannon; (2) Shannon's formula as a fundamental tradeoff between transmission rate, bandwidth, and signal-to-noise ratio came out unexpected in 1948; (3) Hartley's rule is inexact while Shannon's formula is characteristic of the additive white Gaussian noise channel; (4) Hartley's rule is an imprecise relation that is not an appropriate formula for the capacity of a communication channel. We show that all these four statements are somewhat wrong. In fact, a careful calculation shows that ``Hartley's rule'' in fact coincides with Shannon's formula. We explain this mathematical coincidence by deriving the necessary and sufficient conditions on an additive noise channel such that its capacity is given by Shannon's formula and construct a sequence of such channels that makes the link between the uniform (Hartley) and Gaussian (Shannon) channels.},
author = {Rioul, Olivier and Magossi, Jos{\'{e}} Carlos},
doi = {10.3390/e16094892},
file = {:Users/liang-tingchen/Dropbox/References/Rioul, Magossi - 2014 - On {\{}S{\}}hannon's formula and {\{}H{\}}artley's rule Beyond the mathematical coincidence.pdf:pdf},
isbn = {9780735412804},
issn = {10994300},
journal = {Entropy},
keywords = {Additive noise channel,Additive white Gaussian noise (AWGN) channel,Central limit theorem,Channel capacity,Characteristic function,Differential entropy,Hartley's rule,Pulse-amplitude modulation (PAM),Shannon's formula,Signal-to-noise ratio,Uniform B-spline function,Uniform noise channel,Uniform sum distribution},
number = {9},
pages = {4892--4910},
title = {{On {\{}S{\}}hannon's formula and {\{}H{\}}artley's rule: Beyond the mathematical coincidence}},
volume = {16},
year = {2014}
}
@incollection{Barr1989,
address = {Providence, Rhode Island},
author = {Barr, Michael},
booktitle = {Categories in Computer Science and Logic},
doi = {10.1090/conm/092},
editor = {Gray, John W. and Scedrov, Andre},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1989 - Models of Horn theories.pdf:pdf},
isbn = {9780821851005},
pages = {1--7},
publisher = {American Mathematical Society},
series = {Contemporary Mathematics},
title = {{Models of Horn theories}},
url = {http://www.ams.org/conm/092/},
year = {1989}
}
@inproceedings{Nakano2000,
author = {Nakano, Hiroshi},
booktitle = {Proceedings Fifteenth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2000.855774},
file = {:Users/liang-tingchen/Dropbox/References/Nakano - 2000 - A modality for recursion.pdf:pdf},
isbn = {0-7695-0725-5},
publisher = {IEEE Comput. Soc},
title = {{A modality for recursion}},
url = {http://ieeexplore.ieee.org/document/855774/},
year = {2000}
}
@inproceedings{licata_et_al:LIPIcs:2018:9192,
abstract = {We begin by recalling the essentially global character of universes in various models of homotopy type theory, which prevents a straightforward axiomatization of their properties using the internal language of the presheaf toposes from which these model are constructed. We get around this problem by extending the internal language with a modal operator for expressing properties of global elements. In this setting we show how to construct a universe that classifies the Cohen-Coquand-Huber-M{\"{o}}rtberg (CCHM) notion of fibration from their cubical sets model, starting from the assumption that the interval is tiny-a property that the interval in cubical sets does indeed have. This leads to an elementary axiomatization of that and related models of homotopy type theory within what we call crisp type theory.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Internal Universes in Models of Homotopy Type Theory - Licata, Daniel R; Orton, Ian; Pitts, Andrew M; Spitters, Bas)

Keywords: cubical sets, dependent type theory, homotopy type theory, internal language, modalities, univalent foundations, universes},
archivePrefix = {arXiv},
arxivId = {1801.07664},
author = {Licata, Daniel R. and Orton, Ian and Pitts, Andrew M. and Spitters, Bas},
booktitle = {3rd International Conference on Formal Structures for Computation and Deduction (FSCD 2018)},
doi = {10.4230/LIPIcs.FSCD.2018.22},
editor = {Kirchner, H{\'{e}}l{\`{e}}ne},
eprint = {1801.07664},
file = {:Users/liang-tingchen/Dropbox/References//Licata et al. - 2018 - Internal Universes in Models of Homotopy Type Theory.pdf:pdf},
isbn = {978-3-95977-077-4},
issn = {1868-8969},
keywords = {Cubical sets,Dependent type theory,Homotopy type theory,Internal language,Modalities,Univalent foundations,Universes},
number = {12386},
pages = {22:1----22:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Internal Universes in Models of Homotopy Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9192},
volume = {108},
year = {2018}
}
@article{VanBreugel2012,
author = {van Breugel, Franck},
doi = {10.1016/j.ipl.2012.06.019},
file = {:Users/liang-tingchen/Dropbox/References/van Breugel - 2012 - On behavioural pseudometrics and closure ordinals.pdf:pdf},
issn = {00200190},
journal = {Information Processing Letters},
month = {oct},
number = {19},
pages = {715--718},
publisher = {Elsevier B.V.},
title = {{On behavioural pseudometrics and closure ordinals}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020019012001706},
volume = {112},
year = {2012}
}
@article{Rodriguez-Lopez2002,
abstract = {We investigate the problem of characterizing those quasi-uniform spaces for which the Vietoris topology is compatible with the Hausdorff quasi-uniformity. In particular, we prove that the Vietoris topology of a quasi-uniform space (X,U) is compatible with the Hausdorff quasi-uniformity on the family K 0(X) of nonempty compact subsets of X, if and only if for each K∈K 0(X),U -1 K is precompact. We show that for a T 1 quasi-uniform space (X,U), the Vietoris topology is compatible with the Hausdorff quasi-uniformity on the family of nonempty closed subsets of X, if and only if U is equinormal and U -1 is hereditarily precompact. We also discuss the problem in the setting of quasi-metric spaces and show, among other results, that the Vietoris topology of a quasi-metric space (X,d) is compatible with the Hausdorff extended quasi-pseudo-metric on the family of nonempty subsets of X, if and only if the quasi-uniformity induced by d coincides with the Pervin quasi-uniformity of X. {\textcopyright} 2001 Elsevier Science B.V. All rights reserved.},
author = {Rodr{\'{i}}guez-L{\'{o}}pez, Jes{\'{u}}s and Romaguera, Salvador},
doi = {10.1016/S0166-8641(01)00252-8},
file = {:Users/liang-tingchen/Dropbox/References/Rodr{\'{i}}guez-L{\'{o}}pez, Romaguera - 2002 - The relationship between the Vietoris topology and the Hausdorff quasi-uniformity.pdf:pdf},
issn = {01668641},
journal = {Topology and its Applications},
keywords = {Equinormal,Hausdorff quasi-uniformity,Hereditarily precompact,Pervin quasi-uniformity,Proximal topology,Quasi-metric,Uqu space,Vietoris topology},
month = {oct},
number = {3},
pages = {451--464},
title = {{The relationship between the Vietoris topology and the Hausdorff quasi-uniformity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166864101002528},
volume = {124},
year = {2002}
}
@article{Dwork2008c,
abstract = {In 1977 Tore Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a natural formalization of Dalenius goal cannot be achieved if the database is useful. The key obstacle is the side information that may be available to an adversary. Our results hold under very general conditions regarding the database, the notion of privacy violation, and the notion of utility. Contrary to intuition, a variant of the result threatens the privacy even of someone not in the database. This state of affairs motivated the notion of differential privacy 15, 16, a strong ad omnia privacy which, intuitively, captures the increased risk to ones privacy incurred by participating in a database. 1},
author = {Dwork, Cynthia and Naor, Moni},
file = {:Users/liang-tingchen/Dropbox/References/Dwork, Naor - 2008 - On the difficulties of disclosure prevention in statistical databases or the case for differential privacy.pdf:pdf},
journal = {Journal of Privacy and Confidentiality},
number = {1},
pages = {93--107},
title = {{On the difficulties of disclosure prevention in statistical databases or the case for differential privacy}},
url = {http://repository.cmu.edu/jpc/vol2/iss1/8/},
year = {2008}
}
@article{Pare2011,
abstract = {We show that any directed colimit of acessible categories and accessible full embeddings is accessible and, assuming the existence of arbitrarily large strongly compact cardinals, any directed colimit of acessible categories and accessible embeddings is accessible.},
archivePrefix = {arXiv},
arxivId = {1110.0767},
author = {Par{\'{e}}, Robert and Rosick{\'{y}}, Jiř{\'{i}}},
eprint = {1110.0767},
file = {:Users/liang-tingchen/Dropbox/References/Par{\'{e}}, Rosick{\'{y}} - 2011 - Colimits of accessible categories.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {accessible category,and phrases,compact cardinal,directed colimit},
month = {oct},
pages = {1--6},
title = {{Colimits of accessible categories}},
url = {http://arxiv.org/abs/1110.0767},
year = {2011}
}
@inproceedings{Bilkova2016,
abstract = {We apply methods developed to study coalgebraic logic to investigate expressivity of many-valued modal logics which we consider as coalgebraic languages interpreted over set-coalgebras with many-valued valuations. The languages are based on many-valued predicate liftings. We provide a characterization theorem for a language generated by a set of such modalities to be expressive for bisimilarity: in addition to the usual condition on the set of predicate liftings being separating, we indicate a sufficient and sometimes also necessary condition on the algebra of truth values which guarantees expressivity. Thus, adapting results of Schr¨oder [16] concerning expressivity of boolean coalgebraic logics to many-valued setting, we generalize results of Metcalfe and Mart{\'{i}} [13], concerning Hennessy-Milner property for many-valued modal logics based on ⧠ and ◇.},
author = {B{\'{i}}lkov{\'{a}}, Marta and Dost{\'{a}}l, Mat{\v{e}}j},
booktitle = {Logic, Language, Information, and Computation. WoLLIC 2016},
doi = {10.1007/978-3-662-52921-8_8},
editor = {V{\"{a}}{\"{a}}n{\"{a}}nen, Jouko and Hirvonen, {\AA}sa and de Queiroz, Ruy},
file = {:Users/liang-tingchen/Dropbox/References/B{\'{i}}lkov{\'{a}}, Dost{\'{a}}l - 2016 - Expressivity of many-valued modal logics, coalgebraically.pdf:pdf},
isbn = {9783662529201},
issn = {16113349},
pages = {109--124},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Expressivity of many-valued modal logics, coalgebraically}},
volume = {9803},
year = {2016}
}
@article{Korostenski1993,
author = {Korostenski, Mareli and Tholen, Walter},
doi = {10.1016/0022-4049(93)90171-O},
file = {:Users/liang-tingchen/Dropbox/References/Korostenski, Tholen - 1993 - Factorization systems as Eilenberg-Moore algebras.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {mar},
number = {1},
pages = {57--72},
title = {{Factorization systems as Eilenberg-Moore algebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499390171O},
volume = {85},
year = {1993}
}
@article{Carboni1993,
abstract = {In recent years, there has been considerable discussion as to the appropriate definition of distributive categories. Three definitions which have had some support are: (1) A category with finite sums and products such that the canonical map ??:A??B+ A??C???A??(B+C) is an isomorphism (Walters). (2) A category with finite sums and products such that the canonical functor +:A/A?? A/B???A/(A+B) is an equivalence (Monro). (3) A category with finite sums and finite limits such that the canonical functor + of (2) is an equivalence (Lawvere and Schanuel). There has been some confusion as to which of these was the natural notion to consider. This resulted from the fact that there are actually two elementary notions being combined in the above three definitions. The first, to which we give the name distributivity, is exactly that of (1). The second notion, which we shall call extensivity, is that of a category with finite sums for which the canonical functor + of definitions (2) and (3) is an equivalence. Extensivity, although it implies the existence of certain pullbacks, is essentially a property of having well-behaved sums. It is the existence of these pullbacks which has caused the confusion. The connections between definition (1) and definitions (2) and (3) are that any extensive category with products is distributive in the first sense, and that any category satisfying (3) satisfies (1) locally. The purpose of this paper is to present some basic facts about extensive and distributive categories, and to discuss the relationships between the two notions. ?? 1993.},
author = {Carboni, Aurelio and Lack, Stephen and Walters, R.F.C.},
doi = {10.1016/0022-4049(93)90035-R},
file = {:Users/liang-tingchen/Dropbox/References/Carboni, Lack, Walters - 1993 - Introduction to extensive and distributive categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {feb},
number = {2},
pages = {145--158},
title = {{Introduction to extensive and distributive categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002240499390035R},
volume = {84},
year = {1993}
}
@article{Bezem2021a,
abstract = {We give a syntax independent formulation of finitely presented generalized algebraic theories as initial objects in categories of categories with families (cwfs) with extra structure. To this end, we simultaneously define the notion of a presentation $\Sigma$ of a generalized algebraic theory and the associated category CwF $\Sigma$ of small cwfs with a $\Sigma$-structure and cwf-morphisms that preserve $\Sigma$-structure on the nose. Our definition refers to the purely semantic notion of uniform family of contexts, types, and terms in CwF $\Sigma$ . Furthermore, we show how to syntactically construct an initial cwf with a $\Sigma$-structure. This result can be viewed as a generalization of Birkhoff's completeness theorem for equational logic. It is obtained by extending Castellan, Clairambault, and Dybjer's construction of an initial cwf. We provide examples of generalized algebraic theories for monoids, categories, categories with families, and categories with families with extra structure for some type formers of Martin-L{\"{o}}f type theory. The models of these are internal monoids, internal categories, and internal categories with families (with extra structure) in a small category with families. Finally, we show how to extend our definition to some generalized algebraic theories that are not finitely presented, such as the theory of contextual cwfs.},
author = {Bezem, Marc and Coquand, Thierry and Dybjer, Peter and Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel},
doi = {10.1017/S0960129521000268},
file = {:Users/liang-tingchen/Dropbox/References/Bezem et al. - 2021 - On generalized algebraic theories and categories with families.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {category with families,dependent type theory,generalized algebraic theory,initial model,internal category,martin-l{\"{o}}f type theory},
month = {oct},
pages = {1--18},
title = {{On generalized algebraic theories and categories with families}},
url = {https://www.cambridge.org/core/product/identifier/S0960129521000268/type/journal{\_}article},
year = {2021}
}
@article{Mariano2004,
abstract = {We establish the following model-theoretic characterization: profinite {\$}L{\$}-structures, the cofiltered limits of finite {\$}L{\$}-structures,are retracts of ultraproducts of finite {\$}L{\$}-structures. As a consequence, any elementary class of {\$}L{\$}-structures axiomatized by {\$}L{\$}-sentences of the form {\$}\backslashforall \backslashvec{\{}x{\}} (\backslashpsi{\_}{\{}0{\}}(\backslashvec{\{}x{\}}) \backslashra \backslashpsi{\_}{\{}1{\}}(\backslashvec{\{}x{\}})){\$}, where {\$}\backslashpsi{\_}{\{}0{\}}(\backslashvec{\{}x{\}}),\backslashpsi{\_}{\{}1{\}}(\backslashvec{\{}x{\}}){\$} are existencial-positives {\$}L{\$}-formulas, is closed under the formation of profinite objects in the category {\{}$\backslash$bf L-mod{\}}, the category of structures suitable for the language {\$}L{\$} and {\$}L{\$}-homomorphisms.},
archivePrefix = {arXiv},
arxivId = {math/0401095},
author = {Mariano, Hugo Luiz},
eprint = {0401095},
file = {:Users/liang-tingchen/Dropbox/References/Mariano - 2004 - Profinite Structures are Retracts of Ultraproducts of Finite Structures.pdf:pdf},
journal = {ArXiv e-prints},
pages = {1--13},
primaryClass = {math},
title = {{Profinite Structures are Retracts of Ultraproducts of Finite Structures}},
url = {http://arxiv.org/abs/math/0401095},
year = {2004}
}
@article{Worrell2005,
abstract = {A standard construction of the final coalgebra of an endofunctor involves defining a chain of iterates, starting at the final object of the underlying category and successively applying the functor. In this paper we show that, for a finitary set functor, this construction always yields a final coalgebra in $\omega$2=$\omega$+$\omega$ steps.},
author = {Worrell, James},
doi = {10.1016/j.tcs.2004.12.009},
file = {:Users/liang-tingchen/Dropbox/References/Worrell - 2005 - On the final sequence of a finitary set functor.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jun},
number = {1-3},
pages = {184--199},
title = {{On the final sequence of a finitary set functor}},
url = {http://dx.doi.org/10.1016/j.tcs.2004.12.009},
volume = {338},
year = {2005}
}
@article{GOVERNATORI2005,
abstract = {This paper presents an approach for the specification and implementation of translating contracts from a human-oriented form into an executable representation for monitoring. This will be done in the setting of RuleML. The task of monitoring contract execution and performance requires a logical account of deontic and defeasible aspects of legal language; currently such aspects are not covered by RuleML; accordingly we show how to extend it to cover such notions. From its logical form, the contract will be thus transformed into a machine readable rule notation and eventually implemented as executable semantics via any mark-up languages depending on the client's preference, for contract monitoring purposes.},
author = {GOVERNATORI, GUIDO},
doi = {10.1142/S0218843005001092},
file = {:Users/liang-tingchen/Dropbox/References/GOVERNATORI - 2005 - REPRESENTING BUSINESS CONTRACTS IN RuleML.pdf:pdf},
isbn = {0218843005001},
issn = {0218-8430},
journal = {International Journal of Cooperative Information Systems},
keywords = {1,agreements between two or,background and motivation,business contracts,business contracts are mutual,defeasible logic,deontic logic,economic exchanges and transactions,in various types of,logic of violation,more parties engaging,ruleml,specify,they are used to},
month = {jun},
number = {02n03},
pages = {181--216},
title = {{REPRESENTING BUSINESS CONTRACTS IN RuleML}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218843005001092},
volume = {14},
year = {2005}
}
@article{Baez2009,
abstract = {In physics, Feynman diagrams are used to reason about quantum processes. In the 1980s, it became clear that underlying these diagrams is a powerful analogy between quantum physics and topology: namely, a linear operator behaves very much like a "cobordism". Similar diagrams can be used to reason about logic, where they represent proofs, and computation, where they represent programs. With the rise of interest in quantum cryptography and quantum computation, it became clear that there is extensive network of analogies between physics, topology, logic and computation. In this expository paper, we make some of these analogies precise using the concept of "closed symmetric monoidal category". We assume no prior knowledge of category theory, proof theory or computer science.},
archivePrefix = {arXiv},
arxivId = {0903.0340},
author = {Baez, John C. and Stay, Mike},
eprint = {0903.0340},
file = {:Users/liang-tingchen/Dropbox/References/Baez, Stay - 2009 - Physics, Topology, Logic and Computation A Rosetta Stone.pdf:pdf},
journal = {ArXiv e-prints},
month = {mar},
pages = {73},
title = {{Physics, Topology, Logic and Computation: A Rosetta Stone}},
url = {http://arxiv.org/abs/0903.0340},
year = {2009}
}
@article{Berardi2019,
abstract = {A cyclic proof system, called CLKID-omega, gives us another way of representing inductive definitions and effcient proof search. The 2005 paper by Brotherston showed that the provability of CLKID-omega includes the provability of LKID, first order classical logic with inductive definitions in Martin-L{\"{o}}f's style, and conjectured the equivalence. The equivalence has been left an open question since 2011. This paper shows that CLKID-omega and LKID are indeed not equivalent. This paper considers a statement called 2-Hydra in these two systems with the first-order language formed by 0, the successor, the natural number predicate, and a binary predicate symbol used to express 2-Hydra. This paper shows that the 2-Hydra statement is provable in CLKID-omega, but the statement is not provable in LKID, by constructing some Henkin model where the statement is false.},
author = {Berardi, Stefano and Tatsuta, Makoto},
doi = {10.23638/LMCS-15(3:10)2019},
file = {:Users/liang-tingchen/Dropbox/References/Berardi, Tatsuta - 2019 - Classical System of Martin-Lof's Inductive Definitions is not Equivalent to Cyclic Proofs.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Brotherston-Simpson conjecture,Cyclic proof,Henkin models,Inductive definitions,Martin-Lof's system of inductive definitions,Proof theory},
number = {3},
pages = {1--10},
title = {{Classical System of Martin-Lof's Inductive Definitions is not Equivalent to Cyclic Proofs}},
volume = {15},
year = {2019}
}
@incollection{Gabbay1999,
author = {Gabbay, Dov M},
booktitle = {Logic Programs, Norms and Action},
doi = {10.1007/978-3-642-29414-3_5},
editor = {Stathis, Alexander ArtikisRobert CravenNihan Kesim {\c{C}}i{\c{c}}ekliBabak SadighiKostas},
file = {:Users/liang-tingchen/Dropbox/References/Gabbay - 2012 - What Is Negation as Failure.pdf:pdf},
isbn = {0792355695},
pages = {52--78},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{What Is Negation as Failure?}},
url = {http://link.springer.com/10.1007/978-3-642-29414-3{\_}5},
volume = {7360},
year = {2012}
}
@article{Tt2000,
archivePrefix = {arXiv},
arxivId = {math/0004117},
author = {Joyal, Andr{\'{e}} and Street, Ross},
doi = {10.1016/0001-8708(91)90003-P},
eprint = {0004117},
file = {:Users/liang-tingchen/Dropbox/References/Joyal, Street - 1991 - The geometry of tensor calculus, I.pdf:pdf},
isbn = {9780521849425},
issn = {00018708},
journal = {Advances in Mathematics},
month = {jul},
number = {1},
pages = {55--112},
primaryClass = {math},
title = {{The geometry of tensor calculus, I}},
url = {http://www.tandfonline.com/doi/full/10.1080/14790726.2015.1073744 http://linkinghub.elsevier.com/retrieve/pii/000187089190003P},
volume = {88},
year = {1991}
}
@article{Kavvos2019,
author = {Kavvos, G. Alex},
doi = {10.1145/3290333},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2019 - Modalities, cohesion, and information flow.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {category theory,cohesion,information flow,information flow control,modal type systems,modal type theory,modalities,noninterference,type systems},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Modalities, cohesion, and information flow}},
url = {https://dl.acm.org/doi/10.1145/3290333},
volume = {3},
year = {2019}
}
@article{Sarathy2011,
abstract = {Laplace noise addition is often advanced as an approach for satisfying differ-ential privacy. There have been several illustrations of the application of Laplace noise addition for count data, but no evaluation of its performance for numeric data. In this study we evaluate the privacy and utility performance of Laplace noise addition for numeric data. Our results indicate that Laplace noise addition delivers the promised level of privacy only by adding a large quantity of noise for even relatively large sub-sets. Because of this, even for simple mean queries, the responses for a masking mecha-nism that uses Laplace noise addition is of little value. We also show that Laplace noise addition may be vulnerable to a tracker attack. In order to avoid this, it may be neces-sary to increase the variance of the noise added as a function of the number of queries issued. This implies that the utility of the responses would be further reduced. These results raise serious questions regarding the viability of Laplace based noise addition for masking numeric data.},
author = {Sarathy, Rathindra and Muralidhar, Krishnamurty},
file = {:Users/liang-tingchen/Dropbox/References/Sarathy, Muralidhar - 2011 - Evaluating laplace noise addition to satisfy differential privacy for numeric data.pdf:pdf},
isbn = {1888-5063},
issn = {18885063},
journal = {Transactions on Data Privacy},
number = {1},
pages = {1--17},
title = {{Evaluating laplace noise addition to satisfy differential privacy for numeric data}},
volume = {4},
year = {2011}
}
@incollection{Moshier2009,
abstract = {The full subcategory of proximity lattices equipped with some additional structure (a certain form of negation) is equivalent to the category of compact Hausdorff spaces. Using the Stone-Gelfand-Naimark duality, we know that the category of proximity lattices with negation is dually equivalent to the category of real C * algebras. The aim of this paper is to give a new proof for this duality, avoiding the construction of spaces. We prove that the category of C * algebras is equivalent to the category of skew frames with negation, which appears in the work of Moshier and Jung on the bitopological nature of Stone duality.},
author = {Moshier, M. Andrew and Petrişan, Daniela},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-03741-2_20},
editor = {Kurz, Alexander and Lenisa, Marina and Tarlecki, Andrzej},
file = {:Users/liang-tingchen/Dropbox/References/Moshier, Petrişan - 2009 - A Duality Theorem for Real C∗ Algebras.pdf:pdf},
isbn = {978-3-642-03740-5},
pages = {284--299},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Duality Theorem for Real C{\^{}}∗ Algebras}},
url = {10.1007/978-3-642-03741-2{\_}20},
volume = {5728},
year = {2009}
}
@article{Sozeau2020b,
abstract = {The MetaCoq project aims to provide a certified meta-programming environment in Coq. It builds on Template-Coq, a plugin for Coq originally implemented by Malecha (Extensible proof engineering in intensional type theory, Harvard University, http://gmalecha.github.io/publication/2015/02/01/extensible-proof-engineering-in-intensional-type-theory.html, 2014), which provided a reifier for Coq terms and global declarations, as represented in the Coq kernel, as well as a denotation command. Recently, it was used in the CertiCoq certified compiler project (Anand et al., in: CoqPL, Paris, France, http://conf.researchr.org/event/CoqPL-2017/main-certicoq-a-verified-compiler-for-coq, 2017), as its front-end language, to derive parametricity properties (Anand and Morrisett, in: CoqPL'18, Los Angeles, CA, USA, 2018). However, the syntax lacked semantics, be it typing semantics or operational semantics, which should reflect, as formal specifications in Coq, the semantics of Coq 's type theory itself. The tool was also rather bare bones, providing only rudimentary quoting and unquoting commands. We generalize it to handle the entire polymorphic calculus of cumulative inductive constructions, as implemented by Coq, including the kernel's declaration structures for definitions and inductives, and implement a monad for general manipulation of Coq 's logical environment. We demonstrate how this setup allows Coq users to define many kinds of general purpose plugins, whose correctness can be readily proved in the system itself, and that can be run efficiently after extraction. We give a few examples of implemented plugins, including a parametricity translation and a certified extraction to call-by-value $\lambda$-calculus. We also advocate the use of MetaCoq as a foundation for higher-level tools.},
author = {Sozeau, Matthieu and Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Forster, Yannick and Kunze, Fabian and Malecha, Gregory and Tabareau, Nicolas and Winterhalter, Th{\'{e}}o},
doi = {10.1007/s10817-019-09540-0},
file = {:Users/liang-tingchen/Dropbox/References/Sozeau et al. - 2020 - The MetaCoq Project.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Meta-Programming,Program certification,Proof assistants},
month = {jun},
number = {5},
pages = {947--999},
publisher = {Springer Netherlands},
title = {{The MetaCoq Project}},
url = {https://doi.org/10.1007/s10817-019-09540-0 http://link.springer.com/10.1007/s10817-019-09540-0},
volume = {64},
year = {2020}
}
@inproceedings{Cirstea2013,
abstract = {We consider state-based systems modelled as coalgebras whose type incorporates branching, and show that by suitably adapting the definition of coalgebraic bisimulation, one obtains a general and uniform account of the linear-time behaviour of a state in such a coalgebra. By moving away from a boolean universe of truth values, our approach can measure the extent to which a state in a system with branching is able to exhibit a particular linear-time behaviour. This instantiates to measuring the probability of a specific behaviour occurring in a probabilistic system, or measuring the minimal cost of exhibiting a specific behaviour in the case of weighted computations.},
author = {C{\^{i}}rstea, Corina},
booktitle = {Workshop on Fixed Points in Computer Science},
doi = {10.4204/EPTCS.126.2},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea - 2013 - From branching to linear time, coalgebraically.pdf:pdf},
issn = {2075-2180},
month = {aug},
pages = {11--27},
title = {{From branching to linear time, coalgebraically}},
url = {http://arxiv.org/abs/1309.0891v1},
volume = {126},
year = {2013}
}
@incollection{Rogozin2020,
author = {Rogozin, Daniel},
booktitle = {Logical Foundations of Computer Science. LFCS 2020},
doi = {10.1007/978-3-030-36755-8_15},
editor = {Artemov, Sergei and Nerode, Anil},
file = {:Users/liang-tingchen/Dropbox/References/Rogozin - 2020 - Modal Type Theory Based on the Intuitionistic Modal Logic {\$}{\$}mathbf{\{}IEL{\}}{\{}-{\}}{\$}{\$}.pdf:pdf},
isbn = {9783030367558},
keywords = {applicative functor,functional programming,intuitionistic epistemic logic,modal type theory},
pages = {236--248},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Modal Type Theory Based on the Intuitionistic Modal Logic {\$}{\$}$\backslash$mathbf{\{}IEL{\}}{\^{}}{\{}-{\}}{\$}{\$}}},
url = {http://link.springer.com/10.1007/978-3-030-36755-8{\_}15},
volume = {11972},
year = {2020}
}
@article{Bonchi2015,
abstract = {We propose an abstract framework for modelling state-based systems with internal behaviour as e.g. given by silent or $\epsilon$-transitions. Our approach employs monads with a parametrized fixpoint operator † to give a semantics to those systems and implement a sound procedure of abstraction of the internal transitions, whose labels are seen as the unit of a free monoid. More broadly, our approach extends the standard coalgebraic framework for state-based systems by taking into account the algebraic structure of the labels of their transitions. This allows to consider a wide range of other examples, including Mazurkiewicz traces for concurrent systems and non-deterministic transducers.},
archivePrefix = {arXiv},
arxivId = {1402.4062},
author = {Bonchi, Filippo and Milius, Stefan and Silva, Alexandra and Zanasi, Fabio},
doi = {10.1016/j.tcs.2015.03.024},
eprint = {1402.4062},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi et al. - 2015 - Killing epsilons with a dagger A coalgebraic study of systems with algebraic label structure.pdf:pdf},
isbn = {9783662441237},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Coalgebras on kleisli categories,Epsilon transitions,Mazurkiewicz traces,Non-deterministic transducers,Parametrized fixpoint operator,Trace semantics},
pages = {102--126},
publisher = {Elsevier B.V.},
title = {{Killing epsilons with a dagger: A coalgebraic study of systems with algebraic label structure}},
url = {http://dx.doi.org/10.1016/j.tcs.2015.03.024},
volume = {604},
year = {2015}
}
@inproceedings{Jeuring2010,
address = {New York, New York, USA},
author = {Magalh{\~{a}}es, Jos{\'{e}} Pedro and Dijkstra, Atze and Jeuring, Johan and L{\"{o}}h, Andres},
booktitle = {Proceedings of the third ACM Haskell symposium on Haskell - Haskell '10},
doi = {10.1145/1863523.1863529},
file = {:Users/liang-tingchen/Dropbox/References/Magalh{\~{a}}es et al. - 2010 - A generic deriving mechanism for Haskell.pdf:pdf},
isbn = {9781450302524},
pages = {37},
publisher = {ACM Press},
title = {{A generic deriving mechanism for Haskell}},
url = {http://portal.acm.org/citation.cfm?doid=1863523.1863529},
year = {2010}
}
@article{Cockett2008,
abstract = {We give an introduction to Turing categories, which are a convenient setting for the categorical study of abstract notions of computability. The concept of a Turing category first appeared (albeit not under that name or at the level of generality we present it here) in the work of Longo and Moggi; later, Di Paolo and Heller introduced the closely related recursion categories. One of the purposes of Turing categories is that they may be used to develop categorical formulations of recursion theory, but they also include other notions of computation, such as models of (partial) combinatory logic and of the (partial) lambda calculus. In this paper our aim is to give an introduction to the basic structural theory, while at the same time illustrating how the notion is a meeting point for various other areas of logic and computation. We also provide a detailed exposition of the connection between Turing categories and partial combinatory algebras and show the sense in which the study of Turing categories is equivalent to the study of PCAs. {\textcopyright} 2008.},
author = {Cockett, J.R.B. and Hofstra, P.J.W.},
doi = {10.1016/j.apal.2008.04.005},
file = {:Users/liang-tingchen/Dropbox/References/Cockett, Hofstra - 2008 - Introduction to Turing categories.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Computability theory,Models of computation,Partial algebra,Partial combinatory algebra,Partial map category},
month = {dec},
number = {2-3},
pages = {183--209},
publisher = {Elsevier B.V.},
title = {{Introduction to Turing categories}},
url = {http://dx.doi.org/10.1016/j.apal.2008.04.005 https://linkinghub.elsevier.com/retrieve/pii/S0168007208000948},
volume = {156},
year = {2008}
}
@article{Winograd-Cort2017,
abstract = {Differential privacy is a widely studied theory for analyzing sensitive data with a strong privacy guaranteeÐ any change in an individual's data can have only a small statistical effect on the resultÐand a growing number of programming languages now support differentially private data analysis. A common shortcoming of these languages is poor support for adaptivity. In practice, a data analyst rarely wants to run just one function over a sensitive database, nor even a predetermined sequence of functions with fixed privacy parameters; rather, she wants to engage in an interaction where, at each step, both the choice of the next function and its privacy parameters are informed by the results of prior functions. Existing languages support this scenario using a simple composition theorem, which often gives rather loose bounds on the actual privacy cost of composite functions, substantially reducing how much computation can be performed within a given privacy budget. The theory of differential privacy includes other theorems with much better bounds, but these have not yet been incorporated into programming languages. We propose a novel framework for adaptive composition that is elegant, practical, and implementable. It consists of a reformulation based on typed functional programming of privacy filters, together with a concrete realization of this framework in the design and implementation of a new language, called Adaptive Fuzz. Adaptive Fuzz transplants the core static type system of Fuzz to the adaptive setting by wrapping the Fuzz typechecker and runtime system in an outer adaptive layer, allowing Fuzz programs to be conveniently constructed and typechecked on the fly. We describe an interpreter for Adaptive Fuzz and report results from two case studies demonstrating its effectiveness for implementing common statistical algorithms over real data sets.},
author = {Winograd-Cort, Daniel and Haeberlen, Andreas and Roth, Aaron and Pierce, Benjamin C},
doi = {10.1145/3110254},
file = {:Users/liang-tingchen/Dropbox/References/Winograd-Cort et al. - 2017 - A framework for adaptive differential privacy.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Adaptivity,Case Study,Differential Privacy,Fuzz,Privacy Filter},
month = {aug},
number = {ICFP},
pages = {1--29},
title = {{A framework for adaptive differential privacy}},
url = {https://doi.org/10.1145/3110254 http://dl.acm.org/citation.cfm?doid=3136534.3110254},
volume = {1},
year = {2017}
}
@article{Bellin1994,
author = {Bellin, Gianluigi and Scott, Philip J.},
doi = {10.1016/0304-3975(94)00104-9},
file = {:Users/liang-tingchen/Dropbox/References/Bellin, Scott - 1994 - On the $\pi$-calculus and linear logic.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1},
pages = {11--65},
title = {{On the $\pi$-calculus and linear logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0304397594001049},
volume = {135},
year = {1994}
}
@book{Kelly1982,
author = {Kelly, Gregory Maxwell},
booktitle = {Theory and Applications of Categories},
file = {:Users/liang-tingchen/Dropbox/References/Kelly - 1982 - Basic Concepts of Enriched Category Theory.pdf:pdf},
number = {10},
publisher = {Cambridge University Press},
series = {Lecture Notes in Mathematics},
title = {{Basic Concepts of Enriched Category Theory}},
url = {http://www.tac.mta.ca/tac/reprints/articles/10/tr10.html},
volume = {64},
year = {1982}
}
@misc{Ballester-Bolinches2012,
author = {Ballester-Bolinches, Adolfo and Pin, Jean-{\'{E}}ric and Soler-Escriv{\`{a}}, Xaro},
booktitle = {Forum Mathematicum},
doi = {10.1515/forum-2012-0055},
file = {:Users/liang-tingchen/Dropbox/References/Ballester-Bolinches, Pin, Soler-Escriv{\`{a}} - 2012 - Formations of finite monoids and formal languages Eilenberg's variety theorem revisite.pdf:pdf},
issn = {0933-7741},
number = {6},
pages = {1737--1761},
title = {{Formations of finite monoids and formal languages: Eilenberg's variety theorem revisited}},
volume = {26},
year = {2012}
}
@article{Smyth1983a,
author = {Smyth, Michael B.},
doi = {10.1007/BFb0036946},
editor = {Diaz, Josep},
file = {:Users/liang-tingchen/Dropbox/References/Smyth - 1983 - Power domains and predicate transformers A topological view.pdf:pdf},
journal = {Automata, Languages and Programming},
pages = {662--675},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Power domains and predicate transformers: A topological view}},
type = {Journal article},
url = {http://dx.doi.org/10.1007/BFb0036946},
volume = {154},
year = {1983}
}
@article{Dybjer2006,
abstract = {An indexed inductive definition (IID) is a simultaneous inductive definition of an indexed family of sets. An inductive-recursive definition (IRD) is a simultaneous inductive definition of a set and a recursive definition of a function on that set. An indexed inductive-recursive definition (IIRD) is a combination of both. We present a closed theory which allows us to introduce all IIRD in a natural way without much encoding. By specialising it we also get a closed theory of IID. Our theory of IIRD includes essentially all definitions of sets which occur in Martin-L{\"{o}}f type theory. We show in particular that Martin-L{\"{o}}f's computability predicates for dependent types and Palmgren's higher order universes are special kinds of IIRD and thereby clarify why they are constructively acceptable notions. We give two axiomatisations. The first formalises a principle for introducing meaningful IIRD by using the data-construct in the original version of the proof assistant Agda for Martin-L{\"{o}}f type theory. The second one admits a more general form of introduction rule, including the introduction rule for the intensional identity relation, which is not covered by the first axiomatisation. If we add an extensional identity relation to our logical framework, we show that the theories of restricted and general IIRD are equivalent by interpreting them in each other. Finally, we show the consistency of our theories by constructing a model in classical set theory extended by a Mahlo cardinal. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {Dybjer, Peter and Setzer, Anton},
doi = {10.1016/j.jlap.2005.07.001},
file = {:Users/liang-tingchen/Dropbox/References/Dybjer, Setzer - 2006 - Indexed induction–recursion.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
keywords = {Dependent type theory,Generic programming,Inductive definitions,Inductive families,Inductive-recursive definitions,Initial algebras,Martin-L{\"{o}}f type theory,Normalisation proofs},
month = {jan},
number = {1},
pages = {1--49},
title = {{Indexed induction–recursion}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1567832605000536},
volume = {66},
year = {2006}
}
@book{Mader1997,
abstract = {In this paper we show the equivalence of model checking infinite systems$\backslash$nand solving infinite Boolean equation systems, andgive a method that$\backslash$nsolves infinite Boolean equation systems. The method issound and$\backslash$ncomplete, even if the problem itself is undecidable.},
address = {Berlin},
author = {Mader, Angelika},
file = {:Users/liang-tingchen/Dropbox/References/Mader - 1997 - Verification of Modal Properties using Boolean Equation Systems.pdf:pdf},
isbn = {9783929470581},
issn = {1571-5078},
publisher = {Bertz Verlag},
series = {Edition versal 8},
title = {{Verification of Modal Properties using Boolean Equation Systems}},
url = {http://eprints.eemcs.utwente.nl/1078/},
year = {1997}
}
@inproceedings{Allais2017,
abstract = {We abstract the common type-and-scope safe structure from computations on terms that deliver, e.g., renaming, substitution, evaluation, CPS-transformation, and printing with a name supply. By exposing this structure, we can prove generic simulation and fusion lemmas relating operations built this way. This work has been fully formalised in Agda.},
address = {New York, NY, USA},
author = {Allais, Guillaume and Chapman, James and McBride, Conor and McKinna, James},
booktitle = {Proceedings of the 6th ACM SIGPLAN Conference on Certified Programs and Proofs},
doi = {10.1145/3018610.3018613},
file = {:Users/liang-tingchen/Dropbox/References/Allais et al. - 2017 - Type-and-scope safe programs and their proofs.pdf:pdf},
isbn = {9781450347051},
keywords = {Agda,Generic programming,Lambda-calculus,Mechanized meta-theory,Normalisation by evaluation,Semantics},
month = {jan},
pages = {195--207},
publisher = {ACM},
title = {{Type-and-scope safe programs and their proofs}},
url = {https://dl.acm.org/doi/10.1145/3018610.3018613},
year = {2017}
}
@inproceedings{Losch2013,
address = {New York, New York, USA},
author = {L{\"{o}}sch, Steffen and Pitts, Andrew M.},
booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '13},
doi = {10.1145/2429069.2429073},
file = {:Users/liang-tingchen/Dropbox/References/L{\"{o}}sch, Pitts - 2013 - Full abstraction for nominal Scott domains.pdf:pdf},
isbn = {9781450318327},
keywords = {denotational semantics,domain theory,full ab-,nominal sets,straction,symmetry},
number = {Theorem 8},
pages = {3},
publisher = {ACM Press},
title = {{Full abstraction for nominal Scott domains}},
url = {http://dl.acm.org/citation.cfm?doid=2429069.2429073},
year = {2013}
}
@article{Nelson1947,
author = {Nelson, David},
doi = {10.2307/1990222},
file = {:Users/liang-tingchen/Dropbox/References/Nelson - 1947 - Recursive Functions and Intuitionistic Number Theory.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
month = {mar},
number = {2},
pages = {307},
title = {{Recursive Functions and Intuitionistic Number Theory}},
url = {https://www.jstor.org/stable/1990222?origin=crossref},
volume = {61},
year = {1947}
}
@book{Lurie2009,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0608040v4},
author = {Lurie, Jacob},
eprint = {0608040v4},
file = {:Users/liang-tingchen/Dropbox/References/Lurie - 2009 - Higher topos theory.pdf:pdf},
isbn = {978-0691140490},
month = {jul},
primaryClass = {arXiv:math},
publisher = {Princeton University Press},
title = {{Higher topos theory}},
url = {http://arxiv.org/abs/math/0608040v4},
year = {2009}
}
@article{Shulman2008a,
abstract = {In some bicategories, the 1-cells are 'morphisms' between the 0-cells, such as functors between categories, but in others they are 'objects' over the 0-cells, such as bimodules, spans, distributors, or parametrized spectra. Many bicategorical notions do not work well in these cases, because the 'morphisms between 0-cells', such as ring homomorphisms, are missing. We can include them by using a pseudo double category, but usually these morphisms also induce base change functors acting on the 1-cells. We avoid complicated coherence problems by describing base change 'nonalgebraically', us-ing categorical fibrations. The resulting 'framed bicategories' assemble into 2-categories, with attendant notions of equivalence, adjunction, and so on which are more appropriate for our examples than are the usual bicategorical ones. We then describe two ways to construct framed bicategories. One is an analogue of rings and bimodules which starts from one framed bicategory and builds another. The other starts from a 'monoidal fibration', meaning a parametrized family of monoidal categories, and produces an analogue of the framed bicategory of spans. Combining the two, we obtain a construction which includes both enriched and internal categories as special cases.},
archivePrefix = {arXiv},
arxivId = {0706.1286},
author = {Shulman, Michael},
eprint = {0706.1286},
file = {:Users/liang-tingchen/Dropbox/References/Shulman - 2008 - Framed bicategories and monoidal fibrations.pdf:pdf},
journal = {Theory and Applications of Categories},
number = {18},
pages = {650--738},
title = {{Framed bicategories and monoidal fibrations}},
url = {http://www.tac.mta.ca/tac/volumes/20/18/20-18.pdf},
volume = {20},
year = {2008}
}
@article{Capretta2005,
author = {Capretta, Venanzio},
doi = {10.2168/LMCS-1(2:1)2005},
editor = {Barendregt, Henk},
file = {:Users/liang-tingchen/Dropbox/References/Capretta - 2005 - General recursion via coinductive types.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {jul},
number = {2},
pages = {1--28},
title = {{General recursion via coinductive types}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=55},
volume = {1},
year = {2005}
}
@article{Seely1983,
author = {Seely, Robert A. G.},
doi = {10.1002/malq.19830291005},
file = {:Users/liang-tingchen/Dropbox/References/Seely - 1983 - Hyperdoctrines, Natural Deduction and the Beck Condition.pdf:pdf},
issn = {00443050},
journal = {Mathematical Logic Quarterly},
number = {10},
pages = {505--542},
title = {{Hyperdoctrines, Natural Deduction and the Beck Condition}},
url = {http://doi.wiley.com/10.1002/malq.19830291005},
volume = {29},
year = {1983}
}
@phdthesis{Clarkson2010a,
abstract = {Computer security policies often are stated informally in terms of confidentiality, integrity, and availability of information and resources; these policies can be qualitative or quantitative. To formally quantify confidentiality and integrity, a new model of quantitative information flow is proposed in which information flow is quantified as the change in the accuracy of an observers beliefs. This new model resolves anomalies present in previous quantitative information-flow models, which are based on change in uncertainty. And the new model is sufficiently general that it can be instantiated to measure either accuracy or uncertainty. To formalize security policies in general, a generalization of the theory of trace properties (originally developed for program verification) is proposed. Security policies are modeled as hyperproperties, which are sets of trace properties. Although important security policies, such as secure information flow, cannot be expressed as trace properties, they can be expressed as hyperproperties. Safety and liveness are generalized from trace properties to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. Verification, refinement, and topology of hyperproperties are also addressed. Hyperproperties for system representations beyond trace sets are investigated.},
author = {Clarkson, Michael Ryan},
booktitle = {New York},
file = {:Users/liang-tingchen/Dropbox/References/Clarkson - 2010 - Quantification and Formalization of Security.pdf:pdf},
number = {February},
school = {Cornell University},
title = {{Quantification and Formalization of Security}},
url = {http://www.cs.cornell.edu/people/clarkson/papers/clarkson{\_}dissertation.pdf},
year = {2010}
}
@book{Yanofsky2017,
abstract = {Theoretical computer science discusses foundational issues about computations. It asks and answers questions such as "What is a computation?", "What is computable?", "What is efficiently computable?","What is information?", "What is random?", "What is an algorithm?", etc. We will present many of the major themes and theorems with the basic language of category theory. Surprisingly, many interesting theorems and concepts of theoretical computer science are easy consequences of functoriality and composition when you look at the right categories and functors connecting them.},
archivePrefix = {arXiv},
arxivId = {1710.03090},
author = {Yanofsky, Noson S.},
doi = {10.1017/9781108872348},
eprint = {1710.03090},
file = {:Users/liang-tingchen/Dropbox/References/Yanofsky - 2022 - Theoretical Computer Science for the Working Category Theorist.pdf:pdf},
isbn = {9781108872348},
issn = {1178-3540},
month = {mar},
publisher = {Cambridge University press},
title = {{Theoretical Computer Science for the Working Category Theorist}},
url = {http://arxiv.org/abs/1710.03090 https://www.cambridge.org/core/product/identifier/9781108872348/type/element},
volume = {1861},
year = {2022}
}
@article{GUMM2002,
author = {Gumm, H. Peter and Schr{\"{o}}der, Tobias},
file = {:Users/liang-tingchen/Dropbox/References/Gumm, Schr{\"{o}}der - 2002 - Coalgebras of bounded type.pdf:pdf},
issn = {1469-8072},
journal = {Mathematical Structures in Computer Science},
language = {English},
month = {oct},
number = {05},
pages = {565--578},
title = {{Coalgebras of bounded type}},
url = {http://journals.cambridge.org/abstract{\_}S0960129501003590},
volume = {12},
year = {2002}
}
@article{ZuiderveenBorgesius2016,
abstract = {Information about millions of people is collected for behavioural targeting, a type of marketing that involves tracking people's online behaviour for targeted advertising. It is hotly debated whether data protection law applies to behavioural targeting. Many behavioural targeting companies say that, as long as they do not tie names to data they hold about individuals, they do not process any personal data, and that, therefore, data protection law does not apply to them. European Data Protection Authorities, however, take the view that a company processes personal data if it uses data to single out a person, even if it cannot tie a name to these data. This paper argues that data protection law should indeed apply to behavioural targeting. Companies can often tie a name to nameless data about individuals. Furthermore, behavioural targeting relies on collecting information about individuals, singling out individuals, and targeting ads to individuals. Many privacy risks remain, regardless of whether companies tie a name to the information they hold about a person. A name is merely one of the identifiers that can be tied to data about a person, and it is not even the most practical identifier for behavioural targeting. Seeing data used to single out a person as personal data fits the rationale for data protection law: protecting fairness and privacy.},
author = {{Zuiderveen Borgesius}, Frederik J.},
doi = {10.1016/j.clsr.2015.12.013},
file = {:Users/liang-tingchen/Dropbox/References/Zuiderveen Borgesius - 2016 - Singling out people without knowing their names – Behavioural targeting, pseudonymous data, and the new.pdf:pdf},
isbn = {3162754496},
issn = {02673649},
journal = {Computer Law {\&} Security Review},
keywords = {Behavioural targeting,Cookie,Data protection law,IP address,Online behavioural advertising,Personal data,Privacy,Profiling,Pseudonymous data,Tracking},
month = {apr},
number = {2},
pages = {256--271},
publisher = {Elsevier Ltd},
title = {{Singling out people without knowing their names – Behavioural targeting, pseudonymous data, and the new Data Protection Regulation}},
url = {http://dx.doi.org/10.1016/j.clsr.2015.12.013 https://linkinghub.elsevier.com/retrieve/pii/S0267364915001788},
volume = {32},
year = {2016}
}
@article{Weber2007,
author = {Weber, Mark},
doi = {10.1007/s10485-007-9079-2},
file = {:Users/liang-tingchen/Dropbox/References/Weber - 2007 - Yoneda structures from 2-toposes.pdf:pdf},
isbn = {1048500790792},
issn = {09272852},
journal = {Applied Categorical Structures},
keywords = {2-topos,Fibration,Internal category theory,Yoneda structure},
number = {May},
pages = {259--323},
title = {{Yoneda structures from 2-toposes}},
volume = {15},
year = {2007}
}
@article{Davey2006,
author = {Davey, Brian A.},
file = {:Users/liang-tingchen/Dropbox/References/Davey - 2006 - Natural dualities for structures.pdf:pdf},
journal = {Acta univ. M. Belii},
keywords = {natural duality,partial structure,topological partial structure},
number = {13},
pages = {3--28},
title = {{Natural dualities for structures}},
url = {http://actamath.savbb.sk/pdf/acta13.pdf},
volume = {13},
year = {2006}
}
@article{Zangurashvili1999,
abstract = {Several results on the translation of factorization systems along adjunctions are proved. The first of these results is the answer to the question posed by G.Janelidze.},
author = {Zangurashvili, Dali},
doi = {10.1023/A:1022180801295},
file = {:Users/liang-tingchen/Dropbox/References/Zangurashvili - 1999 - Factorization Systems and Adjunctions.pdf:pdf},
issn = {1072-947X},
journal = {Georgian Mathematical Journal},
keywords = {Mathematics and Statistics},
month = {mar},
number = {2},
pages = {191--200},
publisher = {Springer Netherlands},
title = {{Factorization Systems and Adjunctions}},
url = {http://www.springerlink.com/content/g774071054q388w1/},
volume = {6},
year = {1999}
}
@inproceedings{Cavallo2020,
abstract = {We define a computational type theory combining the contentful equality structure of cartesian cubical type theory with internal parametricity primitives. The combined theory supports both univalence and its relational equivalent, which we call relativity. We demonstrate the use of the theory by analyzing polymorphic functions between higher inductive types, and we give an account of the identity extension lemma for internal parametricity.},
address = {Dagstuhl, Germany},
archivePrefix = {arXiv},
arxivId = {1901.00489},
author = {Cavallo, Evan and Harper, Robert},
booktitle = {28th EACSL Annual Conference on Computer Science Logic (CSL 2020)},
doi = {10.4230/LIPIcs.CSL.2020.13},
editor = {Fern{\'{a}}ndez, Maribel and Muscholl, Anca},
eprint = {1901.00489},
file = {:Users/liang-tingchen/Dropbox/References/Cavallo, Harper - 2020 - Internal parametricity for cubical type theory.pdf:pdf},
isbn = {9783959771320},
issn = {18688969},
keywords = {Cubical type theory,Higher inductive types,Parametricity},
number = {13},
pages = {13:1----13:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Internal parametricity for cubical type theory}},
url = {https://drops.dagstuhl.de/opus/volltexte/2020/11656},
volume = {152},
year = {2020}
}
@inproceedings{Weirich2013,
abstract = {Abstract System FC , the core language of the Glasgow Haskell Compiler, is an explicitly - typed variant of System F with first-class type equality proofs called coercions. This extensible proof system forms the foundation for type system extensions such as type ... $\backslash$n},
address = {New York, New York, USA},
author = {Weirich, Stephanie and Hsu, Justin and Eisenberg, Richard A.},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500599},
file = {:Users/liang-tingchen/Dropbox/References/Weirich, Hsu, Eisenberg - 2013 - System FC with explicit kind equality.pdf:pdf},
isbn = {9781450323260},
issn = {03621340},
pages = {275},
publisher = {ACM Press},
title = {{System FC with explicit kind equality}},
url = {http://dl.acm.org/citation.cfm?doid=2500365.2500599},
year = {2013}
}
@book{MacLane1994,
address = {New York, NY},
author = {{Mac Lane}, Saunders and Moerdijk, Ieke},
booktitle = {Book},
doi = {10.1007/978-1-4612-0927-0},
file = {:Users/liang-tingchen/Dropbox/References/Mac Lane, Moerdijk - 1994 - Sheaves in Geometry and Logic.pdf:pdf},
isbn = {978-0-387-97710-2},
publisher = {Springer New York},
series = {Universitext},
title = {{Sheaves in Geometry and Logic}},
url = {http://link.springer.com/10.1007/978-1-4612-0927-0},
year = {1994}
}
@incollection{Levy2011,
author = {Levy, Paul Blain},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-642-19805-2_3},
editor = {Hofmann, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2011 - Similarity quotients as final coalgebras.pdf:pdf},
pages = {27--41},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Similarity quotients as final coalgebras}},
year = {2011}
}
@techreport{Jones2017,
author = {Jones, Prof Mark W and Roach, Matt},
file = {:Users/liang-tingchen/Dropbox/References/Jones, Roach - 2017 - Data Aggregation Impacts Report.pdf:pdf},
title = {{Data Aggregation Impacts Report}},
year = {2017}
}
@incollection{Hensel1997,
abstract = {Abstract. Data types like trees which are fmitdy branching and of (possibly) infinite depth are described by iterating initial algebras and terminal coalgebras. We study proof principles for such data types in the context of categorical logic, following and extending the approach ...},
author = {Hensel, U. and Jacobs, Bart},
booktitle = {Category Theory and Computer Science},
doi = {10.1007/BFb0026991},
editor = {Moggi, Eugenio and Rosolini, Giuseppe},
file = {:Users/liang-tingchen/Dropbox/References/Hensel, Jacobs - 1997 - Proof principles for datatypes with iterated recursion.pdf:pdf},
isbn = {978-3-540-63455-3},
pages = {220--241},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Proof principles for datatypes with iterated recursion}},
url = {http://www.springerlink.com/index/58617272g6033w22.pdf{\%}5Cnpapers://cff96cb1-96b7-4b11-a3e3-f4947c1d45b9/Paper/p5905},
year = {1997}
}
@inproceedings{Adamek2014c,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Myers, Robert Samuel Ralph and Urbat, Henning},
booktitle = {Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-642-54830-7_24},
editor = {Muscholl, Anca},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2014 - Generalized Eilenberg theorem I Local varieties of languages.pdf:pdf},
pages = {366--380},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generalized Eilenberg theorem I : Local varieties of languages}},
year = {2014}
}
@incollection{Chatzikokolakis2013,
author = {Chatzikokolakis, Konstantinos and Andr{\'{e}}s, Miguel E. and Bordenabe, Nicol{\'{a}}s Emilio and Palamidessi, Catuscia},
booktitle = {Privacy Enhancing Technologies. PETS 2013},
doi = {10.1007/978-3-642-39077-7_5},
editor = {Cristofaro, Emiliano De and Wright, Matthew},
file = {:Users/liang-tingchen/Dropbox/References/Chatzikokolakis et al. - 2013 - Broadening the Scope of Differential Privacy Using Metrics.pdf:pdf},
isbn = {9783642390777},
pages = {82--102},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Broadening the Scope of Differential Privacy Using Metrics}},
url = {http://link.springer.com/10.1007/978-3-642-39077-7{\_}5},
volume = {7981},
year = {2013}
}
@article{Jacobs2002,
author = {Jacobs, Bart},
doi = {10.1016/S1571-0661(04)80362-1},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2002 - Comprehension for Coalgebras.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {oct},
number = {1},
pages = {112--134},
title = {{Comprehension for Coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104803621},
volume = {65},
year = {2002}
}
@inproceedings{Kifer2009,
abstract = {In this paper we present a method for reasoning about privacy using the concepts of exchangeability and deFinetti's theorem. We illustrate the usefulness of this technique by using it to attack a popular data sanitization scheme known as Anatomy. We stress that Anatomy is not the only sanitization scheme that is vulnerable to this attack. In fact, any scheme that uses the random worlds model, i.i.d. model, or tuple-independent model needs to be re-evaluated. The difference between the attack presented here and others that have been proposedin the past is that we do not need extensive background knowledge. An attacker only needs to know the nonsensitive attributes of one individual in the data, and can carry out this attack just by building a machine learning model over the sanitized data. The reason this attack is successful is that it exploits a subtle flaw in the way prior work computed the probability of disclosure of a sensitive attribute. We demonstrate this theoretically, empirically, and with intuitive examples. We also discuss how this generalizes to many other privacy schemes.},
address = {New York, New York, USA},
author = {Kifer, Daniel},
booktitle = {Proceedings of the 35th SIGMOD international conference on Management of data - SIGMOD '09},
doi = {10.1145/1559845.1559861},
file = {:Users/liang-tingchen/Dropbox/References/Kifer - 2009 - Attacks on privacy and deFinetti's theorem.pdf:pdf},
isbn = {9781605585512},
keywords = {privacy,random worlds},
pages = {127},
publisher = {ACM Press},
title = {{Attacks on privacy and deFinetti's theorem}},
url = {http://portal.acm.org/citation.cfm?doid=1559845.1559861},
year = {2009}
}
@phdthesis{Mansfield2013,
author = {Mansfield, Shane},
file = {:Users/liang-tingchen/Dropbox/References/Mansfield - 2013 - The Mathematical Structure of Non-locality {\&} Contextuality.pdf:pdf},
school = {University of Oxford},
title = {{The Mathematical Structure of Non-locality {\&} Contextuality}},
url = {http://www.amazon.com/Mathematical-Structure-Stable-Physical-Systems/dp/1490723641/},
year = {2013}
}
@inproceedings{Altenkirch2020,
abstract = {We consider the problem of defining the integers in Homotopy Type Theory (HoTT). We can define the type of integers as signed natural numbers (i.e., using a coproduct), but its induction principle is very inconvenient to work with, since it leads to an explosion of cases. An alternative is to use set-quotients, but here we need to use set-truncation to avoid non-trivial higher equalities. This results in a recursion principle that only allows us to define function into sets (types satisfying UIP). In this paper we consider higher inductive types using either a small universe or bi-invertible maps. These types represent integers without explicit set-truncation that are equivalent to the usual coproduct representation. This is an interesting example since it shows how some coherence problems can be handled in HoTT. We discuss some open questions triggered by this work. The proofs have been formally verified using cubical Agda.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2007.00167},
author = {Altenkirch, Thorsten and Scoccola, Luis},
booktitle = {Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science},
doi = {10.1145/3373718.3394760},
eprint = {2007.00167},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch, Scoccola - 2020 - The Integers as a Higher Inductive Type.pdf:pdf},
isbn = {9781450371049},
keywords = {coherence problem,higher inductive type,initiality,truncation},
month = {jul},
pages = {67--73},
publisher = {ACM},
title = {{The Integers as a Higher Inductive Type}},
url = {https://dl.acm.org/doi/10.1145/3373718.3394760},
year = {2020}
}
@article{Adamek2002a,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Borceux, Francis and Lack, Stephen and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/S0022-4049(02)00126-3},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek et al. - 2002 - A classification of accessible categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {1-3},
pages = {7--30},
title = {{A classification of accessible categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404902001263},
volume = {175},
year = {2002}
}
@book{Davey2002a,
author = {Davey, Brian A. and Priestley, Hilary A.},
edition = {2},
isbn = {0521784514},
month = {apr},
publisher = {Cambridge University Press},
title = {{Introduction to Lattices and Order}},
type = {Book},
year = {2002}
}
@article{Abadi1997,
address = {New York, New York, USA},
author = {Abadi, Martı́n and Gordon, Andrew D.},
doi = {10.1006/inco.1998.2740},
file = {:Users/liang-tingchen/Dropbox/References/Abadi, Gordon - 1999 - A calculus for cryptographic protocols the Spi calculus.pdf:pdf},
isbn = {0897919122},
issn = {08905401},
journal = {Information and Computation},
month = {jan},
number = {1},
pages = {1--70},
publisher = {ACM Press},
title = {{A calculus for cryptographic protocols: the Spi calculus}},
url = {http://portal.acm.org/citation.cfm?doid=266420.266432 http://linkinghub.elsevier.com/retrieve/pii/S0890540198927407},
volume = {148},
year = {1999}
}
@book{Codd1990,
abstract = {From the Preface (See Front Matter for full Preface) An important adjunct to precision is a sound theoretical foundation. The relational model is solidly based on two parts of mathematics: firstorder predicate logic and the theory of relations. This book, however, does not dwell on the theoretical foundations, but rather on all the features of the relational model that I now perceive as important for database users, and therefore for DBMS vendors. My perceptions result from 20 years of practical experience in computing and data processing (chiefly, but not exclusively, with large-scale customers of IBM), followed by another 20 years of research. I believe that this is the first book to deal exclusively with the relational approach. It does, however, include design principles in Chapters 21 and 22. It is also the first book on the relational model by the originator of that model. All the ideas in the relational model described in this book are mine, except in cases where I explicitly credit someone else. In developing the relational model, I have tried to follow Einstein's advice, "Make it as simple as possible, but no simpler." I believe that in the last clause he was discouraging the pursuit of simplicity to the extent of distorting reality. So why does the book contain 30 chapters and two appendixes? To answer this question, it is necessary to look at the history of research and development of the relational model.},
author = {Codd, E. F.},
file = {:Users/liang-tingchen/Dropbox/References/Codd - 1990 - The Relational Model for Database Management Version 2.pdf:pdf},
isbn = {0201141922},
pages = {538},
pmid = {1917145},
publisher = {Pearson},
title = {{The Relational Model for Database Management: Version 2}},
url = {http://books.google.co.kr/books?q=9780201141924},
year = {1990}
}
@incollection{Melton1982,
abstract = {For any category K we investigate the family of all factorization structures on K . In particular, for each such structure, (E,M), we investigate the complete lattice of all factorization structures on K with left factor a subclass of E; this investigation is based on a Galois connection between all such structures and the lattice of all full isomorphism-closed subcategories of K . The Galois-closed families are precisely all the E-reflective subcategories of K and all the (E,M)-dispersed factorization structures of Herrlich, Salicrup and Vazquez.},
author = {Melton, Austin C. and Strecker, George E. and Kamps, Klaus and Pumpl{\"{u}}n, Dieter and Tholen, Walter},
booktitle = {Category Theory},
doi = {10.1007/BFb0066878},
editor = {Kamps, Klaus Heiner and Pumpl{\"{u}}n, Dieter and Tholen, Walter},
file = {:Users/liang-tingchen/Dropbox/References/Melton et al. - 1982 - On the structure of factorization structures.pdf:pdf},
isbn = {978-3-540-11961-6},
keywords = {Mathematics and Statistics},
pages = {197--208},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{On the structure of factorization structures}},
url = {http://www.springerlink.com/content/jm82274471xk0308/},
volume = {962},
year = {1982}
}
@article{Cleaveland2005,
abstract = {This paper presents a mu-calculus-based modal logic for describing properties of reactive probabilistic labeled transition systems (RPLTSs) and develops a model-checking algorithm for determining whether or not states in finite-state RPLTSs satisfy formulas in the logic. The logic is based on the distinction between (probabilistic) "systems" and (nonprobabilistic) "observations": using the modal mu-calculus, one may specify sets of observations, and the semantics of our logic then enable statements to be made about the measures of such sets at various system states. The logic may be used to encode a variety of probabilistic modal and temporal logics; in addition, the model-checking problem for it may be reduced to the calculation of solutions to systems of non-linear equations. Finally, the logic induces an equivalence on RPLTSs that coincides with accepted notions of probabilistic bisimulation in the literature. {\textcopyright} 2005 Published by Elsevier B.V.},
author = {Cleaveland, Rance and Iyer, S. Purushothaman and Narasimha, Murali},
doi = {10.1016/j.tcs.2005.03.048},
file = {:Users/liang-tingchen/Dropbox/References/Cleaveland, Iyer, Narasimha - 2005 - Probabilistic temporal logics via the modal mu-calculus.pdf:pdf},
isbn = {3-540-65719-3},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Model-checking,Probabilistic bisimulation,Probabilistic temporal logic,Probabilistic transition systems,Reactive systems},
number = {2-3},
pages = {316--350},
title = {{Probabilistic temporal logics via the modal mu-calculus}},
volume = {342},
year = {2005}
}
@article{Gibbons2009,
abstract = {The ITERATOR pattern gives a clean interface for element-by-element access to a collection, independent of the collections shape. Imperative iterations using the pattern have two simultaneous aspects: mapping and accumulating. Various existing functional models of iteration capture one or other of these aspects, but not both simultaneously.We argue thatMcBride and Patersons applicative functors, and in particular the corresponding traverse operator, do exactly this, and therefore capture the essence of the ITERATOR pattern. Moreover, they do so in a way that nicely supports modular programming.We present some axioms for traversal, discuss modularity concerns, and illustrate with a simple example, the wordcount problem.},
author = {GIBBONS, JEREMY and OLIVEIRA, BRUNO C. d. S.},
doi = {10.1017/S0956796809007291},
file = {:Users/liang-tingchen/Dropbox/References/GIBBONS, OLIVEIRA - 2009 - The essence of the Iterator pattern.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jul},
number = {3-4},
pages = {377},
title = {{The essence of the Iterator pattern}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796809007291},
volume = {19},
year = {2009}
}
@inproceedings{Gehrke2010,
address = {Bordeaux},
author = {Gehrke, Mai and Grigorieff, Serge and Pin, Jean-{\'{E}}ric},
booktitle = {Proceedings of ICALP 2010 Part II},
doi = {10.1007/978-3-642-14162-1},
editor = {Abramsky, Samson and Gavoille, Cyril and Kirchner, Claude and {Meyer auf der Heide}, Friedhelm and Spirakis, Paul G.},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke, Grigorieff, Pin - 2010 - A topological approach to Recognition.pdf:pdf},
isbn = {978-3-642-14161-4},
pages = {151--162},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A topological approach to Recognition}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-14162-1},
volume = {6199},
year = {2010}
}
@article{House1986,
author = {Cartmell, John},
doi = {10.1016/0168-0072(86)90053-9},
file = {:Users/liang-tingchen/Dropbox/References/Cartmell - 1986 - Generalised algebraic theories and contextual categories.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
pages = {209--243},
title = {{Generalised algebraic theories and contextual categories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0168007286900539},
volume = {32},
year = {1986}
}
@incollection{Kurucz2007,
author = {Kurucz, Agi},
booktitle = {Handbook of Modal Logic},
chapter = {15},
doi = {10.1016/S1570-2464(07)80018-8},
editor = {Blackburn, Patrick and Benthem, Johan Van and Wolter, Frank},
file = {:Users/liang-tingchen/Dropbox/References/Kurucz - 2007 - Combining modal logics.pdf:pdf},
pages = {869--924},
publisher = {Elsevier},
series = {Studies in Logic and Practical Reasoning},
title = {{Combining modal logics}},
url = {http://www.sciencedirect.com/science/article/pii/S1570246407800188},
year = {2007}
}
@article{KLIN2004,
abstract = {An abstract coalgebraic approach to well-structured relations on processes is presented, based on notions of tests and test suites. Preorders and equivalences on processes are modelled as coalgebras for behaviour endofunctors lifted to a category of test suites. The general framework is specialized to the case of finitely branching labelled transition systems. It turns out that most equivalences from the so-called van Glabbeek spectrum can be described by well-structured test suites. As an immediate application, coinductive proof principles are described for these equivalences, in particular for trace equivalence.},
author = {Klin, Bartek},
doi = {10.1016/j.entcs.2004.02.029},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2004 - A Coalgebraic Approach to Process Equivalence and a Coinduction Principle for Traces.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coalgebra,coinduction,van glabbeek spectrum},
month = {dec},
pages = {201--218},
title = {{A Coalgebraic Approach to Process Equivalence and a Coinduction Principle for Traces}},
url = {http://dx.doi.org/10.1016/j.entcs.2004.02.029},
volume = {106},
year = {2004}
}
@article{Erne1993,
author = {Ern{\'{e}}, Marcel and Koslowski, J{\"{u}}rgen and Melton, Austin C. and Strecker, George E.},
doi = {10.1111/j.1749-6632.1993.tb52513.x},
file = {:Users/liang-tingchen/Dropbox/References/Ern{\'{e}} et al. - 1993 - A Primer on Galois Connections.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
month = {dec},
pages = {103--125},
title = {{A Primer on Galois Connections}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1993.tb52513.x},
volume = {704},
year = {1993}
}
@incollection{Tschantz2009,
author = {Tschantz, Michael Carl and Wing, Jeannette M},
booktitle = {FM 2009: Formal Methods},
doi = {10.1007/978-3-642-05089-3_1},
editor = {Cavalcanti, Ana and Dams, Dennis R.},
file = {:Users/liang-tingchen/Dropbox/References/Tschantz, Wing - 2009 - Formal Methods for Privacy.pdf:pdf},
pages = {1--15},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Formal Methods for Privacy}},
url = {http://link.springer.com/10.1007/978-3-642-05089-3{\_}1},
volume = {5850},
year = {2009}
}
@article{Cubric1998a,
abstract = {We show how to solve the word problem for simply typed $\lambda$$\beta$$\eta$-calculus by using a few well-known facts about categories of presheaves and the Yoneda embedding. The formal setting for these results is [Pscr ]-category theory, a version of ordinary category theory where each hom-set is equipped with a partial equivalence relation. The part of [Pscr ]-category theory we develop here is constructive and thus permits extraction of programs from proofs. It is important to stress that in our method we make no use of traditional proof-theoretic or rewriting techniques. To show the robustness of our method, we give an extended treatment for more general $\lambda$-theories in the Appendix.},
author = {{\v{C}}ubri{\'{c}}, Djordje and Dybjer, Peter and Scott, Philip J.},
doi = {10.1017/S0960129597002508},
file = {:Users/liang-tingchen/Dropbox/References/{\v{C}}ubri{\'{c}}, Dybjer, Scott - 1998 - Normalization and the Yoneda embedding.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {apr},
number = {2},
pages = {153--192},
title = {{Normalization and the Yoneda embedding}},
url = {https://www.cambridge.org/core/product/identifier/S0960129597002508/type/journal{\_}article},
volume = {8},
year = {1998}
}
@incollection{Ghani2016a,
author = {Ghani, Neil and {Nordvall Forsberg}, Fredrik and Orsanigo, Federico},
booktitle = {A List of Successes That Can Change the World.},
doi = {10.1007/978-3-319-30936-1_6},
editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Nordvall Forsberg, Orsanigo - 2016 - Proof-Relevant Parametricity.pdf:pdf},
isbn = {9783319309354},
issn = {16113349},
pages = {109--131},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Proof-Relevant Parametricity}},
url = {http://link.springer.com/10.1007/978-3-319-30936-1{\_}6},
volume = {9600},
year = {2016}
}
@article{Bonchi2012a,
author = {Bonchi, Filippo and Bonsangue, Marcello M. and Boreale, Michele and Rutten, Jan J.M.M. and Silva, Alexandra},
doi = {10.1016/j.ic.2011.12.002},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi et al. - 2012 - A coalgebraic perspective on linear weighted automata.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {feb},
pages = {77--105},
publisher = {Elsevier Inc.},
title = {{A coalgebraic perspective on linear weighted automata}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540111001830},
volume = {211},
year = {2012}
}
@article{Ziliani2015,
abstract = {Effective support for custom proof automation is essential for large-scale interactive proof development. However, existing languages for automation via tactics either (a) provide no way to specify the behavior of tactics within the base logic of the accompanying theorem prover, or (b) rely on advanced type-theoretic machinery that is not easily integrated into established theorem provers.},
author = {Ziliani, Beta and Dreyer, Derek and Krishnaswami, Neelakantan R. and Nanevski, Aleksandar and Vafeiadis, Viktor},
doi = {10.1017/S0956796815000118},
file = {:Users/liang-tingchen/Dropbox/References/Ziliani et al. - 2015 - Mtac A monad for typed tactic programming in Coq.pdf:pdf},
isbn = {0956796815000},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {aug},
title = {{Mtac: A monad for typed tactic programming in Coq}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796815000118},
volume = {25},
year = {2015}
}
@article{Isbell1968,
author = {Isbell, John R.},
doi = {10.1007/BF01691344},
file = {:Users/liang-tingchen/Dropbox/References/Isbell - 1968 - Small subcategories and completeness.pdf:pdf},
issn = {0025-5661},
journal = {Mathematical Systems Theory},
month = {mar},
number = {1},
pages = {27--50},
title = {{Small subcategories and completeness}},
url = {http://link.springer.com/10.1007/BF01691344},
volume = {2},
year = {1968}
}
@inproceedings{Li2007,
author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
booktitle = {2007 IEEE 23rd International Conference on Data Engineering},
doi = {10.1109/ICDE.2007.367856},
file = {:Users/liang-tingchen/Dropbox/References/Li, Li, Venkatasubramanian - 2007 - {\$}t{\$}-Closeness Privacy Beyond {\$}k{\$}-Anonymity and {\$}l{\$}-Diversity.pdf:pdf},
isbn = {1-4244-0802-4},
number = {3},
pages = {106--115},
publisher = {IEEE},
title = {{{\$}t{\$}-Closeness: Privacy Beyond {\$}k{\$}-Anonymity and {\$}l{\$}-Diversity}},
url = {http://ieeexplore.ieee.org/document/4221659/},
year = {2007}
}
@book{Aczel1988a,
author = {Aczel, Peter},
publisher = {Center for the Study of Language and Information, Stanford},
title = {{Non-well-founded sets}},
type = {Book},
year = {1988}
}
@inproceedings{Kaposi2018a,
abstract = {Higher inductive-inductive types (HIITs) generalise inductive types of dependent type theories in two directions. On the one hand they allow the simultaneous definition of multiple sorts that can be indexed over each other. On the other hand they support equality constructors, thus generalising higher inductive types of homotopy type theory. Examples that make use of both features are the Cauchy reals and the well-typed syntax of type theory where conversion rules are given as equality constructors. In this paper we propose a general definition of HIITs using a domain-specific type theory. A context in this small type theory encodes a HIIT by listing the type formation rules and constructors. The type of the elimination principle and its {\ss}-rules are computed from the context using a variant of the syntactic logical relation translation. We show that for indexed W-types and various examples of HIITs the computed elimination principles are the expected ones. Showing that the thus specified HIITs exist is left as future work. The type theory specifying HIITs was formalised in Agda together with the syntactic translations. A Haskell implementation converts the types of sorts and constructors into valid Agda code which postulates the elimination principles and computation rules.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (A Syntax for Higher Inductive-Inductive Types - Kaposi, Ambrus; Kov{\'{a}}cs, Andr{\'{a}}s)

Keywords: homotopy type theory, inductive-inductive types, higher inductive types, quotient inductive types, logical relations},
author = {Kaposi, Ambrus and Kov{\'{a}}cs, Andr{\'{a}}s},
booktitle = {3rd International Conference on Formal Structures for Computation and Deduction (FSCD 2018)},
doi = {10.4230/LIPIcs.FSCD.2018.20},
editor = {Kirchner, H{\'{e}}l{\`{e}}ne},
file = {:Users/liang-tingchen/Dropbox/References/Kaposi, Kov{\'{a}}cs - 2018 - A Syntax for Higher Inductive-Inductive Types.pdf:pdf},
isbn = {978-3-95977-077-4},
issn = {1868-8969},
keywords = {Higher inductive types,Homotopy type theory,Inductive-inductive types,Logical relations,Quotient inductive types},
number = {20},
pages = {20:1----20:18},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{A Syntax for Higher Inductive-Inductive Types}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9190},
volume = {108},
year = {2018}
}
@article{Kingdom2015,
annote = {NULL},
author = {Bonsangue, Marcello and Hansen, Helle Hvid and Kurz, Alexander and Rot, Jurriaan},
doi = {10.2168/LMCS-11(3:2)2015},
editor = {Milius, Stefan},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue et al. - 2015 - Presenting distributive laws.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {algebraic techniques in automata,and phrases,probabilistic automata,value 1 problem},
month = {aug},
number = {3},
pages = {1--50},
title = {{Presenting distributive laws}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1574},
volume = {11},
year = {2015}
}
@inproceedings{Pickering2016,
abstract = {Pattern matching has proven to be a convenient, expressive way of inspecting data. Yet this language feature, in its traditional form, is limited: patterns must be data constructors of concrete data types. No computation or abstraction is allowed. The data type in question must be concrete, with no ability to enforce any invariants. Any change in this data type requires all clients to update their code. This paper introduces pattern synonyms, which allow programmers to abstract over patterns, painting over all the shortcomings listed above. Pattern synonyms are assigned types, enabling a compiler to check the validity of a synonym independent of its definition. These types are intricate; detailing how to assign a type to a pattern synonym is a key contribution of this work.We have implemented pattern synonyms in the Glasgow Haskell Compiler, where they have enjoyed immediate popularity, but we believe this feature could easily be exported to other languages that support pattern matching.},
address = {New York, New York, USA},
author = {Pickering, Matthew and {\'{E}}rdi, Gergő and {Peyton Jones}, Simon and Eisenberg, Richard A.},
booktitle = {Proceedings of the 9th International Symposium on Haskell - Haskell 2016},
doi = {10.1145/2976002.2976013},
file = {:Users/liang-tingchen/Dropbox/References/Pickering et al. - 2016 - Pattern synonyms.pdf:pdf},
isbn = {9781450344340},
keywords = {-,abstract the details away,and write,funargty,functional programming,haskell,pattern matching,t1,tyapp,type,we would prefer to},
pages = {80--91},
publisher = {ACM Press},
title = {{Pattern synonyms}},
url = {http://dl.acm.org/citation.cfm?doid=2976002.2976013},
year = {2016}
}
@article{Milner1992,
author = {Milner, Robin and Parrow, Joachim and Walker, David},
doi = {10.1016/0890-5401(92)90008-4},
file = {:Users/liang-tingchen/Dropbox/References/Milner, Parrow, Walker - 1992 - A calculus of mobile processes, I.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {sep},
number = {1},
pages = {1--40},
pmid = {2522913},
title = {{A calculus of mobile processes, I}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0890540192900084},
volume = {100},
year = {1992}
}
@article{Pin2003,
abstract = {This paper is a contribution to the algebraic study of the concatenation product. In the first part of the paper, we extend to the ordered case standard algebraic tools related to the concatenation product, like the Sch??tzenberger product and the relational morphisms. We show in a precise way how the ordered Sch??tzenberger product corresponds to polynomial operations on languages. In the second part of the paper, we apply these results to establish a bridge between the three standard concatenation hierarchies, namely the Straubing-Th??rien hierarchy, the Brzozowski's (or dot-depth) hierarchy and the group hierarchy. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Pin, Jean-{\'{E}}ric},
doi = {10.1016/S0304-3975(01)00230-4},
file = {:Users/liang-tingchen/Dropbox/References/Pin - 2003 - Algebraic tools for the concatenation product.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Concatenation,Finite automata,Recognizable languages},
number = {1},
pages = {317--342},
title = {{Algebraic tools for the concatenation product}},
volume = {292},
year = {2003}
}
@inproceedings{Atkey,
address = {New York, New York, USA},
author = {Atkey, Robert},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '18},
doi = {10.1145/3209108.3209189},
file = {:Users/liang-tingchen/Dropbox/References/Atkey - 2018 - Syntax and Semantics of Quantitative Type Theory.pdf:pdf},
isbn = {9781450355834},
keywords = {18,2018,33rd annual acm,acm reference format,ieee symposium on logic,in,in computer science,lics,linear logic,quantitative type theory,robert atkey,syntax and semantics of,type theory},
pages = {56--65},
publisher = {ACM Press},
title = {{Syntax and Semantics of Quantitative Type Theory}},
url = {http://dl.acm.org/citation.cfm?doid=3209108.3209189},
year = {2018}
}
@incollection{Scott1980,
abstract = {The chapter presents an exposition of why the $\lambda$-calculus has models. The A-calculus was one of the first areas of research of Professor Kleene, in which the experience gained by him was surely beneficial in his later development of the recursive function theory. The chapter discusses a very short historical summary, and it is found that there is considerable overlap with CURRY. There is a review of the theory of functions and relations as sets leading up to the important notion of a continuous set mapping. The problem of the self-application of a function to itself as an argument is discussed in the chapter from a new angle. The model (essentially due to PLOTKIN) of the basic laws of $\lambda$ -calculus thus results. The chapter describes self-application to recursion by the proof of David Park's theorem to the effect that the least fixed-point operator and the paradoxical combinator are the same in a wide class of well-behaved models. The connection thus engendered to recursion theory (r. e. sets) is outlined, and some remarks on recent results about ill-behaved models and on induction principles are discussed. The theme of type theory and a construction of an ($\eta$)-model with fewer -type distinctions is presented. There is a brief discussion of how to introduce more type distinctions into models via equivalence relations. The chapter also presents various points of philosophical disagreement with Professor Curry. {\textcopyright} 1980, North-Holland Publishing Company. All rights reserved.},
author = {Scott, Dana},
booktitle = {Studies in Logic and the Foundations of Mathematics},
doi = {10.1016/S0049-237X(08)71262-X},
file = {:Users/liang-tingchen/Dropbox/References/Scott - 1980 - Lambda Calculus Some Models, Some Philosophy.pdf:pdf},
issn = {0049237X},
number = {C},
pages = {223--265},
publisher = {North-Holland Publishing Company},
title = {{Lambda Calculus: Some Models, Some Philosophy}},
url = {http://dx.doi.org/10.1016/S0049-237X(08)71262-X https://linkinghub.elsevier.com/retrieve/pii/S0049237X0871262X},
volume = {101},
year = {1980}
}
@article{Davey2011,
author = {Davey, Brian A. and Gouveia, M. J. and Haviar, M. and Priestley, Hilary A.},
doi = {10.1007/s00012-011-0155-y},
file = {:Users/liang-tingchen/Dropbox/References/Davey et al. - 2011 - Natural extensions and profinite completions of algebras.pdf:pdf},
issn = {00025240},
journal = {Algebra Universalis},
keywords = {Canonical extension,Natural duality,Natural extension,Profinite completion,Residually finite},
pages = {205--241},
title = {{Natural extensions and profinite completions of algebras}},
volume = {66},
year = {2011}
}
@article{Tarjan1975,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Tarjan, Robert Endre},
doi = {10.1145/321879.321884},
file = {:Users/liang-tingchen/Dropbox/References/Tarjan - 1975 - Efficiency of a Good But Not Linear Set Union Algorithm.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {algorithm,and phrases,complexity,cr c a t,e g o r,eqmvalence,i e s,partition,set umon,tree},
month = {apr},
number = {2},
pages = {215--225},
title = {{Efficiency of a Good But Not Linear Set Union Algorithm}},
url = {http://portal.acm.org/citation.cfm?doid=321879.321884},
volume = {22},
year = {1975}
}
@article{Bezhanishvili2015,
author = {Bezhanishvili, Guram and Bezhanishvili, Nick and Harding, John},
doi = {10.1007/s10485-013-9332-9},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili, Bezhanishvili, Harding - 2015 - Modal Operators on Compact Regular Frames and de Vries Algebras.pdf:pdf},
isbn = {1048501393329},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {06d22,2010,54b20,54e05,b,bezhanishvili,compact hausdorff space,compact regular frame,de vries algebra,g,mathematics subject classifications,modal operator,vietoris space},
number = {3},
pages = {365--379},
title = {{Modal Operators on Compact Regular Frames and de Vries Algebras}},
url = {http://link.springer.com/10.1007/s10485-013-9332-9},
volume = {23},
year = {2015}
}
@article{Joachimski2004a,
abstract = {The coinductive $\lambda$-calculus $\Lambda$co arises by a coinductive interpretation of the grammar of the standard $\lambda$-calculus $\Lambda$ and contains non-well-founded $\lambda$-terms. An appropriate notion of reduction is analyzed and proven to be confluent by means of a detailed analysis of the usual Tait/Martin-L{\"{o}}f style development argument. This yields bounds for the lengths of those joining reduction sequences that are guaranteed to exist by confluence. These bounds also apply to the well-founded $\lambda$-calculus, thus adding quantitative information to the classic result. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Joachimski, Felix},
doi = {10.1016/S0304-3975(03)00324-4},
file = {:Users/liang-tingchen/Dropbox/References/Joachimski - 2004 - Confluence of the coinductive $\lambda$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {jan},
number = {1-3},
pages = {105--119},
title = {{Confluence of the coinductive $\lambda$-calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397503003244},
volume = {311},
year = {2004}
}
@article{Dalenius1986,
author = {Dalenius, Tore},
file = {:Users/liang-tingchen/Dropbox/References/Dalenius - 1986 - Finding a Needle In a Haystack or Identifying Anonymous Census Records.pdf:pdf},
journal = {Journal of Official Statistics},
number = {3},
pages = {329--336},
title = {{Finding a Needle In a Haystack or Identifying Anonymous Census Records}},
url = {http://www.jos.nu/Articles/abstract.asp?article=23329},
volume = {2},
year = {1986}
}
@article{Clifton2013,
abstract = {Recently, there has been a growing debate over approaches for handling and analyzing private data. Research has identified issues with syntactic approaches such as k-anonymity and diversity. Differential privacy, which is based on adding noise to the analysis outcome, has been promoted as the answer to privacy-preserving data mining. This paper looks at the issues involved and criticisms of both approaches. We conclude that both approaches have their place, and that each approach has issues that call for further research. We identify these research challenges, and discuss recent developments and future directions that will enable greater access to data while improving privacy guarantees.},
author = {Clifton, Chris and Tassa, Tamir},
doi = {10.1109/ICDEW.2013.6547433},
file = {:Users/liang-tingchen/Dropbox/References/Clifton, Tassa - 2013 - On syntactic anonymity and differential privacy.pdf:pdf},
isbn = {9781467353021},
issn = {18885063},
journal = {Transactions on Data Privacy},
keywords = {[Electronic Manuscript]},
number = {2},
pages = {161--183},
title = {{On syntactic anonymity and differential privacy}},
volume = {6},
year = {2013}
}
@incollection{Lambek1969,
author = {Lambek, Joachim},
booktitle = {Category Theory, Homology Theory and their Applications I},
doi = {10.1007/BFb0079385},
editor = {Hilton, Peter J.},
file = {:Users/liang-tingchen/Dropbox/References/Lambek - 1969 - Deductive systems and categories II. Standard constructions and closed categories.pdf:pdf},
pages = {76--122},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Deductive systems and categories II. Standard constructions and closed categories}},
url = {http://link.springer.com/10.1007/BFb0079385},
volume = {86},
year = {1969}
}
@article{Adamek1977,
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
doi = {10.1017/S0004972700010704},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 1977 - Colimits of algebras revisited.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
number = {03},
pages = {433},
title = {{Colimits of algebras revisited}},
volume = {17},
year = {1977}
}
@incollection{Elgot1975,
author = {Elgot, Calvin C.},
booktitle = {Proceedings of the Logic Colloquium '73},
doi = {10.1016/S0049-237X(08)71949-9},
file = {:Users/liang-tingchen/Dropbox/References/Elgot - 1975 - Monadic computation and iterative algebraic theories.pdf:pdf},
isbn = {9780444106421},
issn = {0049-237X},
pages = {175--230},
publisher = {Elsevier},
series = {Studies in Logic and the Foundations of Mathematics},
title = {{Monadic computation and iterative algebraic theories}},
url = {http://dx.doi.org/10.1016/S0049-237X(08)71949-9},
year = {1975}
}
@article{Tsukada2010,
abstract = {According to a theorem of Courcelle monadic second-order logic and guarded second-order logic (where one can also quantify over sets of edges) have the same expressive power over the class of all countable {\$}k{\$}-sparse hypergraphs. In the first part of the present paper we extend this result to hypergraphs of arbitrary cardinality. In the second part, we present a generalisation dealing with methods to encode sets of vertices by single vertices.},
archivePrefix = {arXiv},
arxivId = {0910.3085},
author = {Tsukada, Takeshi and Igarashi, Atsushi},
doi = {10.2168/LMCS-6(4:8)2010},
editor = {Curien, Pierre-Louis},
eprint = {0910.3085},
file = {:Users/liang-tingchen/Dropbox/References/Tsukada, Igarashi - 2010 - A Logical Foundation for Environment Classifiers.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {dec},
number = {4},
pages = {1--19},
title = {{A Logical Foundation for Environment Classifiers}},
url = {https://lmcs.episciences.org/1065},
volume = {6},
year = {2010}
}
@article{Homer2008,
abstract = {We use high-density single nucleotide polymorphism (SNP) genotyping microarrays to demonstrate the ability to accurately and robustly determine whether individuals are in a complex genomic DNA mixture. We first develop a theoretical framework for detecting an individual's presence within a mixture, then show, through simulations, the limits associated with our method, and finally demonstrate experimentally the identification of the presence of genomic DNA of specific individuals within a series of highly complex genomic mixtures, including mixtures where an individual contributes less than 0.1{\%} of the total genomic DNA. These findings shift the perceived utility of SNPs for identifying individual trace contributors within a forensics mixture, and suggest future research efforts into assessing the viability of previously sub-optimal DNA sources due to sample contamination. These findings also suggest that composite statistics across cohorts, such as allele frequency or genotype counts, do not mask identity within genome-wide association studies. The implications of these findings are discussed.},
archivePrefix = {arXiv},
arxivId = {1310.3197},
author = {Homer, Nils and Szelinger, Szabolcs and Redman, Margot and Duggan, David and Tembe, Waibhav and Muehling, Jill and Pearson, John V. and Stephan, Dietrich A. and Nelson, Stanley F. and Craig, David W.},
doi = {10.1371/journal.pgen.1000167},
editor = {Visscher, Peter M.},
eprint = {1310.3197},
file = {:Users/liang-tingchen/Dropbox/References/Homer et al. - 2008 - Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotypi.pdf:pdf},
isbn = {1553-7404},
issn = {1553-7404},
journal = {PLoS Genetics},
month = {aug},
number = {8},
pages = {e1000167},
pmid = {18769715},
title = {{Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays}},
url = {http://dx.plos.org/10.1371/journal.pgen.1000167},
volume = {4},
year = {2008}
}
@article{Berger2011,
author = {Berger, Ulrich},
doi = {10.2168/LMCS-7(1:8)2011},
editor = {Kahle, Reinhard},
file = {:Users/liang-tingchen/Dropbox/References/Berger - 2011 - From coinductive proofs to exact real arithmetic theory and applications.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,coinduction,exact real number,program extraction,proof theory,realizability},
month = {mar},
number = {1},
pages = {1--24},
title = {{From coinductive proofs to exact real arithmetic: theory and applications}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=704},
volume = {7},
year = {2011}
}
@book{Kanamori2003,
address = {Berlin, Heidelberg},
author = {Kanamori, Akihiro},
doi = {10.1007/978-3-540-88867-3},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Kanamori - 2003 - The Higher Infinite.pdf:pdf},
isbn = {978-3-540-88866-6},
issn = {1439-7382},
pages = {536},
publisher = {Springer Berlin Heidelberg},
series = {Springer Monographs in Mathematics},
title = {{The Higher Infinite}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-88867-3},
year = {2003}
}
@article{Yanofsky2003,
abstract = {Following F. William Lawvere, we show that many self-referential paradoxes, incompleteness theorems and fixed point theorems fall out of the same simple scheme. We demonstrate these similarities by showing how this simple scheme encompasses the semantic paradoxes, and how they arise as diagonal arguments and fixed point theorems in logic, computability theory, complexity theory and formal language theory.},
archivePrefix = {arXiv},
arxivId = {math/0305282},
author = {Yanofsky, Noson S.},
doi = {10.2178/bsl/1058448677},
eprint = {0305282},
file = {:Users/liang-tingchen/Dropbox/References/Yanofsky - 2003 - A Universal Approach to Self-Referential Paradoxes, Incompleteness and Fixed Points.pdf:pdf},
issn = {1079-8986},
journal = {Bulletin of Symbolic Logic},
month = {sep},
number = {3},
pages = {362--386},
primaryClass = {math},
title = {{A Universal Approach to Self-Referential Paradoxes, Incompleteness and Fixed Points}},
url = {https://www.cambridge.org/core/product/identifier/S107989860000442X/type/journal{\_}article},
volume = {9},
year = {2003}
}
@inproceedings{Jeffrey2012,
author = {Jeffrey, Alan},
booktitle = {Proceedings of the 6th ACM workshop on Programming languages meets program verification},
file = {:Users/liang-tingchen/Dropbox/References/Jeffrey - 2012 - LTL types FRP.pdf:pdf},
title = {{LTL types FRP}},
type = {Conference proceedings (article)},
year = {2012}
}
@article{Lack2004a,
abstract = {A PROP is a way of encoding structure borne by an object of a symmetric monoidal category. We describe a notion of distributive law for PROPs, based on Beck's distributive laws for monads. A distributive law between PROPs allows them to be composed, and an algebra for the composite PROP consists of a single object with an algebra structure for each of the original PROPs, subject to compatibility conditions encoded by the distributive law. An example is the PROP for bialgebras, which is a composite of the PROP for coalgebras and that for algebras.},
author = {Lack, Stephen},
file = {:Users/liang-tingchen/Dropbox/References/Lack - 2004 - Composing PROPs.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Algebra,Bialgebra,Distributive law,Monad,PROP,Symmetric monoidal category},
number = {9},
pages = {147--163},
title = {{Composing PROPs}},
volume = {13},
year = {2004}
}
@incollection{Staton2013a,
abstract = {We present an algebraic theory for a fragment of predicate logic. The fragment has disjunction, existential quantification and equality. It is not an algebraic theory in the classical sense, but rather within a new framework that we call ‘parameterized algebraic theories'. We demonstrate the relevance of this algebraic presentation to computer science by identifying a programming language in which every type carries a model of the algebraic theory. The result is a simple functional logic programming language. We provide a syntax-free representation theorem which places terms in bijection with sieves, a concept from category theory. We study presentation-invariance for general parameterized algebraic theories by providing a theory of clones. We show that parameterized algebraic theories characterize a class of enriched monads.},
author = {Staton, Sam},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2013},
doi = {10.1007/978-3-642-37075-5_26},
editor = {Pfenning, Frank},
file = {:Users/liang-tingchen/Dropbox/References/Staton - 2013 - An Algebraic Presentation of Predicate Logic.pdf:pdf},
isbn = {9783642370748},
issn = {03029743},
pages = {401--417},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{An Algebraic Presentation of Predicate Logic}},
url = {http://link.springer.com/10.1007/978-3-642-37075-5{\_}26},
volume = {7794},
year = {2013}
}
@incollection{Dwork2006,
abstract = {In 1977 Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a formalization of Dalenius' goal along the lines of semantic security cannot be achieved. Contrary to intuition, a variant of the result threatens the privacy even of someone not in the database. This state of affairs suggests a new measure, differential privacy, which, intuitively, captures the increased risk to one's privacy incurred by participating in a database. The techniques developed in a sequence of papers [8, 13, 3], culminating in those described in [12], can achieve any desired level of privacy under this measure. In many cases, extremely accurate information about the database can be provided while simultaneously ensuring very high levels of privacy.},
address = {Berlin, Heidelberg},
author = {Dwork, Cynthia},
booktitle = {Proceedings of the International Colloquium on Automata, Languages and Programming, Part II (ICALP)},
doi = {10.1007/11787006_1},
editor = {Bugliesi, Michele and Preneel, Bart and Sassone, Vladimiro and Wegener, Ingo},
file = {:Users/liang-tingchen/Dropbox/References/Dwork - 2006 - Differential Privacy.pdf:pdf},
isbn = {978-3-540-35907-4},
pages = {1--12},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Differential Privacy}},
url = {http://link.springer.com/10.1007/11787006{\_}1},
volume = {4052},
year = {2006}
}
@article{Krieger2018,
author = {Krieger, Martin H.},
doi = {10.1090/noti1658},
file = {:Users/liang-tingchen/Dropbox/References/Krieger - 2018 - Opinion Don't Just Begin with Let A be an algebra.pdf:pdf},
issn = {0002-9920},
journal = {Notices of the American Mathematical Society},
month = {apr},
number = {04},
title = {{Opinion: Don't Just Begin with "Let A be an algebra..."}},
url = {http://www.ams.org/notices/201804/rnoti-p437.pdf},
volume = {65},
year = {2018}
}
@article{Adamek2012e,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Trnkov{\'{a}}, V{\v{e}}ra},
doi = {10.1016/j.jpaa.2012.02.026},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Trnkov{\'{a}} - 2012 - Relatively terminal coalgebras.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {mar},
publisher = {Elsevier B.V.},
title = {{Relatively terminal coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404912000655},
year = {2012}
}
@phdthesis{Hermida1993,
abstract = {Within the framework of categorical logic/type theory, we provide a category-theoretic account of some logical concepts, i.e. first-order logical predicates for simply typed lambda-calculus, structural induction for inductive data types, and indeterminates for polymorphic calculi. The main concept which underlies the issues above is that of fibration, which gives an abstract presentation of the indexing present in all cases: predicates indexed by types/contexts in first-order logic and types indexed by kinds in polymorphic calculi. The characterisation of the logical concepts in terms of fibrations relies on a fundamental property of adjunctions between fibrations, which in particular relates some structure in the total category of a fibration with that of the fibres. Suitable instances of this property reflect the above-mentioned logical concepts in an abstract way, independently of their syntactic presentation, thereby illuminating their main features.},
author = {Hermida, Claudio},
file = {:Users/liang-tingchen/Dropbox/References/Hermida - 1993 - Fibrations, Logical Predicates and Indeterminates.pdf:pdf},
issn = {0105-8517},
school = {University of Edinburgh},
title = {{Fibrations, Logical Predicates and Indeterminates}},
type = {PhD Thesis},
url = {http://ojs.statsbiblioteket.dk/index.php/daimipb/article/view/6935},
year = {1993}
}
@inproceedings{berger:LIPIcs:2016:6566,
address = {Dagstuhl, Germany},
annote = {From Duplicate 2 (Extracting Non-Deterministic Concurrent Programs - Berger, Ulrich)

Keywords: Proof theory, realizability, program extraction, non-determinism, concurrency, computable analysis},
author = {Berger, Ulrich},
booktitle = {25th EACSL Annual Conference on Computer Science Logic (CSL 2016)},
doi = {10.4230/LIPIcs.CSL.2016.26},
editor = {Talbot, Jean-Marc and Regnier, Laurent},
file = {:Users/liang-tingchen/Dropbox/References//Berger - 2016 - Extracting Non-Deterministic Concurrent Programs.pdf:pdf},
isbn = {978-3-95977-022-4},
issn = {1868-8969},
keywords = {2016,26,4230,and phrases proof theory,computable analysis,con-,csl,currency,digital object identifier 10,lipics,non-determinism,program extraction,realizability},
number = {26},
pages = {26:1----26:21},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Extracting Non-Deterministic Concurrent Programs}},
url = {http://drops.dagstuhl.de/opus/volltexte/2016/6566},
volume = {62},
year = {2016}
}
@article{Bove2005,
abstract = {Constructive type theory is an expressive programming language in which both algorithms and proofs can be represented. A limitation of constructive type theory as a programming language is that only terminating programs can be defined in it. Hence, general recursive algorithms have no direct formalisation in type theory since they contain recursive calls that satisfy no syntactic condition guaranteeing termination. In this work, we present a method to formalise general recursive algorithms in type theory. Given a general recursive algorithm, our method is to define an inductive special-purpose accessibility predicate that characterises the inputs on which the algorithm terminates. The type-theoretic version of the algorithm is then defined by structural recursion on the proof that the input values satisfy this predicate. The method separates the computational and logical parts of the definitions and thus the resulting type-theoretic algorithms are clear, compact and easy to understand. They are as simple as their equivalents in a functional programming language, where there is no restriction on recursive calls. Here, we give a formal definition of the method and discuss its power and its limitations.},
author = {Bove, Ana and Capretta, Venanzio},
doi = {10.1017/S0960129505004822},
file = {:Users/liang-tingchen/Dropbox/References/Bove, Capretta - 2005 - Modelling general recursion in type theory.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {aug},
number = {4},
pages = {671--708},
title = {{Modelling general recursion in type theory}},
url = {https://www.cambridge.org/core/product/identifier/S0960129505004822/type/journal{\_}article},
volume = {15},
year = {2005}
}
@techreport{Phoa1992,
abstract = {A topos is a categorical model of constructive set theory. In particular, the eeective topos is the categorica{\`{i}}universe' of recursive mathematics. Among its objects are the modest sets, which form a set-theoretic model for polymorphism. More precisely, there is a bration of modest sets which satisses suitable categorical completeness properties, that make it a model for various polymorphic type theories. These lecture notes provide a reasonably thorough introduction to this body of material, aimed at theoretical computer scientists rather than topos theorists. Chapter 2 is an outline of the theory of brations, and sketches how they can be used to model various typed -calculi. Chapter 3 is an exposition of some basic topos theory, and explains why a topos can be regarded as a model of set theory. Chapter 4 discusses the classical PER model for polymorphism, and shows how ilives inside' a particular topos|the eeective topos|as the category of modest sets. An appendix contains a full presentation of the internal language of a topos, and a map of the eeective topos. Chapters 2 and 3 provide a sampler of categorical type theory and categorical logic, and should be of more general interest than Chapter 4. They can be read more or less independently of each other; a connection is made at the end of Chapter 3. The main prerequisite for reading these notes is some basic category theory: limits and col-imits, functors and natural transformations, adjoints, cartesian closed categories. No knowledge of indexed categories or categorical logic is needed. Some familiarity witordinary' logic and typed -calculus is assumed.},
author = {Phoa, Wesley},
file = {:Users/liang-tingchen/Dropbox/References/Phoa - 1992 - An introduction to fibrations, topos theory, the effective topos and modest sets.pdf:pdf},
keywords = {categories,mathematics},
pages = {150},
series = {LFCS report},
title = {{An introduction to fibrations, topos theory, the effective topos and modest sets}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.4533{\&}rep=rep1{\&}type=pdf{\%}5Cnpapers2://publication/uuid/A7D3F298-0445-4BD6-9F32-BBEC186165AB},
volume = {ECS-LFCS-9},
year = {1992}
}
@incollection{Pin1998,
author = {Pin, Jean-{\'{E}}ric},
booktitle = {LATIN'98: Theoretical Informatics},
doi = {10.1007/BFb0054312},
editor = {Lucchesi, Cl{\'{a}}udio L. and Moura, Arnaldo V.},
file = {:Users/liang-tingchen/Dropbox/References/Pin - 1998 - Positive varieties and infinite words.pdf:pdf},
pages = {76--87},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Positive varieties and infinite words}},
url = {http://link.springer.com/10.1007/BFb0054312},
year = {1998}
}
@article{Saha2003,
abstract = {Compilers for polymorphic languages can use run-time type inspection to support advanced implementation techniques such as tagless garbage collection, polymorphic marshalling, and flattened data structures. Intensional type analysis is a type-theoretic framework for expressing and certifying such type-analyzing computations. Unfortunately, existing approaches to intensional analysis do not work well on quantified types such as existential or polymorphic types. This makes it impossible to code (in a type-safe language) applications such as garbage collection, persistency, or marshalling which must be able to examine the type of any run-time value. We present a typed intermediate language that supports the analysis of quantified types. In particular, we provide both type-level and term-level constructs for analyzing quantified types. Our system supports structural induction on quantified types yet type-checking remains decidable. We also show that our system is compatible with a type-erasure semantics.},
author = {Saha, Bratin and Trifonov, Valery and Shao, Zhong},
doi = {10.1145/641888.641889},
file = {:Users/liang-tingchen/Dropbox/References/Saha, Trifonov, Shao - 2003 - Intensional analysis of quantified types.pdf:pdf},
issn = {0164-0925},
journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
keywords = {Certified code,Intensional type analysis,Runtime type dispatch,Typed intermediate languages},
month = {mar},
number = {2},
pages = {159--209},
title = {{Intensional analysis of quantified types}},
url = {http://dl.acm.org/doi/10.1145/641888.641889},
volume = {25},
year = {2003}
}
@article{Ghani2019,
abstract = {In the 1980s, John Reynolds postulated that a parametrically polymorphic function is an ad-hoc polymorphic function satisfying a uniformity principle. This allowed him to prove that his set-theoretic semantics has a relational lifting which satisfies the Identity Extension Lemma and the Abstraction Theorem . However, his definition (and subsequent variants) has only been given for specific models. In contrast, we give a model-independent axiomatic treatment by characterising Reynolds' definition via a universal property, and show that the above results follow from this universal property in the axiomatic setting.},
author = {Ghani, Neil and Forsberg, Fredrik Nordvall and Orsanigo, Federico},
doi = {10.1017/S0960129518000336},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Forsberg, Orsanigo - 2019 - Universal properties for universal types in bifibrational parametricity.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
keywords = {Relational parametricity,categorical semantics,comprehension categories},
month = {jun},
number = {06},
pages = {810--827},
title = {{Universal properties for universal types in bifibrational parametricity}},
url = {https://www.cambridge.org/core/product/identifier/S0960129518000336/type/journal{\_}article},
volume = {29},
year = {2019}
}
@incollection{Hasuo2011,
author = {Hasuo, Ichiro},
booktitle = {4th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-22944-2_16},
editor = {Corradini, Andrea and Klin, Bartek and C{\^{i}}rstea, Corina},
file = {:Users/liang-tingchen/Dropbox/References/Hasuo - 2011 - The Microcosm Principle and Compositionality of GSOS-Based Component Calculi.pdf:pdf},
pages = {222--236},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Microcosm Principle and Compositionality of GSOS-Based Component Calculi}},
year = {2011}
}
@article{Guagliardo2017,
abstract = {While formal semantics of theoretical languages underlying SQL have been provided in the past, they all made sim-plifying assumptions ranging from changes in the syntax to omitting bag semantics and nulls. This situation is reminis-cent of what happens in the field of programming languages, where semantics of formal calculi underlying the main fea-tures of languages are abundant, but formal semantics of real languages that people use are few and far between. We consider the basic class of SQL queries – essentially SELECT-FROM-WHERE queries with subqueries, set/bag opera-tions, and nulls – and define a formal semantics for it, with-out any departures from the real language. This fragment already requires decisions related to the data model and handling variable names that are normally disregarded by simplified semantics. To justify our choice of the semantics, we validate it experimentally on a large number of randomly generated queries and databases. We give two applications of the semantics. One is the first formal proof of the equivalence of basic SQL and relational algebra that extends to bag semantics and nulls. The other application looks at the three-valued logic employed by SQL, which is universally assumed to be necessary to handle nulls. We prove however that this is not so, as three-valued logic does not add expressive power: every SQL query in our frag-ment can be evaluated under the usual two-valued Boolean semantics of conditions.},
author = {Guagliardo, Paolo and Libkin, Leonid},
doi = {10.14778/3151113.3151116},
file = {:Users/liang-tingchen/Dropbox/References/Guagliardo, Libkin - 2017 - A formal semantics of SQL queries, its validation, and applications.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {sep},
number = {1},
pages = {27--39},
title = {{A formal semantics of SQL queries, its validation, and applications}},
url = {https://doi.org/10.14778/3136610.3136613{\%}0Ahttp://www.vldb.org/pvldb/vol11/p27-guagliardo.pdf http://dl.acm.org/citation.cfm?doid=3151113.3151116},
volume = {11},
year = {2017}
}
@article{Kohlas2017,
abstract = {The basic idea behind information algebras is that information comes in pieces, each referring to a certain question, that these pieces can be combined or aggregated and that the part relating to a given question can be extracted. This algebraic structure can be given different forms. Questions were originally represented by subsets of variables. Pieces of information were then represented by valuations associated with the domains of variables. This leads to an algebraic structure called valuation algebras. The basic axiomatics of this algebraic structure was in essence proposed by Shenoy and Shafer. Here a much more general view of systems of questions is proposed and pieces of information are related to the elements of this system of questions. This leads to a new and extended system of axioms for information algebras. Classical valuation algebras are essentially a special case of this new system. A full discussion of the algebraic theory of this new information algebras is given, including local computation, duality between labeled and domain-free versions of the algebras, order of information, finiteness of information and approximation, compact and continuous information algebras. Finally a rather complete discussion of uncertain information, based on random maps into information algebras is presented. This is shown to represent a generalisation of classical Dempster-Shafer theory.},
archivePrefix = {arXiv},
arxivId = {1701.02658},
author = {Kohlas, J{\"{u}}rg},
eprint = {1701.02658},
file = {:Users/liang-tingchen/Dropbox/References/Kohlas - 2017 - Algebras of Information {\{}A{\}} New and Extended Axiomatic Foundation.pdf:pdf},
journal = {ArXiv preprint},
month = {jan},
title = {{Algebras of Information: {\{}A{\}} New and Extended Axiomatic Foundation}},
url = {http://arxiv.org/abs/1701.02658},
year = {2017}
}
@article{Hyland2002a,
abstract = {Realizability and related functional interpretations provide models for constructive mathematics. Generally, these models do not validate the axiom of choice for propositions taken over hierarchies of extensional functionals. We describe simple classes of models where the axiom is validated. {\textcopyright} 2002, Cambridge University Press. All rights reserved.},
author = {Hyland, John Martin Elliott},
doi = {10.1017/S0960129502003651},
file = {:Users/liang-tingchen/Dropbox/References/Hyland - 2002 - Variations on realizability realizing the propositional axiom of choice.pdf:pdf},
isbn = {0960129502},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {03},
pages = {295--317},
title = {{Variations on realizability: realizing the propositional axiom of choice}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129502003651},
volume = {12},
year = {2002}
}
@incollection{Street1974,
author = {Street, Ross},
booktitle = {Proc. Sydney Category Theory Seminar 1972/1973},
doi = {10.1007/BFb0063102},
editor = {Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1974 - Fibrations and Yoneda's lemma in a 2-category.pdf:pdf},
pages = {104--133},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Fibrations and Yoneda's lemma in a 2-category}},
url = {http://www.springerlink.com/content/407n62422140864p/},
year = {1974}
}
@incollection{Ahmed2006,
abstract = {We present a sound and complete proof technique, based on syntactic logical relations, for showing contextual equivalence of expressions in a $\lambda$-calculus with recursive types and impredicative universal and existential types. Our development builds on the step-indexed PER model of recursive types presented by Appel and McAllester. We have discovered that a direct proof of transitivity of that model does not go through, leaving the "PER" status of the model in question. We show how to extend the Appel-McAllester model to obtain a logical relation that we can prove is transitive, as well as sound and complete with respect to contextual equivalence. We then augment this model to support relational reasoning in the presence of quantified types. Step-indexed relations are indexed not just by types, but also by the number of steps available for future evaluation. This stratification is essential for handling various circularities, from recursive functions, to recursive types, to impredicative polymorphism. The resulting construction is more elementary than existing logical relations which require complex machinery such as domain theory, admissibility, syntactic minimal invariance, and TT-closure. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Ahmed, Amal},
booktitle = {Programming Languages and Systems. ESOP 2006},
doi = {10.1007/11693024_6},
editor = {Sestoft, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Ahmed - 2006 - Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types.pdf:pdf},
isbn = {354033095X},
issn = {03029743},
pages = {69--83},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types}},
url = {http://link.springer.com/10.1007/11693024{\_}6},
volume = {3924},
year = {2006}
}
@article{Angiuli2016,
abstract = {Homotopy type theory is an extension of Martin-L{\"{o}}f type theory, based on a correspondence with homotopy theory and higher category theory. In homotopy type theory, the propositional equality type is proof-relevant, and corresponds to paths in a space. This allows for a new class of datatypes, called higher inductive types, which are specified by constructors not only for points but also for paths. In this paper, we consider a programming application of higher inductive types. Version control systems such as Darcs are based on the notion of patches—syntactic representations of edits to a repository. We show how patch theory can be developed in homotopy type theory. Our formulation separates formal theories of patches from their interpretation as edits to repositories. A patch theory is presented as a higher inductive type. Models of a patch theory are given by maps out of that type, which, being functors, automatically preserve the structure of patches. Several standard tools of homotopy theory come into play, demonstrating the use of these methods in a practical programming context.},
author = {ANGIULI, CARLO and MOREHOUSE, EDWARD and LICATA, DANIEL R. and HARPER, ROBERT},
doi = {10.1017/S0956796816000198},
file = {:Users/liang-tingchen/Dropbox/References/ANGIULI et al. - 2016 - Homotopical patch theory.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
pages = {e18},
title = {{Homotopical patch theory}},
url = {https://www.cambridge.org/core/product/identifier/S0956796816000198/type/journal{\_}article},
volume = {26},
year = {2016}
}
@article{TenCate2009,
author = {ten Cate, Balder and Gabelaia, David and Sustretov, Dmitry},
doi = {10.1016/j.apal.2008.11.001},
file = {:Users/liang-tingchen/Dropbox/References/ten Cate, Gabelaia, Sustretov - 2009 - Modal languages for topology Expressivity and definability.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {03b48,03c40,1991 msc,54a05,definability,expressivity,modal logic,topology},
month = {may},
number = {1-2},
pages = {146--170},
title = {{Modal languages for topology: Expressivity and definability}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S016800720800184X},
volume = {159},
year = {2009}
}
@article{Mcilroy1999,
abstract = {Quicksort can be made to go quadratic by constructing input on-the-fly in response to the sequence of items compared. The technique is illustrated by a specific adversary for the standard C qsort function. The general method works against any implementation of quicksort – even a randomizing one – that satisfies certain very mild and realistic assumptions. Copyright {\textcopyright} 1999 John Wiley {\&} Sons, Ltd.},
author = {McIlroy, M. D.},
doi = {10.1002/(SICI)1097-024X(19990410)29:4<341::AID-SPE237>3.0.CO;2-R},
file = {:Users/liang-tingchen/Dropbox/References/McIlroy - 1999 - A killer adversary for quicksort.pdf:pdf},
isbn = {1097-024X},
issn = {0038-0644},
journal = {Software: Practice and Experience},
month = {apr},
number = {4},
pages = {341--344},
title = {{A killer adversary for quicksort}},
url = {http://doi.wiley.com/10.1002/{\%}28SICI{\%}291097-024X{\%}2819990410{\%}2929{\%}3A4{\%}3C341{\%}3A{\%}3AAID-SPE237{\%}3E3.0.CO{\%}3B2-R},
volume = {29},
year = {1999}
}
@incollection{Chang2012,
abstract = {The existing call-by-need lambda calculi describe lazy evaluation via equational logics. A programmer can use these logics to safely ascertain whether one term is behaviorally equivalent to another or to determine the value of a lazy program. However, neither of the existing calculi models evaluation in a way that matches lazy implementations. Both calculi suffer from the same two problems. First, the calculi never discard function calls, even after they are completely resolved. Second, the calculi include re-association axioms even though these axioms are merely administrative steps with no counterpart in any implementation. In this paper, we present an alternative axiomatization of lazy evaluation using a single axiom. It eliminates both the function call retention problem and the extraneous re-association axioms. Our axiom uses a grammar of contexts to describe the exact notion of a needed computation. Like its predecessors, our new calculus satisfies consistency and standardization properties and is thus suitable for reasoning about behavioral equivalence. In addition, we establish a correspondence between our semantics and Launchbury's natural semantics.},
archivePrefix = {arXiv},
arxivId = {1201.3907},
author = {Chang, Stephen and Felleisen, Matthias},
booktitle = {Proceedings of 21st European Symposium on Programming},
doi = {10.1007/978-3-642-28869-2_7},
editor = {Seidl, Helmut},
eprint = {1201.3907},
file = {:Users/liang-tingchen/Dropbox/References/Chang, Felleisen - 2012 - The call-by-need lambda calculus, revisited.pdf:pdf},
keywords = {call-by-need,lambda calculus,laziness},
pages = {128--147},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Note in Computer Science},
title = {{The call-by-need lambda calculus, revisited}},
url = {http://link.springer.com/10.1007/978-3-642-28869-2{\_}7},
volume = {7211},
year = {2012}
}
@article{Pouly2013,
abstract = {This paper develops a new uncertainty measure for the theory of hints that complies with the established semantics of statistical information theory and further satisfies all classical requirements for such a measure imposed in the literature. The proposed functional decomposes into conversant uncertainty measures and therefore discloses a new interpretation of the latters as well. By abstracting to equivalence classes of hints we transport the new measure to mass functions in Dempster-Shafer theory and analyse its relationship with the aggregate uncertainty, which currently is the only known functional for the Dempster-Shafer theory of evidence that satisfies the same set of properties. Moreover, the perspective of hints reveals that the standard independence notion in Dempster-Shafer theory called non-interactivity corresponds to an amalgamation of probabilistic independence and qualitative independence between frames of discernment. All results in this paper are developed for arbitrary families of compatible frames generalizing the very specialized multi-variate systems that are usually studied in information theory. {\textcopyright} 2012 Elsevier Inc. All rights reserved.},
author = {Pouly, Marc and Kohlas, J{\"{u}}rg and Ryan, Peter Y A},
doi = {10.1016/j.ijar.2012.08.004},
file = {:Users/liang-tingchen/Dropbox/References/Pouly, Kohlas, Ryan - 2013 - Generalized information theory for hints.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Dempster-Shafer theory,Information theory,Theory of Hints},
month = {jan},
number = {1},
pages = {228--251},
publisher = {Elsevier Inc.},
title = {{Generalized information theory for hints}},
url = {http://dx.doi.org/10.1016/j.ijar.2012.08.004 http://linkinghub.elsevier.com/retrieve/pii/S0888613X12001454},
volume = {54},
year = {2013}
}
@incollection{Garay2015,
abstract = {We present a novel method for constructing linear secret sharing schemes (LSSS) from linear error correcting codes and linear universal hash functions in a blackbox way. The main advantage of this new construction is that the privacy property of the resulting secret sharing scheme essentially becomes independent of the code we use, only depending on its rate. This allows us to fully harness the algorithmic properties of recent code constructions such as efficient encoding and decoding or efficient list-decoding. Choosing the error correcting codes and universal hash functions involved carefully, we obtain solutions to the following open problems: – A linear near-threshold secret sharing scheme with both linear time sharing and reconstruction algorithms and large secrets (i.e. secrets of size $\Omega$(n)). Thus, the computational overhead per shared bit in this scheme is constant. – An efficiently reconstructible robust secret sharing scheme for n/3 ≤ t {\textless} (1−){\textperiodcentered}n/2 corrupted players (for any constant {\textgreater} 0) with shares of optimal size O(1 + $\lambda$/n) and secrets of size $\Omega$(n + $\lambda$), where $\lambda$ is the security parameter.},
address = {Berlin, Heidelberg},
author = {Garay, Juan and Kiayias, Aggelos and Leonardos, Nikos},
booktitle = {Advances in Cryptology - EUROCRYPT 2015: 34th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Sofia, Bulgaria, April 26-30, 2015, Proceedings, Part II},
doi = {10.1007/978-3-662-46803-6_10},
editor = {Oswald, Elisabeth and Fischlin, Marc},
file = {:Users/liang-tingchen/Dropbox/References/Garay, Kiayias, Leonardos - 2015 - The bitcoin backbone protocol Analysis and applications.pdf:pdf},
isbn = {978-3-662-46803-6},
issn = {16113349},
pages = {281--310},
publisher = {Springer Berlin Heidelberg},
title = {{The bitcoin backbone protocol: Analysis and applications}},
url = {http://dx.doi.org/10.1007/978-3-662-46803-6{\_}10 http://link.springer.com/10.1007/978-3-662-46803-6{\_}10},
volume = {9057},
year = {2015}
}
@article{Adamek1998,
abstract = {Analogously to the fact that Lawvere's algebraic theories of (finitary) varieties are precisely the small categories with finite products, we prove that (i) algebraic theories of many-sorted quasivarieties are precisely the small, left exact categories with enough regular injectives and (ii) algebraic theories of many-sorted Horn classes are precisely the small left exact categories with enough -injectives, where is a class of monomorphisms closed under finite products and containing all regular monomorphisms. We also present a Gabriel–Ulmer-type duality theory for quasivarieties and Horn classes.},
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Porst, Hans-E.},
doi = {10.1006/jabr.1998.7499},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Porst - 1998 - Algebraic Theories of Quasivarieties.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
month = {oct},
number = {2},
pages = {379--398},
title = {{Algebraic Theories of Quasivarieties}},
url = {http://dx.doi.org/10.1006/jabr.1998.7499},
volume = {208},
year = {1998}
}
@article{Joachimski2003,
author = {Joachimski, Felix and Matthes, Ralph},
doi = {10.1007/s00153-002-0156-9},
file = {:Users/liang-tingchen/Dropbox/References/Joachimski, Matthes - 2003 - Short proofs of normalization for the simply- typed $\lambda$-calculus, permutative conversions and G{\"{o}}del's T.pdf:pdf},
isbn = {0015300201569},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
keywords = {Generalized application,G{\"{o}}del's Tq-$\omega$-rule,Inductive characterization,Permutative/commuting conversions,Sum types,$\lambda$calculus},
month = {jan},
number = {1},
pages = {59--87},
title = {{Short proofs of normalization for the simply- typed $\lambda$-calculus, permutative conversions and G{\"{o}}del's T}},
url = {http://link.springer.com/10.1007/s00153-002-0156-9},
volume = {42},
year = {2003}
}
@article{lmcs:6194,
abstract = {We present a new and formal coinductive proof of confluence and normalisation of B{\"{o}}hm reduction in infinitary lambda calculus. The proof is simpler than previous proofs of this result. The technique of the proof is new, i.e., it is not merely a coinductive reformulation of any earlier proofs. We formalised the proof in the Coq proof assistant.},
author = {Czajka, {\L}ukasz},
doi = {10.23638/LMCS-16(1:31)2020},
file = {:Users/liang-tingchen/Dropbox/References//Czajka - 2020 - A new coinductive confluence proof for infinitary lambda calculus.pdf:pdf},
issn = {23318422},
journal = {Logical Methods in Computer Science},
keywords = {Computer Science - Logic in Computer Science},
month = {mar},
number = {1},
pages = {1--31},
title = {{A new coinductive confluence proof for infinitary lambda calculus}},
url = {https://lmcs.episciences.org/6194},
volume = {Volume 16},
year = {2020}
}
@incollection{Reynolds1980,
author = {Reynolds, John C.},
booktitle = {Semantics-Directed Compiler Generation. SDCG 1980},
doi = {10.1007/3-540-10250-7_24},
editor = {Jones, Neil D.},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds - 1980 - Using category theory to design implicit conversions and generic operators.pdf:pdf},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Using category theory to design implicit conversions and generic operators}},
url = {http://link.springer.com/10.1007/3-540-10250-7{\_}24},
volume = {94},
year = {1980}
}
@article{Wild2018,
abstract = {Since 2011 the Java runtime library uses a Quicksort variant with two pivot elements. For reasons that remained unclear for years it is faster than the previous Quicksort implementation by more than 10 {\%}; this is not only surprising because the previous code was highly-tuned and is used in many programming libraries, but also since earlier theoretical investigations suggested that using several pivots in Quicksort is not helpful.},
author = {Wild, Sebastian},
doi = {10.1515/itit-2018-0012},
file = {:Users/liang-tingchen/Dropbox/References/Wild - 2018 - Dual-pivot and beyond The potential of multiway partitioning in quicksort.pdf:pdf},
issn = {2196-7032},
journal = {it - Information Technology},
keywords = {average-case analysis,cache misses,external-memory model,multiway partitioning,quicksort},
month = {jul},
number = {3},
pages = {173--177},
title = {{Dual-pivot and beyond: The potential of multiway partitioning in quicksort}},
url = {http://www.degruyter.com/view/j/itit.2018.60.issue-3/itit-2018-0012/itit-2018-0012.xml},
volume = {60},
year = {2018}
}
@article{DeCarvalho2018,
abstract = {The multiset-based relational model of linear logic induces a semantics of the untyped $\lambda$-calculus, which corresponds with a non-idempotent intersection type system, System R . We prove that, in System R , the size of type derivations and the size of types are closely related to the execution time of $\lambda$-terms in a particular environment machine, Krivine's machine.},
author = {{DE CARVALHO}, DANIEL},
doi = {10.1017/S0960129516000396},
file = {:Users/liang-tingchen/Dropbox/References/DE CARVALHO - 2018 - Execution time of $\lambda$-terms via denotational semantics and intersection types.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {aug},
number = {7},
pages = {1169--1203},
title = {{Execution time of $\lambda$-terms via denotational semantics and intersection types}},
url = {https://www.cambridge.org/core/product/identifier/S0960129516000396/type/journal{\_}article},
volume = {28},
year = {2018}
}
@article{Clinger2020,
abstract = {The fully parenthesized Cambridge Polish syntax of Lisp, originally regarded as a temporary expedient to be replaced by more conventional syntax, possesses a peculiar virtue: A read procedure can parse it without knowing the syntax of any expressions, statements, definitions, or declarations it may represent. The result of that parsing is a list structure that establishes a standard representation for uninterpreted abstract syntax trees.},
author = {Clinger, William D. and Wand, Mitchell},
doi = {10.1145/3386330},
file = {:Users/liang-tingchen/Dropbox/References/Clinger, Wand - 2020 - Hygienic macro technology.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Hygiene,Lisp,Macro,Scheme},
month = {jun},
number = {HOPL},
pages = {1--110},
title = {{Hygienic macro technology}},
url = {https://dl.acm.org/doi/10.1145/3386330},
volume = {4},
year = {2020}
}
@article{Klein2014,
abstract = {Este art{\'{i}}culo presenta una cobertura detallada de la verificaci{\'{o}}n formal integral del microkernel SEL4, de su prueba de la correcci{\'{o}}n funcional inicial con los resultados m{\'{a}}s recientes, que se extienden el argumento de garant{\'{i}}a hasta las propiedades de seguridad de nivel superior y hacia abajo a nivel binario de su aplicaci{\'{o}}n. El objetivo de nuestra verificaci{\'{o}}n, el n{\'{u}}cleo, es la parte m{\'{a}}s cr{\'{i}}tica de un sistema, que es nuestra motivaci{\'{o}}n para iniciar la verificaci{\'{o}}n del sistema con este componente},
author = {Klein, Gerwin and Andronick, June and Elphinstone, Kevin and Murray, Toby and Sewell, Thomas and Kolanski, Rafal and Heiser, Gernot},
doi = {10.1145/2560537},
file = {:Users/liang-tingchen/Dropbox/References/Klein et al. - 2014 - Comprehensive formal verification of an OS microkernel.pdf:pdf},
issn = {07342071},
journal = {ACM Transactions on Computer Systems},
month = {feb},
number = {1},
pages = {1--70},
title = {{Comprehensive formal verification of an OS microkernel}},
url = {http://dl.acm.org/citation.cfm?doid=2584468.2560537},
volume = {32},
year = {2014}
}
@book{Streicher2006a,
abstract = {This textbook provides a basis for a PhD course on domain-theoretic semantics of functional programming languages and their meta-mathematical properties. It introduces basic domain theory and the technique of logical relations as developed by Scott and Plotkin. The solution of recursive domain equations is explained in detail. A complete discussion of the famous full abstraction problem for PCF (a functional Kernel language due to Scott and Plotkin) is given including a construction of the fully abstract Milner model using Kripke logical relations. A final chapter introduces computability in Scott domains and shows that this model is fully abstract and universal for appropriate extensions of PCF by parallel language constructs.},
author = {Streicher, Thomas},
doi = {10.1142/6284},
file = {:Users/liang-tingchen/Dropbox/References/Streicher - 2006 - Domain-Theoretic Foundations of Functional Programming.pdf:pdf},
isbn = {978-981-270-142-8},
month = {dec},
pages = {132},
publisher = {World Scientific},
title = {{Domain-Theoretic Foundations of Functional Programming}},
url = {http://www.worldscientific.com/worldscibooks/10.1142/6284},
year = {2006}
}
@article{Iemhoff2005,
abstract = {We study the modal properties of intuitionistic modal logics that belong to the provability logic or the preservativity logic of Heyting Arithmetic. We describe the □-fragment of some preservativity logics and we present fixed point theorems for the logics iL and iPL, and show that they imply the Beth property. These results imply that the fixed point theorem and the Beth property hold for both the provability and preservativity logic of Heyting Arithmetic. We present a frame correspondence result for the preservativity principle Wp that is related to an extension of L{\"{o}}b's principle. {\textcopyright} 2005 Oxford University Press.},
author = {Iemhoff, Rosalie and {De Jongh}, Dick and Zhou, Chunlai},
doi = {10.1093/jigpal/jzi047},
file = {:Users/liang-tingchen/Dropbox/References/Iemhoff, De Jongh, Zhou - 2005 - Properties of Intuitionistic Provability and Preservativity Logics.pdf:pdf},
issn = {1368-9894},
journal = {Logic Journal of the IGPL},
keywords = {Beth definability,Fixed points,Heyting Arithmetic,Intuitionistic modal logic,Preservativity logic,Provability logic},
month = {nov},
number = {6},
pages = {615--636},
title = {{Properties of Intuitionistic Provability and Preservativity Logics}},
url = {http://academic.oup.com/jigpal/article/13/6/615/727737/Properties-of-Intuitionistic-Provability-and},
volume = {13},
year = {2005}
}
@article{Abramsky2011a,
abstract = {We use the mathematical language of sheaf theory to give a unified treatment of non-locality and contextuality, in a setting which generalizes the familiar probability tables used in non-locality theory to arbitrary measurement covers; this includes Kochen-Specker configurations and more. We show that contextuality, and non-locality as a special case, correspond exactly to obstructions to the existence of global sections. We describe a linear algebraic approach to computing these obstructions, which allows a systematic treatment of arguments for non-locality and contextuality. We distinguish a proper hierarchy of strengths of no-go theorems, and show that three leading examples --- due to Bell, Hardy, and Greenberger, Horne and Zeilinger, respectively --- occupy successively higher levels of this hierarchy. A general correspondence is shown between the existence of local hidden-variable realizations using negative probabilities, and no-signalling; this is based on a result showing that the linear subspaces generated by the non-contextual and no-signalling models, over an arbitrary measurement cover, coincide. Maximal non-locality is generalized to maximal contextuality, and characterized in purely qualitative terms, as the non-existence of global sections in the support. A general setting is developed for Kochen-Specker type results, as generic, model-independent proofs of maximal contextuality, and a new combinatorial condition is given, which generalizes the `parity proofs' commonly found in the literature. We also show how our abstract setting can be represented in quantum mechanics. This leads to a strengthening of the usual no-signalling theorem, which shows that quantum mechanics obeys no-signalling for arbitrary families of commuting observables, not just those represented on different factors of a tensor product.},
archivePrefix = {arXiv},
arxivId = {1102.0264},
author = {Abramsky, Samson and Brandenburger, Adam},
doi = {10.1088/1367-2630/13/11/113036},
eprint = {1102.0264},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky, Brandenburger - 2011 - The sheaf-theoretic structure of non-locality and contextuality.pdf:pdf},
issn = {13672630},
journal = {New Journal of Physics},
title = {{The sheaf-theoretic structure of non-locality and contextuality}},
volume = {13},
year = {2011}
}
@phdthesis{Jung1988,
author = {Jung, Achim},
file = {:Users/liang-tingchen/Dropbox/References/Jung - 1988 - Cartesian closed categories of domains.pdf:pdf},
number = {April},
school = {Technische Universit{\"{a}}t Darmstadt},
title = {{Cartesian closed categories of domains}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.37.9634{\&}rep=rep1{\&}type=pdf},
year = {1988}
}
@article{Schroder2011,
author = {Schr{\"{o}}der, Lutz and Pattinson, Dirk},
doi = {10.1017/S0960129510000563},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der, Pattinson - 2011 - Modular algorithms for heterogeneous modal logics via multi-sorted coalgebra.pdf:pdf},
isbn = {0960129510},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
number = {02},
pages = {235--266},
title = {{Modular algorithms for heterogeneous modal logics via multi-sorted coalgebra}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129510000563},
volume = {21},
year = {2011}
}
@article{Czajka2018,
abstract = {Hammers provide most powerful general purpose automation for proof assistants based on HOL and set theory today. Despite the gaining popularity of the more advanced versions of type theory, such as those based on the Calculus of Inductive Constructions, the construction of hammers for such foundations has been hindered so far by the lack of translation and reconstruction components. In this paper, we present an architecture of a full hammer for dependent type theory together with its implementation for the Coq proof assistant. A key component of the hammer is a proposed translation from the Calculus of Inductive Constructions, with certain extensions introduced by Coq, to untyped first-order logic. The translation is “sufficiently” sound and complete to be of practical use for automated theorem provers. We also introduce a proof reconstruction mechanism based on an eauto-type algorithm combined with limited rewriting, congruence closure and some forward reasoning. The algorithm is able to re-prove in the Coq logic most of the theorems established by the ATPs. Together with machine-learning based selection of relevant premises this constitutes a full hammer system. The performance of the whole procedure is evaluated in a bootstrapping scenario emulating the development of the Coq standard library. For each theorem in the library only the previous theorems and proofs can be used. We show that 40.8{\%} of the theorems can be proved in a push-button mode in about 40 s of real time on a 8-CPU system.},
author = {Czajka, {\L}ukasz and Kaliszyk, Cezary},
doi = {10.1007/s10817-018-9458-4},
file = {:Users/liang-tingchen/Dropbox/References/Czajka, Kaliszyk - 2018 - Hammer for Coq Automation for Dependent Type Theory.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Calculus of inductive constructions,Coq,Hammer,Proof automation},
month = {jun},
number = {1-4},
pages = {423--453},
publisher = {Springer Netherlands},
title = {{Hammer for Coq: Automation for Dependent Type Theory}},
url = {https://doi.org/10.1007/s10817-018-9458-4 http://link.springer.com/10.1007/s10817-018-9458-4},
volume = {61},
year = {2018}
}
@article{Kaposi2019,
abstract = {Quotient inductive-inductive types (QIITs) generalise inductive types in two ways: a QIIT can have more than one sort and the later sorts can be indexed over the previous ones. In addition, equality constructors are also allowed. We work in a setting with uniqueness of identity proofs, hence we use the term QIIT instead of higher inductive-inductive type. An example of a QIIT is the well-typed (intrinsic) syntax of type theory quotiented by conversion. In this paper first we specify finitary QIITs using a domain-specific type theory which we call the theory of signatures. The syntax of the theory of signatures is given by a QIIT as well. Then, using this syntax we show that all specified QIITs exist and they have a dependent elimination principle. We also show that algebras of a signature form a category with families (CwF) and use the internal language of this CwF to show that dependent elimination is equivalent to initiality.},
author = {Kaposi, Ambrus and Kov{\'{a}}cs, Andr{\'{a}}s and Altenkirch, Thorsten},
doi = {10.1145/3290315},
file = {:Users/liang-tingchen/Dropbox/References/Kaposi, Kov{\'{a}}cs, Altenkirch - 2019 - Constructing quotient inductive-inductive types.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--24},
title = {{Constructing quotient inductive-inductive types}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290315},
volume = {3},
year = {2019}
}
@article{Pfenning1995,
abstract = {We present $\lambda$→□, a concise formulation of a proof term calculus for the intuitionistic modal logic S4 that is well-suited for practical applications. We show that, with respect to provability, it is equivalent to other formulations in the literature, sketch a simple type checking algorithm, and prove subject reduction and the existence of canonical forms for well-typed terms. Applications include a new formulation of natural deduction for intuitionistic linear logic, modal logical frameworks, and a logical analysis of staged computation and binding-time analysis for functional languages [6]. {\textcopyright} 2000.},
author = {Pfenning, F. and Wong, H.C.},
doi = {10.1016/S1571-0661(04)00028-3},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning, Wong - 1995 - On a Modal $\lambda$-Calculus for S4.pdf:pdf},
issn = {15710661},
journal = {MFPS XI, Mathematical Foundations of Programming Semantics, Eleventh Annual Conference},
number = {C},
pages = {515--534},
title = {{On a Modal $\lambda$-Calculus for S4}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066104000283},
volume = {1},
year = {1995}
}
@article{Yang2019,
abstract = {Traditional designs for functional languages (such as Haskell or ML) have separate sorts of syntax for terms and types. In contrast, many dependently typed languages use a unified syntax that accounts for both terms and types. Unified syntax has some interesting advantages over separate syntax, including less duplication of concepts, and added expressiveness. However, integrating unrestricted general recursion in calculi with unified syntax is challenging when some level of type-level computation is present, since properties such as decidable type-checking are easily lost. This paper presents a family of calculi called pure iso-type systems (PITSs), which employs unified syntax, supports general recursion and preserves decidable type-checking. PITS is comparable in simplicity to pure type systems (PTSs), and is useful to serve as a foundation for functional languages that stand in-between traditional ML-like languages and fully blown dependently typed languages. In PITS, recursion and recursive types are completely unrestricted and type equality is simply based on alpha-equality, just like traditional ML-style languages. However, like most dependently typed languages, PITS uses unified syntax, naturally supporting many advanced type system features. Instead of implicit type conversion, PITS provides a generalization of iso-recursive types called iso-types . Iso-types replace the conversion rule typically used in dependently typed calculus and make every type-level computation explicit via cast operators. Iso-types avoid the complexity of explicit equality proofs employed in other approaches with casts. We study three variants of PITS that differ on the reduction strategy employed by the cast operators: call-by-name , call-by-value and parallel reduction . One key finding is that while using call-by-value or call-by-name reduction in casts loses some expressive power, it allows those variants of PITS to have simple and direct operational semantics and proofs. In contrast, the variant of PITS with parallel reduction retains the expressive power of PTS conversion, at the cost of a more complex metatheory.},
author = {YANG, YANPENG and OLIVEIRA, BRUNO C. D. S.},
doi = {10.1017/S0956796819000108},
file = {:Users/liang-tingchen/Dropbox/References/YANG, OLIVEIRA - 2019 - Pure iso-type systems.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
pages = {e14},
title = {{Pure iso-type systems}},
url = {https://www.cambridge.org/core/product/identifier/S0956796819000108/type/journal{\_}article},
volume = {29},
year = {2019}
}
@inproceedings{Orchard2016,
abstract = {Effect and session type systems are two expressive behavioural type systems. The former is usually developed in the context of the $\lambda$- calculus and its variants, the latter for the $\pi$-calculus. In this paper we explore their relative expressive power. Firstly, we give an em- bedding from PCF, augmented with a parameterised effect system, into a session-typed $\pi$-calculus (session calculus), showing that session types are powerful enough to express effects. Secondly, we give a reverse embedding, from the session calculus back into PCF, by instantiating PCF with concurrency primitives and its effect sys- tem with a session-like effect algebra; effect systems are powerful enough to express sessions. The embedding of session types into an effect system is leveraged to give a new implementation of session types in Haskell, via an effect system encoding. The correctness of this implementation follows from the second embedding result.We also discuss various extensions to our embeddings.},
address = {New York, New York, USA},
author = {Orchard, Dominic and Yoshida, Nobuko},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL 2016},
doi = {10.1145/2837614.2837634},
file = {:Users/liang-tingchen/Dropbox/References/Orchard, Yoshida - 2016 - Effects as sessions, sessions as effects.pdf:pdf},
isbn = {9781450335492},
issn = {07308566},
keywords = {concurrent haskell,effect systems,encod-,ing,pcf,session types,type systems,$\pi$ -calculus},
pages = {568--581},
publisher = {ACM Press},
title = {{Effects as sessions, sessions as effects}},
url = {http://dl.acm.org/citation.cfm?doid=2837614.2837634},
year = {2016}
}
@phdthesis{Sterling2021a,
author = {Sterling, Jonathan},
file = {:Users/liang-tingchen/Dropbox/References/Sterling - 2021 - First Steps in Synthetic Tait Computability The Objective Metatheory of Cubical Type Theory.pdf:pdf},
number = {CMU-CS-21-142},
school = {Carnegie Mellon University},
title = {{First Steps in Synthetic Tait Computability: The Objective Metatheory of Cubical Type Theory}},
type = {Doctoral thesis},
year = {2021}
}
@inproceedings{Eisenberg2012,
abstract = {Haskell programmers have been experimenting with dependent types for at least a decade, using clever encodings that push the limits of the Haskell type system. However, the cleverness of these encodings is also their main drawback. Although the ideas},
address = {New York, New York, USA},
author = {Eisenberg, Richard A. and Weirich, Stephanie},
booktitle = {Proceedings of the 2012 symposium on Haskell symposium - Haskell '12},
doi = {10.1145/2364506.2364522},
file = {:Users/liang-tingchen/Dropbox/References/Eisenberg, Weirich - 2012 - Dependently typed programming with singletons.pdf:pdf},
isbn = {9781450315746},
issn = {0362-1340},
keywords = {dependently typed programming,gadts,haskell,singletons},
pages = {117},
pmid = {27592005},
publisher = {ACM Press},
title = {{Dependently typed programming with singletons}},
url = {http://dl.acm.org/citation.cfm?id=2364506.2364522 http://dl.acm.org/citation.cfm?doid=2364506.2364522},
volume = {47},
year = {2012}
}
@article{Higgins1990,
author = {Higgins, Peter M.},
doi = {10.1007/BF01189004},
file = {:Users/liang-tingchen/Dropbox/References/Higgins - 1990 - An algebraic proof that pseudovarieties are defined by pseudoidentities.pdf:pdf},
issn = {00025240},
journal = {Algebra Universalis},
number = {4},
pages = {597--599},
title = {{An algebraic proof that pseudovarieties are defined by pseudoidentities}},
volume = {27},
year = {1990}
}
@article{New2018,
abstract = {We present gradual type theory, a logic and type theory for call-by-name gradual typing. We define the central constructions of gradual typing (the dynamic type, type casts and type error) in a novel way, by universal properties relative to new judgments for gradual type and term dynamism, which were developed in blame calculi and to state the "gradual guarantee" theorem of gradual typing. Combined with the ordinary extensionality ({\$}\backslasheta{\$}) principles that type theory provides, we show that most of the standard operational behavior of casts is uniquely determined by the gradual guarantee. This provides a semantic justification for the definitions of casts, and shows that non-standard definitions of casts must violate these principles. Our type theory is the internal language of a certain class of preorder categories called equipments. We give a general construction of an equipment interpreting gradual type theory from a 2-category representing non-gradual types and programs, which is a semantic analogue of Findler and Felleisen's definitions of contracts, and use it to build some concrete domain-theoretic models of gradual typing.},
archivePrefix = {arXiv},
arxivId = {1802.00061},
author = {New, Max S. and Licata, Daniel R. and Ahmed, Amal},
doi = {10.1145/3290328},
eprint = {1802.00061},
file = {:Users/liang-tingchen/Dropbox/References/New, Licata, Ahmed - 2019 - Gradual type theory.pdf:pdf},
isbn = {9783959770774},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {call-by-push-value,gradual typing,graduality},
month = {jan},
number = {POPL},
pages = {1--31},
title = {{Gradual type theory}},
url = {http://arxiv.org/abs/1802.00061 http://dl.acm.org/citation.cfm?doid=3302515.3290328},
volume = {3},
year = {2019}
}
@article{Cockett2010,
abstract = {We investigate notions of simulation between categories over a base, inspired by and directly relevant for the study of categories arising in computability and realizability, but applicable to other settings as well. Such simulations admit a conceptual description in terms of the free fibration monad; this relates them closely to fibrations of (partitioned) assemblies. Our main application is in the area of abstract computability, where we show that the category of Turing categories over a fixed base and simulations between them is 2-equivalent to the category of relative PCAs in the base. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Cockett, J.R.B. and Hofstra, Pieter J.W.},
doi = {10.1016/j.jpaa.2009.12.028},
file = {:Users/liang-tingchen/Dropbox/References/Cockett, Hofstra - 2010 - Categorical simulations.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {oct},
number = {10},
pages = {1835--1853},
publisher = {Elsevier B.V.},
title = {{Categorical simulations}},
url = {http://dx.doi.org/10.1016/j.jpaa.2009.12.028 https://linkinghub.elsevier.com/retrieve/pii/S0022404909003119},
volume = {214},
year = {2010}
}
@inproceedings{Veltri2019,
abstract = {In type theory, programming and reasoning with possibly non-terminating programs and potentially infinite objects is achieved using coinductive types. Recursively defined programs of these types need to be productive to guarantee the consistency of the type system. Proof assistants such as Agda and Coq traditionally employ strict syntactic productivity checks, which often make programming with coinductive types convoluted. One way to overcome this issue is by encoding productivity at the level of types so that the type system forbids the implementation of non-productive corecursive programs. In this paper we compare two different approaches to type-based productivity: guarded recursion and sized types. More specifically, we show how to simulate guarded recursion in Agda using sized types. We formalize the syntax of a simple type theory for guarded recursion, which is a variant of Atkey and McBride's calculus for productive coprogramming. Then we give a denotational semantics using presheaves over the preorder of sizes. Sized types are fundamentally used to interpret the characteristic features of guarded recursion, notably the fixpoint combinator.},
author = {Veltri, Niccol{\`{o}} and van der Weide, Niels},
booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
doi = {10.4230/LIPIcs.FSCD.2019.32},
editor = {Geuvers, Herman},
file = {:Users/liang-tingchen/Dropbox/References/Veltri, van der Weide - 2019 - Guarded recursion in agda via sized types.pdf:pdf},
isbn = {9783959771078},
issn = {18688969},
keywords = {Coinduction,Guarded recursion,Semantics,Sized types,Type theory},
number = {32},
pages = {32:1----32:19},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Guarded recursion in agda via sized types}},
url = {https://drops.dagstuhl.de/opus/volltexte/2019/10539/},
volume = {131},
year = {2019}
}
@article{Soria-Comas2014,
abstract = {It is not uncommon in the data anonymization literature to oppose the "old" k-anonymity model to the "new" differential privacy model, which offers more robust privacy guarantees. Yet, it is often disregarded that the utility of the anonymized results provided by differential privacy is quite limited, due to the amount of noise that needs to be added to the output, or because utility can only be guaranteed for a restricted type of queries. This is in contrast with k-anonymity mechanisms, which make no assumptions on the uses of anonymized data while focusing on preserving data utility from a general perspective. In this paper, we show that a synergy between differential privacy and {\{}Mathematical expression{\}}-anonymity can be found: {\{}Mathematical expression{\}}-anonymity can help improving the utility of differentially private responses to arbitrary queries. We devote special attention to the utility improvement of differentially private published data sets. Specifically, we show that the amount of noise required to fulfill {\{}Mathematical expression{\}}-differential privacy can be reduced if noise is added to a {\{}Mathematical expression{\}}-anonymous version of the data set, where {\{}Mathematical expression{\}}-anonymity is reached through a specially designed microaggregation of all attributes. As a result of noise reduction, the general analytical utility of the anonymized output is increased. The theoretical benefits of our proposal are illustrated in a practical setting with an empirical evaluation on three data sets.},
author = {Soria-Comas, Jordi and Domingo-Ferrer, Josep and S{\'{a}}nchez, David and Mart{\'{i}}nez, Sergio},
doi = {10.1007/s00778-014-0351-4},
file = {:Users/liang-tingchen/Dropbox/References/Soria-Comas et al. - 2014 - Enhancing data utility in differential privacy via microaggregation-based {\$}k{\$}-anonymity.pdf:pdf},
isbn = {0077801403514},
issn = {1066-8888},
journal = {The VLDB Journal},
keywords = {Data utility,Differential privacy,Microaggregation,Privacy-preserving data publishing,k-Anonymity},
month = {oct},
number = {5},
pages = {771--794},
title = {{Enhancing data utility in differential privacy via microaggregation-based {\$}k{\$}-anonymity}},
url = {http://link.springer.com/10.1007/s00778-014-0351-4},
volume = {23},
year = {2014}
}
@book{Boolos1994,
author = {Boolos, George S.},
doi = {10.1017/CBO9780511625183},
isbn = {9780521433426},
month = {feb},
publisher = {Cambridge University Press},
title = {{The Logic of Provability}},
url = {https://www.cambridge.org/core/product/identifier/9780511625183/type/book},
year = {1994}
}
@book{Power1998a,
abstract = {These notes constitute lecture notes to accompany a course on 2-categories at BRICS in the Computer Science Department of the University of Aarhus in March 1998. Each section corresponds to one lecture.},
author = {Power, A. John},
file = {:Users/liang-tingchen/Dropbox/References/Power - 1998 - 2-Categories.pdf:pdf},
issn = {0909-3206},
month = {aug},
number = {August},
series = {BRICS Notes Series},
title = {{2-Categories}},
url = {http://www.brics.dk/NS/98/7/},
year = {1998}
}
@inproceedings{Matsuda2015,
abstract = {A bidirectional transformation is a pair of mappings between source and view data objects, one in each direction. When the view is modified, the source is updated accordingly with respect to some laws. One way to reduce the development and maintenance effort of bidirectional transformations is to have specialized languages in which the resulting programs are bidirectional by construction-giving rise to the paradigm of bidirectional programming. In this paper, we develop a framework for applicative-style and higher-order bidirectional programming, in which we can write bidirectional transformations as unidirectional programs in standard functional languages, opening up access to the bundle of language features previously only available to conventional unidirectional languages. Our framework essentially bridges two very different approaches of bidirectional programming, namely the lens framework and Voigtl{\"{a}}nder's semantic bidirectionalization, creating a new programming style that is able to bag benefits from both.},
address = {New York, New York, USA},
author = {Matsuda, Kazutaka and Wang, Meng},
booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming - ICFP 2015},
doi = {10.1145/2784731.2784750},
file = {:Users/liang-tingchen/Dropbox/References/Matsuda, Wang - 2015 - Applicative bidirectional programming with lenses.pdf:pdf},
isbn = {9781450336697},
issn = {03621340},
keywords = {Bidirectional programming,Bidirectionalization,Free theorem,Functional programming,Haskell,Lens},
pages = {62--74},
publisher = {ACM Press},
title = {{Applicative bidirectional programming with lenses}},
url = {http://dl.acm.org/citation.cfm?doid=2784731.2784750},
volume = {2015-Augus},
year = {2015}
}
@article{Pfenning1991,
abstract = {We consider the question of whether a useful notion of metacircularity exists for the polymorphic $\lambda$-calculus. Even though complete metacircularity seems to be impossible, we obtain a close approximation to a metacircular interpreter. We begin by presenting an encoding for the Girard-Reynolds second-order polymorphic $\lambda$-calculus in the third-order polymorphic $\lambda$-calculus. The encoding makes use of representations in which abstractions are represented by abstractions, thus eliminating the need for the explicit representation of environments. We then extend this construction to encompass all of the $\omega$-order polymorphic $\lambda$-calculus (F$\omega$). The representation has the property that evaluation is definable, and furthermore that only well-typed terms can be represented and thus type inference does not have to be explicitly defined. Unfortunately, this metacircularity result seems to fall short of providing a useful framework for typed metaprogramming. We speculate on the reasons for this failure and the prospects for overcoming it in the future. In addition, we briefly describe our efforts in designing a practical programming language based on F$\omega$. {\textcopyright} 1991.},
author = {Pfenning, Frank and Lee, Peter},
doi = {10.1016/0304-3975(90)90109-U},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning, Lee - 1991 - Metacircularity in the polymorphic $\lambda$-calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
number = {1},
pages = {137--159},
title = {{Metacircularity in the polymorphic $\lambda$-calculus}},
volume = {89},
year = {1991}
}
@article{Jansen2015,
abstract = {In this paper, we investigate the semantic intricacies of conditioning in probabilistic programming, a major feature, e.g., in machine learning. We provide a quantitative weakest pre-condition semantics. In contrast to all other approaches, non-termination is taken into account by our semantics. We also present an operational semantics in terms of Markov models and show that expected rewards coincide with quantitative pre-conditions. A program transformation that entirely eliminates conditioning from programs is given; the correctness is shown using our semantics. Finally, we show that an inductive semantics for conditioning in non-deterministic probabilistic programs cannot exist.},
archivePrefix = {arXiv},
arxivId = {1504.00198},
author = {Jansen, Nils and Kaminski, Benjamin Lucien and Katoen, Joost-Pieter and Olmedo, Federico and Gretz, Friedrich and McIver, Annabelle},
doi = {10.1016/j.entcs.2015.12.013},
eprint = {1504.00198},
file = {:Users/liang-tingchen/Dropbox/References/Jansen et al. - 2015 - Conditioning in Probabilistic Programming.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Conditional Probabilities,Probabilistic Programming,Program Transformation,Semantics},
month = {dec},
pages = {199--216},
publisher = {Elsevier B.V.},
title = {{Conditioning in Probabilistic Programming}},
url = {http://dx.doi.org/10.1016/j.entcs.2015.12.013 http://linkinghub.elsevier.com/retrieve/pii/S1571066115000808},
volume = {319},
year = {2015}
}
@article{Terrovitis2008,
abstract = {In this paper we study the problem of protecting privacy in the publication of set-valued data. Consider a collection of transactional data that contains detailed information about items bought together by individuals. Even after removing all personal characteristics of the buyer, which can serve as links to his identity, the publication of such data is still subject to privacy attacks from adversaries who have partial knowledge about the set. Unlike most previous works, we do not distinguish data as sensitive and non-sensitive, but we consider them both as potential quasi-identifiers and potential sensitive data, depending on the point of view of the adversary. We define a new version of the k-anonymity guarantee, the k m-anonymity, to limit the effects of the data dimensionality and we propose efficient algorithms to transform the database. Our anonymization model relies on generalization instead of suppression, which is the most common practice in related works on such data. We develop an algorithm which finds the optimal solution, however, at a high cost which makes it inapplicable for large, realistic problems. Then, we propose two greedy heuristics, which scale much better and in most of the cases find a solution close to the optimal. The proposed algorithms are experimentally evaluated using real datasets.},
author = {Terrovitis, Manolis and Mamoulis, Nikos and Kalnis, Panos},
doi = {10.14778/1453856.1453874},
file = {:Users/liang-tingchen/Dropbox/References/Terrovitis, Mamoulis, Kalnis - 2008 - Privacy-preserving anonymization of set-valued data.pdf:pdf},
isbn = {0000000000000},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {aug},
number = {1},
pages = {115--125},
title = {{Privacy-preserving anonymization of set-valued data}},
url = {http://dl.acm.org/citation.cfm?doid=1453856.1453874},
volume = {1},
year = {2008}
}
@article{Cockx2020a,
abstract = {Dependently typed languages such as Coq and Agda can statically guarantee the correctness of our proofs and programs. To provide this guarantee, they restrict users to certain schemes a- such as strictly positive datatypes, complete case analysis, and well-founded induction a- that are known to be safe. However, these restrictions can be too strict, making programs and proofs harder to write than necessary. On a higher level, they also prevent us from imagining the different ways the language could be extended. In this paper I show how to extend a dependently typed language with user-defined higher-order non-linear rewrite rules. Rewrite rules are a form of equality reflection that is applied automatically by the typechecker. I have implemented rewrite rules as an extension to Agda, and I give six examples how to use them both to make proofs easier and to experiment with extensions of type theory. I also show how to make rewrite rules interact well with other features of Agda such as-equality, implicit arguments, data and record types, irrelevance, and universe level polymorphism. Thus rewrite rules break the chains on computation and put its power back into the hands of its rightful owner: Yours.},
author = {Cockx, Jesper},
doi = {10.4230/LIPIcs.TYPES.2019.2},
file = {:Users/liang-tingchen/Dropbox/References/Cockx - 2020 - Type Theory Unchained Extending Agda with User-Defined Rewrite Rules.pdf:pdf},
isbn = {9783959771580},
issn = {18688969},
journal = {Leibniz International Proceedings in Informatics, LIPIcs},
keywords = {Agda,Dependent types,Higher-order rewriting,Proof assistants,Rewrite rules},
number = {2},
pages = {1--2},
title = {{Type Theory Unchained: Extending Agda with User-Defined Rewrite Rules}},
volume = {175},
year = {2020}
}
@article{Botta2014,
author = {Botta, Nicola and Ionescu, Cezar and Jansson, Patrik and Brady, Edwin and Christiansen, David R},
doi = {10.23638/LMCS-13(1:7)2017},
file = {:Users/liang-tingchen/Dropbox/References/Botta et al. - 2017 - Sequential decision problems, dependent types and generic solutions.pdf:pdf},
journal = {Logical Methods in Computer Science},
number = {1},
title = {{Sequential decision problems, dependent types and generic solutions}},
url = {https://lmcs.episciences.org/3202},
volume = {13},
year = {2017}
}
@incollection{Milius2013b,
author = {Milius, Stefan and Litak, Tadeusz},
booktitle = {The Proceedings of the Ninth Workshop on Fixed Points in Computer Science},
doi = {10.4204/EPTCS.126.6},
editor = {Baelde, David and Carayol, Arnaud},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Litak - 2013 - Guard your daggers and traces On the equational properties of guarded (co-)recursion.pdf:pdf},
issn = {2075-2180},
number = {Informatik 8},
pages = {72--86},
title = {{Guard your daggers and traces: On the equational properties of guarded (co-)recursion}},
url = {http://arxiv.org/abs/1309.0895v1},
volume = {126},
year = {2013}
}
@article{Ishtiaq1998,
author = {Ishtiaq, S.},
doi = {10.1093/logcom/8.6.809},
file = {:Users/liang-tingchen/Dropbox/References/Ishtiaq - 1998 - A relevant analysis of natural deduction.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Linear logic,Logical frameworks,Natural deduction,Relevant logic,Type theory},
month = {dec},
number = {6},
pages = {809--838},
title = {{A relevant analysis of natural deduction}},
url = {https://academic.oup.com/logcom/article-lookup/doi/10.1093/logcom/8.6.809},
volume = {8},
year = {1998}
}
@article{Walia2019,
abstract = {Probabilistic programming languages are valuable because they allow domain experts to express probabilistic models and inference algorithms without worrying about irrelevant details. However, for decades there remained an important and popular class of probabilistic inference algorithms whose efficient implementation required manual low-level coding that is tedious and error-prone. They are algorithms whose idiomatic expression requires random array variables that are latent or whose likelihood is conjugate . Although that is how practitioners communicate and compose these algorithms on paper, executing such expressions requires eliminating the latent variables and recognizing the conjugacy by symbolic mathematics. Moreover, matching the performance of handwritten code requires speeding up loops by more than a constant factor.},
author = {Walia, Rajan and Narayanan, Praveen and Carette, Jacques and Tobin-Hochstadt, Sam and Shan, Chung-chieh},
doi = {10.1145/3341702},
file = {:Users/liang-tingchen/Dropbox/References/Walia et al. - 2019 - From high-level inference algorithms to efficient code.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {arrays,collapsed Gibbs sampling,conjugacy,loop optimization,map-reduce,marginalization,multidimensional distributions,plates,probabilistic programs},
month = {jul},
number = {ICFP},
pages = {1--30},
title = {{From high-level inference algorithms to efficient code}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341702 https://dl.acm.org/doi/10.1145/3341702},
volume = {3},
year = {2019}
}
@inproceedings{Barenbaum2020,
abstract = {Justification Logic is a refinement of modal logic where the modality is annotated with a reason s for "knowing"A and written . The expression s is a proof of A that may be encoded as a lambda calculus term of type A, according to the propositions-as-types interpretation. Our starting point is the observation that terms of type are reductions between lambda calculus terms. Reductions are usually encoded as rewrites essential tools in analyzing the reduction behavior of lambda calculus and term rewriting systems, such as when studying standardization, needed strategies, L{\'{e}}vy permutation equivalence, etc. We explore a new propositions-as-types interpretation for Justification Logic, based on the principle that terms of type are proof terms encoding reductions (with source s). Note that this provides a logical language to reason about rewrites.},
address = {New York, NY, USA},
author = {Barenbaum, Pablo and Bonelli, Eduardo},
booktitle = {22nd International Symposium on Principles and Practice of Declarative Programming},
doi = {10.1145/3414080.3414091},
file = {:Users/liang-tingchen/Dropbox/References/Barenbaum, Bonelli - 2020 - Rewrites as Terms through Justification Logic.pdf:pdf},
isbn = {9781450388214},
issn = {21531633},
keywords = {Curry-Howard,Lambda calculus,modal logic,term rewriting,type systems},
month = {sep},
pages = {1--13},
publisher = {ACM},
title = {{Rewrites as Terms through Justification Logic}},
url = {https://dl.acm.org/doi/10.1145/3414080.3414091},
year = {2020}
}
@article{Mio2013,
author = {Mio, Matteo and Simpson, Alex},
doi = {10.4204/EPTCS.126.7},
file = {:Users/liang-tingchen/Dropbox/References/Mio, Simpson - 2013 - {\L}ukasiewicz mu-Calculus.pdf:pdf},
issn = {2075-2180},
journal = {Electronic Proceedings in Theoretical Computer Science},
month = {aug},
number = {Fics},
pages = {87--104},
title = {{{\L}ukasiewicz mu-Calculus}},
url = {http://arxiv.org/abs/1309.0896v1},
volume = {126},
year = {2013}
}
@article{Nakano2013,
author = {Nakano, Keisuke},
doi = {10.1017/S0956796812000391},
file = {:Users/liang-tingchen/Dropbox/References/Nakano - 2013 - Metamorphism in jigsaw.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
number = {2},
pages = {161--173},
title = {{Metamorphism in jigsaw}},
volume = {23},
year = {2013}
}
@misc{McBride2006,
author = {McBride, Conor},
title = {{Idiom brackets}},
url = {https://personal.cis.strath.ac.uk/conor.mcbride/pub/she/idiom.html},
urldate = {2019-06-26},
year = {2009}
}
@article{Mclarty1990,
abstract = {The view that toposes originated as generalized set theory is a figment of set theoretically educated common sense. This false history obstructs understanding of category theory and especially of categorical foundations for mathematics. Problems in geometry, topology, and related algebra led to categories and toposes. Elementary toposes arose when Lawvere's interest in the foundations of physics and Tierney's in the foundations of topology led both to study Grothendieck's foundations for algebraic geometry. I end with remarks on a categorical view of the history of set theory, including a false history plausible from that point of view that would make it helpful to introduce toposes as a generalization from set theory.},
author = {Mclarty, Colin},
doi = {10.1093/bjps/41.3.351},
file = {:Users/liang-tingchen/Dropbox/References/Mclarty - 1990 - The uses and abuses of the history of topos theory.pdf:pdf},
isbn = {0007-0882},
issn = {00070882},
journal = {British Journal for the Philosophy of Science},
number = {3},
pages = {351--375},
title = {{The uses and abuses of the history of topos theory}},
volume = {41},
year = {1990}
}
@inproceedings{Pretnar2015,
author = {Pretnar, Matija},
booktitle = {MFPS XXXI},
file = {:Users/liang-tingchen/Dropbox/References/Pretnar - 2015 - An Introduction to Algebraic Effects and Handlers Invited tutorial paper.pdf:pdf},
keywords = {16,18,a set of operations,algebraic effects,algebraic effects are an,approach to computational effects,based on a premise,effect system,handlers,impure behaviour arises from,logic,or raise for exceptions,output,print for interactive input,read,semantics,set for mutable store,such as get,that,this nat-,tutorial},
title = {{An Introduction to Algebraic Effects and Handlers Invited tutorial paper}},
year = {2015}
}
@inproceedings{Downen2016,
abstract = {The $\lambda$-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would be a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented variant of sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.},
address = {New York, New York, USA},
author = {Downen, Paul and Maurer, Luke and Ariola, Zena M. and {Peyton Jones}, Simon},
booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming - ICFP 2016},
doi = {10.1145/2951913.2951931},
file = {:Users/liang-tingchen/Dropbox/References/Downen et al. - 2016 - Sequent calculus as a compiler intermediate language.pdf:pdf},
isbn = {9781450342193},
issn = {03621340},
keywords = {3,4,a type system,and standard meta-,compiler optimizations,continuations,haskell,intermediate representations,natural deduction,quent calculus,se-,section 2,theoretical properties,translations to,we also give direct-style},
month = {sep},
number = {9},
pages = {74--88},
publisher = {ACM Press},
title = {{Sequent calculus as a compiler intermediate language}},
url = {http://dl.acm.org/citation.cfm?doid=3022670.2951931 http://dl.acm.org/citation.cfm?doid=2951913.2951931},
volume = {51},
year = {2016}
}
@incollection{Kupke2005,
abstract = {This paper studies finitary modal logics as specification languages for Set-coalgebras (coalgebras on the category of sets) using Stone duality. It is well-known that Set-coalgebras are not semantically adequate for finitary modal logics in the sense that bisimilarity does not in general coincide with logical equivalence. Stone-coalgebras (coalgebras over the category of Stone spaces), on the other hand, do provide an adequate semantics for finitary modal logics. This leads us to study the relationship of finitary modal logics and Set-coalgebras by uncovering the relationship between Set-coalgebras and Stone-coalgebras. This builds on a long tradition in modal logic, where one studies canonical extensions of modal algebras and ultrafilter extensions of Kripke frames to account for finitary logics. Our main contributions are the generalisations of two classical theorems in modal logic to coalgebras, namely the J{\'{o}}nsson-Tarski theorem giving a set-theoretic representation for each modal algebra and the bisimulation-somewhere-else theorem stating that two states of a coalgebra have the same (finitary modal) theory iff they are bisimilar (or behaviourally equivalent) in the ultrafilter extension of the coalgebra.},
author = {Kupke, Clemens and Kurz, Alexander and Pattinson, Dirk},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/11548133_17},
editor = {Fiadeiro, Jos{\'{e}} and Harman, Neil and Roggenbach, Markus and Rutten, Jan},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Kurz, Pattinson - 2005 - Ultrafilter extensions for coalgebras.pdf:pdf},
isbn = {978-3-540-28620-2},
pages = {263--277},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Ultrafilter extensions for coalgebras}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/11548133{\_}17},
volume = {3629},
year = {2005}
}
@inproceedings{Jay2011,
abstract = {Self-interpreters can be roughly divided into two sorts: self-recognisers that recover the input program from a canonical representation, and self-enactors that execute the input program. Major progress for statically-typed languages was achieved in 2009 by Rendel, Ostermann, and Hofer who presented the first typed selfrecogniser that allows representations of different terms to have different types. A key feature of their type system is a type:type rule that renders the kind system of their language inconsistent. In this paper we present the first statically-typed language that not only allows representations of different terms to have different types, and supports a self-recogniser, but also supports a selfenactor. Our language is a factorisation calculus in the style of Jay and Given-Wilson, a combinatory calculus with a factorisation operator that is powerful enough to support the pattern-matching functions necessary for a self-interpreter. This allows us to avoid a type:type rule. Indeed, the types of System F are sufficient. We have implemented our approach and our experiments support the theory. Copyright {\textcopyright} 2011 ACM.},
address = {New York, New York, USA},
author = {Jay, Barry and Palsberg, Jens},
booktitle = {Proceeding of the 16th ACM SIGPLAN international conference on Functional programming - ICFP '11},
doi = {10.1145/2034773.2034808},
file = {:Users/liang-tingchen/Dropbox/References/Jay, Palsberg - 2011 - Typed self-interpretation by pattern matching.pdf:pdf},
isbn = {9781450308656},
issn = {0362-1340},
keywords = {Pattern matching,Self-interpretation},
month = {sep},
number = {9},
pages = {247},
publisher = {ACM Press},
title = {{Typed self-interpretation by pattern matching}},
url = {https://dl.acm.org/doi/10.1145/2034574.2034808 http://dl.acm.org/citation.cfm?doid=2034773.2034808},
volume = {46},
year = {2011}
}
@incollection{Huang2016,
author = {Huang, Daniel and Morrisett, Greg},
booktitle = {Programming Languages and Systems. ESOP 2016},
doi = {10.1007/978-3-662-49498-1_14},
editor = {Thiemann, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Huang, Morrisett - 2016 - An Application of Computable Distributions to the Semantics of Probabilistic Programming Languages.pdf:pdf},
isbn = {978-3-662-49497-4},
keywords = {probabilistic programs},
pages = {337--363},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{An Application of Computable Distributions to the Semantics of Probabilistic Programming Languages}},
url = {http://link.springer.com/10.1007/978-3-662-49498-1{\_}14},
volume = {9632},
year = {2016}
}
@article{Greenberg2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1907.05308v1},
author = {Greenberg, Michael and Blatt, Austin J.},
doi = {10.1145/3371111},
eprint = {arXiv:1907.05308v1},
file = {:Users/liang-tingchen/Dropbox/References/Greenberg, Blatt - 2019 - Executable formal semantics for the POSIX shell.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {POSIX,command line interfaces,formalization,small-step semantics},
month = {dec},
number = {POPL},
pages = {1--30},
title = {{Executable formal semantics for the POSIX shell}},
url = {http://dl.acm.org/citation.cfm?doid=3377388.3371111},
volume = {4},
year = {2019}
}
@article{Wadler,
author = {Wadler, Philip},
doi = {10.1145/2699407},
file = {:Users/liang-tingchen/Dropbox/References/Wadler - 2015 - Propositions as types.pdf:pdf},
issn = {0001-0782},
journal = {Communications of the ACM},
month = {nov},
number = {12},
pages = {75--84},
title = {{Propositions as types}},
url = {https://dl.acm.org/doi/10.1145/2699407},
volume = {58},
year = {2015}
}
@article{Doberkat2012,
author = {Doberkat, Ernst-Erich},
doi = {10.2178/jsl/1333566646},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat - 2012 - A stochastic interpretation of propositional dynamic logic expressivity.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
language = {EN},
month = {jun},
number = {2},
pages = {687--716},
title = {{A stochastic interpretation of propositional dynamic logic: expressivity}},
url = {http://projecteuclid.org/euclid.jsl/1333566646},
volume = {77},
year = {2012}
}
@article{Tsuiki2002,
abstract = {We propose an embedding G of the unit open interval to the set {\{}0, 1{\}}⊥,$\omega$, 1 of infinite sequences of {\{}0, 1{\}} with at most one undefined element. This embedding is based on Gray code and it is a topological embedding with a natural topology on {\{}0, 1{\}}⊥,$\omega$, 1. We also define a machine called an indeterministic multihead Type 2 machine which input/output sequences in {\{}0, 1{\}}⊥$\omega$, 1, and show that the computability notion induced on real functions through the embedding G is equivalent to the one induced by the signed digit representation and Type 2 machines. We also show that basic algorithms can be expressed naturally with respect to this embedding. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
author = {Tsuiki, Hideki},
doi = {10.1016/S0304-3975(01)00104-9},
file = {:Users/liang-tingchen/Dropbox/References/Tsuiki - 2002 - Real number computation through Gray code embedding.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Gray code,IM2-machines,Indeterminism,Multihead,Real number computation},
month = {jul},
number = {2},
pages = {467--485},
title = {{Real number computation through Gray code embedding}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397501001049},
volume = {284},
year = {2002}
}
@article{Gibbons2011,
author = {Gibbons, Jeremy and Hinze, Ralf},
doi = {10.1145/2034574.2034777},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons, Hinze - 2011 - Just do it Simple monadic equational reasoning.pdf:pdf},
isbn = {978-1-4503-0865-6},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {algebraic specification,equational reasoning,lawvere theories,monads},
month = {sep},
number = {9},
pages = {2},
title = {{Just do it: Simple monadic equational reasoning}},
url = {http://dl.acm.org/citation.cfm?doid=2034574.2034777},
volume = {46},
year = {2011}
}
@book{Milner1989a,
author = {Milner, Robin},
isbn = {0-13-115007-3},
publisher = {Prentice Hall International Ltd.},
title = {{Communication and Concurrency}},
type = {Book},
year = {1989}
}
@incollection{Liang2007,
abstract = {A focused proof system provides a normal form to cut-free proofs that structures the application of invertible and non-invertible inference rules. The focused proof system of Andreoli for linear logic has been applied to both the proof search and the proof normalization approaches to computation. Various proof systems in literature exhibit characteristics of focusing to one degree or another. We present a new, focused proof system for intuitionistic logic, called LJF, and show how other proof systems can be mapped into the new system by inserting logical connectives that prematurely stop focusing. We also use LJF to design a focused proof system for classical logic. Our approach to the design and analysis of these systems is based on the completeness of focusing in linear logic and on the notion of polarity that appears in Girard's LC and LU proof systems. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
archivePrefix = {arXiv},
arxivId = {0708.2252},
author = {Liang, Chuck and Miller, Dale},
booktitle = {Computer Science Logic. CSL 2007},
doi = {10.1007/978-3-540-74915-8_34},
editor = {Duparc, Jacques and Henzinger, Thomas A.},
eprint = {0708.2252},
file = {:Users/liang-tingchen/Dropbox/References/Liang, Miller - 2007 - Focusing and polarization in intuitionistic logic.pdf:pdf},
isbn = {9783540749141},
issn = {16113349},
pages = {451--465},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Focusing and polarization in intuitionistic logic}},
volume = {4646},
year = {2007}
}
@article{Ghani2001,
abstract = {Whilst the relationship between initial algebras and monads is well-understood, the relationship between final coalgebras and comonads is less well explored. This paper shows that the problem is more subtle and that final coalgebras can just as easily form monads as comonads and dually, that initial algebras form both monads and comonads. In developing these theories we strive to provide them with an associated notion of syntax. In the case of initial algebras and monads this corresponds to the standard notion of algebraic theories consisting of signatures and equations: models of such algebraic theories are precisely the algebras of the representing monad. We attempt to emulate this result for the coalgebraic case by defining a notion cosignature and coequation and then proving the models of this syntax are precisely the coalgebras of the representing comonad. {\textcopyright}2001 Published by Elsevier Science B. V.},
author = {Ghani, Neil and L{\"{u}}th, Christoph and {De Marchi}, Federico and Power, A. John},
doi = {10.1016/S1571-0661(04)80905-8},
file = {:Users/liang-tingchen/Dropbox/References/Ghani et al. - 2001 - Algebras, coalgebras, monads and comonads.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {1},
pages = {131--148},
title = {{Algebras, coalgebras, monads and comonads}},
volume = {44},
year = {2001}
}
@article{Jeannin2017,
abstract = {Functional languages offer a high level of abstraction, which results in programs that are elegant and easy to understand. Central to the development of functional programming are in-ductive and coinductive types and associated programming constructs, such as pattern-matching. Whereas inductive types have a long tradition and are well supported in most languages, coinduc-tive types are subject of more recent research and are less mainstream. We present CoCaml, a functional programming language extending OCaml, which allows us to define recursive functions on regular coinductive datatypes. These functions are defined like usual recursive functions, but parameterized by an equation solver. We present a full implementation of all the constructs and solvers and show how these can be used in a variety of examples, including operations on infinite lists, infinitary $\lambda$-terms, and p-adic numbers.},
author = {Jeannin, Jean-Baptiste and Kozen, Dexter and Silva, Alexandra},
doi = {10.3233/FI-2017-1473},
editor = {Baelde, David and Carayol, Arnaud and Matthes, Ralph and Walukiewicz, Igor},
file = {:Users/liang-tingchen/Dropbox/References/Jeannin, Kozen, Silva - 2017 - CoCaml Functional Programming with Regular Coinductive Types.pdf:pdf},
issn = {01692968},
journal = {Fundamenta Informaticae},
keywords = {Coalgebra,Coinductive types,Functional programming,Recursive types},
month = {mar},
number = {3-4},
pages = {347--377},
title = {{CoCaml: Functional Programming with Regular Coinductive Types}},
url = {http://www.medra.org/servlet/aliasResolver?alias=iospress{\&}doi=10.3233/FI-2017-1473},
volume = {150},
year = {2017}
}
@article{Andrikonis2012,
abstract = {In [J. Andrikonis, Loop-free calculus for modal logic S4. I, Lith. Math. J., 52(1):1-12, 2012], loop-free calculus for modal logic S4 is presented. The calculus uses several types of indexes to avoid loops and obtain termination of derivation search. Although the mentioned article proves that derivation search in the calculus is finite, the proof of soundness and completeness is omitted and, therefore, is presented in this paper. Moreover, this paper presents loop-free calculus for modal logics K4, which is obtained by modifying the calculus for S4. Finally, some remarks for programming the given calculi are offered. {\textcopyright} 2012 Springer Science+Business Media, Inc.},
author = {Andrikonis, Julius},
doi = {10.1007/s10986-012-9160-x},
file = {:Users/liang-tingchen/Dropbox/References/Andrikonis - 2012 - Loop-free calculus for modal logic S4. II.pdf:pdf},
issn = {0363-1672},
journal = {Lithuanian Mathematical Journal},
keywords = {loop-free calculus,modal logic,sequent calculus},
month = {apr},
number = {2},
pages = {123--133},
title = {{Loop-free calculus for modal logic S4. II}},
url = {http://link.springer.com/10.1007/s10986-012-9160-x},
volume = {52},
year = {2012}
}
@incollection{Pattinson2015,
author = {Pattinson, Dirk and Schr{\"{o}}der, Lutz},
booktitle = {Proceedings of the 31st Conference on the Mathematical Foundations of Programming Semantics},
doi = {10.1016/j.entcs.2015.12.019},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson, Schr{\"{o}}der - 2015 - Sound and Complete Equational Reasoning over Comodels.pdf:pdf},
issn = {15710661},
keywords = {bisimulation,comodels,completeness,equational logic},
month = {dec},
pages = {315--331},
publisher = {Elsevier B.V.},
series = {Electronic Notes in Theoretical Computer Science},
title = {{Sound and Complete Equational Reasoning over Comodels}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066115000869},
year = {2015}
}
@article{Sullivan2015,
abstract = {We aim to highlight certain points and considerations for graduate students and young researchers, which should be avoided in submissions to good research journals. Observing these remarks could substantially decrease the probability of rejections of papers.},
archivePrefix = {arXiv},
arxivId = {1504.03789},
author = {Sullivan, Gail M.},
doi = {10.4300/JGME-D-14-00686.1},
eprint = {1504.03789},
file = {:Users/liang-tingchen/Dropbox/References/Sullivan - 2015 - What to Do When Your Paper Is Rejected.pdf:pdf},
issn = {1949-8349},
journal = {Journal of Graduate Medical Education},
month = {mar},
number = {1},
pages = {1--3},
pmid = {26217410},
title = {{What to Do When Your Paper Is Rejected}},
url = {http://www.jgme.org/doi/10.4300/JGME-D-14-00686.1},
volume = {7},
year = {2015}
}
@article{Makkai1996,
abstract = {The notion of anafunctor is introduced. An anafunctor is, roughly, a "functor defined up to isomorphism". Anafunctors have a general theory paralleling that of ordinary functors; they have natural transformations, they form categories, they can be composed, etc. Anafunctors can be saturated, to ensure that any object isomorphic to a possible value of the anafunctor is also a possible value at the same argument object. The existence of anafunctors in situations when ordinarily one would use choice is ensured without choice; e.g., for a category which has binary products, but not specified binary products, the anaversion of the product functor is canonically definable, unlike the ordinary product functor that needs the axiom of choice. When the composition functors in a bicategory are changed into anafunctors, one obtains anabicategories. In the standard definitions of bicategories such as the monoidal category of modules over a ring, or the bicategory of spans in a category with pullbacks, and many others, one uses choice; the anaversions of these bicategories have canonical definitions. The overall effect is an elimination of the axiom of choice, and of non-canonical choices, in large parts of general category theory. To ensure the Cartesian closed character of the bicategory of small categories, with anafunctors as 1-cells, one uses a weak version of the axiom of choice, which is related to A. Blass' axiom of Small Violations of Choice (1979).},
author = {Makkai, Michael},
doi = {10.1016/0022-4049(95)00029-1},
file = {:Users/liang-tingchen/Dropbox/References/Makkai - 1996 - Avoiding the axiom of choice in general category theory.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
number = {95},
pages = {109--173},
title = {{Avoiding the axiom of choice in general category theory}},
volume = {108},
year = {1996}
}
@techreport{Motwani2007,
abstract = {A quasi-identifier refers to a subset of attributes that can uniquely identify most tuples in a table. Incautious pub-lication of quasi-identifiers will lead to privacy leakage. In this paper we consider the problems of finding and masking quasi-identifiers. Both problems are provably hard with se-vere time and space requirements. We focus on designing efficient approximation algorithms for large data sets. We first propose two natural measures for quantifying quasi-identifiers: distinct ratio and separation ratio. We develop efficient algorithms that find small quasi-identifiers with provable size and separation/distinct ratio guarantees, with space and time requirements sublinear in the number of tuples. We also design practical algorithms for finding all minimal quasi-identifiers. Finally we propose efficient algo-rithms for masking quasi-identifiers, where we use a random sampling technique to greatly reduce the space and time requirements, without much sacrifice in the quality of the results. Our algorithms for masking and finding minimum quasi-identifiers naturally apply to stream databases. Ex-tensive experimental results on real world data sets confirm efficiency and accuracy of our algorithms.},
author = {Motwani, Rajeev and Xu, Ying},
file = {:Users/liang-tingchen/Dropbox/References/Motwani, Xu - 2007 - Efficient Algorithms for Masking and Finding Quasi-Identifiers.pdf:pdf},
isbn = {9781595936493},
title = {{Efficient Algorithms for Masking and Finding Quasi-Identifiers}},
year = {2007}
}
@article{Nishiwaki2018,
abstract = {This paper investigates modal type theories by using a new categorical semantics called change-of-base semantics. Change-of-base semantics is novel in that it is based on (possibly infinitely) iterated enrichment and interpretation of modality as hom objects. In our semantics, the relationship between meta and object levels in multi-staged computation exactly corresponds to the relationship between enriching and enriched categories. As a result, we obtain a categorical explanation of situations where meta and object logics may be completely different. Our categorical models include conventional models of modal type theory (e.g., cartesian closed categories with a monoidal endofunctor) as special cases and hence can be seen as a natural refinement of former results. On the type theoretical side, it is shown that Fitch-style modal type theory can be directly interpreted in iterated enrichment of categories. Interestingly, this interpretation suggests the fact that Fitch-style modal type theory is the right adjoint of dual-context calculus. In addition, we present how linear temporal, S4, and linear exponential modalities are described in terms of change-of-base semantics. Finally, we show that the change-of-base semantics can be naturally extended to multi-staged effectful computation and generalized contextual modality a la Nanevski et al. We emphasize that this paper answers the question raised in the survey paper by de Paiva and Ritter in 2011, what a categorical model for Fitch-style type theory is like.},
archivePrefix = {arXiv},
arxivId = {1804.02809},
author = {Nishiwaki, Yuichi and Kakutani, Yoshihiko and Murase, Yuito},
doi = {10.1016/j.entcs.2018.11.015},
eprint = {1804.02809},
file = {:Users/liang-tingchen/Dropbox/References/Nishiwaki, Kakutani, Murase - 2018 - Modality via Iterated Enrichment.pdf:pdf},
issn = {15710661},
journal = {Proceedings of the Thirty-Fourth Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXIV)},
keywords = {Curry-Howard Isomorphism,Enriched Category Theory,Lambda Calculus,Modal Logic},
month = {dec},
pages = {297--320},
publisher = {Elsevier B.V.},
title = {{Modality via Iterated Enrichment}},
url = {https://doi.org/10.1016/j.entcs.2018.11.015 https://linkinghub.elsevier.com/retrieve/pii/S1571066118300963},
volume = {341},
year = {2018}
}
@article{Courcelle1989,
abstract = {Every set of finite graphs definable in monadic second-order logic is recognizable in the algebraic sense of Mezei and Wright (no "graph automaton" is provided). We apply this result to the comparison of several definitions of sets of finite graphs, in particular by context-free graph grammars, and by forbidden configurations. It follows that the monadic second order theory of a context-free set of graphs is decidable, and that every graph property expressible in monadic second-order logic is decidable in polynomial time for graphs of a given maximal tree-width.},
author = {Courcelle, Bruno},
doi = {10.1016/0890-5401(90)90043-H},
file = {:Users/liang-tingchen/Dropbox/References/Courcelle - 1990 - The monadic second-order logic of graphs. I. Recognizable sets of finite graphs.pdf:pdf},
isbn = {9783540507284},
issn = {08905401},
journal = {Information and Computation},
month = {mar},
number = {1},
pages = {12--75},
title = {{The monadic second-order logic of graphs. I. Recognizable sets of finite graphs}},
url = {https://linkinghub.elsevier.com/retrieve/pii/089054019090043H},
volume = {85},
year = {1990}
}
@incollection{Shenoy1990a,
author = {Shenoy, Prakash P. and Shafer, Glenn},
booktitle = {Uncertainty in Artificial Intelligence 4},
doi = {10.1016/B978-0-444-88650-7.50019-6},
editor = {Shachter, Ross D. and Levitt, Tod S. and Kanal, Laveen N. and Lemmer, John F.},
file = {:Users/liang-tingchen/Dropbox/References/Shenoy, Shafer - 1990 - Axioms for Probability and Belief-Function Propagation.pdf:pdf},
issn = {0923-0459},
pages = {169--198},
publisher = {North-Holland},
series = {Machine Intelligence and Pattern Recognition},
title = {{Axioms for Probability and Belief-Function Propagation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780444886507500196},
volume = {9},
year = {1990}
}
@article{Wisbauer2007,
author = {Wisbauer, Robert},
doi = {10.1007/s10485-007-9076-5},
file = {:Users/liang-tingchen/Dropbox/References/Wisbauer - 2007 - Algebras Versus Coalgebras.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {16w30,18a40,18c15,18c20,2000,algebras,categories,coalgebras,hopf algebras,mathematics subject classifications},
month = {may},
number = {1-2},
pages = {255--295},
title = {{Algebras Versus Coalgebras}},
url = {http://link.springer.com/10.1007/s10485-007-9076-5},
volume = {16},
year = {2007}
}
@article{Kock1970a,
author = {Kock, Anders},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 1970 - On double dualization monads.pdf:pdf},
issn = {0025-5521},
journal = {Mathematica Scandinavica},
pages = {151--165},
title = {{On double dualization monads}},
volume = {27},
year = {1970}
}
@article{Abramsky1993,
abstract = {We study Girard's linear logic from the point of view of giving a concrete computational interpretation of the logic, based on the Curry-Howard isomorphism. In the case of Intuitionistic linear logic, this leads to a refinement of the lambda calculus, giving finer control over order of evaluation and storage allocation, while maintaining the logical content of programs as proofs, and computation as cut-elimination. In the classical case, it leads to a concurrent process paradigm with an operational semantics in the style of Berry and Boudol's chemical abstract machine. This opens up a promising new approach to the parallel implementation of functional programming languages; and offers the prospect of typed concurrent programming in which correctness is guaranteed by the typing. {\textcopyright} 1993.},
author = {Abramsky, Samson},
doi = {10.1016/0304-3975(93)90181-R},
file = {:Users/liang-tingchen/Dropbox/References/Abramsky - 1993 - Computational interpretations of linear logic.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {apr},
number = {1-2},
pages = {3--57},
title = {{Computational interpretations of linear logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/030439759390181R},
volume = {111},
year = {1993}
}
@article{Low2013,
archivePrefix = {arXiv},
arxivId = {1304.5227},
author = {Low, Zhen Lin},
eprint = {1304.5227},
file = {:Users/liang-tingchen/Dropbox/References/Low - 2013 - Universes for category theory.pdf:pdf},
journal = {ArXiv e-prints},
pages = {1--27},
title = {{Universes for category theory}},
year = {2013}
}
@article{Jung2001,
abstract = {Stably compact spaces are a natural generalization of compact Hausdorff spaces in the T0 setting. They have been studied intensively by a number of researchers and from a variety of standpoints. In this paper we let the morphisms between stably compact spaces be certain ``closed relations'' and study the resulting categorical properties. Apart from extending ordinary continuous maps, these morphisms have a number of pleasing properties, the most prominent, perhaps, being that they correspond to preframe homomorphisms on the localic side. We exploit this Stone-type duality to establish that the category of stably compact spaces and closed relations has bilimits.},
author = {Jung, Achim and Kegelmann, Mathias and Moshier, M. Andrew},
doi = {10.1016/S1571-0661(04)80964-2},
file = {:Users/liang-tingchen/Dropbox/References/Jung, Kegelmann, Moshier - 2001 - Stably compact spaces and closed relations.pdf:pdf},
issn = {1571-0661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {0},
pages = {209--231},
title = {{Stably compact spaces and closed relations}},
type = {Journal article},
url = {http://www.sciencedirect.com/science/article/pii/S1571066104809642},
volume = {45},
year = {2001}
}
@article{Joyal1993,
author = {Joyal, A. and Street, R.},
doi = {10.1006/aima.1993.1055},
file = {:Users/liang-tingchen/Dropbox/References/Joyal, Street - 1993 - Braided Tensor Categories.pdf:pdf},
issn = {00018708},
journal = {Advances in Mathematics},
month = {nov},
number = {1},
pages = {20--78},
title = {{Braided Tensor Categories}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0001870883710558},
volume = {102},
year = {1993}
}
@incollection{Chen2016,
abstract = {The Sch{\"{u}}tzenberger product of monoids is a key tool for the algebraic treatment of language concatenation. In this paper we gener-alize the Sch{\"{u}}tzenberger product to the level of monoids in an algebraic category D, leading to a uniform view of the corresponding construc-tions for monoids (Sch{\"{u}}tzenberger), ordered monoids (Pin), idempotent semirings (Kl{\'{i}}ma and Pol{\'{a}}k), and algebras over a field (Reutenauer). In addition, assuming that D is part of a Stone-type duality, we derive a characterization of the languages recognized by Sch{\"{u}}tzenberger products.},
author = {Chen, Liang-Ting and Urbat, Henning},
booktitle = {Proceedings of the 20th International Conference on Developments in Language Theory},
doi = {10.1007/978-3-662-53132-7},
editor = {Brlek, Sre{\v{c}}ko and Reutenauer, Christophe},
file = {:Users/liang-tingchen/Dropbox/References/Chen, Urbat - 2016 - Sch{\"{u}}tzenberger products in a category.pdf:pdf},
isbn = {978-3-662-53131-0},
pages = {89--101},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Sch{\"{u}}tzenberger products in a category}},
url = {http://link.springer.com/10.1007/978-3-662-53132-7},
volume = {9840},
year = {2016}
}
@article{Bezhanishvili2001,
author = {Bezhanishvili, Guram},
doi = {10.1007/PL00000358},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili - 2001 - Locally finite varieties.pdf:pdf},
issn = {0002-5240},
journal = {Algebra Universalis},
month = {nov},
number = {4},
pages = {531--548},
title = {{Locally finite varieties}},
url = {http://link.springer.com/10.1007/PL00000358},
volume = {46},
year = {2001}
}
@article{Joyal2014,
author = {Joyal, Andr{\'{e}} and Street, Ross},
file = {:Users/liang-tingchen/Dropbox/References/Joyal, Street - 2014 - The geometry of tensor calculus II.pdf:pdf},
keywords = {autonomous tensor category,balanced,braiding,monoidal category,morse function,pivotal,progressive diagram,ribbon,rigid tensor category,spherical category,tensor cateory,tortile,trace},
title = {{The geometry of tensor calculus II}},
year = {2014}
}
@article{Liang2013,
abstract = {We combine intuitionistic logic and classical logic into a new, first-order logic called polarized intuitionistic logic. This logic is based on a distinction between two dual polarities which we call red and green to distinguish them from other forms of polarization. The meaning of these polarities is defined model-theoretically by a Kripke-style semantics for the logic. Two proof systems are also formulated. The first system extends Gentzen's intuitionistic sequent calculus LJ. In addition, this system also bears essential similarities to Girard's LC proof system for classical logic. The second proof system is based on a semantic tableau and extends Dragalin's multiple-conclusion version of intuitionistic sequent calculus. We show that soundness and completeness hold for these notions of semantics and proofs, from which it follows that cut is admissible in the proof systems and that the propositional fragment of the logic is decidable. {\textcopyright} 2012 Elsevier B.V.},
author = {Liang, Chuck and Miller, Dale},
doi = {10.1016/j.apal.2012.09.005},
file = {:Users/liang-tingchen/Dropbox/References/Liang, Miller - 2013 - Kripke semantics and proof systems for combining intuitionistic logic and classical logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Classical and intuitionistic logics,Hybrid Kripke models,Polarized logic,Sequent calculus,Soundness and completeness proofs},
month = {feb},
number = {2},
pages = {86--111},
publisher = {Elsevier B.V.},
title = {{Kripke semantics and proof systems for combining intuitionistic logic and classical logic}},
url = {http://dx.doi.org/10.1016/j.apal.2012.09.005 https://linkinghub.elsevier.com/retrieve/pii/S0168007212001534},
volume = {164},
year = {2013}
}
@incollection{Almeida2005,
address = {Dordrecht},
author = {Almeida, Jorge},
booktitle = {Structural Theory of Automata, Semigroups, and Universal Algebra},
doi = {10.1007/1-4020-3817-8},
editor = {Kudryavtsev, Valery B. and Rosenberg, Ivo G. and Goldstein, Martin},
file = {:Users/liang-tingchen/Dropbox/References/Almeida - 2005 - Profinite semigroups and applications.pdf:pdf},
isbn = {1-4020-3815-1},
pages = {1--45},
publisher = {Springer-Verlag},
series = {NATO Science Series II: Mathematics, Physics and Chemistry},
title = {{Profinite semigroups and applications}},
url = {http://www.springerlink.com/index/10.1007/1-4020-3817-8},
volume = {207},
year = {2005}
}
@article{Mitchell1991,
abstract = {We present a tentative theory of programming language expressiveness based on reductions (language translations) that preserve observational equivalence. These are called “abstraction-preserving” because of a connection with a definition of “abstraction” or “information-hiding” mechanism. If there is an abstraction-preserving reduction from one language to another, then essentially every function on natural numbers that is definable in the first is also definable in the second. Moreover, regardless of the set of first-order functions definable in either language, no programming language with an abstraction mechanism can be reduced to a language without. Since Lisp with user-defined special forms does not have an abstraction mechanism, it is therefore not “universal” in this theory, in spite of the ability to define every partial recursive function on the natural numbers. Several examples and counter-examples to abstractionpreserving reductions are given. We do not know whether there is a natural universal language with respect to abstraction-preserving reduction.},
author = {Mitchell, John C.},
doi = {10.1016/0167-6423(93)90004-9},
file = {:Users/liang-tingchen/Dropbox/References/Mitchell - 1993 - On abstraction and the expressive power of programming languages.pdf:pdf},
isbn = {9783540544159},
issn = {01676423},
journal = {Science of Computer Programming},
month = {oct},
number = {2},
pages = {141--163},
title = {{On abstraction and the expressive power of programming languages}},
url = {http://link.springer.com/10.1007/3-540-54415-1{\_}51 https://linkinghub.elsevier.com/retrieve/pii/0167642393900049},
volume = {21},
year = {1993}
}
@article{Nakamoto2008,
abstract = {Abstract. A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.},
archivePrefix = {arXiv},
arxivId = {43543534534v343453},
author = {Nakamoto, Satoshi},
doi = {10.1007/s10838-008-9062-0},
eprint = {43543534534v343453},
file = {:Users/liang-tingchen/Dropbox/References/Nakamoto - 2008 - Bitcoin A Peer-to-Peer Electronic Cash System.pdf:pdf},
isbn = {978-972-757-716-3},
issn = {09254560},
journal = {www.Bitcoin.Org},
pages = {9},
pmid = {14533183},
title = {{Bitcoin: A Peer-to-Peer Electronic Cash System}},
url = {https://bitcoin.org/bitcoin.pdf},
year = {2008}
}
@article{Power2009,
author = {Power, A. John},
doi = {10.1007/s10485-009-9202-7},
file = {:Users/liang-tingchen/Dropbox/References/Power - 2009 - Unicity of Enrichment over Cat or Gpd.pdf:pdf},
issn = {0927-2852},
journal = {Applied Categorical Structures},
keywords = {18c10,18c15,18c20,18c30,2000,cotensors,enrichment,mathematics subject classifications,monads,tensors},
month = {may},
number = {1},
pages = {293--299},
title = {{Unicity of Enrichment over Cat or Gpd}},
url = {http://link.springer.com/10.1007/s10485-009-9202-7},
volume = {19},
year = {2009}
}
@article{ONeill2009,
abstract = {A much beloved and widely used example showing the elegance and simplicity of lazy functional programming represents itself as The Sieve of Eratosthenes. This paper shows that this example is not the sieve, and presents an implementation that actually is.},
author = {O'NEILL, MELISSA E.},
doi = {10.1017/S0956796808007004},
file = {:Users/liang-tingchen/Dropbox/References/O'NEILL - 2009 - The Genuine Sieve of Eratosthenes.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
number = {01},
pages = {95},
title = {{The Genuine Sieve of Eratosthenes}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796808007004},
volume = {19},
year = {2009}
}
@article{Barendregt1991a,
abstract = {Programming languages which are capable of interpreting themselves have been fascinating computer scientists. Indeed, if this is possible then a ‘strange loop' (in the sense of Hofstadter, 1979) is involved. Nevertheless, the phenomenon is a direct consequence of the existence of universal languages. Indeed, if all computable functions can be captured by a language, then so can the particular job of interpreting the code of a program of that language. Self-interpretation will be shown here to be possible in lambda calculus.},
author = {Barendregt, Henk},
doi = {10.1017/S0956796800020062},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt - 1991 - Theoretical Pearls Self-interpretation in lambda calculus.pdf:pdf},
isbn = {0956796800020},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {apr},
number = {2},
pages = {229--233},
title = {{Theoretical Pearls: Self-interpretation in lambda calculus}},
url = {https://www.cambridge.org/core/product/identifier/S0956796800020062/type/journal{\_}article},
volume = {1},
year = {1991}
}
@article{Street1980,
author = {Street, Ross},
doi = {10.1090/S0002-9947-1980-0558176-3},
file = {:Users/liang-tingchen/Dropbox/References/Street - 1980 - Cosmoi of internal categories.pdf:pdf},
issn = {0002-9947},
journal = {Transactions of the American Mathematical Society},
keywords = {cartesian closed,category,fibred,gabriel theory,internal full subcategory,internally complete,locally presentable category,locally small,multiple,site,sketched structures},
month = {feb},
number = {2},
pages = {271--271},
title = {{Cosmoi of internal categories}},
url = {http://www.ams.org/jourcgi/jour-getitem?pii=S0002-9947-1980-0558176-3},
volume = {258},
year = {1980}
}
@book{hottbook,
address = {Institute for Advanced Study},
author = {{Univalent Foundations Program}, The},
file = {:Users/liang-tingchen/Dropbox/References/Univalent Foundations Program - 2013 - Homotopy Type Theory Univalent Foundations of Mathematics.pdf:pdf},
publisher = {http://homotopytypetheory.org/book},
title = {{Homotopy Type Theory: Univalent Foundations of Mathematics}},
year = {2013}
}
@article{Hennessy2005,
abstract = {The security ??-calculus is a typed version of the asynchronous ??-calculus in which the types, in addition to constraining the input/output behaviour of processes, have security levels associated with them. This enables us to introduce a range of typing disciplines which allow input or output behaviour, or both, to be bounded above or below by a given security level. We define typed versions of may and must equivalences for the security ??-calculus, where the tests are parameterised relative to a security level. We provide alternative characterisations of these equivalences in terms of actions in context; these describe the actions a process may perform in a given typing environment, assuming the observer is constrained by a related, but possibly different, environment. The paper also contains non-interference results with respect to may and must testing. These show that certain form of non-interference can be enforced using our typing systems. ?? 2004 Elsevier Inc. All rights reserved.},
annote = {NULL},
author = {Hennessy, Matthew},
doi = {10.1016/j.jlap.2004.01.003},
file = {:Users/liang-tingchen/Dropbox/References/Hennessy - 2005 - The security pi-calculus and non-interference.pdf:pdf},
issn = {15678326},
journal = {Journal of Logic and Algebraic Programming},
keywords = {Distributed systems,Non-interference,Pi-calculus,Security types,Testing equivalences},
number = {1},
pages = {3--34},
title = {{The security pi-calculus and non-interference}},
volume = {63},
year = {2005}
}
@inproceedings{Wieczorek2018,
address = {New York, New York, USA},
author = {Wieczorek, Pawe{\l} and Biernacki, Dariusz},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs - CPP 2018},
doi = {10.1145/3167091},
file = {:Users/liang-tingchen/Dropbox/References/Wieczorek, Biernacki - 2018 - A Coq formalization of normalization by evaluation for Martin-L{\"{o}}f type theory.pdf:pdf},
isbn = {9781450355865},
keywords = {Coq,Normalization by evaluation,Program certification,Type theory},
pages = {266--279},
publisher = {ACM Press},
title = {{A Coq formalization of normalization by evaluation for Martin-L{\"{o}}f type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3176245.3167091},
volume = {2018-Janua},
year = {2018}
}
@article{Bellin1985,
author = {Bellin, Gianluigi},
doi = {10.1111/j.1755-2567.1985.tb00089.x},
file = {:Users/liang-tingchen/Dropbox/References/Bellin - 2008 - A system of natural deduction for GL.pdf:pdf},
issn = {00405825},
journal = {Theoria},
month = {feb},
number = {2},
pages = {89--114},
title = {{A system of natural deduction for GL}},
url = {http://doi.wiley.com/10.1111/j.1755-2567.1985.tb00089.x},
volume = {51},
year = {2008}
}
@incollection{Bonsangue2008,
abstract = {We present a novel coalgebraic logic for deterministic Mealy machines that is sound, complete and expressive w.r.t. bisimulation. Every finite Mealy machine corresponds to a finite formula in the language. For the converse, we give a compositional synthesis algorithm which transforms every formula into a finite Mealy machine whose behaviour is exactly the set of causal functions satisfying the formula.},
author = {Bonsangue, Marcello M. and Rutten, Jan J.M.M. and Silva, Alexandra},
booktitle = {Foundations of Software Science and Computational Structures},
doi = {10.1007/978-3-540-78499-9_17},
editor = {Amadio, Roberto},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Rutten, Silva - 2008 - Coalgebraic logic and synthesis of Mealy machines.pdf:pdf},
pages = {231--245},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Coalgebraic logic and synthesis of Mealy machines}},
year = {2008}
}
@incollection{Riba2015a,
author = {Riba, Colin},
booktitle = {13th International Conference on Typed Lambda Calculi and Applications},
doi = {10.4230/LIPIcs.TLCA.2015.302},
editor = {Altenkirch, Thorsten},
file = {:Users/liang-tingchen/Dropbox/References/Riba - 2015 - Fibrations of Tree Automata.pdf:pdf},
isbn = {978-3-939897-87-3},
keywords = {2015,302,4230,Categorical logic,Game semantics,Tree automata,and phrases tree automata,categorical logic,digital object identifier 10,game semantics,lipics,tlca},
pages = {302--316},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{Fibrations of Tree Automata}},
year = {2015}
}
@book{Doberkat2009a,
address = {Berlin, Heidelberg},
author = {Doberkat, Ernst-Erich},
doi = {10.1007/978-3-642-02995-0},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat - 2009 - Stochastic Coalgebraic Logic.pdf:pdf},
isbn = {978-3-642-02994-3},
publisher = {Springer Berlin Heidelberg},
series = {Monographs in Theoretical Computer Science},
title = {{Stochastic Coalgebraic Logic}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-02995-0},
year = {2009}
}
@article{Stone1936a,
author = {Stone, Marshall H.},
doi = {10.2307/1989664},
file = {:Users/liang-tingchen/Dropbox/References/Stone - 1936 - The theory of representation for Boolean algebras.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
month = {jul},
number = {1},
pages = {37--111},
title = {{The theory of representation for Boolean algebras}},
type = {Journal article},
url = {http://www.jstor.org/stable/1989664},
volume = {40},
year = {1936}
}
@inproceedings{Vial2018,
address = {New York, New York, USA},
author = {Vial, Pierre},
booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science - LICS '18},
doi = {10.1145/3209108.3209133},
file = {:Users/liang-tingchen/Dropbox/References/Vial - 2018 - Every $\lambda$-Term is Meaningful for the Infinitary Relational Model.pdf:pdf},
isbn = {9781450355834},
keywords = {Curry-Howard,coinductive types,curry-howard,der,non-productive reduction,or-,order,relational model,sequence types},
pages = {899--908},
publisher = {ACM Press},
title = {{Every $\lambda$-Term is Meaningful for the Infinitary Relational Model}},
url = {http://dl.acm.org/citation.cfm?doid=3209108.3209133},
year = {2018}
}
@article{Robinson1988,
abstract = {This paper attempts to reconcile the various abstract notions of "category of partial maps" which appear in the literature. First a particular algebraic theory (p-categories) is introduced and a representation theorem proved. This gives the authors a coherent framework in which to place the various other definitions. Both algebraic theories and theories which make essential use of the poset-enriched structure of partial maps are discussed. Proofs of equivalence are given where possible and counterexamples where known. The paper concludes with brief sections on the representation of partial maps and on partial algebras. {\textcopyright} 1988.},
author = {Robinson, E. and Rosolini, G.},
doi = {10.1016/0890-5401(88)90034-X},
file = {:Users/liang-tingchen/Dropbox/References/Robinson, Rosolini - 1988 - Categories of partial maps.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {nov},
number = {2},
pages = {95--130},
title = {{Categories of partial maps}},
url = {https://linkinghub.elsevier.com/retrieve/pii/089054018890034X},
volume = {79},
year = {1988}
}
@article{Liang2009,
abstract = {A focused proof system provides a normal form to cut-free proofs in which the application of invertible and non-invertible inference rules is structured. Within linear logic, the focused proof system of Andreoli provides an elegant and comprehensive normal form for cut-free proofs. Within intuitionistic and classical logics, there are various different proof systems in the literature that exhibit focusing behavior. These focused proof systems have been applied to both the proof search and the proof normalization approaches to computation. We present a new, focused proof system for intuitionistic logic, called LJF, and show how other intuitionistic proof systems can be mapped into the new system by inserting logical connectives that prematurely stop focusing. We also use LJF to design a focused proof system LKF for classical logic. Our approach to the design and analysis of these systems is based on the completeness of focusing in linear logic and on the notion of polarity that appears in Girard's LC and LU proof systems. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Liang, Chuck and Miller, Dale},
doi = {10.1016/j.tcs.2009.07.041},
file = {:Users/liang-tingchen/Dropbox/References/Liang, Miller - 2009 - Focusing and polarization in linear, intuitionistic, and classical logics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Classical logic,Focused proof system,Intuitionistic logic,Sequent calculus},
month = {nov},
number = {46},
pages = {4747--4768},
publisher = {Elsevier B.V.},
title = {{Focusing and polarization in linear, intuitionistic, and classical logics}},
url = {http://dx.doi.org/10.1016/j.tcs.2009.07.041 https://linkinghub.elsevier.com/retrieve/pii/S0304397509005301},
volume = {410},
year = {2009}
}
@article{Bird1995,
author = {Bird, Richard S.},
doi = {10.1016/0167-6423(95)00033-X},
file = {:Users/liang-tingchen/Dropbox/References/Bird - 1996 - Functional algorithm design.pdf:pdf},
isbn = {3540601171},
issn = {01676423},
journal = {Science of Computer Programming},
month = {may},
number = {1-3},
pages = {15--31},
title = {{Functional algorithm design}},
url = {http://linkinghub.elsevier.com/retrieve/pii/016764239500033X},
volume = {26},
year = {1996}
}
@inproceedings{Benaissa1999,
address = {Trento, Italy},
author = {Benaissa, Zine El-abidine and Moggi, Eugenio and Taha, Walid and Sheard, Tim},
booktitle = {IMLA'99, Intuitionistic Modal Logics and Applications Workshop},
file = {:Users/liang-tingchen/Dropbox/References/Benaissa et al. - 1999 - Logical Modalities and Multi-Stage Programming.pdf:pdf},
keywords = {3,categorical,categorical models for multi-stage,combination of logics,culi,languages,modal and temporal,models,multi-level typed cal-,multi-stage programming,semantics,type systems},
title = {{Logical Modalities and Multi-Stage Programming}},
year = {1999}
}
@article{Tanaka2006,
author = {Tanaka, Miki and Power, A. John},
doi = {10.1007/s10990-006-8750-x},
file = {:Users/liang-tingchen/Dropbox/References/Tanaka, Power - 2006 - Pseudo-distributive laws and axiomatics for variable binding.pdf:pdf},
issn = {1388-3690},
journal = {Higher-Order and Symbolic Computation},
keywords = {binding signatures,context,initial algebra semantics,pseudo-distributive law,pseudo-monad,substitution monoidal structure},
month = {sep},
number = {2-3},
pages = {305--337},
title = {{Pseudo-distributive laws and axiomatics for variable binding}},
url = {http://link.springer.com/10.1007/s10990-006-8750-x},
volume = {19},
year = {2006}
}
@incollection{Mir2013,
author = {Mir, Darakhshan J},
booktitle = {Foundations and Practice of Security. FPS 2012},
doi = {10.1007/978-3-642-37119-6_25},
editor = {Tawbi, Joaquin Garcia-Alfaro and Cuppens, Fr{\'{e}}d{\'{e}}ric and Cuppens-Boulahia, Nora and MiriNadia, Ali},
file = {:Users/liang-tingchen/Dropbox/References/Mir - 2013 - Information-Theoretic Foundations of Differential Privacy.pdf:pdf},
pages = {374--381},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Information-Theoretic Foundations of Differential Privacy}},
url = {http://link.springer.com/10.1007/978-3-642-37119-6{\_}25},
volume = {7743},
year = {2013}
}
@article{JEANNIN2016,
abstract = {Theoretical models of recursion schemes have been well studied under the names well-founded coalgebras, recursive coalgebras, corecursive algebras and Elgot algebras. Much of this work focuses on conditions ensuring unique or canonical solutions, e.g. when the coalgebra is well founded.},
author = {Jeannin, Jean-Baptiste and Kozen, Dexter and Silva, Alexandra},
doi = {10.1017/S0960129515000481},
file = {:Users/liang-tingchen/Dropbox/References/Jeannin, Kozen, Silva - 2016 - Well-founded coalgebras, revisited.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
pages = {1--21},
title = {{Well-founded coalgebras, revisited}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129515000481},
year = {2016}
}
@incollection{Pfenning2002,
author = {Pfenning, Frank},
booktitle = {Proof and System-Reliability},
doi = {10.1007/978-94-010-0413-8_5},
editor = {Schwichtenberg, Helmut and Steinbr{\"{u}}ggen, Ralf},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning - 2002 - Logical Frameworks—A Brief Introduction.pdf:pdf},
keywords = {logical frameworks,type theory},
pages = {137--166},
publisher = {Springer Netherlands},
series = {NATO Science Series},
title = {{Logical Frameworks—A Brief Introduction}},
year = {2002}
}
@article{Rot2015,
abstract = {We present a systematic study of bisimulation-up-to techniques for coalgebras. This enhances the bisimulation proof method for a large class of state based systems, including labelled transition systems but also stream systems and weighted automata. Our approach allows for compositional reasoning about the soundness of enhancements. Applications include the soundness of bisimulation up to bisimilarity, up to equivalence and up to congruence. All in all, this gives a powerful and modular framework for simplified coinductive proofs of equivalence.},
author = {Rot, Jurriaan and Bonchi, Filippo and Bonsangue, Marcello M. and Pous, Damien and Rutten, Jan J.M.M. and Silva, Alexandra},
doi = {10.1017/S0960129515000523},
file = {:Users/liang-tingchen/Dropbox/References/Rot et al. - 2015 - Enhanced coalgebraic bisimulation.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {dec},
pages = {1--29},
title = {{Enhanced coalgebraic bisimulation}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129515000523},
year = {2015}
}
@phdthesis{Stewart2010,
abstract = {We present a solution to the problem of dynamic extension in statically typed functional languages with type erasure. The presented solution retains the benefits of static checking, including type safety, aggressive optimizations, and native code compilation of components, while allowing extensibility of programs at runtime. Our approach is based on a framework for dynamic extension in a stat- ically typed setting, combining dynamic linking, runtime type checking, first class modules and code hot swapping. We show that this framework is sufficient to allow a broad class of dynamic extension capabilities in any statically typed functional language with type erasure semantics. Uniquely, we employ the full compile-time type system to perform run- time type checking of dynamic components, and emphasize the use of na- tive code extension to ensure that the performance benefits of static typing are retained in a dynamic environment. We also develop the concept of fully dynamic software architectures, where the static core is minimal and all code is hot swappable. Benefits of the approach include hot swappable code and sophisticated application extension via embedded domain specific languages. We instantiate the concepts of the framework via a full implementation in the Haskell programming language: providing rich mechanisms for dy- namic linking, loading, hot swapping, and runtime type checking in Haskell for the first time. We demonstrate the feasibility of this architecture through a number of novel applications: an extensible text editor; a plugin-based network chat bot; a simulator for polymer chemistry; and xmonad, an ex- tensible window manager. In doing so, we demonstrate that static typing is no barrier to dynamic extension.},
author = {Stewart, Don},
file = {:Users/liang-tingchen/Dropbox/References/Stewart - 2010 - Dynamic Extension of Typed Functional Languages.pdf:pdf},
pages = {205},
school = {University of New South Wales},
title = {{Dynamic Extension of Typed Functional Languages}},
year = {2010}
}
@incollection{Forster2022,
author = {Forster, Yannick},
booktitle = {Logical Foundations of Computer Science. LFCS 2022},
doi = {10.1007/978-3-030-93100-1_6},
editor = {Artemov, Sergei and Nerode, Anil},
file = {:Users/liang-tingchen/Dropbox/References/Forster - 2022 - Parametric Church's Thesis Synthetic Computability Without Choice.pdf:pdf},
isbn = {9783030931001},
pages = {70--89},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Parametric Church's Thesis: Synthetic Computability Without Choice}},
url = {http://dx.doi.org/10.1007/978-3-030-93100-1{\_}6 https://link.springer.com/10.1007/978-3-030-93100-1{\_}6},
volume = {13137},
year = {2022}
}
@book{Rutten2005,
author = {Rutten, Jan J.M.M.},
booktitle = {Mathematical Structures in Computer Science},
doi = {10.1017/S0960129504004517},
file = {:Users/liang-tingchen/Dropbox/References/Rutten - 2005 - A coinductive calculus of streams.pdf:pdf},
isbn = {0960129504004},
issn = {0960-1295},
month = {feb},
number = {1},
pages = {93--147},
title = {{A coinductive calculus of streams}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129504004517},
volume = {15},
year = {2005}
}
@book{Statistik2014,
abstract = {The objective of this case study was to obtain some first-hand information about the functional consequences of a cosmetic tongue split operation for speech and tongue motility. One male patient who had performed the operation on himself was interviewed and underwent a tongue motility assessment, as well as an ultrasound examination. Tongue motility was mildly reduced as a result of tissue scarring. Speech was rated to be fully intelligible and highly acceptable by 4 raters, although 2 raters noticed slight distortions of the sibilants /s/ and /z/. The 3-dimensional ultrasound demonstrated that the synergy of the 2 sides of the tongue was preserved. A notably deep posterior genioglossus furrow indicated compensation for the reduced length of the tongue blade. It is concluded that the tongue split procedure did not significantly affect the participant's speech intelligibility and tongue motility.},
address = {Berlin, Heidelberg},
doi = {10.1007/BFb0079380},
editor = {Hilton, Peter J.},
file = {:Users/liang-tingchen/Dropbox/References/Unknown - 1969 - Category Theory, Homology Theory and their Applications I.pdf:pdf},
isbn = {978-3-540-04605-9},
keywords = {12,2007,3,Adolescence,Adolescencia,Adolescent,Adolescent Behavior,Adolescent Behavior: psychology,Adult,Agresiones al cuerpo,Attachment to the body,Attaque au corps,Autolesiones deliberadas,Automutilation d{\'{e}}lib{\'{e}}r{\'{e}}e,Body Piercing,Body Piercing: psychology,Body Piercing: statistics {\&} numerical data,Body image,CUERPO,Chile,Chile: epidemiology,Cornway,Corporate Finance,Cosmetic Techniques,Deliberate self-harm,Epidemiologic Methods,Female,Humans,Image corporelle,Imagen corporal,Industrial Organization,J.,JUVENTUD,Lumb,MODIFICACIONES CORPORALES,Male,Masood,Motivation,Movement,Public,R.,Risk-Taking,S.,S.K.,Self Mutilation,Self Mutilation: physiopathology,Self Mutilation: ultrasonography,Sex Distribution,Skan,Speech Articulation Tests,Speech Intelligibility,Tattooing,Tattooing: psychology,Tattooing: statistics {\&} numerical data,Tongue,Tongue: injuries,Tongue: physiopathology,Tongue: ultrasonography,advantages,aesthetics,and e-banking,and on cor-,anomaly detection,as none were found,authentication,autoinjury and health,body,business model,candidate,classification,collaboration,competition,complications did not,complications from inserting a,constituci{\'{o}}n del yo,control postural- estabilizaci{\'{o}}n- v{\'{i}}as,corporal modifications,corps,credit access,credit financing,credit score,credit scoring,critical success factors,cuerpo,culturas juveniles,cultures juv{\'{e}}niles,customer satisfaction,customer scoring,data mining,decision tree,department of economics at,e-,e- banking,e-banking,e-commerce,e-payment,e-trading,electronic communication and computation,emergency,endogenous tie,epidural,esth{\'{e}}tique,est{\'{e}}tica,feature sim-,finance includes e-payment,financial fervices technology,financial services innovation,find any reports of,fintech,fintech analysis,fintech start-ups,functions,genetic programming,global fintech comparison,high resolution images,if neuraxial anes-,in practice,indonesia,information technology,ing with neuraxial anesthesia,internet bank,internet primary bank,jarunee wonglimpiyarat,jeunesse,jibc december 2007,juvenile cultures,juventud,limitations,luation of non-urgent visits,m-commerce,mecanismos de anteroalimentaci{\'{o}}n y,modificacio -,multimodal biometric,needle through a,nes corporales,network security,networks,neural networks,no,patents analysis,perforaci{\'{o}}n corporal,piel,professor of marketing,professor of marketing at,pr{\'{a}}ctica autolesiva,psicoan{\'{a}}lisis,recommender system,research,retroalimentaci{\'{o}}n,risks management,segunda piel,sensitivas y motoras,smart cards,social network analysis,social networks,social status,spinal,strategic,strategy,support vector machine,sustainable reconstruction,sydney fintech,sydney start-ups,tattoo,tattooing,tattoos,tatuaje,the literature on tattoos,the university of pennsylvania,the wharton school of,to a busy urban,traditional banking services,unimodal biometric,university of pennsylvania,vol,was reviewed to see,youth},
number = {2},
pages = {81--87},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Category Theory, Homology Theory and their Applications I}},
url = {http://www.americanbanker.com/issues/179{\_}124/which-city-is-the-next-big-fintech-hub-new-york-stakes-its-claim-1068345-1.html{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/15003161{\%}5Cnhttp://cid.oxfordjournals.org/lookup/doi/10.1093/cid/cir991{\%}5Cnhttp://www.scielo.cl/pd},
volume = {86},
year = {1969}
}
@article{Taha2000,
abstract = {We introduce MetaML, a practically motivated, statically typed multi-stage programming language. MetaML is a "real" language. We have built an implementation and used it to solve multi-stage problems. MetaML allows the programmer to construct, combine, and execute code fragments in a type-safe manner. Code fragments can contain free variables, but they obey the static-scoping principle. MetaML performs type-checking for all stages once and for all before the execution of the first stage. Certain anomalies with our first MetaML implementation led us to formalize an illustrative subset of the MetaML implementation. We present both a big-step semantics and type system for this subset, and prove the type system's soundness with respect to a big-step semantics. From a software engineering point of view, this means that generators written in the MetaML subset never generate unsafe programs. A type system and semantics for full MetaML is still ongoing work. We argue that multi-stage languages are useful as programming languages in their own right, that they supply a sound basis for high-level program generation technology, and that they should support features that make it possible for programmers to write staged computations without significantly changing their normal programming style. To illustrate this we provide a simple three-stage example elaborating a number of practical issues. The design of MetaML was based on two main principles that we identified as fundamental for high-level program generation, namely, cross-stage persistence and cross-stage safety. We present these principles, explain the technical problems they give rise to, and how we address with these problems in our implementation. {\textcopyright} 2000 Published by Elsevier Science B.V. All rights reserved.},
author = {Taha, Walid and Sheard, Tim},
doi = {10.1016/S0304-3975(00)00053-0},
file = {:Users/liang-tingchen/Dropbox/References/Taha, Sheard - 2000 - MetaML and multi-stage programming with explicit annotations.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Functional programming,High-level program generation,Multi-level languages,Multi-stage languages,Programming language semantics,Type-safety,Type-systems,$\lambda$-Calculus},
month = {oct},
number = {1-2},
pages = {211--242},
title = {{MetaML and multi-stage programming with explicit annotations}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397500000530},
volume = {248},
year = {2000}
}
@article{Santocanale2003,
author = {Santocanale, Luigi},
doi = {10.1016/S0304-3975(02)00412-7},
file = {:Users/liang-tingchen/Dropbox/References/Santocanale - 2003 - On the equational definition of the least prefixed point.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {fixed point calculi,least {\"{y}}xed point,programs,semantics and logics of,temporal logic},
month = {feb},
number = {1-3},
pages = {341--370},
title = {{On the equational definition of the least prefixed point}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397502004127},
volume = {295},
year = {2003}
}
@incollection{Moggi1998,
abstract = {We propose a denotational semantics for the two-level language of [GJ91, Gom92], and prove its correctness w.r.t. a standard denotational semantics. Other researchers (see [Gom91, GJ91, Gom92, JGS93, HM94]) have claimed correctness for lambda-mix (or extensions of it) based on denotational models, but the proofs of such claims rely on imprecise definitions and are basically flawed. At a technical level there are two important differences between our model and more naive models in Cpo: the domain for interpreting dynamic expressions is more abstract (we interpret code as $\lambda$-terms modulo $\alpha$-conversion), the semantics of newname is handled differently (we exploit functor categories). The key idea is to interpret a two-level language in a suitable functor category Cpo Dop rather than Cpo. The semantics of newname follows the ideas pioneered by Oles and Reynolds for modeling the stack discipline of Algol-like languages. Indeed, we can think of the objects of D (i.e. the natural numbers) as the states of a name counter, which is incremented when entering the body of a $\lambda$-abstraction and decremented when coming out. Correctness is proved using Kripke logical relations (see [MM91, NN92]).},
author = {Moggi, E.},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 1998},
doi = {10.1007/BFb0053552},
editor = {Nivat, Maurice},
file = {:Users/liang-tingchen/Dropbox/References/Moggi - 1998 - Functor categories and two-level languages.pdf:pdf},
isbn = {3540643001},
issn = {16113349},
pages = {211--225},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Functor categories and two-level languages}},
url = {http://link.springer.com/10.1007/BFb0053552},
volume = {1378},
year = {1998}
}
@article{Hyland2007,
author = {Hyland, Martin and Levy, Paul Blain and Plotkin, Gordon D. and Power, A. John},
doi = {10.1016/j.tcs.2006.12.026},
file = {:Users/liang-tingchen/Dropbox/References/Hyland et al. - 2007 - Combining algebraic effects with continuations.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {computational effect,lawvere theory,modularity,monad},
month = {may},
number = {1-3},
pages = {20--40},
title = {{Combining algebraic effects with continuations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506009157},
volume = {375},
year = {2007}
}
@article{Jacobs2015b,
abstract = {The Dijkstra and Hoare monads have been introduced recently for capturing weakest precondition computations and computations with pre- and post-conditions, within the context of program verification, supported by a theorem prover. Here we give a more general description of such monads in a categorical setting. We first elaborate the recently developed view on program semantics in terms of a triangle of computations, state transformers, and predicate transformers. Instantiating this triangle for different computational monads T shows how to define the Dijkstra monad associated with T, via the logic involved.Subsequently we give abstract definitions of the Dijkstra and Hoare monad, parametrised by a computational monad. These definitions presuppose a suitable (categorical) predicate logic, defined on the Kleisli category of the underlying monad. When all this structure exists, we show that there are maps of monads (Hoare) ⇒ (State) ⇒ (Dijkstra), all parametrised by a monad T.},
author = {Jacobs, Bart},
doi = {10.1016/j.tcs.2015.03.020},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2015 - Dijkstra and hoare monads in monadic computation.pdf:pdf},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Hoare logic,Monad,Program semantics,Weakest precondition},
pages = {30--45},
publisher = {Elsevier B.V.},
title = {{Dijkstra and hoare monads in monadic computation}},
url = {http://dx.doi.org/10.1016/j.tcs.2015.03.020},
volume = {604},
year = {2015}
}
@article{Wang2016,
abstract = {This paper investigates the relation between three different notions of privacy: identifiability, differential privacy and mutual-information privacy. Under a unified privacy-distortion framework, where the distortion is defined to be the Hamming distance of the input and output databases, we establish some fundamental connections between these three privacy notions. Given a distortion level {\$}D{\$}, define {\$}\backslashepsilon{\_}{\{}\backslashmathrm{\{}i{\}}{\}}{\^{}}*(D){\$} to be the smallest (best) identifiability level, and {\$}\backslashepsilon{\_}{\{}\backslashmathrm{\{}d{\}}{\}}{\^{}}*(D){\$} to be the smallest differential privacy level. We characterize {\$}\backslashepsilon{\_}{\{}\backslashmathrm{\{}i{\}}{\}}{\^{}}*(D){\$} and {\$}\backslashepsilon{\_}{\{}\backslashmathrm{\{}d{\}}{\}}{\^{}}*(D){\$}, and prove that {\$}\backslashepsilon{\_}{\{}\backslashmathrm{\{}i{\}}{\}}{\^{}}*(D)-\backslashepsilon{\_}X\backslashle\backslashepsilon{\_}{\{}\backslashmathrm{\{}d{\}}{\}}{\^{}}*(D)\backslashle\backslashepsilon{\_}{\{}\backslashmathrm{\{}i{\}}{\}}{\^{}}*(D){\$} for {\$}D{\$} in some range, where {\$}\backslashepsilon{\_}X{\$} is a constant depending on the distribution of the original database {\$}X{\$}, and diminishes to zero when the distribution of {\$}X{\$} is uniform. Furthermore, we show that identifiability and mutual-information privacy are consistent in the sense that given distortion level {\$}D{\$}, the mechanism that optimizes the mutual-information privacy also minimizes the identifiability level.},
archivePrefix = {arXiv},
arxivId = {1402.3757},
author = {Wang, Weina and Ying, Lei and Zhang, Junshan},
doi = {10.1109/TIT.2016.2584610},
eprint = {1402.3757},
file = {:Users/liang-tingchen/Dropbox/References/Wang, Ying, Zhang - 2016 - On the relation between identifiability, differential privacy, and mutual-information privacy.pdf:pdf},
isbn = {9781479980093},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Differential privacy,Hamming distance,identifiability,mutual information,rate-distortion},
number = {9},
pages = {5018--5029},
title = {{On the relation between identifiability, differential privacy, and mutual-information privacy}},
volume = {62},
year = {2016}
}
@incollection{Cirstea2017a,
abstract = {{\textcopyright} Corina C{\^{i}}rstea, Shunsuke Shimizu, and Ichiro Hasuo; licensed under Creative Commons License CC-BY. We initiate a study of automata-based model checking for previously proposed quantitative linear time logics interpreted over coalgebras. Our results include: (i) an automata-theoretic characterisation of the semantics of these logics, based on a notion of extent of a quantitative parity automaton, (ii) a study of the expressive power of B{\"{u}}chi variants of such automata, with implications on the expressiveness of fragments of the logics considered, and (iii) a na{\"{i}}ve algorithm for computing extents, under additional assumptions on the domain of truth values.},
author = {C{\^{i}}rstea, C. and Shimizu, S. and Hasuo, I.},
booktitle = {7th Conference on Algebra and Coalgebra in Computer Science (CALCO 2017)},
doi = {10.4230/LIPIcs.CALCO.2017.7},
editor = {K{\{}$\backslash$"o{\}}nig, Filippo Bonchi and Barbara},
file = {:Users/liang-tingchen/Dropbox/References/C{\^{i}}rstea, Shimizu, Hasuo - 2017 - Parity automata for quantitative linear time logics.pdf:pdf},
isbn = {9783959770330},
issn = {18688969},
keywords = {Coalgebra,Linear time logic,Parity automaton,Quantitative logic},
pages = {7:1----7:18},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Parity automata for quantitative linear time logics}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/8046/},
volume = {72},
year = {2017}
}
@inproceedings{Corradini1998,
abstract = {This paper relates labeled transition systems and coalgebras with the motivation of comparing and combining their complementary contributions to the theory of concurrent systems. The well-known mismatch between these two notions for what concerns the morphisms is resolved by extending the coalgebraic framework by lax cohomomorphisms. Enriching both labeled transition systems and coalgebras with algebraic structure for an algebraic specification, the correspondence is lost again. This leads to the introduction of lax coalgebras, where the coalgebra structure is given by a lax homomorphism. The resulting category of lax coalgebras and lax cohomomorphisms for a suitable endofunctor is shown to be isomorphic to the category of structured transition systems, where both states and transitions form algebras. The framework is also presented on a more abstract categorical level using monads and comonads, extending the bialgebraic approach recently introduced by Turi and Plotkin. {\textcopyright} 1998 Published by Elsevier Science B.V.},
author = {Corradini, Andrea and Gro{\ss}e-Rhode, Martin and Heckel, Reiko},
booktitle = {First Workshop on Coalgebraic Methods in Computer Scienc},
doi = {10.1016/S1571-0661(04)00051-9},
file = {:Users/liang-tingchen/Dropbox/References/Corradini, Gro{\ss}e-Rhode, Heckel - 1998 - Structured transition systems as lax coalgebras.pdf:pdf},
issn = {15710661},
pages = {22--41},
title = {{Structured transition systems as lax coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104000519},
volume = {11},
year = {1998}
}
@inproceedings{Cheney2002,
abstract = {The recent years have seen a number of proposals for extending statically typed languages by dynamics or generics. Most proposals - if not all - require significant extensions to the underlying language. In this paper we show that this need not be the case. We propose a particularly lightweight extension that supports both dynamics and genetics. Furthermore, the two features are smoothly integrated: dynamic values, for instance, can be passed to generic functions. Our proposal makes do with a standard Hindley-Milner type system augmented by existential types. Building upon these ideas we have implemented a small library that is readily usable both with Hugs and with the Glasgow Haskell compiler.},
address = {New York, New York, USA},
author = {Cheney, James and Hinze, Ralf},
booktitle = {Proceedings of the ACM SIGPLAN workshop on Haskell - Haskell '02},
doi = {10.1145/581690.581698},
file = {:Users/liang-tingchen/Dropbox/References/Cheney, Hinze - 2002 - A lightweight implementation of generics and dynamics.pdf:pdf},
isbn = {1581136056},
keywords = {Dynamic typing,Genetic programming,Type representations},
pages = {90--104},
publisher = {ACM Press},
title = {{A lightweight implementation of generics and dynamics}},
url = {http://portal.acm.org/citation.cfm?doid=581690.581698},
year = {2002}
}
@incollection{Barendregt1992,
author = {Barendregt, Henk},
booktitle = {Handbook of Logic in Computer Science},
doi = {10.1.1.26.4391},
editor = {Abramsky, Samson and Gabbay, Dov and Maibaum, Thomas S.E.},
file = {:Users/liang-tingchen/Dropbox/References/Barendregt - 1993 - Lambda calculi with types.pdf:pdf},
isbn = {9780198537618},
pages = {117--309},
publisher = {Oxford University Press},
title = {{Lambda calculi with types}},
volume = {2},
year = {1993}
}
@article{Kifer2014,
abstract = {In this article, we introduce a new and general privacy framework called Pufferfish. The Pufferfish framework can be used to create new privacy definitions that are customized to the needs of a given application. The goal of Pufferfish is to allow experts in an application domain, who frequently do not have expertise in privacy, to develop rigorous privacy definitions for their data sharing needs. In addition to this, the Pufferfish framework can also be used to study existing privacy definitions. We illustrate the benefits with several applications of this privacy framework: we use it to analyze differ- ential privacy and formalize a connection to attackers who believe that the data records are independent; we use it to create a privacy definition called hedging privacy, which can be used to rule out attackers whose prior beliefs are inconsistent with the data; we use the framework to define and study the notion of composi- tion in a broader context than before; we show how to apply the framework to protect unbounded continuous attributes and aggregate information; and we show how to use the framework to rigorously account for prior data releases.},
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
doi = {10.1145/2514689},
file = {:Users/liang-tingchen/Dropbox/References/Kifer, Machanavajjhala - 2014 - Pufferfish A Framework for Mathematical Privacy Definitions.pdf:pdf},
issn = {03625915},
journal = {ACM Transactions on Database Systems},
month = {jan},
number = {1},
pages = {1--36},
title = {{Pufferfish: A Framework for Mathematical Privacy Definitions}},
url = {http://dl.acm.org/citation.cfm?doid=2576988.2514689},
volume = {39},
year = {2014}
}
@article{Clairambault2014,
abstract = {Seely's paper Locally cartesian closed categories and type theory (Seely 1984) contains a well-known result in categorical type theory: that the category of locally cartesian closed categories is equivalent to the category of Martin-Lof type theories with $\Pi$, $\Sigma$ and extensional identity types. However, Seely's proof relies on the problematic assumption that substitution in types can be interpreted by pullbacks. Here we prove a corrected version of Seely's theorem: that the Be ́nabou–Hofmann interpretation of Martin-Lo ̈f type theory in locally cartesian closed categories yields a biequivalence of 2-categories. To facilitate the technical development, we employ categories with families as a substitute for syntactic Martin-Lo ̈f type theories. As a second result, we prove that if we remove $\Pi$-types, the resulting categories with families with only $\Sigma$ and extensional identity types are biequivalent to left exact categories.},
author = {Clairambault, Pierre and Dybjer, Peter},
doi = {10.1017/S0960129513000881},
file = {:Users/liang-tingchen/Dropbox/References/Clairambault, Dybjer - 2014 - The biequivalence of locally cartesian closed categories and Martin-l{\"{o}}f type theories.pdf:pdf},
journal = {Mathematical Structures in Computer Science},
number = {6},
title = {{The biequivalence of locally cartesian closed categories and Martin-l{\"{o}}f type theories}},
url = {http://journals.cambridge.org/action/displayAbstract?fromPage=online{\&}aid=9219639{\&}fileId=S0960129513000881},
volume = {24},
year = {2014}
}
@article{Cavallo2019,
abstract = {In homotopy type theory (HoTT), higher inductive types provide a means of defining and reasoning about higher-dimensional objects such as circles and tori. The formulation of a schema for such types remains a matter of current research. We investigate the question in the context of cubical type theory, where the homotopical structure implicit in HoTT is made explicit in the judgmental apparatus. Within the computational cubical type system framework of Angiuli et al., we implement a class we call cubical inductive types, which includes n-truncations, W-quotients, and localizations. We suggest an extension to indexed inductive types by defining an example, a homotopy fiber type. From this we derive an identity type, making our theory a model of Martin-L{\"{o}}f type theory. Using Angiuli et al.'s implementation of univalence, we obtain a computational interpretation of HoTT with a general class of higher inductive types. This interpretation admits a canonicity theorem: any zero-dimensional element of a cubical inductive type evaluates to a constructor.},
author = {Cavallo, Evan and Harper, Robert},
doi = {10.1145/3290314},
file = {:Users/liang-tingchen/Dropbox/References/Cavallo, Harper - 2019 - Higher inductive types in cubical computational type theory.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {cubical type theory,higher inductive types,homotopy type theory},
month = {jan},
number = {POPL},
pages = {1--27},
title = {{Higher inductive types in cubical computational type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290314},
volume = {3},
year = {2019}
}
@article{Szlach??nyi2003,
abstract = {Strong monoidal functors U:C???M with left adjoints determine, in a universal way, monoids T in the category of opmonoidal endofunctors on M. Treating such opmonoidal monads as abstract "quantum groupoids" we derive Tannaka duality between right adjoint strong monoidal functors and opmonoidal monads. Bialgebroids, i.e., Takeuchi's ??R-bialgebras, appear as the special case when T has also a right adjoint. Street's 2-category of monads then leads to a natural definition of the 2-category of bialgebroids. ?? 2003 Elsevier Science B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {math/0208198},
author = {Szlach{\'{a}}nyi, Korn{\'{e}}l},
doi = {10.1016/S0022-4049(03)00018-5},
eprint = {0208198},
file = {:Users/liang-tingchen/Dropbox/References/Szlach{\'{a}}nyi - 2003 - The monoidal Eilenberg–Moore construction and bialgebroids.pdf:pdf},
isbn = {3613959151},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {aug},
number = {2-3},
pages = {287--315},
primaryClass = {math},
title = {{The monoidal Eilenberg–Moore construction and bialgebroids}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022404903000185},
volume = {182},
year = {2003}
}
@article{Baldan2014,
archivePrefix = {arXiv},
arxivId = {1410.3385},
author = {Baldan, Paolo and Bonchi, Filippo and Kerstan, Henning and K{\"{o}}nig, Barbara},
eprint = {1410.3385},
file = {:Users/liang-tingchen/Dropbox/References/Baldan et al. - 2014 - Behavioral Metrics via Functor Lifting.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {behavioral metric,coalgebra,functor lifting,pseudometric},
month = {oct},
title = {{Behavioral Metrics via Functor Lifting}},
url = {http://arxiv.org/abs/1410.3385v1},
year = {2014}
}
@incollection{Pavlovic2012b,
author = {Pavlovic, Dusko and Meadows, Catherine},
booktitle = {Distributed Computing and Internet Technology. ICDCIT 2012.},
doi = {10.1007/978-3-642-28073-3_2},
editor = {Ramanujam, R. and Ramaswamy, Srini},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovic, Meadows - 2012 - Actor-Network Procedures.pdf:pdf},
pages = {7--26},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Actor-Network Procedures}},
url = {http://link.springer.com/10.1007/978-3-642-28073-3{\_}2},
volume = {7154},
year = {2012}
}
@article{Day1978a,
author = {Day, Brian J.},
doi = {10.1017/S0004972700008613},
file = {:Users/liang-tingchen/Dropbox/References/Day - 1978 - Duality in topological algebra Addendum.pdf:pdf},
issn = {0004-9727},
journal = {Bulletin of the Australian Mathematical Society},
number = {01},
pages = {157},
title = {{Duality in topological algebra: Addendum}},
volume = {19},
year = {1978}
}
@article{Yang2017,
abstract = {Ever since proposed by Dwork, differential privacy has been a hot topic in academia. However, few attempts have been made on reasoning about differential privacy at a system level. In this paper, we propose a formal framework to verify differential privacy in probabilistic systems. With a metric on the states of a system, we formalize differential privacy by the ratio of the probabilities in the distributions after the same labeled transitions of relevant states. We explain how traditional differential privacy can be embedded in our framework and raise an infimum metric, the least distance between two states, while not violating differential privacy. It is proven that the infimum metric is also a metric instance of differential privacy itself. Furthermore, we propose a two-level logic, a privacy variant of the familiar Hennessy–Milner logic, to characterize differential privacy in our framework. Our results have close relations to probabilistic bisimilarity as well.},
author = {Yang, Jiannan and Cao, Yongzhi and Wang, Hanpin},
doi = {10.1016/j.ic.2017.03.002},
file = {:Users/liang-tingchen/Dropbox/References/Yang, Cao, Wang - 2017 - Differential privacy in probabilistic systems.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {Differential privacy,Logical characterization,Metric,Probabilistic bisimilarity,Probabilistic system},
month = {jun},
pages = {84--104},
publisher = {Elsevier Inc.},
title = {{Differential privacy in probabilistic systems}},
url = {http://dx.doi.org/10.1016/j.ic.2017.03.002 http://linkinghub.elsevier.com/retrieve/pii/S0890540117300469 https://linkinghub.elsevier.com/retrieve/pii/S0890540117300469},
volume = {254},
year = {2017}
}
@book{Hoare1985,
author = {Hoare, C.A.R.},
file = {:Users/liang-tingchen/Dropbox/References/Hoare - 1985 - Communicating Sequential Processes.pdf:pdf},
isbn = {0-13-153271-5},
keywords = {and phrases,concurrency,guarded commands,input,nondeterminacy,output,parallel programming,program structures,programming,programming languages,programming primitives},
pages = {256},
publisher = {Prentice Hall},
series = {Prentice Hall International Series in Computing Science},
title = {{Communicating Sequential Processes}},
year = {1985}
}
@phdthesis{Abel2013,
author = {Abel, Andreas M.},
file = {:Users/liang-tingchen/Dropbox/References/Abel - 2013 - Normalization by Evaluation.pdf:pdf},
school = {Ludwig-Maximilians-Universit{\"{u}}t M{\"{u}}nchen},
title = {{Normalization by Evaluation}},
type = {Habilitation},
year = {2013}
}
@incollection{Droste2009,
abstract = {Weighted finite automata are classical nondeterministic finite automata in which the transitions carry weights. These weights may model, for example, the cost involved when executing a transition, the resources or time needed for this, or the probability or reliability of its successful execution. Weights can also be added to classical automata with infinite state sets like pushdown automata, and this extension constitutes the general concept of weighted automata. Since their introduction in the 1960s they have stimulated research in related areas of theoretical computer science, including formal language theory, algebra, logic, and discrete structures. Moreover, weighted automata and weighted context-free grammars have found application in natural-language processing, speech recognition, and digital image compression.This book covers all the main aspects of weighted automata and formal power series methods, ranging from theory to applications. The contributors are the leading experts in their respective areas, and each chapter presents a detailed survey of the state of the art and pointers to future research. The chapters in Part I cover the foundations of the theory of weighted automata, specifically addressing semirings, power series, and fixed point theory. Part II investigates different concepts of weighted recognizability. Part III examines alternative types of weighted automata and various discrete structures other than words. Finally, Part IV deals with applications of weighted automata, including digital image compression, fuzzy languages, model checking, and natural-language processing.Computer scientists and mathematicians will find this book an excellent survey and reference volume, and it will also be a valuable resource for students exploring this exciting research area.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{\'{E}}sik, Zolt{\'{a}}n},
booktitle = {Handbook of Weighted Automata},
doi = {10.1007/978-3-642-01492-5 2},
editor = {Droste, Manfred and Kuich, Werner and Vogler, Heiko},
eprint = {arXiv:1011.1669v3},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik - 2009 - Fixed point theory.pdf:pdf},
isbn = {9783642014918},
issn = {1098-6596},
pages = {608},
pmid = {25246403},
publisher = {Springer Berlin Heidelberg},
series = {Monographs in Theoretical Computer Science. An EATCS Series},
title = {{Fixed point theory}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-01492-5},
year = {2009}
}
@article{Chikhladze2015,
author = {Chikhladze, Dimitri},
file = {:Users/liang-tingchen/Dropbox/References/Chikhladze - 2015 - Lax formal theory of monads, monoidal approach to bicategorical structures and generalized operads.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Bicategories,Equipments,Formal theory of monads,Generalized multicategories,Lax categorification,Tricategories},
number = {10},
pages = {332--386},
title = {{Lax formal theory of monads, monoidal approach to bicategorical structures and generalized operads}},
volume = {30},
year = {2015}
}
@article{Carette2009,
abstract = {We have built the first family of tagless interpretations for a higher-order typed object language in a typed metalanguage (Haskell or ML) that require no dependent types, generalized algebraic data types, or postprocessing to eliminate tags. The statically type-preserving interpretations include an evaluator, a compiler (or staged evaluator), a partial evaluator, and call-by-name and call-by-value continuation-passing style (CPS) transformers. Our principal technique is to encode de Bruijn or higher-order abstract syntax using combinator functions rather than data constructors. In other words, we represent object terms not in an initial algebra but using the coalgebraic structure of the $\lambda$-calculus. Our representation also simulates inductive maps from types to types, which are required for typed partial evaluation and CPS transformations. Our encoding of an object term abstracts uniformly over the family of ways to interpret it, yet statically assures that the interpreters never get stuck. This family of interpreters thus demonstrates again that it is useful to abstract over higher-kinded types.},
author = {CARETTE, JACQUES and KISELYOV, OLEG and SHAN, CHUNG-CHIEH},
doi = {10.1017/S0956796809007205},
file = {:Users/liang-tingchen/Dropbox/References/CARETTE, KISELYOV, SHAN - 2009 - Finally tagless, partially evaluated Tagless staged interpreters for simpler typed languages.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {sep},
number = {5},
pages = {509--543},
title = {{Finally tagless, partially evaluated: Tagless staged interpreters for simpler typed languages}},
url = {https://www.cambridge.org/core/product/identifier/S0956796809007205/type/journal{\_}article},
volume = {19},
year = {2009}
}
@article{Hofmann2012,
abstract = {In this paper we present methods of transition from one perspective on logic to others, and apply this in particular to obtain a coalgebraic presentation of logic. The central ingredient in this process is to view consequence relations as morphisms in a category.},
archivePrefix = {arXiv},
arxivId = {1202.0915},
author = {Hofmann, Dirk and Martins, Manuel A.},
eprint = {1202.0915},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann, Martins - 2012 - On a coalgebraic view on Logic.pdf:pdf},
month = {feb},
title = {{On a coalgebraic view on Logic}},
url = {http://arxiv.org/abs/1202.0915},
year = {2012}
}
@article{Niu2022,
abstract = {We present calf , a c ost- a ware l ogical f ramework for studying quantitative aspects of functional programs. Taking inspiration from recent work that reconstructs traditional aspects of programming languages in terms of a modal account of phase distinctions , we argue that the cost structure of programs motivates a phase distinction between intension and extension . Armed with this technology, we contribute a synthetic account of cost structure as a computational effect in which cost-aware programs enjoy an internal noninterference property: input/output behavior cannot depend on cost. As a full-spectrum dependent type theory, calf presents a unified language for programming and specification of both cost and behavior that can be integrated smoothly with existing mathematical libraries available in type theoretic proof assistants.},
author = {Niu, Yue and Sterling, Jonathan and Grodin, Harrison and Harper, Robert},
doi = {10.1145/3498670},
file = {:Users/liang-tingchen/Dropbox/References/Niu et al. - 2022 - A cost-aware logical framework.pdf:pdf},
issn = {2475-1421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jan},
number = {POPL},
pages = {1--31},
title = {{A cost-aware logical framework}},
url = {https://dl.acm.org/doi/10.1145/3498670},
volume = {6},
year = {2022}
}
@inproceedings{Bonchi2015a,
address = {New York, New York, USA},
author = {Bonchi, Filippo and Sobocinski, Pawel and Zanasi, Fabio},
booktitle = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL '15},
doi = {10.1145/2676726.2676993},
file = {:Users/liang-tingchen/Dropbox/References/Bonchi, Sobocinski, Zanasi - 2015 - Full abstraction for signal flow graphs.pdf:pdf},
isbn = {9781450333009},
issn = {15232867},
keywords = {a simple mathematical meaning,at least,can be given to,full abstraction,it is,one delay component,props,signal flow graphs,string diagrams,struc-,those sfgs,tural operational semantics,where feedbacks pass through},
pages = {515--526},
publisher = {ACM Press},
title = {{Full abstraction for signal flow graphs}},
url = {http://dl.acm.org/citation.cfm?doid=2676726.2676993},
year = {2015}
}
@article{Birkedal2010,
abstract = {It is well known that one can use an adaptation of the inverse-limit construction to solve recursive equations in the category of complete ultrametric spaces. We show that this construction generalizes to a large class of categories with metric-space structure on each set of morphisms: the exact nature of the objects is less important. In particular, the construction immediately applies to categories where the objects are ultrametric spaces with 'extra structure', and where the morphisms preserve this extra structure. The generalization is inspired by classical domain-theoretic work by Smyth and Plotkin. For many of the categories we consider, there is a natural subcategory in which each set of morphisms is required to be a compact metric space. Our setting allows for a proof that such a subcategory always inherits solutions of recursive equations from the full category. As another application, we present a construction that relates solutions of generalized domain equations in the sense of Smyth and Plotkin to solutions of equations in our class of categories. Our primary motivation for solving generalized recursive metric-space equations comes from recent and ongoing work on Kripke-style models in which the sets of worlds must be recursively defined. We show a series of examples motivated by this line of work. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Birkedal, Lars and St{\o}vring, Kristian and Thamsborg, Jacob},
doi = {10.1016/j.tcs.2010.07.010},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal, St{\o}vring, Thamsborg - 2010 - The category-theoretic solution of recursive metric-space equations.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Fixed point,Metric space,Recursive equation},
number = {47},
pages = {4102--4122},
publisher = {Elsevier B.V.},
title = {{The category-theoretic solution of recursive metric-space equations}},
url = {http://dx.doi.org/10.1016/j.tcs.2010.07.010},
volume = {411},
year = {2010}
}
@article{Copello2016,
abstract = {We formulate principles of induction and recursion for a variant of lambda calculus in its original syntax (i.e., with only one sort of names) where $\alpha$-conversion is based upon name swapping as in nominal abstract syntax. The principles allow to work modulo $\alpha$-conversion and implement the Barendregt variable convention. We derive them all from the simple structural induction principle on concrete terms and work out applications to some fundamental meta-theoretical results, such as the substitution lemma for $\alpha$-conversion and the lemma on substitution composition. The whole work is implemented in Agda.},
author = {Copello, Ernesto and Tasistro, {\'{A}}lvaro and Szasz, Nora and Bove, Ana and Fern{\'{a}}ndez, Maribel},
doi = {10.1016/j.entcs.2016.06.008},
file = {:Users/liang-tingchen/Dropbox/References/Copello et al. - 2016 - Alpha-Structural Induction and Recursion for the Lambda Calculus in Constructive Type Theory.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Constructive Type Theory,Formal Metatheory,Lambda Calculus},
month = {jul},
pages = {109--124},
publisher = {Elsevier B.V.},
title = {{Alpha-Structural Induction and Recursion for the Lambda Calculus in Constructive Type Theory}},
url = {http://dx.doi.org/10.1016/j.entcs.2016.06.008 https://linkinghub.elsevier.com/retrieve/pii/S1571066116300354},
volume = {323},
year = {2016}
}
@article{Bird1999,
abstract = {“I have no data yet. It is a capital mistake to theorise before one has data.” Sir Arthur Conan Doyle The Adventures of Sherlock Holmes},
author = {Bird, Richard and Paterson, Ross},
doi = {10.1017/S0956796899003366},
file = {:Users/liang-tingchen/Dropbox/References/Bird, Paterson - 1999 - de Bruijn notation as a nested datatype.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {jan},
number = {1},
pages = {77--91},
publisher = {Institute of Mathematics, Academia sinica},
title = {{de Bruijn notation as a nested datatype}},
url = {https://www.cambridge.org/core/product/identifier/S0956796899003366/type/journal{\_}article},
volume = {9},
year = {1999}
}
@incollection{Hulsbusch2012,
abstract = {We consider conditional reactive systems, a general abstract framework for rewriting, in which reactive systems {\`{a}} la Leifer and Milner are enriched with (nested) application conditions. We study the problem of deriving labelled transitions and bisimulation congruences from a reduction semantics. That is, we synthesize interactions with the environment in order to obtain a compositional semantics. Compared to earlier work we not only address the problem of deriving information about the (minimal) context needed to obtain a full left-hand side and thus be able to perform a reduction, but also generate conditions on the remaining context.},
annote = {10.1007/978-3-642-28729-9{\_}24},
author = {H{\"{u}}lsbusch, Mathias and K{\"{o}}nig, Barbara},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/H{\"{u}}lsbusch, K{\"{o}}nig - 2012 - Deriving Bisimulation Congruences for Conditional Reactive Systems.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {361--375},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Deriving Bisimulation Congruences for Conditional Reactive Systems}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}24},
volume = {7213},
year = {2012}
}
@inproceedings{Marti2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.02319v1},
author = {Marti, Johannes and Seifan, Fatemeh and Venema, Yde},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.238},
editor = {Moss, Lawrence S. and Sobocinski, Pawel},
eprint = {arXiv:1503.02319v1},
file = {:Users/liang-tingchen/Dropbox/References/Marti, Seifan, Venema - 2015 - Uniform Interpolation for Coalgebraic Fixpoint Logic.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
keywords = {2015,236,4230,and phrases µ -calculus,automata,calco,coalgebra,digital object identifier 10,lipics,uniform interpolation},
pages = {238----252},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{Uniform Interpolation for Coalgebraic Fixpoint Logic}},
volume = {35},
year = {2015}
}
@article{Awodey2008,
abstract = {We compare realizability models over partial combinatory algebras by embedding them into sheaf toposes. We then use the machinery of Grothendieck toposes and geometric morphisms to study the relationship between realizability models over different partial combinatory algebras. This research is part of the Logic of Types and Computation project at Carnegie Mellon University under the direction of Dana Scott. {\textcopyright} 2008 Springer-Verlag.},
author = {Awodey, Steven and Bauer, Andrej},
doi = {10.1007/s00153-008-0090-6},
file = {:Users/liang-tingchen/Dropbox/References/Awodey, Bauer - 2008 - Sheaf toposes for realizability.pdf:pdf},
issn = {0933-5846},
journal = {Archive for Mathematical Logic},
month = {aug},
number = {5},
pages = {465--478},
title = {{Sheaf toposes for realizability}},
url = {http://link.springer.com/10.1007/s00153-008-0090-6},
volume = {47},
year = {2008}
}
@article{Tzevelekos2012,
author = {Tzevelekos, Nikos},
doi = {10.1016/j.cl.2012.02.002},
file = {:Users/liang-tingchen/Dropbox/References/Tzevelekos - 2012 - Program equivalence in a simple language with state.pdf:pdf},
issn = {14778424},
journal = {Computer Languages, Systems {\&} Structures},
keywords = {Environmental bisimulations,Game semantics,Higher-order computation and local state,Logical relations,Nominal computation,Program equivalence},
month = {jul},
number = {2},
pages = {181--198},
publisher = {Elsevier},
title = {{Program equivalence in a simple language with state}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1477842412000036},
volume = {38},
year = {2012}
}
@article{Bezhanishvili2010,
abstract = {Building on the fact that descriptive frames are coalgebras for the Vietoris functor on the category of Stone spaces, we introduce and study the concept of a Vietoris bisimulation between two descriptive modal models, together with the associated notion of bisimilarity. We prove that our notion of bisimilarity, which is defined in terms of relation lifting, coincides with Kripke bisimilarity (with respect to the underlying Kripke models), with behavioural equivalence, and with modal equivalence, but not with Aczel–Mendler bisimilarity. As a corollary, we obtain that the Vietoris functor does not preserve weak pullbacks. Comparing Vietoris bisimulations between descriptive models to Kripke bisimulations on the underlying Kripke models, we prove that the closure of such a Kripke bisimulation is a Vietoris bisimulation. As a corollary, we show that the collection of Vietoris bisimulations between two descriptive models forms a complete lattice. Finally, we provide a game-theoretic characterization of Vietoris bisimilarity.},
author = {Bezhanishvili, Nick and Fontaine, Ga{\"{e}}lle M.M. and Venema, Yde},
doi = {10.1093/logcom/exn091},
file = {:Users/liang-tingchen/Dropbox/References/Bezhanishvili, Fontaine, Venema - 2010 - Vietoris Bisimulations.pdf:pdf},
issn = {0955-792X},
journal = {Journal of Logic and Computation},
keywords = {Modal logic,Vietoris construction,bisimulation,coalgebra,descriptive frame},
month = {oct},
number = {5},
pages = {1017--1040},
title = {{Vietoris Bisimulations}},
url = {http://logcom.oxfordjournals.org/cgi/doi/10.1093/logcom/exn091},
volume = {20},
year = {2010}
}
@article{Pollack2012,
abstract = {This paper is about completely formal representation of languages$\backslash$nwith binding. We have previously written about a representation following$\backslash$nan approach going back to Frege, based on first-order syntax using$\backslash$ndistinct syntactic classes for locally bound variables vs. global$\backslash$nor free variables (Sato and Pollack, J Symb Comput 45:598–616, 2010$\backslash$n). The present paper differs from our previous work by being more$\backslash$nabstract. Whereas we previously gave a particular concrete function$\backslash$nfor canonically choosing the names of binders, here we characterize$\backslash$nabstractly the properties required of such a choice function to guarantee$\backslash$ncanonical representation, and focus on the metatheory of the representation,$\backslash$nproving that it is in substitution preserving isomorphism with the$\backslash$nnominal Isabelle representation of pure lambda terms. This metatheory$\backslash$nis formalized in Isabelle/HOL. The final section outlines a formalization$\backslash$nin Matita of a challenging language with multiple binding and simultaneous$\backslash$nsubstitution. The Isabelle and Matita proof files are available online.},
author = {Pollack, Randy and Sato, Masahiko and Ricciotti, Wilmer},
doi = {10.1007/s10817-011-9229-y},
file = {:Users/liang-tingchen/Dropbox/References/Pollack, Sato, Ricciotti - 2012 - A Canonical Locally Named Representation of Binding.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
keywords = {Binding,Formal proof,Lambda calculus},
month = {aug},
number = {2},
pages = {185--207},
title = {{A Canonical Locally Named Representation of Binding}},
url = {http://link.springer.com/10.1007/s10817-011-9229-y},
volume = {49},
year = {2012}
}
@article{Adamek2014,
abstract = {The category of all monads over many-sorted sets (and over other "set-like" categories) is proved to have coequalizers and strong cointersections. And a general diagram has a colimit whenever all the monads involved preserve monomorphisms and have arbitrarily large joint pre-fixpoints. In contrast, coequalizers fail to exist e.g. for monads over the (presheaf) category of graphs. For more general categories we extend the results on coproducts of monads from [2]. We call a monad separated if, when restricted to monomorphisms, its unit has a complement. We prove that every collection of separated monads with arbitrarily large joint pre-fixpoints has a coproduct. And a concrete formula for these coproducts is presented.},
archivePrefix = {arXiv},
arxivId = {1409.3805},
author = {Ad{\'{a}}mek, Jiř{\'{i}}},
eprint = {1409.3805},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek - 2014 - Colimits of Monads.pdf:pdf},
journal = {ArXiv e-prints},
month = {sep},
pages = {1--26},
title = {{Colimits of Monads}},
url = {http://arxiv.org/abs/1409.3805},
year = {2014}
}
@incollection{Rot2013,
abstract = {Bisimulation-up-to enhances the bisimulation proof method for process equivalence. We present its generalization from labelled transition systems to arbitrary coalgebras, and show that for a large class of systems, enhancements such as bisimulation up to bisimilarity, up to equivalence and up to context are sound proof techniques. This allows for simplified bisimulation proofs for many different types of state-based systems.},
author = {Rot, Jurriaan and Bonsangue, Marcello M. and Rutten, Jan J.M.M.},
booktitle = {SOFSEM 2013: Theory and Practice of Computer Science},
doi = {10.1007/978-3-642-35843-2_32},
editor = {{van Emde Boas}, Peter and Groen, Frans C. A. and F., Italiano Giuseppe and Nawrocki, Jerzy and Sack, Harald},
file = {:Users/liang-tingchen/Dropbox/References/Rot, Bonsangue, Rutten - 2013 - Coalgebraic Bisimulation-up-to.pdf:pdf},
pages = {1--13},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Coalgebraic Bisimulation-up-to}},
year = {2013}
}
@article{Shafer2015,
abstract = {The theory of belief functions is a generalization of probability theory; a belief function is a set function more general than a probability measure but whose values can still be interpreted as degrees of belief. Dempster's rule of combination is a rule for combining two or more belief functions; when the belief functions combined are based on distinct or "independent" sources of evidence, the rule corresponds intuitively to the pooling of evidence. As a special case, the rule yields a rule of conditioning which generalizes the usual rule for conditioning probability measures. The rule of combination was studied extensively, but only in the case of finite sets of possibilities, in the author's monograph A Mathematical Theory of Evidence. The present paper describes the rule for general, possibly infinite, sets of possibilities. We show that the rule preserves the regularity conditions of continuity and condensability, and we investigate the two distinct generalizations of probabilistic independence which the rule suggests.},
author = {Shafer, Glenn},
doi = {10.1016/j.ijar.2015.12.009},
file = {:Users/liang-tingchen/Dropbox/References/Shafer - 2016 - Dempster's rule of combination.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Belief function,Cognitive independence,Conditioning,Dempster's rule,Evidential independence,Upper probabilities},
month = {dec},
pages = {26--40},
publisher = {Elsevier Inc.},
title = {{Dempster's rule of combination}},
url = {http://dx.doi.org/10.1016/j.ijar.2015.12.009 http://linkinghub.elsevier.com/retrieve/pii/S0888613X15001978},
volume = {79},
year = {2016}
}
@article{McLarty1986,
author = {McLarty, Colin},
doi = {10.1016/0022-4049(86)90100-3},
file = {:Users/liang-tingchen/Dropbox/References/McLarty - 1986 - Left exact logic.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jan},
pages = {63--66},
title = {{Left exact logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404986901003},
volume = {41},
year = {1986}
}
@article{Moss1999a,
author = {Moss, Lawrence S.},
doi = {10.1016/S0168-0072(99)00027-5},
file = {:Users/liang-tingchen/Dropbox/References/Moss - 1999 - Erratum to “coalgebraic logic”.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {characterization,greatest fixed point,infinitary modal logic},
month = {aug},
number = {1-3},
pages = {241--259},
title = {{Erratum to “coalgebraic logic”}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168007299000275},
volume = {99},
year = {1999}
}
@incollection{Emerson1994,
abstract = {We give a comprehensive and unifying survey of the theoretical aspects of Temporal and Modal Logic.},
author = {Emerson, E. Allen},
booktitle = {Handbook of Theoretical Computer Science},
editor = {van Leeuwen, J.},
file = {:Users/liang-tingchen/Dropbox/References/Emerson - 1990 - Temporal and modal logic.pdf:pdf},
isbn = {9780262220392},
pages = {995--1072},
publisher = {MIT Press},
title = {{Temporal and modal logic}},
url = {http://dl.acm.org/citation.cfm?id=114907},
volume = {B},
year = {1990}
}
@article{Weirich2019,
abstract = {Modern Haskell supports zero-cost coercions, a mechanism where types that share the same run-time representation may be freely converted between. To make sure such conversions are safe and desirable, this feature relies on a mechanism of roles to prohibit invalid coercions. In this work, we show how to integrate roles with dependent type systems and prove, using the Coq proof assistant, that the resulting system is sound. We have designed this work as a foundation for the addition of dependent types to the Glasgow Haskell Compiler, but we also expect that it will be of use to designers of other dependently-typed languages who might want to adopt Haskell's safe coercions feature.},
archivePrefix = {arXiv},
arxivId = {1905.13706},
author = {Weirich, Stephanie and Choudhury, Pritam and Voizard, Antoine and Eisenberg, Richard A.},
doi = {10.1145/3341705},
eprint = {1905.13706},
file = {:Users/liang-tingchen/Dropbox/References/Weirich et al. - 2019 - A role for dependent types in Haskell.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Dependent Types,Haskell},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{A role for dependent types in Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341705},
volume = {3},
year = {2019}
}
@inproceedings{Reynolds1983,
author = {Reynolds, John C.},
booktitle = {Information Processing 83},
editor = {Mason, R. E. A.},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds - 1983 - Types, abstraction, and parametric Polymorphism.pdf:pdf},
pages = {513--513},
publisher = {Elsevier Science Publishers},
title = {{Types, abstraction, and parametric Polymorphism}},
year = {1983}
}
@incollection{Jacobs2002a,
abstract = {An introduction to coalgebraic specification is presented via examples. A coalgebralc specification describes a collection of coalgebras satisfying certain assertions. It is thus an axiomatic description of a particular class of mathematical structures. Such specifications are especially suitable for state-based dynamical systems in general, and for classes in object-oriented programming languages in particular. This chapter will gradually introduce the notions of bisimilarity, invariance, component classes, temporal logic and refinement in a coalgebraic setting. Besides the running example of the coalgebraic specification of (possibly infinite) binary trees, a specification of Peterson's mutual exclusion algorithm is elaborated in detail.},
annote = {NULL},
author = {Jacobs, Bart},
booktitle = {Algebraic and Coalgebraic Methods in the Mathematics of Program Construction},
doi = {10.1007/3-540-47797-7_7},
editor = {Backhouse, Roland and Crole, Roy and Gibbons, Jeremy},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2002 - Exercises in coalgebraic specification.pdf:pdf},
isbn = {3-540-43613-8},
pages = {237--280},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Exercises in coalgebraic specification}},
url = {http://portal.acm.org/citation.cfm?id=763795},
volume = {2297},
year = {2002}
}
@article{Benthem1994,
author = {van Benthem, Johan and Bergstra, Jan},
doi = {10.1007/BF01160018},
file = {:Users/liang-tingchen/Dropbox/References/van Benthem, Bergstra - 1994 - Logic of transition systems.pdf:pdf},
issn = {0925-8531},
journal = {Journal of Logic, Language and Information},
month = {dec},
number = {4},
pages = {247--283},
title = {{Logic of transition systems}},
url = {http://link.springer.com/10.1007/BF01160018},
volume = {3},
year = {1994}
}
@article{Carboni1998,
author = {Carboni, Aurelio and Kelly, Gregory Maxwell and Verity, Dominic and Wood, Richard J.},
file = {:Users/liang-tingchen/Dropbox/References/Carboni et al. - 1998 - A 2-categorical approach to change of base and geometric morphisms II.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Adjunction,Equipment,Span},
number = {5},
pages = {82--136},
title = {{A 2-categorical approach to change of base and geometric morphisms II}},
volume = {4},
year = {1998}
}
@article{Sangiorgi2006,
abstract = {A process M terminates if it cannot produce an infinite sequence of reductions M $\tau$ −→ M 1 $\tau$ −→ M 2 . . .. Termination is a useful property in concurrency. For instance, a terminating applet, when loaded on a machine, will not run for ever, possibly absorbing all computing},
author = {SANGIORGI, DAVIDE},
doi = {10.1017/S0960129505004810},
file = {:Users/liang-tingchen/Dropbox/References/SANGIORGI - 2006 - Termination of processes.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {feb},
number = {01},
pages = {1},
title = {{Termination of processes}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129505004810},
volume = {16},
year = {2006}
}
@inproceedings{Jarvi2011,
abstract = {Affiliated with the 16th ACM SIGPLAN International Conference on Functional Programming (ICFP 2011).},
address = {New York, New York, USA},
author = {Hinze, Ralf and Wu, Nicolas},
booktitle = {Proceedings of the seventh ACM SIGPLAN workshop on Generic programming - WGP '11},
doi = {10.1145/2036918.2036926},
file = {:Users/liang-tingchen/Dropbox/References/Hinze, Wu - 2011 - Towards a categorical foundation for generic programming.pdf:pdf},
isbn = {9781450308618},
keywords = {category theory,generic programming,slice category},
pages = {47},
publisher = {ACM Press},
title = {{Towards a categorical foundation for generic programming}},
url = {http://dl.acm.org/citation.cfm?doid=2036918.2036926},
year = {2011}
}
@book{Nordstrom1990,
author = {Nordstr{\"{o}}m, Bengt and Petersson, Kent and Smith, Jan M.},
booktitle = {Evaluation},
file = {:Users/liang-tingchen/Dropbox/References/Nordstr{\"{o}}m, Petersson, Smith - 1990 - Programming in Martin-L{\"{o}}f Type Theory An Introduction.pdf:pdf},
isbn = {9780198538141},
publisher = {Oxford University Press},
title = {{Programming in Martin-L{\"{o}}f Type Theory: An Introduction}},
url = {http://www.cse.chalmers.se/research/group/logic/},
year = {1990}
}
@incollection{Kinoshita1996,
author = {Kinoshita, Y. and Power, A. J.},
booktitle = {Extensions of Logic Programming. ELP 1996},
doi = {10.1007/3-540-60983-0_12},
editor = {Dyckhoff, Roy and Herre, Heinrich and Schroeder-Heister, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Kinoshita, Power - 1996 - A fibrational semantics for logic programs.pdf:pdf},
pages = {177--191},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A fibrational semantics for logic programs}},
url = {http://link.springer.com/10.1007/3-540-60983-0{\_}12},
volume = {1050},
year = {1996}
}
@incollection{Carton2008,
author = {Carton, Olivier and Perrin, Dominique and Pin, Jean-{\'{E}}ric},
booktitle = {Logic and Automata: History and Perspectives},
editor = {Flum, Jörg and Grädel, Erich and Wilke, Thomas},
file = {:Users/liang-tingchen/Dropbox/References/Carton, Perrin, Pin - 2008 - Automata and semigroups recognizing infinite words.pdf:pdf},
isbn = {978 90 5356 576 6},
pages = {133--167},
publisher = {Amsterdam University Press},
series = {Texts in Logic and Games},
title = {{Automata and semigroups recognizing infinite words}},
year = {2008}
}
@incollection{Gheri2017,
author = {Gheri, Lorenzo and Popescu, Andrei},
booktitle = {Interactive Theorem Proving. ITP 2017},
doi = {10.1007/978-3-319-66107-0_16},
editor = {Ayala-Rinc{\'{o}}n, Mauricio and Mu{\~{n}}oz, C{\'{e}}sar A.},
file = {:Users/liang-tingchen/Dropbox/References/Gheri, Popescu - 2017 - A Formalized General Theory of Syntax with Bindings.pdf:pdf},
isbn = {9783319661070},
pages = {241--261},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Formalized General Theory of Syntax with Bindings}},
url = {http://link.springer.com/10.1007/978-3-319-66107-0{\_}16},
volume = {10499},
year = {2017}
}
@inproceedings{Accattoli2019,
abstract = {The (untyped) $\lambda$-calculus is almost 90 years old. And yet – we argue here – its study is far from being over. The paper is a bird's eye view of the questions the author worked on in the last few years: how to measure the complexity of $\lambda$-terms, how to decompose their evaluation, how to implement it, and how all this varies according to the evaluation strategy. The paper aims at inducing a new way of looking at an old topic, focussing on high-level issues and perspectives.},
author = {Accattoli, Beniamino},
booktitle = {4th International Conference on Formal Structures for Computation and Deduction (FSCD 2019)},
doi = {10.4230/LIPIcs.FSCD.2019.1},
editor = {Geuvers, Herman},
file = {:Users/liang-tingchen/Dropbox/References/Accattoli - 2019 - A fresh look at the $\lambda$-calculus.pdf:pdf},
isbn = {9783959771078},
issn = {18688969},
keywords = {Abstract machines,Rewriting,Sharing,Type systems,$\lambda$-calculus},
pages = {1:1--1:20},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
title = {{A fresh look at the $\lambda$-calculus}},
volume = {131},
year = {2019}
}
@article{Ghani2012,
author = {Ghani, Neil and Johann, Patricia and Fumex, Clement},
doi = {10.2168/LMCS-8(2:12)2012},
editor = {Veith, Helmut},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Johann, Fumex - 2012 - Generic fibrational induction.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {jun},
number = {2},
pages = {1--27},
title = {{Generic fibrational induction}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=821},
volume = {8},
year = {2012}
}
@inproceedings{Nogatz2018,
address = {New York, New York, USA},
author = {Nogatz, Falco and Kalkus, Jona and Seipel, Dietmar},
booktitle = {Proceedings of the 20th International Symposium on Principles and Practice of Declarative Programming - PPDP '18},
doi = {10.1145/3236950.3236966},
file = {:Users/liang-tingchen/Dropbox/References/Nogatz, Kalkus, Seipel - 2018 - Web-based Visualisation for Definite Clause Grammars Using Prolog Meta-Interpreters.pdf:pdf},
isbn = {9781450364416},
keywords = {definite clause grammar,interpreter,meta,prolog,term expan-},
pages = {1--10},
publisher = {ACM Press},
title = {{Web-based Visualisation for Definite Clause Grammars Using Prolog Meta-Interpreters}},
url = {http://dl.acm.org/citation.cfm?doid=3236950.3236966},
year = {2018}
}
@incollection{Bonsangue2013,
address = {Warsaw},
author = {Bonsangue, Marcello M. and Hansen, Helle Hvid and Kurz, Alexander and Rot, Jurriaan},
booktitle = {5th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-40206-7_9},
editor = {Heckel, Reiko and Milius, Stefan},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue et al. - 2013 - Presenting Distributive Laws.pdf:pdf},
isbn = {978-3-642-40205-0},
number = {639},
pages = {95--109},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Presenting Distributive Laws}},
year = {2013}
}
@article{Pickering2017,
abstract = {Data accessors allow one to read and write components of a data structure, such as the fields of a record, the variants of a union, or the elements of a container. These data accessors are collectively known as optics; they are fundamental to programs that manipulate complex data. Individual data accessors for simple data structures are easy to write, for example as pairs of 'getter' and 'setter' methods. However, it is not obvious how to combine data accessors, in such a way that data accessors for a compound data structure are composed out of smaller data accessors for the parts of that structure. Generally, one has to write a sequence of statements or declarations that navigate step by step through the data structure, accessing one level at a time—which is to say, data accessors are traditionally not first-class citizens, combinable in their own right. We present a framework for modular data access, in which individual data accessors for simple data struc-tures may be freely combined to obtain more complex data accessors for compound data structures. Data accessors become first-class citizens. The framework is based around the notion of profunctors, a flexible gen-eralization of functions. The language features required are higher-order functions ('lambdas' or 'closures'), parametrized types ('generics' or 'abstract types') of higher kind, and some mechanism for separating inter-faces from implementations ('abstract classes' or 'modules'). We use Haskell as a vehicle in which to present our constructions, but other languages such as Scala that provide the necessary features should work just as well. We provide implementations of all our constructions, in the form of a literate program: the manuscript file for the paper is also the source code for the program, and the extracted code is available separately for evaluation. We also prove the essential properties, demonstrating that our profunctor-based representations are precisely equivalent to the more familiar concrete representations. Our results should pave the way to simpler ways of writing programs that access the components of compound data structures.},
author = {Pickering, Matthew and Gibbons, Jeremy and Wu, Nicolas},
doi = {10.22152/programming-journal.org/2017/1/7},
file = {:Users/liang-tingchen/Dropbox/References/Pickering, Gibbons, Wu - 2017 - Profunctor Optics Modular Data Accessors.pdf:pdf},
issn = {2473-7321},
journal = {The Art, Science, and Engineering of Programming},
keywords = {Program Families,Variability-related Transformati,and engineering of programming,program families,science,static analysis,the art,variability-related transformations,verification},
month = {apr},
number = {2},
pages = {1--25},
title = {{Profunctor Optics: Modular Data Accessors}},
url = {http://programming-journal.org/2017/1/7},
volume = {1},
year = {2017}
}
@article{Birkedal2002,
author = {Birkedal, Lars},
doi = {10.2178/bsl/1182353873},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal - 2002 - A General Notion of Realizability.pdf:pdf},
journal = {Bulletin of Symbolic Logic},
number = {2},
pages = {266--282},
title = {{A General Notion of Realizability}},
url = {https://www.cambridge.org/core/journals/bulletin-of-symbolic-logic/article/general-notion-of-realizability/1E9CEDE9852EB984EA59FC35812CB0F8},
volume = {8},
year = {2002}
}
@article{Dupre2009,
abstract = {By basing Bayesian probability theory on five axioms, we can give a trivial proof of Cox's Theorem on the product rule and sum rule for conditional plausibility without assuming continuity or differentiablity of plausibility. Instead, we extend the notion of plausibility to apply to unknowns, giving them plausi-ble values. Thus, we combine the best aspects of two approaches to Bayesian probability theory, namely the Cox-Jaynes theory and the de Finetti theory.},
author = {Dupr{\'{e}}, Maurice J. and Tipler, Frank J.},
doi = {10.1214/09-BA422},
file = {:Users/liang-tingchen/Dropbox/References/Dupr{\'{e}}, Tipler - 2009 - New axioms for rigorous Bayesian probability.pdf:pdf},
isbn = {1936-0975},
issn = {1936-0975},
journal = {Bayesian Analysis},
keywords = {Axiomatic bayesian probability,Cox,De Finetti,Jaynes,Product rule,Sum rule},
month = {sep},
number = {3},
pages = {599--606},
title = {{New axioms for rigorous Bayesian probability}},
url = {http://projecteuclid.org/euclid.ba/1340369856},
volume = {4},
year = {2009}
}
@incollection{Osdol1971,
author = {Osdol, Donovan H. Van},
booktitle = {Exact Categories and Categories of Sheaves},
doi = {10.1007/BFb0058582},
file = {:Users/liang-tingchen/Dropbox/References/Osdol - 1971 - Sheaves in regular categories.pdf:pdf},
isbn = {978-3-540-05678-2},
pages = {223--239},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Sheaves in regular categories}},
year = {1971}
}
@article{Lee1998,
abstract = {The Hindley/Milner let-polymorphic type inference system has two different algorithms: one is the de facto standard Algorithm W that is bottom-up (or context-insensitive), and the other is a folklore algorithm that is top-down (or context-sensitive). Because the latter algorithm has not been formally presented with its soundness and completeness proofs, and its relation with the W algorithm has not been rigorously investigated, its use in place of (or in combination with) W is not well founded. In this article, we formally define the context-sensitive, top-down type inference algorithm (named M), prove its soundness and completeness, and show a distinguishing property that M always stops earlier than W if the input program is ill typed. Our proofs can be seen as theoretical justifications for various type-checking strategies being used in practice.},
author = {Lee, Oukseh and Yi, Kwangkeun},
doi = {10.1145/291891.291892},
file = {:Users/liang-tingchen/Dropbox/References/Lee, Yi - 1998 - Proofs about a folklore let-polymorphic type inference algorithm.pdf:pdf},
issn = {01640925},
journal = {ACM Transactions on Programming Languages and Systems},
month = {jul},
number = {4},
pages = {707--723},
title = {{Proofs about a folklore let-polymorphic type inference algorithm}},
url = {http://portal.acm.org/citation.cfm?doid=291891.291892},
volume = {20},
year = {1998}
}
@inproceedings{berger_et_al:LIPIcs:2017:7277,
abstract = {Homogeneous generative meta-programming (HGMP) enables the generation of program fragments at compile-time or run-time. We present the first foundational calculus which can model powerful HGMP languages such as Template Haskell. The calculus is designed such that we can gradually enhance it with the features needed to model many of the advanced features of real languages. As a demonstration of the flexibility of our approach, we also provide a simple type system for the calculus.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Modelling Homogeneous Generative Meta-Programming - Berger, Martin; Tratt, Laurence; Urban, Christian)

Keywords: Formal Methods, Meta-Programming, Operational Semantics, Types, Quasi-Quotes, Abstract Syntax Trees},
author = {Berger, Martin and Tratt, Laurence and Urban, Christian},
booktitle = {31st European Conference on Object-Oriented Programming (ECOOP 2017)},
doi = {10.4230/LIPIcs.ECOOP.2017.5},
editor = {M{\"{u}}ller, Peter},
file = {:Users/liang-tingchen/Dropbox/References//Berger, Tratt, Urban - 2017 - Modelling Homogeneous Generative Meta-Programming.pdf:pdf},
isbn = {978-3-95977-035-4},
issn = {1868-8969},
keywords = {Abstract Syntax Trees.,Formal Methods,Meta-Programming,Operational Semantics,Quasi-Quotes,Types},
number = {5},
pages = {5:1----5:23},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Modelling Homogeneous Generative Meta-Programming}},
url = {http://drops.dagstuhl.de/opus/volltexte/2017/7277},
volume = {74},
year = {2017}
}
@incollection{Sano2011a,
author = {Sano, Katsuhiko},
booktitle = {Algebra and Coalgebra in Computer Science},
doi = {10.1007/978-3-642-22944-2_23},
editor = {Corradini, Andrea and Klin, Bartek and C{\^{i}}rstea, Corina},
file = {:Users/liang-tingchen/Dropbox/References/Sano - 2011 - Generalized product of coalgebraic hybrid logics.pdf:pdf},
pages = {329--343},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Generalized product of coalgebraic hybrid logics}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-22944-2{\_}23},
year = {2011}
}
@article{Tholen2016a,
abstract = {For a quantaloid {\$}\backslashmathcal{\{}Q{\}}{\$}, considered as a bicategory, Walters introduced categories enriched in {\$}\backslashmathcal{\{}Q{\}}{\$}. Here we extend the study of monad-quantale-enriched categories of the past fifteen years by introducing monad-quantaloid-enriched categories. We do so by making lax distributive laws of a monad {\$}\backslashmathbb{\{}T{\}}{\$} over the discrete presheaf monad of the small quantaloid {\$}\backslashmathcal{\{}Q{\}}{\$} the primary data of the theory, rather than the lax monad extensions of {\$}\backslashmathbb{\{}T{\}}{\$} to the category of {\$}\backslashmathcal{\{}Q{\}}{\$}-relations that they equivalently describe. The central piece of the paper establishes a Galois correspondence between such lax distributive laws and lax Eilenberg-Moore {\$}\backslashmathbb{\{}T{\}}{\$}-algebra structures on the set of discrete presheaves over the object set of {\$}\backslashmathcal{\{}Q{\}}{\$}. We give a precise comparison of these structures with the more restrictive notion introduced by Hofmann in the case of a commutative quantale, called natural topological theories here, and describe the lax monad extensions introduced by him as minimal. Throughout the paper, a variety of old and new examples of ordered, metric and topological structures illustrate the theory developed, which includes the consideration of algebraic functors and change-of-base functors in full generality.},
archivePrefix = {arXiv},
arxivId = {1603.06251},
author = {Tholen, Walter},
eprint = {1603.06251},
file = {:Users/liang-tingchen/Dropbox/References/Tholen - 2016 - Lax Distributive Laws for Topology, I.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {18 c15,18c20,18d99,2010 msc,algebraic functor,change-of-base functor,discrete presheaf monad,lax,lax distributive law,lax monad extension,monad,monad-quantaloid-enriched category,natural,quantale,quantaloid,topological theory,$\lambda$ -algebra},
month = {mar},
pages = {1--32},
title = {{Lax Distributive Laws for Topology, I}},
url = {http://arxiv.org/abs/1603.06251},
year = {2016}
}
@article{Jakl2016,
author = {Jakl, Tom{\'{a}}{\v{s}} and Jung, Achim and Pultr, Ale{\v{s}}},
doi = {10.1016/j.entcs.2016.09.039},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {bilattices,bitopological spaces,d-frames,four-valued logic,nd-frames},
month = {oct},
pages = {201--219},
title = {{Bitopology and Four-valued Logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066116300895},
volume = {325},
year = {2016}
}
@article{Benton1998,
abstract = {Moggi's computational lambda calculus is a metalanguage for denotational semantics which arose from the observation that many different notions of computation have the categorical structure of a strong monad on a cartesian closed category. In this paper we show that the computational lambda calculus also arises naturally as the term calculus corresponding (by the Curry–Howard correspondence) to a novel intuitionistic modal propositional logic. We give natural deduction, sequent calculus and Hilbert-style presentations of this logic and prove strong normalisation and confluence results.},
author = {BENTON, P. N. and BIERMAN, G. M. and {DE PAIVA}, V. C. V.},
doi = {10.1017/S0956796898002998},
file = {:Users/liang-tingchen/Dropbox/References/BENTON, BIERMAN, DE PAIVA - 1998 - Computational types from a logical perspective.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {177--193},
publisher = {Swansea University Libraries},
title = {{Computational types from a logical perspective}},
url = {https://www.cambridge.org/core/product/identifier/S0956796898002998/type/journal{\_}article},
volume = {8},
year = {1998}
}
@article{Kurz2010,
author = {Kurz, Alexander and Petrişan, Daniela},
doi = {10.1016/j.ic.2009.11.007},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Petrişan - 2010 - Presenting functors on many-sorted varieties and applications.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {dec},
number = {12},
pages = {1421--1446},
title = {{Presenting functors on many-sorted varieties and applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540110000970},
volume = {208},
year = {2010}
}
@inproceedings{Allais2019,
abstract = {Agda's standard library struggles in various places with nary functions and relations. It introduces congruence and substitution operators for functions of arities one and two, and provides users with convenient combinators for manipulating indexed families of arity exactly one. After a careful analysis of the kinds of problems the unifier can easily solve, we design a unifier-friendly representation of n-ary functions. This allows us to write generic programs acting on n-ary functions which automatically reconstruct the representation of their inputs' types by unification. In particular, we can define fully level polymorphic n-ary versions of congruence, substitution and the combinators for indexed families, all requiring minimal user input.},
address = {New York, New York, USA},
author = {Allais, Guillaume},
booktitle = {Proceedings of the 4th ACM SIGPLAN International Workshop on Type-Driven Development - TyDe 2019},
doi = {10.1145/3331554.3342604},
file = {:Users/liang-tingchen/Dropbox/References/Allais - 2019 - Generic level polymorphic n-ary functions.pdf:pdf},
isbn = {9781450368155},
keywords = {Agda,Arity-generic programming,Dependent types,Universe polymorphism},
pages = {14--26},
publisher = {ACM Press},
title = {{Generic level polymorphic n-ary functions}},
url = {http://dl.acm.org/citation.cfm?doid=3331554.3342604},
year = {2019}
}
@article{Athorne2012,
abstract = {The relative cell complexes with respect to a generating set of cofibrations are an important class of morphisms in any model structure. In the particular case of the standard (algebraic) model structure on {\$}\backslashtextbf{\{}Top{\}}{\$}, we give a new expression of these morphisms by defining a category of relative cell complexes, which has a forgetful functor to the arrow category. This allows us to prove a conjecture of Richard Garner: considering the algebraic weak factorisation system given in that algebraic model structure between cofibrations and trivial fibrations, we show that the category of relative cell complexes is equivalent to the category of coalgebras.},
archivePrefix = {arXiv},
arxivId = {1202.6034},
author = {Athorne, Thomas},
eprint = {1202.6034},
file = {:Users/liang-tingchen/Dropbox/References/Athorne - 2012 - The coalgebraic structure of cell complexes.pdf:pdf},
journal = {ArXiv e-prints},
month = {feb},
pages = {28},
title = {{The coalgebraic structure of cell complexes}},
url = {http://arxiv.org/abs/1202.6034},
year = {2012}
}
@article{BREUGEL1996,
author = {van Breugel, Franck},
doi = {10.1111/j.1749-6632.1996.tb49160.x},
file = {:Users/liang-tingchen/Dropbox/References/van Breugel - 1996 - A theory of metric labelled transition systems.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
keywords = {and phrases,banach,compactly branching,complete metric space,finitely branching,labelled transition system,metric labelled,s theorem,transition system,unique},
month = {dec},
pages = {69--87},
title = {{A theory of metric labelled transition systems}},
url = {http://doi.wiley.com/10.1111/j.1749-6632.1996.tb49160.x},
volume = {806},
year = {1996}
}
@incollection{Li1994,
author = {Li, Benjamin Z},
booktitle = {Programming Languages and Systems — ESOP '94Donald Sannella},
doi = {10.1007/3-540-57880-3_25},
editor = {Sannella, Donald},
file = {:Users/liang-tingchen/Dropbox/References/Li - 1994 - A $\pi$-calculus specification of prolog.pdf:pdf},
pages = {379--393},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A $\pi$-calculus specification of prolog}},
url = {http://link.springer.com/10.1007/3-540-57880-3{\_}25},
volume = {788},
year = {1994}
}
@article{Sojakova2015,
abstract = {Homotopy Type Theory is a new field of mathematics based on the surprising and elegant correspondence between Martin-Lofs constructive type theory and abstract homotopy theory. We have a powerful interplay between these disciplines - we can use geometric intuition to formulate new concepts in type theory and, conversely, use type-theoretic machinery to verify and often simplify existing mathematical proofs. A crucial ingredient in this new system are higher inductive types, which allow us to represent objects such as spheres, tori, pushouts, and quotients. We investigate a variant of higher inductive types whose computational behavior is determined up to a higher path. We show that in this setting, higher inductive types are characterized by the universal property of being a homotopy-initial algebra.},
archivePrefix = {arXiv},
arxivId = {1402.0761},
author = {Sojakova, Kristina},
doi = {10.1145/2775051.2676983},
eprint = {1402.0761},
file = {:Users/liang-tingchen/Dropbox/References/Sojakova - 2015 - Higher Inductive Types as Homotopy-Initial Algebras.pdf:pdf},
isbn = {9781450333009},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {higher induc-,homotopy type theory,homotopy-initial algebra,tive type,w-suspension},
month = {jan},
number = {1},
pages = {31--42},
title = {{Higher Inductive Types as Homotopy-Initial Algebras}},
url = {http://dl.acm.org/citation.cfm?doid=2775051.2676983},
volume = {50},
year = {2015}
}
@article{Vitale1994,
author = {Vitale, Enrico M.},
file = {:Users/liang-tingchen/Dropbox/References/Vitale - 1994 - On the characterization of monadic categories over set.pdf:pdf},
journal = {Cahiers de Topologie et G{\'{e}}om{\'{e}}trie Diff{\'{e}}rentielle Cat{\'{e}}goriques},
number = {4},
pages = {351--358},
title = {{On the characterization of monadic categories over set}},
url = {http://www.numdam.org/item?id=CTGDC{\_}1994{\_}{\_}35{\_}4{\_}351{\_}0},
volume = {35},
year = {1994}
}
@article{Galmiche2000,
abstract = {We introduce the main concepts and problems in the theory of proof-search in type-theoretic languages and survey some specific, connected topics. We do not claim to cover all of the theoretical and implementation issues in the study of proof-search in type-theoretic languages; rather, we present some key ideas and problems, starting from well-motivated points of departure such as a definition of a type-theoretic language or the relationship between languages and proof-objects. The strong connections between different proof-search methods in logics, type theories and logical frameworks, together with their impact on programming and implementation issues, are central in this context. {\textcopyright} 2000 Elsevier Science B.V. All rights reserved.},
author = {Galmiche, Didier and Pym, David J.},
doi = {10.1016/S0304-3975(99)00169-3},
file = {:Users/liang-tingchen/Dropbox/References/Galmiche, Pym - 2000 - Proof-search in type-theoretic languages an introduction.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Logical frameworks,Logics,Proof-objects,Proof-search,Semantics,Type theory,Type-theoretic languages},
month = {feb},
number = {1-2},
pages = {5--53},
title = {{Proof-search in type-theoretic languages: an introduction}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397599001693},
volume = {232},
year = {2000}
}
@article{Antoniou2000,
abstract = {Recently there has been increased interest in logic programming-based default reasoning approaches which are not using negation-as-failure in their object language. Instead, default reasoning is modelled by rules and a priority relation among them. In this paper we compare the expressive power of two approaches in this family of logics. Defeasible Logic, and sceptical Logic Programming without Negation as Failure (LPwNF). Our results show that the former has a strictly stronger expressive power. The difference is caused by the latter logic's failure to capture the idea of teams of rules supporting a specific conclusion.},
author = {Antoniou, G. and Maher, Michael J. and Billington, D.},
doi = {10.1016/S0743-1066(99)00060-6},
file = {:Users/liang-tingchen/Dropbox/References/Antoniou, Maher, Billington - 2000 - Defeasible logic versus Logic Programming without Negation as Failure.pdf:pdf},
issn = {07431066},
journal = {The Journal of Logic Programming},
keywords = {defeasible logic,logic programming},
month = {jan},
number = {1},
pages = {47--57},
title = {{Defeasible logic versus Logic Programming without Negation as Failure}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0743106699000606},
volume = {42},
year = {2000}
}
@inproceedings{mannaa_et_al:LIPIcs:2018:9193,
abstract = {Clocked Type Theory (CloTT) is a type theory for guarded recursion useful for programming with coinductive types, allowing productivity to be encoded in types, and for reasoning about advanced programming language features using an abstract form of step-indexing. CloTT has previously been shown to enjoy a number of syntactic properties including strong normalisation, canonicity and decidability of type checking. In this paper we present a denotational semantics for CloTT useful, e.g., for studying future extensions of CloTT with constructions such as path types. The main challenge for constructing this model is to model the notion of ticks used in CloTT for coinductive reasoning about coinductive types. We build on a category previously used to model guarded recursion, but in this category there is no object of ticks, so tick-assumptions in a context can not be modelled using standard tools. Instead we show how ticks can be modelled using adjoint functors, and how to model the tick constant using a semantic substitution.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (The Clocks They Are Adjunctions Denotational Semantics for Clocked Type Theory - Mannaa, Bassel; M$\backslash$ogelberg, Rasmus Ejlers)

Keywords: Guarded type theory, Coinduction, Presheaf model, Clocked type theory, Dependent adjunction},
archivePrefix = {arXiv},
arxivId = {1804.06687},
author = {Mannaa, Bassel and M{\o}gelberg, Rasmus Ejlers},
booktitle = {3rd International Conference on Formal Structures for Computation and Deduction (FSCD 2018)},
doi = {10.4230/LIPIcs.FSCD.2018.23},
editor = {Kirchner, H{\'{e}}l{\`{e}}ne},
eprint = {1804.06687},
file = {:Users/liang-tingchen/Dropbox/References/Mannaa, M{\o}gelberg - 2018 - The Clocks They Are Adjunctions Denotational Semantics for Clocked Type Theory.pdf:pdf},
isbn = {978-3-95977-077-4},
issn = {1868-8969},
keywords = {Clocked type theory,Coinduction,Dependent adjunction,Guarded type theory,Presheaf model},
number = {23},
pages = {23:1----23:17},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{The Clocks They Are Adjunctions Denotational Semantics for Clocked Type Theory}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/9193},
volume = {108},
year = {2018}
}
@article{Makarov2006,
abstract = {It is well-known that a constructive proof of a $\Pi$20 formula F written as a $\lambda$-term via Curry-Howard isomorphism, computes a function that witnesses F. Murthy [Murthy, C.R., Classical proofs as programs: How, what and why, Technical Report TR 91-1215, Cornell University, Department of Computer Science (1991)] outlined an extension of this result to classical logic, with the double-negation rule mapped to Felleisen's control operator C [Felleisen, M., D. Friedman, E. Kohlbecker and B. Duba, A syntactic theory of sequential control, Theoretical Computer Science 52 (1987), pp. 205-237]. Since C is similar to call/cc operator in Scheme and SML/NJ, this opens a possibility of extracting programs in these languages from classical proofs. However, even though the basic idea has appeared in the literature, there appears to be little work that uses Griffin's extension of the Curry-Howard isomorphism to extract practical programs in real programming languages. In this article, we fill in missing steps in Murthy's argument and extend his method to encompass more interesting proofs by allowing additional ubiquitous inference rules: equality rules, rules for atomic formulas (such as transitivity of {\{}less-than or slanted equal to{\}}), and rules for pairs of dual decidable atoms (such as {\{}less-than or slanted equal to{\}} and {\textgreater}). We illustrate the usefulness of this extension with a complete example of program extraction. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Makarov, Yevgeniy},
doi = {10.1016/j.entcs.2005.11.071},
file = {:Users/liang-tingchen/Dropbox/References/Makarov - 2006 - Practical Program Extraction from Classical Proofs.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Curry-Howard isomorphism,Program extraction,classical logic,control operators,functional programming,lambda calculus},
month = {may},
number = {1 SPEC. ISS.},
pages = {521--542},
publisher = {Elsevier B.V.},
title = {{Practical Program Extraction from Classical Proofs}},
url = {http://dx.doi.org/10.1016/j.entcs.2005.11.071 http://linkinghub.elsevier.com/retrieve/pii/S1571066106002088},
volume = {155},
year = {2006}
}
@inproceedings{Wu2014,
abstract = {Algebraic effect handlers are a powerful means for describing effectful computations. They provide a lightweight and orthogonal technique to define and compose the syntax and semantics of different effects. The semantics is captured by handlers, which are functions that transform syntax trees. Unfortunately, the approach does not support syntax for scoping constructs, which arise in a number of scenarios. While handlers can be used to provide a limited form of scope, we demonstrate that this approach constrains the possible interactions of effects and rules out some desired semantics. This paper presents two different ways to capture scoped constructs in syntax, and shows how to achieve different semantics by reordering handlers. The first approach expresses scopes using the existing algebraic handlers framework, but has some limitations. The problem is fully solved in the second approach where we introduce higher-order syntax.},
address = {New York, New York, USA},
author = {Wu, Nicolas and Schrijvers, Tom and Hinze, Ralf},
booktitle = {Proceedings of the 2014 ACM SIGPLAN symposium on Haskell - Haskell '14},
doi = {10.1145/2633357.2633358},
file = {:Users/liang-tingchen/Dropbox/References/Wu, Schrijvers, Hinze - 2014 - Effect handlers in scope.pdf:pdf},
isbn = {9781450330411},
issn = {03621340},
pages = {1--12},
publisher = {ACM Press},
title = {{Effect handlers in scope}},
url = {http://dl.acm.org/citation.cfm?doid=2633357.2633358},
year = {2014}
}
@article{Visser2019,
abstract = {The logic iGLC is the intuitionistic version of L{\"{o}}b's Logic plus the completeness principle A→□A. In this paper, we prove an arithmetical completeness theorems for iGLC for theories equipped with two provability predicates □ and △ that prove the schemes A→△A and □△S→□S for S∈$\Sigma$ 1 . We provide two salient instances of the theorem. In the first, □ is fast provability and △ is ordinary provability and, in the second, □ is ordinary provability and △ is slow provability. Using the second instance, we reprove a theorem previously obtained by Mohammad Ardeshir and Mojtaba Mojtahedi [1] determining the $\Sigma$ 1 -provability logic of Heyting Arithmetic.},
archivePrefix = {arXiv},
arxivId = {1804.09451},
author = {Visser, Albert and Zoethout, Jetze},
doi = {10.1016/j.apal.2019.02.001},
eprint = {1804.09451},
file = {:Users/liang-tingchen/Dropbox/References/Visser, Zoethout - 2019 - Provability logic and the completeness principle(2).pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {Constructivism,Provability logic},
month = {jun},
number = {6},
pages = {718--753},
publisher = {Elsevier B.V.},
title = {{Provability logic and the completeness principle}},
url = {https://doi.org/10.1016/j.apal.2019.02.001 https://linkinghub.elsevier.com/retrieve/pii/S0168007219300120},
volume = {170},
year = {2019}
}
@article{Ghani2013,
author = {Ghani, Neil and Johann, Patricia and Fumex, Clement},
doi = {10.2168/LMCS-9(3:6)2013},
editor = {Klin, Bartek},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Johann, Fumex - 2013 - Indexed Induction and Coinduction, Fibrationally.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
month = {aug},
number = {3},
pages = {1--31},
title = {{Indexed Induction and Coinduction, Fibrationally}},
url = {https://lmcs.episciences.org/738},
volume = {9},
year = {2013}
}
@incollection{Islam1994,
abstract = {This paper uses category theory to provide a formal mathematical framework for specifying and integrating relational database schemas; it builds on the work of Buneman et al. [2], who develop a domain-theoretic version of relational database theory. We generalize their setting in the following way: we let a schema be a functor V from a category L of attribute names to the category of domains; this reflects the fact that attributes may take values of different types, and that there may be functional constraints between attributes. As an application, we show how the process of schema integration and the resolution of conflicts between schemas may be carried out in a mathematically rigorous setting, using simple concepts from category theory; this proposal is shown to be consistent with the way in which queries on a federated database are processed (by `distributing' them among its component databases).},
address = {Berlin, Heidelberg},
author = {Islam, Amitavo and Phoa, Wesley},
booktitle = {Theoretical Aspects of Computer Software: International Symposium TACS '94 Sendai, Japan, April 19--22, 1994 Proceedings},
doi = {10.1007/3-540-57887-0_118},
editor = {Hagiya, Masami and Mitchell, John C},
file = {:Users/liang-tingchen/Dropbox/References/Islam, Phoa - 1994 - Categorical models of relational databases I Fibrational formulation, schema integration.pdf:pdf},
isbn = {978-3-540-48383-0},
pages = {618--641},
publisher = {Springer Berlin Heidelberg},
title = {{Categorical models of relational databases I: Fibrational formulation, schema integration}},
url = {http://link.springer.com/10.1007/3-540-57887-0{\_}118},
year = {1994}
}
@incollection{Matsuda2018,
abstract = {ficial intelligence; computer architecture; computer software selection and evaluation; distributed computer systems; formal logic; formal model; java; model checking; processors; program compilers; program verification; programming language; semantics; separation logic; software engineering specifications; theorem proving; type; systems verification},
author = {Matsuda, Kazutaka and Wang, Meng},
booktitle = {Programming Languages and Systems. ESOP 2018.},
doi = {10.1007/978-3-319-89884-1_2},
editor = {Ahmed, Amal},
file = {:Users/liang-tingchen/Dropbox/References/Matsuda, Wang - 2018 - HOBiT Programming Lenses Without Using Lens Combinators.pdf:pdf},
isbn = {978-3-319-89883-4},
keywords = {artificial intelligence,computer architecture,computer software selection and evaluation,distributed computer systems,formal logic,formal model,java,model checking,processors,program compilers,program verification,programming language,semantics,separation logic,software engineering specifications,systems verification,theorem proving,type},
pages = {31--59},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{HOBiT: Programming Lenses Without Using Lens Combinators}},
url = {http://link.springer.com/10.1007/978-3-319-89884-1{\_}2},
volume = {10801},
year = {2018}
}
@article{Harmanec1996,
author = {Harmanec, David and Klir, George J and Wang, Zhenyuan},
doi = {10.1016/0888-613X(95)00111-S},
file = {:Users/liang-tingchen/Dropbox/References/Harmanec, Klir, Wang - 1996 - Modal logic interpretation of Dempster-Shafer theory An infinite case.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {1,belief,dempster-shafer theory,dempster-shafer theory and,especially,i n t r,measures,modal logic,necessity measures,o d u c,plausibility measures,possibility measures,possibility the-,possibility theory,t i o n,the idea of connecting},
month = {feb},
number = {2-3},
pages = {81--93},
title = {{Modal logic interpretation of Dempster-Shafer theory: An infinite case}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0888613X9500111S},
volume = {14},
year = {1996}
}
@article{Kupke2008,
abstract = {We generalize some of the central results in automata theory to the abstraction level of coalgebras and thus lay out the foundations of a universal theory of automata operating on infinite objects. Let F be any set functor that preserves weak pullbacks. We show that the class of recognizable languages of F-coalgebras is closed under taking unions, intersections, and projections. We also prove that if a nondeterministic F-automaton accepts some coalgebra it accepts a finite one of the size of the automaton. Our main technical result concerns an explicit construction which transforms a given alternating F-automaton into an equivalent nondeterministic one, whose size is exponentially bound by the size of the original automaton.},
author = {Kupke, Clemens and Venema, Yde},
doi = {10.2168/LMCS-4(4:10)2008},
file = {:Users/liang-tingchen/Dropbox/References/Kupke, Venema - 2008 - Coalgebraic Automata Theory Basic Results.pdf:pdf},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,automata,coalgebra,fixed-point logics,parity games},
number = {4:10},
pages = {1--43},
title = {{Coalgebraic Automata Theory: Basic Results}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=281},
volume = {4},
year = {2008}
}
@book{Johnson2020a,
archivePrefix = {arXiv},
arxivId = {2002.06055},
author = {Johnson, Niles and Yau, Donald},
doi = {10.1093/oso/9780198871378.001.0001},
eprint = {2002.06055},
file = {:Users/liang-tingchen/Dropbox/References/Johnson, Yau - 2020 - 2-Dimensional Categories.pdf:pdf},
isbn = {9780198871378},
issn = {23318422},
publisher = {Oxford University Press},
title = {{2-Dimensional Categories}},
url = {https://oxford.universitypressscholarship.com/view/10.1093/oso/9780198871378.001.0001/oso-9780198871378},
year = {2020}
}
@phdthesis{Bowman2019,
abstract = {Dependently typed languages have proven useful for developing large-scale fully verified software, but we do not have any guarantees after compiling that verified software. A verified program written in a dependently typed language, such as Coq, can be type checked to ensure that the program meets its specification. Similarly, type checking prevents us from importing a library and violating the specification declared by its types. Unfortunately, we cannot perform either of these checks after compiling a dependently typed program, since all current implementations erase types before compiling the program. Instead, we must trust the compiler to not introduce errors into the verified code, and, after compilation, trust the programmer to never introduce errors by linking two incompatible program components. As a result, the compiled and linked program is not verified— we have no guarantees about what it will do. In this dissertation, I develop a theory for preserving dependent types through compilation so that we can use type checking after compilation to check that no errors are introduced by the compiler or by linking. Type-preserving compilation is a well-known technique that has been used to design compilers for non-dependently typed languages, such as ML, that statically enforce safety and security guarantees in compiled code. But there are many open challenges in scaling type preservation to dependent types. The key problems are adapting syntactic type systems to interpret low-level representations of code, and breaking the complex mutually recursive structure of dependent type systems to make proving type preservation and compiler correctness feasible. In this dissertation, I explain the concepts required to scale type preservation to dependent types, present a proof architecture and language design that support type preservation, and prove type preservation and compiler correctness for four early-stage compiler translations of a realistic dependently typed calculus. These translations include an A-normal form (ANF), a continuation-passing style (CPS), an abstract closure conversion, and a parametric closure conversion translation.},
author = {Bowman, William J.},
file = {:Users/liang-tingchen/Dropbox/References/Bowman - 2019 - Compiling with Dependent Types.pdf:pdf},
keywords = {emotional intelligence,motivational learning mathematics},
school = {Northeastern University},
title = {{Compiling with Dependent Types}},
year = {2019}
}
@incollection{Schurmann2005,
author = {Sch{\"{u}}rmann, Carsten and Poswolsky, Adam and Sarnat, Jeffrey},
booktitle = {Typed Lambda Calculi and Applications. TLCA 2005},
doi = {10.1007/11417170_2},
file = {:Users/liang-tingchen/Dropbox/References/Sch{\"{u}}rmann, Poswolsky, Sarnat - 2005 - The ∇ -Calculus. Functional Programming with Higher-Order Encodings.pdf:pdf},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The ∇ -Calculus. Functional Programming with Higher-Order Encodings}},
url = {http://link.springer.com/10.1007/11417170{\_}2},
volume = {3461},
year = {2005}
}
@article{Smith2019,
abstract = {- Security and privacy -{\textgreater} Privacy-preserving protocols.- Theory of computation -{\textgreater} Type theory.Theory of database privacy and security.- Software and its engineering -{\textgreater} Programming by example.},
author = {Smith, Calvin and Albarghouthi, Aws},
doi = {10.1145/3341698},
file = {:Users/liang-tingchen/Dropbox/References/Smith, Albarghouthi - 2019 - Synthesizing differentially private programs.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {differential privacy,linear type systems,program synthesis},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Synthesizing differentially private programs}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341698},
volume = {3},
year = {2019}
}
@article{Ulmer1968a,
author = {Ulmer, Friedrich},
doi = {10.1016/0021-8693(68)90037-9},
file = {:Users/liang-tingchen/Dropbox/References/Ulmer - 1968 - Representable functors with values in arbitrary categories.pdf:pdf},
issn = {00218693},
journal = {Journal of Algebra},
month = {jan},
number = {1},
pages = {96--129},
title = {{Representable functors with values in arbitrary categories}},
url = {http://scholar.google.com/scholar?q=representable+functors+with+values+in+arbitrary+categories{\&}hl=en{\&}btnG=Search{\&}as{\_}sdt=1,5{\&}as{\_}sdtp=on{\#}0 http://linkinghub.elsevier.com/retrieve/pii/0021869368900379},
volume = {8},
year = {1968}
}
@article{Hofmann2016,
abstract = {Motivated by the need to reason about hybrid systems, we study limits in categories of coalgebras whose underlying functor is a Vietoris polynomial one - intuitively, the topological analogue of a Kripke polynomial functor. Among other results, we prove that every Vietoris polynomial functor admits a final coalgebra if it respects certain conditions concerning separation axioms and compactness. When the functor is restricted to some of the categories induced by these conditions the resulting categories of coalgebras are even complete. As a practical application, we use these developments in the specification and analysis of non-deterministic hybrid systems, in particular to obtain suitable notions of stability, and behaviour.},
archivePrefix = {arXiv},
arxivId = {1612.03318},
author = {Hofmann, Dirk and Neves, Renato and Nora, Pedro},
eprint = {1612.03318},
file = {:Users/liang-tingchen/Dropbox/References/Hofmann, Neves, Nora - 2016 - Limits in categories of Vietoris coalgebras.pdf:pdf},
month = {dec},
pages = {1--28},
title = {{Limits in categories of Vietoris coalgebras}},
url = {http://arxiv.org/abs/1612.03318},
year = {2016}
}
@phdthesis{Saville2019,
author = {Saville, Philip James},
doi = {10.17863/CAM.55080},
file = {:Users/liang-tingchen/Dropbox/References/Saville - 2019 - Cartesian closed bicategories type theory and coherence.pdf:pdf},
keywords = {18C50 (Secondary),18N10 (Primary),F.3.2,F.4.1,cs.LO,math.CT},
number = {October},
pages = {343},
school = {University of Cambridge},
title = {{Cartesian closed bicategories: type theory and coherence}},
type = {Doctoral thesis},
url = {https://doi.org/10.17863/CAM.55080},
year = {2019}
}
@incollection{DArgenio2012,
abstract = {We present a format for the specification of probabilistic transition systems that guarantees that bisimulation equivalence is a congruence for any operator defined in this format. In this sense, the format is somehow comparable to the ntyft/ntyxt format in a non-probabilistic setting. We also study the modular construction of probabilistic transition systems specifications and prove that some standard conservative extension theorems also hold in our setting. Finally, we show that the trace congruence for image-finite processes induced by our format is precisely bisimulation on probabilistic systems.},
annote = {10.1007/978-3-642-28729-9{\_}30},
author = {D'Argenio, Pedro and Lee, Matias},
booktitle = {Foundations of Software Science and Computational Structures},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/D'Argenio, Lee - 2012 - Probabilistic Transition System Specification Congruence and Full Abstraction of Bisimulation.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {452--466},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Probabilistic Transition System Specification: Congruence and Full Abstraction of Bisimulation}},
url = {http://dx.doi.org/10.1007/978-3-642-28729-9{\_}30},
volume = {7213},
year = {2012}
}
@inproceedings{Ahrens2018b,
abstract = {Matthes and Uustalu (TCS 327(1-2):155-174, 2004) presented a categorical description of substitution systems capable of capturing syntax involving binding which is independent of whether the syntax is made up from least or greatest fixed points. We extend this work in two directions: we continue the analysis by creating more categorical structure, in particular by organizing substitution systems into a category and studying its properties, and we develop the proofs of the results of the cited paper and our new ones in UniMath, a recent library of univalent mathematics formalized in the Coq theorem prover.},
address = {Dagstuhl, Germany},
annote = {From Duplicate 1 (Heterogeneous Substitution Systems Revisited - Ahrens, Benedikt; Matthes, Ralph)

Keywords: formalization of category theory, nested datatypes, Mendler-style recursion schemes, representation of substitution in languages with variable binding},
archivePrefix = {arXiv},
arxivId = {1601.04299},
author = {Ahrens, Benedikt and Matthes, Ralph},
booktitle = {21st International Conference on Types for Proofs and Programs (TYPES 2015)},
doi = {10.4230/LIPIcs.TYPES.2015.2},
editor = {Uustalu, Tarmo},
eprint = {1601.04299},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Matthes - 2018 - Heterogeneous Substitution Systems Revisited.pdf:pdf},
isbn = {978-3-95977-030-9},
issn = {1868-8969},
keywords = {Formalization of category theory,Mendler-style recursion schemes,Nested datatypes,Representation of substitution in languages with v},
number = {2},
pages = {2:1----2:23},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Heterogeneous Substitution Systems Revisited}},
url = {http://drops.dagstuhl.de/opus/volltexte/2018/8472},
volume = {69},
year = {2018}
}
@article{Hyland2014,
author = {Hyland, Martin},
doi = {10.1016/j.tcs.2014.03.005},
file = {:Users/liang-tingchen/Dropbox/References/Hyland - 2014 - Elements of a theory of algebraic theories.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
pages = {132--144},
publisher = {Elsevier B.V.},
title = {{Elements of a theory of algebraic theories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397514001807},
volume = {546},
year = {2014}
}
@incollection{Wuille2011,
abstract = {Modular extensibility is a highly desirable property of a domain-specific language (DSL): the ability to add new features without affecting the implementation of existing features. Functional mixins (also known as open recursion) are very suitable for},
author = {Wuille, Pieter and Schrijvers, Tom and Samulowitz, Horst and Tack, Guido and Stuckey, Peter},
booktitle = {WFLP'11: Proceedings of the 20th international conference on Functional and constraint logic programming},
doi = {10.1007/978-3-642-22531-4_5},
file = {:Users/liang-tingchen/Dropbox/References/Wuille et al. - 2011 - Memoizing a Monadic Mixin DSL.pdf:pdf},
isbn = {9783642225307},
issn = {0302-9743},
pages = {68--85},
title = {{Memoizing a Monadic Mixin DSL}},
url = {http://portal.acm.org/citation.cfm?id=2032603.2032610{\&}coll=DL{\&}dl=GUIDE{\&}CFID=67224145{\&}CFTOKEN=63111151{\%}5Cnpapers2://publication/uuid/5DA936D4-603E-4361-9A4A-DED49F8430F1 http://link.springer.com/10.1007/978-3-642-22531-4{\_}5},
year = {2011}
}
@article{Kinoshita2014,
abstract = {A setoid is a set together with a constructive representation of an equivalence relation on it. Here, we give category theoretic support to the notion. We first define a category Setoid and prove it is Cartesian closed with coproducts. We then enrich it in the Cartesian closed category Equiv of sets and classical equivalence relations, extend the above results, and prove that Setoid as an Equiv-enriched category has a relaxed form of equalisers. We then recall the definition of E-category, generalising that of Equiv-enriched category, and show that Setoid as an E-category has a relaxed form of coequalisers. In doing all this, we carefully compare our category theoretic constructs with Agda code for type-theoretic constructs on setoids.},
author = {Kinoshita, Yoshiki and Power, John},
doi = {10.1016/j.tcs.2014.03.006},
file = {:Users/liang-tingchen/Dropbox/References/Kinoshita, Power - 2014 - Category theoretic structure of setoids.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Cartesian closed category,Coproduct,E-category,E-coinserter,Equiv-category,Equiv-inserter,Proof assistant,Proof irrelevance,Setoid},
month = {aug},
number = {C},
pages = {145--163},
publisher = {Elsevier B.V.},
title = {{Category theoretic structure of setoids}},
url = {http://dx.doi.org/10.1016/j.tcs.2014.03.006 https://linkinghub.elsevier.com/retrieve/pii/S0304397514001819},
volume = {546},
year = {2014}
}
@article{Kaiser2018,
author = {Kaiser, Jan-Oliver and Ziliani, Beta and Krebbers, Robbert and R{\'{e}}gis-Gianas, Yann and Dreyer, Derek},
doi = {10.1145/3236773},
file = {:Users/liang-tingchen/Dropbox/References/Kaiser et al. - 2018 - Mtac2 typed tactics for backward reasoning in Coq.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--31},
title = {{Mtac2: typed tactics for backward reasoning in Coq}},
url = {http://dl.acm.org/citation.cfm?doid=3243631.3236773},
volume = {2},
year = {2018}
}
@article{Hyland1980,
abstract = {One of the most important constructions in topos theory ia that of the category Shv ( A ) of sheaves on a locale (= complete Heyting algebra) A. Normally, the objects of this category are described as ‘presheaves on A satisfying a gluing condition'; but, as Higgs(7) and Fourman and Scott(5) have observed, they may also be regarded as ‘sets structured with an A -valued equality predicate' (briefly, ‘ A -valued sets'). From the latter point of view, it is an inessential feature of the situation that every sheaf has a canonical representation as a ‘complete' A -valued set. In this paper, our aim is to investigate those properties which A must have for us to be able to construct a topos of A -valued sets: we shall see that there is one important respect, concerning the relationship between the finitary (propositional) structure and the infinitary (quantifier) structure, in which the usual definition of a locale may be relaxed, and we shall give a number of examples (some of which will be explored more fully in a later paper (8)) to show that this relaxation is potentially useful.},
author = {Hyland, J. M. E. and Johnstone, P. T. and Pitts, A. M.},
doi = {10.1017/S0305004100057534},
file = {:Users/liang-tingchen/Dropbox/References/Hyland, Johnstone, Pitts - 1980 - Tripos theory.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {sep},
number = {2},
pages = {205--232},
title = {{Tripos theory}},
url = {https://www.cambridge.org/core/product/identifier/S0305004100057534/type/journal{\_}article},
volume = {88},
year = {1980}
}
@article{Constable2011a,
abstract = {We establish completeness for intuitionistic first-order logic, iFOL, showing that a formula is provable if and only if its embedding into minimal logic, mFOL, is uniformly valid under the Brouwer Heyting Kolmogorov (BHK) semantics, the intended semantics of iFOL and mFOL. Our proof is intuitionistic and provides an effective procedure Prf that converts uniform minimal evidence into a formal first-order proof. We have implemented Prf. Uniform validity is defined using the intersection operator as a universal quantifier over the domain of discourse and atomic predicates. Formulas of iFOL that are uniformly valid are also intuitionistically valid, but not conversely. Our strongest result requires the Fan Theorem; it can also be proved classically by showing that Prf terminates using Konig's Theorem. The fundamental idea behind our completeness theorem is that a single evidence term evd witnesses the uniform validity of a minimal logic formula F. Finding even one uniform realizer guarantees intuitionistic validity because Prf(F, evd) builds a first-order proof of F, establishing its intuitionistic validity and providing a purely logical normalized realizer. We establish completeness for iFOL as follows. Friedman showed that iFOL can be embedded in minimal logic (mFOL) by his A-transformation, mapping formula F to FA. If F is uniformly valid, then so is FA, and by our completeness theorem, we can find a proof of FA in minimal logic. Then we intuitionistically prove F from FFalse, i.e. by taking False for A and for $\backslash$bot of mFOL. Our result resolves an open question posed by Beth in 1947.},
archivePrefix = {arXiv},
arxivId = {1110.1614},
author = {Constable, Robert and Bickford, Mark},
doi = {10.1016/j.apal.2013.07.009},
eprint = {1110.1614},
file = {:Users/liang-tingchen/Dropbox/References/Constable, Bickford - 2011 - Intuitionistic Completeness of First-Order Logic.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
number = {1},
pages = {1--24},
publisher = {Elsevier B.V.},
title = {{Intuitionistic Completeness of First-Order Logic}},
url = {http://arxiv.org/abs/1110.1614},
volume = {165},
year = {2011}
}
@article{Reynolds1993,
abstract = {Given a model of the polymorphic typed lambda calculus based upon a Cartesian closed category K, there will be functors from K to K whose action on objects can be expressed by type expressions and whose action on morphisms can be expressed by ordinary expressions. We show that if T is such a functor then there is a weak initial T-algebra and if, in addition, K possesses equalizers of all subsets of its morphism sets, then there is an initial T-algebra. These results are used to establish the impossibility of certain models, including those in which types denote sets and S ↔ S' denotes the set of all functions from S to S'. {\textcopyright} 1993 Academic Press, Inc.},
author = {Reynolds, J.C. and Plotkin, G.D.},
doi = {10.1006/inco.1993.1037},
file = {:Users/liang-tingchen/Dropbox/References/Reynolds, Plotkin - 1993 - On Functors Expressible in the Polymorphic Typed Lambda Calculus.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {jul},
number = {1},
pages = {1--29},
title = {{On Functors Expressible in the Polymorphic Typed Lambda Calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0890540183710370},
volume = {105},
year = {1993}
}
@phdthesis{Strategia2016,
author = {Ralston, Ryan},
file = {:Users/liang-tingchen/Dropbox/References/Ralston - 2016 - Translating Clojure to ACL2 for Verification.pdf:pdf},
isbn = {0-8078-2851-3},
school = {The University of Oklahoma},
title = {{Translating Clojure to ACL2 for Verification}},
type = {Doctoral Thesis},
url = {https://shareok.org/handle/11244/42982?show=full},
year = {2016}
}
@incollection{Aczel1989a,
author = {Aczel, Peter and Mendler, Nax Paul},
booktitle = {Category Theory and Computer Science},
doi = {10.1007/BFb0018361},
file = {:Users/liang-tingchen/Dropbox/References/Aczel, Mendler - 1989 - A final coalgebra theorem.pdf:pdf},
pages = {357--365},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A final coalgebra theorem}},
type = {Book part (with own title)},
url = {http://dx.doi.org/10.1007/BFb0018361},
volume = {389},
year = {1989}
}
@article{Teheux2007,
author = {Teheux, Bruno},
doi = {10.1007/s11225-007-9074-5},
file = {:Users/liang-tingchen/Dropbox/References/Teheux - 2007 - A Duality for the Algebras of a {\L}ukasiewicz n 1-valued Modal System.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
keywords = {many-valued modal logics,mv-algebras,operator,rela-,topological duality},
month = {oct},
number = {1},
pages = {13--36},
title = {{A Duality for the Algebras of a {\L}ukasiewicz n + 1-valued Modal System}},
url = {http://www.springerlink.com/index/10.1007/s11225-007-9074-5},
volume = {87},
year = {2007}
}
@incollection{Bove2012a,
abstract = {We propose a new approach to the computer-assisted verification of functional programs. We work in first order theories of functional programs which are obtained by extending Aczel's first order theory of combinatory formal arithmetic with positive inductive and coinductive predicates. Rather than building a special purpose system we implement our theories in Agda, a proof assistant for dependent type theory which can be used as a generic theorem prover. Agda provides support for interactive reasoning by encoding first order theories using the formulae-as-types principle. Further support is provided by off-the-shelf automatic theorem provers for first order logic which can be called by a program which translates Agda representations of first order formulae into the TPTP language understood by the provers. We show some examples where we combine interactive and automatic reasoning, covering both proof by induction and coinduction.},
author = {Bove, Ana and Dybjer, Peter and Sicard-Ram{\'{i}}rez, Andr{\'{e}}s and {Andr{\'{e}}s Sicard-Ram{\'{i}}rez}},
booktitle = {Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-642-28729-9_7},
editor = {Birkedal, Lars},
file = {:Users/liang-tingchen/Dropbox/References/Bove et al. - 2012 - Combining Interactive and Automatic Reasoning in First Order Theories of Functional Programs.pdf:pdf},
isbn = {978-3-642-28728-2},
pages = {104--118},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Combining Interactive and Automatic Reasoning in First Order Theories of Functional Programs}},
volume = {7213},
year = {2012}
}
@incollection{DeMoura2015,
author = {de Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and van Doorn, Floris and von Raumer, Jakob},
booktitle = {Automated Deduction - CADE-25. CADE 2015},
doi = {10.1007/978-3-319-21401-6_26},
editor = {Felty, Amy P. and Middeldorp, Aart},
file = {:Users/liang-tingchen/Dropbox/References/de Moura et al. - 2015 - The Lean Theorem Prover (System Description).pdf:pdf},
isbn = {978-3-319-21400-9},
pages = {378--388},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{The Lean Theorem Prover (System Description)}},
url = {http://link.springer.com/10.1007/978-3-319-21401-6{\_}26},
volume = {9195},
year = {2015}
}
@inproceedings{Omar2017,
abstract = {Programs are rich inductive structures, but human programmers typically construct and manipulate them only indirectly, through flat textual representations. This indirection comes at a cost – programmers must comprehend the various subtleties of parsing, and it can require many text editor actions to make a single syntactically and semantically welldefined change. During these sequences of text editor actions, or when the programmer makes a mistake, programmers and programming tools must contend with malformed or semantically illdefined program text, complicating the programming process. Structure editors promise to alleviate these burdens by exposing only edit actions that produce sensible changes to the program structure. Existing designs for structure editors, however, are complex and somewhat ad hoc. They also focus primarily on syntactic wellformedness, so programs can still be left semantically illdefined as they are being constructed. In this paper, we report on our ongoing efforts to develop Hazelnut, a minimal structure editor defined in a principled typetheoretic style where all edit actions leave the program in both a syntactically and semantically welldefined state. Uniquely, Hazelnut does not force the programmer to construct the program in a strictly " outsidein " fashion. Formally, Hazelnut is a bidirectionally typed lambda calculus extended with 1) holes (which mark subterms that are being constructed from the inside out); 2) a focus model ; and 3) a bidirectional action model equipped with a useful action sensibility theorem.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {arXiv:1607.04180v1},
author = {Omar, Cyrus and Voysey, Ian and Hilton, Michael and Aldrich, Jonathan and Hammer, Matthew A.},
booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages - POPL 2017},
doi = {10.1145/3009837.3009900},
eprint = {arXiv:1607.04180v1},
file = {:Users/liang-tingchen/Dropbox/References/Omar et al. - 2017 - Hazelnut a bidirectionally typed structure editor calculus.pdf:pdf},
isbn = {9781450346603},
issn = {07308566},
keywords = {bidirectional type systems,gradual,mechanized metatheory,structure editors,typing},
pages = {86--99},
publisher = {ACM Press},
title = {{Hazelnut: a bidirectionally typed structure editor calculus}},
url = {http://dl.acm.org/citation.cfm?doid=3009837.3009900},
year = {2017}
}
@article{Ahrens2015b,
author = {Ahrens, Benedikt},
doi = {10.6092/issn.1972-5787/4712},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens - 2015 - Initiality for Typed Syntax and Semantics.pdf:pdf},
journal = {Journal of Formalized Reasoning},
number = {2},
pages = {1--155},
title = {{Initiality for Typed Syntax and Semantics}},
url = {https://jfr.unibo.it/article/view/4712},
volume = {8},
year = {2015}
}
@article{Bellin2006,
abstract = {We investigate semantics for classical proof based on the sequent calculus. We show that the propositional connectives are not quite well-behaved from a traditional categorical perspective, and give a more refined, but necessarily complex, analysis of how connectives may be characterised abstractly. Finally we explain the consequences of insisting on more familiar categorical behaviour.},
author = {Bellin, Gianluigi and Hyland, Martin and Robinson, Edmund and Urban, Christian},
doi = {10.1016/j.tcs.2006.08.002},
file = {:Users/liang-tingchen/Dropbox/References/Bellin et al. - 2006 - Categorical proof theory of classical propositional calculus.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {category theory,classical logic,proof theory},
month = {nov},
number = {2},
pages = {146--165},
title = {{Categorical proof theory of classical propositional calculus}},
url = {http://dx.doi.org/10.1016/j.tcs.2006.08.002 http://linkinghub.elsevier.com/retrieve/pii/S0304397506005287},
volume = {364},
year = {2006}
}
@book{Hedman2004,
author = {Hedman, Shawn},
file = {:Users/liang-tingchen/Dropbox/References/Hedman - 2004 - A First Course in Logic An Introduction to Model Theory, Proof Theory, Computability, and Complexity.pdf:pdf},
isbn = {978-0-19-852981-1},
month = {jul},
pages = {452},
publisher = {Oxford University Press},
series = {Oxford Texts in Logic},
title = {{A First Course in Logic: An Introduction to Model Theory, Proof Theory, Computability, and Complexity}},
year = {2004}
}
@inproceedings{Law,
address = {New York, New York, USA},
author = {Prakken, Henry and Sartor, Giovanni},
booktitle = {Proceedings of the fifth international conference on Artificial intelligence and law - ICAIL '95},
doi = {10.1145/222092.222096},
file = {:Users/liang-tingchen/Dropbox/References/Prakken, Sartor - 1995 - On the relation between legal language and legal argument.pdf:pdf},
isbn = {0897917588},
pages = {1--10},
publisher = {ACM Press},
title = {{On the relation between legal language and legal argument}},
url = {http://portal.acm.org/citation.cfm?doid=222092.222096},
year = {1995}
}
@inproceedings{Dreyer2003,
abstract = {We present a type theory for higher-order modules that accounts for many central issues in module system design, including translucency, applicativity, generativity, and modules as first-class values. Our type system harmonizes design elements from previous work, resulting in a simple, economical account of modular programming. The main unifying principle is the treatment of abstraction mechanisms as computational effects. Our language is the first to provide a complete and practical formalization of all of these critical issues in module system design.},
address = {New York, New York, USA},
author = {Dreyer, Derek and Crary, Karl and Harper, Robert},
booktitle = {Proceedings of the 30th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '03},
doi = {10.1145/604131.604151},
file = {:Users/liang-tingchen/Dropbox/References/Dreyer, Crary, Harper - 2003 - A type system for higher-order modules.pdf:pdf},
isbn = {1581136285},
issn = {0362-1340},
keywords = {abstract data types,computational effects,functors,generativity,modularity,singleton types,type theory},
month = {jan},
number = {1},
pages = {236--249},
publisher = {ACM Press},
title = {{A type system for higher-order modules}},
url = {https://dl.acm.org/doi/10.1145/640128.604151 http://portal.acm.org/citation.cfm?doid=604131.604151},
volume = {38},
year = {2003}
}
@article{Quirin2016,
author = {Quirin, Kevin and Tabareau, Nicolas},
doi = {10.6092/issn.1972-5787/6232},
file = {:Users/liang-tingchen/Dropbox/References/Quirin, Tabareau - 2016 - Lawvere-Tierney sheafification in Homotopy Type Theory.pdf:pdf},
journal = {Journal of Formalized Reasoning},
number = {92},
pages = {131--161},
title = {{Lawvere-Tierney sheafification in Homotopy Type Theory}},
url = {https://hal.inria.fr/hal-01451710},
volume = {9},
year = {2016}
}
@article{Simmons2014,
abstract = {Focusing, introduced by Jean-Marc Andreoli in the context of classical linear logic [Andreoli 1992], defines a normal form for sequent calculus derivations that cuts down on the number of possible derivations by eagerly applying invertible rules and grouping sequences of non-invertible rules. A focused sequent calculus is defined relative to some nonfocused sequent calculus; focalization is the property that every nonfocused derivation can be transformed into a focused derivation.},
archivePrefix = {arXiv},
arxivId = {1109.6273},
author = {Simmons, Robert J.},
doi = {10.1145/2629678},
eprint = {1109.6273},
file = {:Users/liang-tingchen/Dropbox/References/Simmons - 2014 - Structural Focalization.pdf:pdf},
issn = {1529-3785},
journal = {ACM Transactions on Computational Logic},
keywords = {Cut admissibility,Focusing,Identity expansion,Intuitionstic logic,Normalization,Polarized logic,Proof search,Proof terms},
month = {jul},
number = {3},
pages = {1--33},
title = {{Structural Focalization}},
url = {https://dl.acm.org/doi/10.1145/2629678},
volume = {15},
year = {2014}
}
@incollection{Escardo2015,
author = {Escard{\'{o}}, Mart{\'{i}}n H{\"{o}}tzel and Xu, Chuangjie},
booktitle = {13th International Conference on Typed Lambda Calculi and Applications},
doi = {10.4230/LIPIcs.TLCA.2015.153},
editor = {Altenkirch, Thorsten},
file = {:Users/liang-tingchen/Dropbox/References/Escard{\'{o}}, Xu - 2015 - The Inconsistency of a Brouwerian Continuity Principle with the Curry – Howard Interpretation.pdf:pdf},
keywords = {153,2015,4230,and phrases dependent type,anonymous existence,brouwerian continuity axioms,constructive mathematics,curry,digital object identifier 10,function extensionality,homotopy type theory,howard in-,intensional martin-l{\"{o}}f type theory,lipics,positional truncation,pro-,terpretation,tlca,topos theory},
pages = {153--164},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{The Inconsistency of a Brouwerian Continuity Principle with the Curry – Howard Interpretation}},
year = {2015}
}
@incollection{Buss2018,
abstract = {We introduce new stable natural merge sort algorithms, called {\$}2{\$}-merge sort and {\$}\backslashalpha{\$}-merge sort. We prove upper and lower bounds for several merge sort algorithms, including Timsort, Shiver's sort, {\$}\backslashalpha{\$}-stack sorts, and our new {\$}2{\$}-merge and {\$}\backslashalpha{\$}-merge sorts. The upper and lower bounds have the forms {\$}c \backslashcdot n \backslashlog m{\$} and {\$}c \backslashcdot n \backslashlog n{\$} for inputs of length{\~{}}{\$}n{\$} comprising {\$}m{\$}{\~{}}runs. For Timsort, we prove a lower bound of {\$}(1.5 - o(1)) n \backslashlog n{\$}. For {\$}2{\$}-merge sort, we prove optimal upper and lower bounds of approximately {\$}(1.089 \backslashpm o(1))n \backslashlog m{\$}. We prove similar asymptotically matching upper and lower bounds for {\$}\backslashalpha{\$}-merge sort, when {\$}\backslashvarphi {\textless} \backslashalpha {\textless} 2{\$}, where {\$}\backslashvarphi{\$} is the golden ratio. These merge strategies can be used for any stable merge sort, not just natural merge sorts. The new {\$}2{\$}-merge and {\$}\backslashalpha{\$}-merge sorts have better worst-case merge cost upper bounds and are slightly simpler to implement than the widely-used Timsort; they also perform better in experiments.},
address = {Philadelphia, PA},
archivePrefix = {arXiv},
arxivId = {1801.04641},
author = {Buss, Sam and Knop, Alexander},
booktitle = {Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms},
doi = {10.1137/1.9781611975482.78},
eprint = {1801.04641},
file = {:Users/liang-tingchen/Dropbox/References/Buss, Knop - 2019 - Strategies for Stable Merge Sorting.pdf:pdf},
month = {jan},
pages = {1272--1290},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Strategies for Stable Merge Sorting}},
url = {http://arxiv.org/abs/1801.04641 https://epubs.siam.org/doi/10.1137/1.9781611975482.78},
year = {2019}
}
@article{Davies2017,
abstract = {This article demonstrates that there is a fundamental relationship between temporal logic and languages that involve multiple stages, such as those used to analyze binding times in the context of partial evaluation. This relationship is based on an extension of the Curry-Howard isomorphism, which identifies proofs with programs, and propositions with types. Our extension involves the "next time" (○) operator from linear-time temporal logic and yields a $\lambda$-calculus $\lambda$° with types of the form ○A for expressions in the subsequent stage, with appropriate introduction and elimination forms. We demonstrate that $\lambda$° is equivalent to the core of a previously studied multilevel binding-time analysis. This is similar to work by Davies and Pfenning on staged computation based on the necessity (□) operator of modal logic, but □ only allows closed code, and naturally supports a code evaluation construct, whereas ○ captures open code, thus is more flexible, but is incompatible with such a construct. Instead, code evaluation is an external global operation that is validated by the proof theory regarding closed proofs of ○ formulas. We demonstrate the relevance of $\lambda$° to staged computation directly by showing that that normalization can be done in an order strictly following the times of the logic. We also extend $\lambda$° to small functional language and show that it would serve as a suitable basis for directly programming with multiple stages by presenting some example programs.},
author = {Davies, Rowan},
doi = {10.1145/3011069},
file = {:Users/liang-tingchen/Dropbox/References/Davies - 2017 - A Temporal Logic Approach to Binding-Time Analysis.pdf:pdf},
issn = {0004-5411},
journal = {Journal of the ACM},
keywords = {Partial evaluation,Propositions as types,Staged computation},
month = {mar},
number = {1},
pages = {1--45},
title = {{A Temporal Logic Approach to Binding-Time Analysis}},
url = {https://dl.acm.org/doi/10.1145/3011069},
volume = {64},
year = {2017}
}
@article{Fu2017,
abstract = {This paper presents a study of operational and type-theoretic properties of different resolution strategies in Horn clause logic. We distinguish four different kinds of resolution: resolution by unification (SLD-resolution), resolution by term-matching, the recently introduced structural resolution, and partial (or lazy) resolution. We express them all uniformly as abstract reduction systems, which allows us to undertake a thorough comparative analysis of their properties. To match this small-step semantics, we propose to take Howard's System H as a type-theoretic semantic counterpart. Using System H, we interpret Horn formulas as types, and a derivation for a given formula as the proof term inhabiting the type given by the formula. We prove soundness of these abstract reduction systems relative to System H, and we show completeness of SLD-resolution and structural resolution relative to System H. We identify conditions under which structural resolution is operationally equivalent to SLD-resolution. We show correspondence between term-matching resolution for Horn clause programs without existential variables and term rewriting.},
archivePrefix = {arXiv},
arxivId = {1604.04114},
author = {Fu, Peng and Komendantskaya, Ekaterina},
doi = {10.1007/s00165-016-0403-1},
eprint = {1604.04114},
file = {:Users/liang-tingchen/Dropbox/References/Fu, Komendantskaya - 2017 - Operational semantics of resolution and productivity in Horn clause logic.pdf:pdf},
issn = {0934-5043},
journal = {Formal Aspects of Computing},
keywords = {Logic programming,Productivity,Reduction systems,Structural resolution,Termination,Typed lambda calculus},
month = {may},
number = {3},
pages = {453--474},
title = {{Operational semantics of resolution and productivity in Horn clause logic}},
url = {http://link.springer.com/10.1007/s00165-016-0403-1},
volume = {29},
year = {2017}
}
@incollection{Nakano2001,
abstract = {We present two modal typing systems with the approximation modality, which has been proposed by the author to capture selfreferences involved in computer programs and their specifications. The systems are based on the simple and the F-semantics of types, respectively, and correspond to the same modal logic, which is considered the intuitionistic version of the logic of provability. We also show Kripke completeness of the modal logic and its decidability, which implies the decidability of type inhabitance in the typing systems.},
author = {Nakano, Hiroshi},
booktitle = {Theoretical Aspects of Computer Software. TACS 2001},
doi = {10.1007/3-540-45500-0_8},
editor = {Kobayashi, Naoki and Pierce, Benjamin C.},
file = {:Users/liang-tingchen/Dropbox/References/Nakano - 2001 - Fixed-Point Logic with the Approximation Modality and Its Kripke Completeness.pdf:pdf},
isbn = {3540427368},
issn = {16113349},
pages = {165--182},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Fixed-Point Logic with the Approximation Modality and Its Kripke Completeness}},
url = {http://link.springer.com/10.1007/3-540-45500-0{\_}8},
volume = {2215},
year = {2001}
}
@article{Bauer2012b,
abstract = {Eff is a programming language based on the algebraic approach to computational effects, in which effects are viewed as algebraic operations and effect handlers as homomorphisms from free algebras. Eff supports first-class effects and handlers through which we may easily define new computational effects, seamlessly combine existing ones, and handle them in novel ways. We give a denotational semantics of eff and discuss a prototype implementation based on it. Through examples we demonstrate how the standard effects are treated in eff, and how eff supports programming techniques that use various forms of delimited continuations, such as backtracking, breadth-first search, selection functionals, cooperative multi-threading, and others.},
archivePrefix = {arXiv},
arxivId = {1203.1539},
author = {Bauer, Andrej and Pretnar, Matija},
eprint = {1203.1539},
file = {:Users/liang-tingchen/Dropbox/References/Bauer, Pretnar - 2012 - Programming with Algebraic Effects and Handlers.pdf:pdf},
journal = {ArXiv e-prints},
keywords = {()},
month = {mar},
pages = {1--25},
title = {{Programming with Algebraic Effects and Handlers}},
url = {http://arxiv.org/abs/1203.1539},
year = {2012}
}
@inproceedings{Lin2012,
abstract = {In statistical privacy, privacy definitions are contracts that guide the$\backslash$nbehavior of algorithms that take in sensitive data and produce sanitized$\backslash$ndata. Historically, data privacy breaches have been the result of$\backslash$nfundamental misunderstandings about what a particular privacy definition$\backslash$nguarantees.$\backslash$nPrivacy definitions are often analyzed using a hit-or-miss approach: a$\backslash$nspecific attack strategy is evaluated to determine if a specific type of$\backslash$ninformation can be inferred. If the attack works, the privacy definition$\backslash$nis known to be too weak. If it doesn't work, little information is$\backslash$ngained. Furthermore, these strategies will not identify cases where a$\backslash$nprivacy definition protects unnecessary pieces of information.$\backslash$nA systematic analysis of privacy definitions is a long-standing open$\backslash$nproblem. In this paper, we present initial steps towards a solution.$\backslash$nUsing privacy axioms, we identify two mathematical objects that are$\backslash$nassociated with privacy definitions - the consistent closure and the row$\backslash$ncone (which is constructed from the consistent closure). The row cone is$\backslash$na geometric object which neatly encapsulates Bayesian guarantees$\backslash$nprovided by a privacy definition.$\backslash$nWe apply these ideas to the study of randomized response to show that it$\backslash$nprovides unnecessarily strong protections on the parity of a dataset.},
author = {Lin, Bing-Rong and Kifer, Daniel},
booktitle = {2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)},
doi = {10.1109/ACSSC.2012.6489162},
file = {:Users/liang-tingchen/Dropbox/References/Lin, Kifer - 2012 - Reasoning about privacy using axioms.pdf:pdf},
isbn = {978-1-4673-5051-8},
issn = {10586393},
month = {nov},
pages = {975--979},
publisher = {IEEE},
title = {{Reasoning about privacy using axioms}},
url = {http://ieeexplore.ieee.org/document/6489162/},
year = {2012}
}
@article{Birkedal2012,
abstract = {This paper describes a formalization of discrete real closed fields in the Coq proof assistant. This abstract structure captures for instance the theory of real algebraic numbers, a decidable subset of real numbers with good algorithmic properties. The theory of real algebraic numbers and more generally of semi-algebraic varieties is at the core of a number of effective methods in real analysis, including decision procedures for non linear arithmetic or optimization methods for real valued functions. After defining an abstract structure of discrete real closed field and the elementary theory of real roots of polynomials, we describe the formalization of an algebraic proof of quantifier elimination based on pseudo-remainder sequences following the standard computer algebra literature on the topic. This formalization covers a large part of the theory which underlies the efficient algorithms implemented in practice in computer algebra. The success of this work paves the way for formal certification of these efficient methods. {\textcopyright} C. Cohen and A. Mahboubi.},
author = {Birkedal, Lars and M{\o}gelberg, Rasmus Ejlers and Schwinghammer, Jan and St{\o}vring, Kristian},
doi = {10.2168/LMCS-8(4:1)2012},
file = {:Users/liang-tingchen/Dropbox/References/Birkedal et al. - 2012 - First steps in synthetic guarded domain theory step-indexing in the topos of trees.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
number = {4},
pages = {1--45},
title = {{First steps in synthetic guarded domain theory: step-indexing in the topos of trees}},
url = {https://lmcs.episciences.org/1041},
volume = {8},
year = {2012}
}
@article{Abel2019,
abstract = {We propose a new collection of benchmark problems in mechanizing the metatheory of programming languages, in order to compare and push the state of the art of proof assistants. In particular, we focus on proofs using logical relations (LRs) and propose establishing strong normalization of a simply typed calculus with a proof by Kripke-style LRs as a benchmark. We give a modern view of this well-understood problem by formulating our LR on well-typed terms. Using this case study, we share some of the lessons learned tackling this problem in different dependently typed proof environments. In particular, we consider the mechanization in Beluga, a proof environment that supports higher-order abstract syntax encodings and contrast it to the development and strategies used in general-purpose proof assistants such as Coq and Agda. The goal of this paper is to engage the community in discussions on what support in proof environments is needed to truly bring mechanized metatheory to the masses and engage said community in the crafting of future benchmarks.},
author = {ABEL, ANDREAS and ALLAIS, GUILLAUME and HAMEER, ALIYA and PIENTKA, BRIGITTE and MOMIGLIANO, ALBERTO and SCH{\"{A}}FER, STEVEN and STARK, KATHRIN},
doi = {10.1017/S0956796819000170},
file = {:Users/liang-tingchen/Dropbox/References/ABEL et al. - 2019 - POPLMark reloaded Mechanizing proofs by logical relations.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {dec},
pages = {e19},
title = {{POPLMark reloaded: Mechanizing proofs by logical relations}},
url = {https://www.cambridge.org/core/product/identifier/S0956796819000170/type/journal{\_}article},
volume = {29},
year = {2019}
}
@article{Caliskan2017,
abstract = {Artificial intelligence and machine learning are in a period of astounding growth. However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions. Here we show for the first time that human-like semantic biases result from the application of standard machine learning to ordinary language---the same sort of language humans are exposed to every day. We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies. We replicate these using a widely used, purely statistical machine-learning model---namely, the GloVe word embedding---trained on a corpus of text from the Web. Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the {\{}$\backslash$em status quo{\}} for the distribution of gender with respect to careers or first names. These regularities are captured by machine learning along with the rest of semantics. In addition to our empirical findings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results have implications not only for AI and machine learning, but also for the fields of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.},
archivePrefix = {arXiv},
arxivId = {1608.07187},
author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
doi = {10.1126/science.aal4230},
eprint = {1608.07187},
file = {:Users/liang-tingchen/Dropbox/References/Caliskan, Bryson, Narayanan - 2017 - Semantics derived automatically from language corpora contain human-like biases.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {results even with,we replicated the iat},
number = {6334},
pages = {183--186},
pmid = {28408601},
title = {{Semantics derived automatically from language corpora contain human-like biases}},
volume = {356},
year = {2017}
}
@article{Sweeney2002a,
author = {Sweeney, Latanya},
doi = {10.1142/S0218488502001648},
file = {:Users/liang-tingchen/Dropbox/References/Sweeney - 2002 - {\$}k{\$}-Anonymity A model for protecting Privacy.pdf:pdf},
journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
number = {05},
pages = {557--570},
title = {{{\$}k{\$}-Anonymity: A model for protecting Privacy}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218488502001648{\%}5Cnhttp://www.cs.pomona.edu/{~}sara/classes/cs190-fall12/k-anonymity.pdf},
volume = {10},
year = {2002}
}
@article{Gratzer2019,
author = {Gratzer, Daniel and Sterling, Jonathan and Birkedal, Lars},
doi = {10.1145/3341711},
file = {:Users/liang-tingchen/Dropbox/References/Gratzer, Sterling, Birkedal - 2019 - Implementing a modal dependent type theory.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {Modal types,dependent types,normalization by evaluation,type-checking},
month = {jul},
number = {ICFP},
pages = {1--29},
title = {{Implementing a modal dependent type theory}},
url = {http://dl.acm.org/citation.cfm?doid=3352468.3341711},
volume = {3},
year = {2019}
}
@article{Marlow2012,
abstract = {We present a new programming model for deterministic parallel computation in a pure functional language. The model is monadic and has explicit granularity, but allows dynamic construction of dataflow networks that are scheduled at runtime, while remaining deterministic and pure. The implementation is based on monadic concurrency, which has until now only been used to simulate con- currency in functional languages, rather than to provide parallelism. We present the API with its semantics, and argue that parallel exe- cution is deterministic. Furthermore, we present a complete work- stealing scheduler implemented as a Haskell library, and we show that it performs at least as well as the existing parallel programming models in Haskell.},
author = {Marlow, Simon and Newton, Ryan and {Peyton Jones}, Simon},
doi = {10.1145/2096148.2034685},
file = {:Users/liang-tingchen/Dropbox/References/Marlow, Newton, Peyton Jones - 2012 - A monad for deterministic parallelism.pdf:pdf},
isbn = {9781450308601},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {jan},
number = {12},
pages = {71},
pmid = {12693812},
title = {{A monad for deterministic parallelism}},
url = {http://dl.acm.org/citation.cfm?doid=2096148.2034685},
volume = {46},
year = {2012}
}
@article{Garner2009,
abstract = {We form tricategories and the homomorphisms between them into a bicategory, whose 2-cells are certain degenerate tritransformations. We then enrich this bicategory into an example of a three-dimensional structure called a locally cubical bicategory, this being a bicategory enriched in the monoidal 2-category of pseudo double categories. Finally, we show that every sufficiently well-behaved locally cubical bicategory gives rise to a tricategory, and thereby deduce the existence of a tricategory of tricategories. {\textcopyright} Cambridge Philosophical Society 2009.},
archivePrefix = {arXiv},
arxivId = {0711.1761},
author = {GARNER, RICHARD and GURSKI, NICK},
doi = {10.1017/S0305004108002132},
eprint = {0711.1761},
file = {:Users/liang-tingchen/Dropbox/References/GARNER, GURSKI - 2009 - The low-dimensional structures formed by tricategories.pdf:pdf},
issn = {0305-0041},
journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
month = {may},
number = {03},
pages = {551},
title = {{The low-dimensional structures formed by tricategories}},
url = {http://www.journals.cambridge.org/abstract{\_}S0305004108002132},
volume = {146},
year = {2009}
}
@article{Doberkat2008,
author = {Doberkat, Ernst-Erich},
doi = {10.1016/j.apal.2008.01.010},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat - 2008 - Stochastic coalgebraic logic Bisimilarity and behavioral equivalence.pdf:pdf},
issn = {01680072},
journal = {Annals of Pure and Applied Logic},
keywords = {1,behavioral equivalence,close cousins like the,coalgebraic and modal logic,coalgebras,hennessy,introduction and motivation,investigating equivalent behavior of,milner theorem,modal logics or their,model checking usually follows,partitioned into states that,predicate liftings,satisfy,stochastic kripke models for,stochastic relations,the state space is,this pattern,tree logics used for},
month = {aug},
number = {1},
pages = {46--68},
title = {{Stochastic coalgebraic logic: Bisimilarity and behavioral equivalence}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168007208000377},
volume = {155},
year = {2008}
}
@inproceedings{Banaschewski1972,
author = {Banaschewski, Bernhard},
booktitle = {General Topology and its Relations to Modern Analysis and Algebra. Proceedings of the Third Prague Topological Symposium, 1971},
file = {:Users/liang-tingchen/Dropbox/References/Banaschewski - 1972 - On profinite universal algebras.pdf:pdf},
pages = {51--62},
publisher = {Academia Publishing House of the Czechoslovak Academy of Sciences},
title = {{On profinite universal algebras}},
url = {http://dml.cz/dmlcz/700756},
year = {1972}
}
@book{Koller2009,
author = {Koller, Daphne and Friedman, Nir},
isbn = {9780262013192},
pages = {1270},
publisher = {MIT Press},
title = {{Probabilistic Graphical Models}},
url = {https://mitpress.mit.edu/books/probabilistic-graphical-models},
year = {2009}
}
@inproceedings{Lincoln1994,
author = {Lincoln, P.D. and Shankar, N},
booktitle = {Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1994.316061},
file = {:Users/liang-tingchen/Dropbox/References/Lincoln, Shankar - 1994 - Proof search in first-order linear logic and other cut-free sequent calculi.pdf:pdf},
isbn = {0-8186-6310-3},
pages = {282--291},
publisher = {IEEE Comput. Soc. Press},
title = {{Proof search in first-order linear logic and other cut-free sequent calculi}},
url = {http://ieeexplore.ieee.org/document/316061/},
year = {1994}
}
@article{Fritz2015,
abstract = {Resources and their use and consumption form a central part of our life. Many branches of science and engineering are concerned with the question of which given resource objects can be converted into which target resource objects. For example, information theory studies the conversion of a noisy communication channel instance into an exchange of information. Inspired by work in quantum information theory, we develop a general mathematical toolbox for this type of question. The convertibility of resources into other ones and the possibility of combining resources is accurately captured by the mathematics of ordered commutative monoids. As an intuitive example, we consider chemistry, where chemical reaction equations such as $\backslash$mathrm{\{}2H{\_}2 + O{\_}2{\}} $\backslash$lra $\backslash$mathrm{\{}2H{\_}2O,{\}} are concerned both with a convertibility relation ‘→' and a combination operation ‘+.' We study ordered commutative monoids from an algebraic and functional-analytic perspective and derive a wealth of results which should have applications to concrete resource theories, such as a formula for rates of conversion. As a running example showing that ordered commutative monoids are also of purely mathematical interest without the resource-theoretic interpretation, we exemplify our results with the ordered commutative monoid of graphs.},
archivePrefix = {arXiv},
arxivId = {1504.03661},
author = {Fritz, Tobias},
doi = {10.1017/S0960129515000444},
eprint = {1504.03661},
file = {:Users/liang-tingchen/Dropbox/References/Fritz - 2017 - Resource convertibility and ordered commutative monoids.pdf:pdf},
isbn = {0960129515000},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {sep},
number = {06},
pages = {850--938},
title = {{Resource convertibility and ordered commutative monoids}},
url = {http://arxiv.org/abs/1504.03661{\%}0Ahttp://dx.doi.org/10.1017/S0960129515000444 https://www.cambridge.org/core/product/identifier/S0960129515000444/type/journal{\_}article},
volume = {27},
year = {2017}
}
@incollection{Pitts2000,
abstract = {This paper describes work in progress on the design of an ML-style metalanguage Fresh ML for programming with recursively defined functions on user-defined, concrete data types whose constructors may involve variable binding. Up to operational equivalence, values of such Fresh ML data types can faithfully encode terms modulo $\alpha$-conversion for a wide range of object languages in a straightforward fashion. The design of Fresh ML is ‘semantically driven', in that it arises from the model of variable binding in set theory with atoms given by the authors in [7]. The language has a type constructor for abstractions over names (= atoms) and facilities for declaring locally fresh names. Moreover, recursive definitions can use a form of pattern-matching on bound names in abstractions. The crucial point is that the Fresh ML type system ensures that these features can only be used in well-typed programs in ways that are insensitive to renaming of bound names.},
author = {Pitts, Andrew M. and Gabbay, Murdoch J.},
booktitle = {Mathematics of Program Construction. MPC 2000},
doi = {10.1007/10722010_15},
editor = {Backhouse, Roland and Oliveira, Jos{\'{e}} Nuno},
file = {:Users/liang-tingchen/Dropbox/References/Pitts, Gabbay - 2000 - A Metalanguage for Programming with Bound Names Modulo Renaming.pdf:pdf},
isbn = {9783540677277},
issn = {16113349},
pages = {230--255},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Metalanguage for Programming with Bound Names Modulo Renaming}},
url = {http://link.springer.com/10.1007/10722010{\_}15},
volume = {1837},
year = {2000}
}
@incollection{Murawski2014,
author = {Murawski, Andrzej S. and Tzevelekos, Nikos},
booktitle = {Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-642-54830-7_11},
editor = {Muscholl, Anca},
file = {:Users/liang-tingchen/Dropbox/References/Murawski, Tzevelekos - 2014 - Game Semantics for Nominal Exceptions.pdf:pdf},
isbn = {978-3-642-54829-1},
pages = {164--179},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Game Semantics for Nominal Exceptions}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-54830-7{\_}11},
year = {2014}
}
@article{Sozeau2020,
author = {Sozeau, Matthieu and Boulier, Simon and Forster, Yannick and Tabareau, Nicolas and Winterhalter, Th{\'{e}}o},
doi = {10.1145/3371076},
file = {:Users/liang-tingchen/Dropbox/References/Sozeau et al. - 2019 - Coq Coq correct! verification of type checking and erasure for Coq, in Coq.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {certification,proof assistants,type checker},
month = {dec},
number = {POPL},
pages = {1--28},
title = {{Coq Coq correct! verification of type checking and erasure for Coq, in Coq}},
url = {https://github.com/coq/coq/blob/master/dev/doc/critical-bugs, http://dl.acm.org/citation.cfm?doid=3377388.3371076},
volume = {4},
year = {2019}
}
@incollection{Artemov2005,
abstract = {Provability logic is a modal logic that is used to investigate what arithmetical theories can express in a restricted language about their provability predicates. The logic has been inspired by developments in meta-mathematics such as G{\"{o}}del's incompleteness theorems of 1931 and L{\"{o}}b's theorem of 1953. As a modal logic, provability logic has been studied since the early seventies, and has had important applications in the foundations of mathematics. From a philosophical point of view, provability logic is interesting because the concept of provability in a fixed theory of arithmetic has a unique and non-problematic meaning, other than concepts like necessity and knowledge studied in modal and epistemic logic. Furthermore, provability logic provides tools to study the notion of self-reference.},
author = {Artemov, Sergei N. and Beklemishev, Lev D.},
booktitle = {Handbook of Philosophical Logic, 2nd Edition},
doi = {10.1007/1-4020-3521-7_3},
editor = {Gabbay, D.M. and Guenthner, F.},
file = {:Users/liang-tingchen/Dropbox/References/Artemov, Beklemishev - 2005 - Provability Logic.pdf:pdf},
pages = {189--360},
publisher = {Springer, Dordrecht},
series = {Handbook of Philosophical Logic},
title = {{Provability Logic}},
url = {http://link.springer.com/10.1007/1-4020-3521-7{\_}3},
volume = {13},
year = {2005}
}
@inproceedings{Jones,
author = {Jones, C. and Plotkin, Gordon D.},
booktitle = {Proceedings. Fourth Annual Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1989.39173},
file = {:Users/liang-tingchen/Dropbox/References/Jones, Plotkin - 1989 - A probabilistic powerdomain of evaluations.pdf:pdf},
isbn = {0-8186-1954-6},
pages = {186--195},
publisher = {IEEE Comput. Soc. Press},
title = {{A probabilistic powerdomain of evaluations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=39173},
year = {1989}
}
@inproceedings{Patra2010,
abstract = {This work proposes an algebraic model for classical information theory. We first give an algebraic model of probability theory. Information theoretic constructs are based on this model. In addition to theoretical insights provided by our model one obtains new computational and analytical tools. Several important theorems of classical probability and information theory are presented in the algebraic framework.},
archivePrefix = {arXiv},
arxivId = {1006.0355},
author = {Patra, Manas K. and Braunstein, Samuel L.},
booktitle = {2010 IEEE International Symposium on Information Theory},
doi = {10.1109/ISIT.2010.5513650},
eprint = {1006.0355},
file = {:Users/liang-tingchen/Dropbox/References/Patra, Braunstein - 2010 - An algebraic approach to information theory.pdf:pdf},
isbn = {978-1-4244-7892-7},
month = {jun},
pages = {2708--2712},
publisher = {IEEE},
title = {{An algebraic approach to information theory}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5513650 http://ieeexplore.ieee.org/document/5513650/},
year = {2010}
}
@article{Milius2009,
abstract = {This paper provides a general account of the notion of recursive program schemes, studying both uninterpreted and interpreted solutions. It can be regarded as the category-theoretic version of the classical area of algebraic semantics. The overall assumptions needed are small indeed: working only in categories with "enough final coalgebras" we show how to formulate, solve, and study recursive program schemes. Our general theory is algebraic and so avoids using ordered, or metric structures. Our work generalizes the previous approaches which do use this extra structure by isolating the key concepts needed to study substitution in infinite trees, including second-order substitution. As special cases of our interpreted solutions we obtain the usual denotational semantics using complete partial orders, and the one using complete metric spaces. Our theory also encompasses implicitly defined objects which are not usually taken to be related to recursive program schemes. For example, the classical Cantor two-thirds set falls out as an interpreted solution (in our sense) of a recursive program scheme.},
archivePrefix = {arXiv},
arxivId = {0904.2385},
author = {Milius, Stefan and Moss, Lawrence S.},
eprint = {0904.2385},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Moss - 2009 - The Category Theoretic Solution of Recursive Program Schemes.pdf:pdf},
journal = {ArXiv e-prints},
number = {March},
pages = {1--54},
title = {{The Category Theoretic Solution of Recursive Program Schemes}},
url = {http://arxiv.org/abs/0904.2385},
year = {2009}
}
@article{Fiore2011a,
author = {Fiore, Marcelo and Hur, Chung-Kil},
doi = {10.2168/LMCS-7(3:12)2011},
file = {:Users/liang-tingchen/Dropbox/References/Fiore, Hur - 2011 - On the mathematical synthesis of equational logics.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Computer Science - Logic in Computer Science,D.3.1,F.3.1,F.3.2,F.4.1,I.2.3,Mathematics - Category Theory,Mathematics - Logic},
mendeley-tags = {Computer Science - Logic in Computer Science,D.3.1,F.3.1,F.3.2,F.4.1,I.2.3,Mathematics - Category Theory,Mathematics - Logic},
number = {3},
pages = {1--19},
title = {{On the mathematical synthesis of equational logics}},
url = {https://lmcs.episciences.org/1071},
volume = {7},
year = {2011}
}
@article{Staton2011,
author = {Staton, Sam},
doi = {10.2168/LMCS-7(1:13)2011},
editor = {Kurz, Alexander},
file = {:Users/liang-tingchen/Dropbox/References/Staton - 2011 - Relating coalgebraic notions of bisimulation.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {and phrases,bisimulation,category theory,coalgebra,coinduction},
month = {mar},
number = {1},
pages = {1--21},
title = {{Relating coalgebraic notions of bisimulation}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=802},
volume = {7},
year = {2011}
}
@article{Kavvos2021,
author = {Kavvos, G. Alex},
editor = {de Paiva, Valeria and Artemov, Sergei},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2021 - Intensionality, Intensional Recursion, and the G{\"{o}}del-L{\"{o}}b Axiom.pdf:pdf},
isbn = {978-1-84890-377-7},
issn = {2631-9810},
journal = {Journal of Applied Logics - The IfCoLog Journal of Logics and their Applications},
number = {8},
pages = {2287--2311},
publisher = {College Publications},
title = {{Intensionality, Intensional Recursion, and the G{\"{o}}del-L{\"{o}}b Axiom}},
url = {http://collegepublications.co.uk/ifcolog/?00050},
volume = {8},
year = {2021}
}
@article{Esik1995a,
abstract = {The equational properties of the iteration operation in Lawvere theories are captured by the notion of iteration theories axiomatized by the Conway identities together with a complicated equation scheme, the "commutative identity". The first result of the paper shows that the commutative identity is implied by the Conway identities and the Scott induction principle formulated to involve only equations. Since the Scott induction principle holds in free iteration theories, we obtain a relatively simple first order axiomatization of the equational properties of iteration theories. We show, by means of an example that a simplified version of the Scott induction principle does not suffice for this purpose: There exists a Conway theory satisfying the scalar Scott induction principle which is not an iteration theory. A second example shows that there exists an iteration theory satisfying the scalar version of the Scott induction principle in which the general form fails. Finally, an example is included to verify the expected fact that there exists an iteration theory violating the scalar Scott induction principle. Interestingly, two of these examples are ordered theories in which the iteration operation is defined via least pre-fixed points. ?? 2000.},
author = {{\'{E}}sik, Zolt{\'{a}}n and Bern{\'{a}}tsky, L.},
doi = {10.1016/S1571-0661(04)80009-4},
file = {:Users/liang-tingchen/Dropbox/References/{\'{E}}sik, Bern{\'{a}}tsky - 1995 - Scott Induction and Equational Proofs.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
number = {C},
pages = {154--181},
publisher = {Elsevier B.V.},
series = {ENTCS},
title = {{Scott Induction and Equational Proofs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104800094},
volume = {1},
year = {1995}
}
@article{Diaconescu1975,
author = {Diaconescu, Radu},
doi = {10.1016/0022-4049(75)90015-8},
file = {:Users/liang-tingchen/Dropbox/References/Diaconescu - 1975 - Change of base for toposes with generators.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {nov},
number = {3},
pages = {191--218},
title = {{Change of base for toposes with generators}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0022404975900158},
volume = {6},
year = {1975}
}
@inproceedings{Forster2019,
abstract = {We formalise the computational undecidability of validity, satisfiability, and provability of first-order formulas following a synthetic approach based on the computation native to Coq's constructive type theory. Concretely, we consider Tarski and Kripke semantics as well as classical and intuitionistic natural deduction systems and provide compact many-one reductions from the Post correspondence problem (PCP). Moreover, developing a basic framework for synthetic computability theory in Coq, we formalise standard results concerning decidability, enumerability, and reducibility without reference to a concrete model of computation. For instance, we prove the equivalence of Post's theorem with Markov's principle and provide a convenient technique for establishing the enumerability of inductive predicates such as the considered proof systems and PCP.},
address = {New York, New York, USA},
author = {Forster, Yannick and Kirst, Dominik and Smolka, Gert},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs - CPP 2019},
doi = {10.1145/3293880.3294091},
file = {:Users/liang-tingchen/Dropbox/References/Forster, Kirst, Smolka - 2019 - On synthetic undecidability in Coq, with an application to the Entscheidungsproblem.pdf:pdf},
isbn = {9781450362221},
keywords = {Coq,Entscheidungsproblem,Markov's principle,Post's theorem,first-order logic,synthetic undecidability},
pages = {38--51},
publisher = {ACM Press},
title = {{On synthetic undecidability in Coq, with an application to the Entscheidungsproblem}},
url = {http://dl.acm.org/citation.cfm?doid=3293880.3294091},
year = {2019}
}
@article{Bauer2017,
abstract = {On the odd day, a mathematician might wonder what construc-tive mathematics is all about. They may have heard arguments in favor of constructivism but are not at all convinced by them, and in any case they may care little about philosophy. A typical introductory text about construc-tivism spends a great deal of time explaining the principles and contains only trivial mathematics, while advanced constructive texts are impenetrable, like all unfamiliar mathematics. How then can a mathematician find out what constructive mathematics feels like? What new and relevant ideas does con-structive mathematics have to offer, if any? I shall attempt to answer these questions. From a psychological point of view, learning constructive mathematics is ago-nizing, for it requires one to first unlearn certain deeply ingrained intuitions and habits acquired during classical mathematical training. In her book On Death and Dying [17] psychologist Elisabeth K{\"{u}}bler-Ross identified five stages through which people reach acceptance of life's traumatizing events: denial, anger, bargaining, depression, and acceptance. We shall follow her path.},
author = {Bauer, Andrej},
doi = {10.1090/bull/1556},
file = {:Users/liang-tingchen/Dropbox/References/Bauer - 2017 - Five stages of accepting constructive mathematics.pdf:pdf},
issn = {02730979},
journal = {Bulletin of the American Mathematical Society},
number = {3},
pages = {481--498},
title = {{Five stages of accepting constructive mathematics}},
volume = {54},
year = {2017}
}
@phdthesis{grahamlengrand:tel-01094980,
author = {Graham-Lengrand, St{\'{e}}phane},
file = {:Users/liang-tingchen/Dropbox/References/Graham-Lengrand - 2014 - Polarities {\&} Focussing a journey from Realisability to Automated Reasoning.pdf:pdf},
keywords = {Automated Reasoning,Classical Logic,Curry-Howard correspondence,DPLL,Focalisation,Focussing,Logic Programming,Orthogonality,Polarities,Polarit{\'{e}}s,Proof-search,Psyche,Realisability,SAT-solving,SMT-solving,Tableaux},
month = {dec},
school = {Paris-Sud XI},
title = {{Polarities {\&} Focussing: a journey from Realisability to Automated Reasoning}},
type = {Habilitation {\`{a}} diriger des recherches},
url = {https://tel.archives-ouvertes.fr/tel-01094980},
year = {2014}
}
@inproceedings{Hinze2012,
abstract = {Many program optimisations involve transforming a program in direct style to an equivalent program in continuation-passing style. This paper investigates the theoretical underpinnings of this transformation in the categorical setting of monads. We argue that so-called absolute Kan Extensions underlie this program optimisation. It is known that every Kan extension gives rise to a monad, the codensity monad, and furthermore that every monad is isomorphic to a codensity monad. The end formula for Kan extensions then induces an implementation of the monad, which can be seen as the categorical counterpart of continuationpassing style. We show that several optimisations are instances of this scheme: Church representations and implementation of backtracking using success and failure continuations, among others. Furthermore, we develop the calculational properties of Kan extensions, powers and ends. In particular, we propose a two-dimensional notation based on string diagrams that aims to support e ective reasoning with Kan extensions.},
author = {Hinze, Ralf},
booktitle = {Proceedings of the 11th international conference on Mathematics of Program Construction},
doi = {10.1007/978-3-642-31113-0_16},
file = {:Users/liang-tingchen/Dropbox/References/Hinze - 2012 - Kan extensions for program optimisation or art and dan explain an old trick.pdf:pdf},
isbn = {978-3-642-31112-3},
issn = {0302-9743},
keywords = {adjunction,backtracking,church representation,codensity monad,cps,end,haskell,kan extension,power,string diagram},
pages = {324--362},
publisher = {Springer-Verlag},
title = {{Kan extensions for program optimisation or: art and dan explain an old trick}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-31113-0{\_}16},
year = {2012}
}
@inproceedings{Griffin1990,
abstract = {The programming language Scheme contains the control construct call/cc that allows access to the current continuation (the current control context). This, in effect, provides Scheme with first-class labels and jumps. We show that the well-known formulae-as-types correspondence, which relates a constructive proof of a formula {\&}agr; to a program of type {\&}agr;, can be extended to a typed Idealized Scheme. What is surprising about this correspondence is that it relates classical proofs to typed programs. The existence of computationally interesting “classical programs” —programs of type {\&}agr;, where {\&}agr; holds classically, but not constructively — is illustrated by the definition of conjunctively, disjunctive, and existential types using standard classical definitions. We also prove that all evaluations of typed terms in Idealized Scheme are finite.},
address = {New York, New York, USA},
author = {Griffin, Timothy G.},
booktitle = {Proceedings of the 17th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '90},
doi = {10.1145/96709.96714},
file = {:Users/liang-tingchen/Dropbox/References/Griffin - 1990 - A formulae-as-type notion of control.pdf:pdf},
isbn = {0897913434},
issn = {07308566},
pages = {47--58},
publisher = {ACM Press},
title = {{A formulae-as-type notion of control}},
url = {papers://cff96cb1-96b7-4b11-a3e3-f4947c1d45b9/Paper/p7713 http://portal.acm.org/citation.cfm?doid=96709.96714},
year = {1990}
}
@incollection{Gibbons2015,
abstract = {A classic layout for complex software applications usually involves a set of fine-tuned performance-optimized routines that are combined and controlled from a higher layer in a lightweight fashion. As the application grows, reliable operation, portability, and maintainability gets to be a real concern. However, this can be tamed by abstracting away from the platform-dependent details by modelling the components and their relation on a higher level. Using a functional programming language combined with the technique of language embedding may be an answer when implementation of such solution comes in question [1][2]. In this design, the component descriptions may be captured by an adequate embedded domain-specific language that compiles to a lower-level language but there also has to be a way for composition and therefore getting a complete working application out of them. In this paper, we propose a method for extending compiled embedded domain-specific languages into a stand-alone system with minimal effort. {\textcopyright} 2012 Springer-Verlag.},
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Gibbons, Jeremy},
booktitle = {Central European Functional Programming School. CEFP 2013},
doi = {10.1007/978-3-319-15940-9_1},
editor = {Zs{\'{o}}k, Vikt{\'{o}}ria and Horv{\'{a}}th, Zolt{\'{a}}n and Csat{\'{o}}, Lehel},
eprint = {9780201398298},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2015 - Functional Programming for Domain-Specific Languages.pdf:pdf},
isbn = {978-3-319-15939-3},
issn = {03029743},
pages = {1--28},
pmid = {4520227},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Functional Programming for Domain-Specific Languages}},
url = {http://link.springer.com/10.1007/978-3-319-15940-9 http://link.springer.com/10.1007/978-3-319-15940-9{\_}1},
volume = {8606},
year = {2015}
}
@article{Orton2018,
abstract = {The homotopical approach to intensional type theory views proofs of equality as paths. We explore what is required of an object I in a topos to give such a path-based model of type theory in which paths are just functions with domain I. Cohen, Coquand, Huber and M{\"{o}}rtberg give such a model using a particular category of presheaves. We investigate the extent to which their model construction can be expressed in the internal type theory of any topos and identify a collection of quite weak axioms for this purpose. This clarifies the definition and properties of the notion of uniform Kan filling that lies at the heart of their constructive interpretation of Voevodsky's univalence axiom.},
archivePrefix = {arXiv},
arxivId = {1712.04864},
author = {Orton, Ian and Pitts, Andrew M.},
doi = {10.23638/LMCS-14(4:23)2018},
eprint = {1712.04864},
file = {:Users/liang-tingchen/Dropbox/References/Orton, Pitts - 2018 - Axioms for modelling cubical type theory in a topos.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Cubical sets,Cubical type theory,Homotopy type theory,Models of dependent type theory,Topos,Univalence},
number = {4},
pages = {1--33},
title = {{Axioms for modelling cubical type theory in a topos}},
volume = {14},
year = {2018}
}
@article{Gumm2009a,
author = {Gumm, H. Peter},
doi = {10.1016/j.tcs.2008.09.057},
file = {:Users/liang-tingchen/Dropbox/References/Gumm - 2009 - Copower functors.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {12-13},
pages = {1129--1142},
publisher = {Elsevier B.V.},
title = {{Copower functors}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397508007305},
volume = {410},
year = {2009}
}
@article{Ghani2004,
author = {Ghani, Neil and Uustalu, Tarmo},
doi = {10.1051/ita:2004016},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Uustalu - 2004 - Coproducts of Ideal Monads.pdf:pdf},
issn = {0988-3754},
journal = {RAIRO - Theoretical Informatics and Applications},
month = {oct},
number = {4},
pages = {321--342},
title = {{Coproducts of Ideal Monads}},
url = {http://www.rairo-ita.org/10.1051/ita:2004016},
volume = {38},
year = {2004}
}
@article{Machanavajjhala2007,
author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
doi = {10.1145/1217299.1217302},
file = {:Users/liang-tingchen/Dropbox/References/Machanavajjhala et al. - 2007 - {\$}l{\$}-diversity Privacy Beyond {\$}k{\$}-Anonymity.pdf:pdf},
issn = {15564681},
journal = {ACM Transactions on Knowledge Discovery from Data},
month = {mar},
number = {1},
pages = {3},
title = {{{\$}l{\$}-diversity: Privacy Beyond {\$}k{\$}-Anonymity}},
url = {http://portal.acm.org/citation.cfm?doid=1217299.1217302},
volume = {1},
year = {2007}
}
@inproceedings{Cave2013,
address = {New York, New York, USA},
author = {Cave, Andrew and Pientka, Brigitte},
booktitle = {Proceedings of the Eighth ACM SIGPLAN international workshop on Logical frameworks {\&} meta-languages: theory {\&} practice - LFMTP '13},
doi = {10.1145/2503887.2503889},
file = {:Users/liang-tingchen/Dropbox/References/Cave, Pientka - 2013 - First-class substitutions in contextual type theory.pdf:pdf},
isbn = {9781450323826},
keywords = {de-,higher-order abstract syntax,logical frameworks},
pages = {15},
publisher = {ACM Press},
title = {{First-class substitutions in contextual type theory}},
url = {http://dl.acm.org/citation.cfm?doid=2503887.2503889},
year = {2013}
}
@incollection{Johnstone1991,
abstract = {Preframes (directed complete posets with finite meets that distribute over the directed joins) are the algebras for an infinitary essentially algebraic theory, and can be presented by generators and relations. This result is combined with a general argument concerning categories of commutative monoids to give a very short proof of the localic Tychonoff Theorem. It is also shown how frames can be presented as preframes, a result analogous to Johnstone's construction of frames from sites, and an application is given.},
author = {Johnstone, Peter T. and Vickers, Steven},
booktitle = {Category Theory},
doi = {10.1007/BFb0084221},
editor = {Carboni, Aurelio and Pedicchio, Maria and Rosolini, Guiseppe},
file = {:Users/liang-tingchen/Dropbox/References/Johnstone, Vickers - 1991 - Preframe presentations present.pdf:pdf},
pages = {193--212},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{Preframe presentations present}},
url = {http://dx.doi.org/10.1007/BFb0084221},
year = {1991}
}
@article{Kock1972,
author = {Kock, Anders},
doi = {10.1007/BF01304852},
file = {:Users/liang-tingchen/Dropbox/References/Kock - 1972 - Strong functors and monoidal monads.pdf:pdf},
issn = {0003-889X},
journal = {Archiv der Mathematik},
month = {dec},
number = {1},
pages = {113--120},
title = {{Strong functors and monoidal monads}},
url = {http://link.springer.com/10.1007/BF01304852},
volume = {23},
year = {1972}
}
@incollection{Shenoy1990,
address = {Berlin, Heidelberg},
author = {Shenoy, Prakash P and Shafer, Glenn},
booktitle = {Classic Works of the Dempster-Shafer Theory of Belief Functions},
doi = {10.1007/978-3-540-44792-4_20},
file = {:Users/liang-tingchen/Dropbox/References/Shenoy, Shafer - 1990 - Axioms for Probability and Belief-Function Propagation(2).pdf:pdf},
pages = {499--528},
publisher = {Springer Berlin Heidelberg},
title = {{Axioms for Probability and Belief-Function Propagation}},
url = {http://link.springer.com/10.1007/978-3-540-44792-4{\_}20},
year = {1990}
}
@incollection{Sulzmann2006,
abstract = {There are a number of extended forms of algebraic data types such as type classes with existential types and generalized algebraic data types. Such extensions are highly useful but their interaction has not been studied formally so far. Here, we present a unifying framework for these extensions. We show that the combination of type classes and generalized algebraic data types allows us to express a number of interesting properties which are desired by programmers. We support type checking based on a novel constraint solver. Our results show that our system is practical and greatly extends the expressive power of languages such as Haskell and ML. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
author = {Sulzmann, Martin and Wazny, Jeremy and Stuckey, Peter J.},
booktitle = {Functional and Logic Programming. FLOPS 2006},
doi = {10.1007/11737414_5},
editor = {Hagiya, Masami and Wadler, Philip},
file = {:Users/liang-tingchen/Dropbox/References/Sulzmann, Wazny, Stuckey - 2006 - A Framework for Extended Algebraic Data Types.pdf:pdf},
isbn = {3540334386},
issn = {03029743},
pages = {47--64},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A Framework for Extended Algebraic Data Types}},
url = {http://link.springer.com/10.1007/11737414{\_}5},
volume = {3945},
year = {2006}
}
@incollection{Harrison2009,
abstract = {Inspired by a number of different applications of rewriting logic, equational logic, and type theory that we present and further advance in this thesis, we study a unified formalism based on the key aspects of these quite different lines of research. The resulting formalism, that we call the open calculus of constructions, is intended as a step towards our long-term goal of developing a unified language for programming, specification and interactive theorem proving. $\backslash$nWe begin our work by exploring the application of rewriting logic as a semantic framework for concurrency. To this end, we give a unified treatment of different classes of Petri nets, a typical and important representative of a class of formalisms that are used for the modeling and specification of concurrent and distributed systems based on a multiset representation of a distributed state space. Specifically, we continue the line of research initiated by Meseguer and Montanari under the motto "Petri nets are monoids" by giving a rewriting semantics for different Petri nets classes. In particular, we have covered important high-level Petri net models, namely algebraic net specifications and colored Petri nets, and we have proved that the models of our representations are naturally isomorphic to the well-known Best-Devillers process semantics. Apart from their contribution to a conceptual unification in this field, the main practical advantage of our representations in rewriting logic is their executability, which allows us to use a rewriting engine such as Maude for the efficient symbolic execution of system models and for their analysis. $\backslash$nThe next application addressed in this thesis is the use of type theory, more precisely the calculus of inductive constructions, as a logical framework and for metalogical reasoning. Specifically, we have used the COQ proof assistant in a formally rigorous development of a UNITY-style temporal logic, which generalizes the original UNITY approach in important aspects. Since all inference rules of the temporal logic are proved as theorems in the metalogic, the result of the development is a verified temporal logic library, which due to the use of labeled transition systems as a semantic basis, can be employed for a wide range of system models, Petri nets and rewriting logic specifications being particular examples. The development also includes a new application of the proposition-as-types interpretation in the context of compositional reasoning. $\backslash$nThe use of membership equational logic or rewriting logic as a semantic and logical framework for higher-order languages, or more generally languages with binding constructs, obviously requires a first-order treatment of names and relevant operations such as substitutions. To systematically address such applications, we develop CINNI, a new calculus of names and substitutions, that takes names seriously in the sense that it does not abstract from names, and is generic in the sense that it can be instantiated to arbitrary object languages. Our calculus unifies the standard named notation and a notation based on de Bruijn indices by employing a representation that was originally developed by Berkling for the lambda-calculus. It furthermore nicely generalizes the calculus lambda upsilon of explicit substitutions developed by Lescanne, and, as we show, most metatheoretic results can be generalized to the new calculus. We furthermore give a very general confluence result for the composition of CINNI with the equations or rules capturing the dynamics of the object language, and we in particular discuss how our approach can be applied to the representation of the untyped lambda-calculus, Abadi and Cardelli's object calculus, also called the sigma-calculus, and Milner's pi-calculus for communicating and mobile systems. As a real-world application of CINNI we briefly discuss a specification of an active network programming language in the rewriting-logic-based language Maude. $\backslash$nWe more specifically address the use of membership equational logic and rewriting logic as a first-order logical framework by representing an important class of pure type systems. Pure type systems generalize a variety of different type theories, including the calculus of constructions and its well-known subsystems, and can be seen as higher-order logics via the propositions-as-types interpretation. Following a methodology based on Meseguer's general logics in combination with rewriting logic as a concrete logical framework, we have studied representations of pure type systems at different levels of abstractions, ranging from an abstract textbook representation to a more concrete executable representation of an important subclass, which can directly serve as a type inference and type checking algorithm. The latter representation is based on a new notion of uniform pure type systems, which take names seriously thanks to the CINNI calculus and simultaneously offer a possible solution to the known problem with alpha-closure pointed out by Pollack. Using an example, in which we validate proofs developed with the LEGO proof assistant in an extension of the calculus of constructions with universes, we have demonstrated how our approach directly leads to an executable prototype in a rewriting logic language such as Maude. $\backslash$nAs an application of type theory in the context of classical reasoning we study Howe's HOL/Nuprl connection, which addresses the problem of formal interoperability between proof assistents, from the viewpoint of Meseguer's general logics. We supplement Howe's semantic justification by a proof-theoretic correctness argument, a piece of work which has lead to proof-translation as new interesting application (explored in joint work with Naumov) that goes beyond Howe's original HOL/Nuprl connection. From a theoretical perspective we found that the core idea of the HOL/Nuprl connection, namely the beneficial coexistence of an intensional and an extensional logic in the same formal system, does not rely on any of the advanced concepts of Nuprl, but can equally well be used in Martin-L{\"{o}}f's type theory and can further be easily adopted to type theories in the line of calculus of constructions. $\backslash$nThe final and main contribution of this thesis is the development of a formalism that we call the open calculus of constructions (OCC). It is based on the surprisingly powerful interaction between its two key features, namely dependent types, in the spirit of Martin-L{\"{o}}f's type theory and the calculus of constructions, and the computational system of rewriting logic and its underlying membership equational logic, which is based on conditional rewriting modulo equations. The applications of membership equational logic, rewriting logic, and type theory, studied in this thesis have not only inspired the development of this unifying formalism, but they become applications of OCC itself and benefit from its use in an essential way. On the theoretical side, we introduce OCC by presenting a classical set-theoretic semantics and a formal system for which we prove soundness and consistency as a logic. The formal system is used to define derivable judgements together with their operational semantics, and is based on the ideas that we developed earlier in the context of uniform pure type systems. The model-theoretic semantics that we develop in this thesis is a very intuitive semantics with proof-irrelevance for impredicative universes, but unlike existing approaches it is more direct and can be given independently of the formal system. Using an experimental prototype of OCC, that we implemented in Maude following the approach to the specification of type theories mentioned before in combination with reflective techniques, we have developed a large collection of examples, many of which are closely related to the applications discussed earlier in this thesis. These examples do not only convey the pragmatics of OCC, but they simultaneously provide a proof-of-concept for our approach. Among the topics covered by our examples we find executable equational/behavioral specifications, programming with dependent types, symbolic execution of system models, formalization of algebraic and categorical concepts, inductive/coinductive theorem proving, and theorem proving modulo equational theories.},
author = {Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Sozeau, Matthieu and Tabareau, Nicolas},
booktitle = {Interactive Theorem Proving. ITP 2018},
doi = {10.1007/978-3-319-94821-8_2},
editor = {Avigad, Jeremy and Mahboubi, Assia},
file = {:Users/liang-tingchen/Dropbox/References/Anand et al. - 2018 - Towards Certified Meta-Programming with Typed Template-Coq.pdf:pdf},
isbn = {9783319948218},
pages = {20--39},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Towards Certified Meta-Programming with Typed Template-Coq}},
url = {http://link.springer.com/10.1007/978-3-319-94821-8{\_}2},
volume = {10895},
year = {2018}
}
@article{Adamek2006,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan},
doi = {10.1016/j.ic.2005.11.005},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius - 2006 - Terminal coalgebras and free iterative theories.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {basic equation,iterative theory,rational tree,terminal coalgebra},
month = {jul},
number = {7},
pages = {1139--1172},
title = {{Terminal coalgebras and free iterative theories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540106000277},
volume = {204},
year = {2006}
}
@inproceedings{EspiritoSanto2017,
abstract = {A natural deduction system isomorphic to the focused sequent calculus for polarized intuitionistic logic is proposed. The system comes with a language of proof-terms, named polarized $\lambda$-calculus, whose reduction rules express simultaneously a normalization procedure and the isomorphic copy of the cut-elimination procedure pertaining to the focused sequent calculus. Noteworthy features of this natural deduction system are: how the polarity of a connective determines the style of its elimination rule; the existence of a proof-search strategy which is equivalent to focusing in the sequent calculus; the highly-disciplined organization of the syntax – even atoms have introduction, elimination and normalization rules. The polarized $\lambda$-calculus is a programming formalism close to call-by-push-value, but justified by its proof-theoretical pedigree.},
author = {{Esp{\'{i}}rito Santo}, Jos{\'{e}}},
booktitle = {LSFA 2016 - 11th Workshop on Logical and Semantic Frameworks with Applications (LSFA)},
doi = {10.1016/j.entcs.2017.04.010},
editor = {Nigam, Vivek and Florido, Mario},
file = {:Users/liang-tingchen/Dropbox/References/Esp{\'{i}}rito Santo - 2017 - The Polarized $\lambda$ -calculus.pdf:pdf},
issn = {15710661},
keywords = {bidirectional natural deduction,eta-expansion,focusing,general elimination rule,polarized logic},
month = {jun},
pages = {149--168},
publisher = {Elsevier B.V.},
series = {Electronic Notes in Theoretical Computer Science},
title = {{The Polarized $\lambda$ -calculus}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066117300221},
volume = {332},
year = {2017}
}
@book{Gay2017,
author = {Gay, Simon and Ravara, Ant{\'{o}}nio},
doi = {10.13052/rp-9788793519817},
file = {:Users/liang-tingchen/Dropbox/References/Gay, Ravara - 2017 - Behavioural Types from Theory to Tools.pdf:pdf},
isbn = {9788793519824},
pages = {1--412},
title = {{Behavioural Types: from Theory to Tools}},
url = {http://riverpublishers.com/dissertations{\_}xml/9788793519817/9788793519817.xml},
year = {2017}
}
@inproceedings{Perera2012,
abstract = {We present techniques that enable higher-order functional computations to "explain" their work by answering questions about how parts of their output were calculated. As explanations, we consider the traditional notion of program slices, which we show can be inadequate, and propose a new notion: trace slices. We present techniques for specifying flexible and rich slicing criteria based on partial expressions, parts of which have been replaced by holes. We characterise program slices in an algorithm-independent fashion and show that a least slice for a given criterion exists. We then present an algorithm, called unevaluation, for computing least program slices from computations reified as traces. Observing a limitation of program slices, we develop a notion of trace slice as another form of explanation and present an algorithm for computing them. The unevaluation algorithm can be applied to any subtrace of a trace slice to compute a program slice whose evaluation generates that subtrace. This close correspondence between programs, traces, and their slices can enable the programmer to understand a computation interactively, in terms of the programming language in which the computation is expressed. We present an implementation in the form of a tool, discuss some important practical implementation concerns and present some techniques for addressing them. {\textcopyright} 2012 ACM.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1705.07678},
author = {Perera, Roly and Acar, Umut A. and Cheney, James and Levy, Paul Blain},
booktitle = {Proceedings of the 17th ACM SIGPLAN international conference on Functional programming - ICFP '12},
doi = {10.1145/2364527.2364579},
eprint = {1705.07678},
file = {:Users/liang-tingchen/Dropbox/References/Perera et al. - 2012 - Functional programs that explain their work.pdf:pdf},
isbn = {9781450310543},
issn = {15232867},
keywords = {Algorithms,Computer debugging,Computer programming language,Functional programs,Given criterion,Practical im},
pages = {365},
publisher = {ACM Press},
title = {{Functional programs that explain their work}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867563933{\&}partnerID=40{\&}md5=bf23ba51d05f1ad8d3c800becf466869 http://dl.acm.org/citation.cfm?doid=2364527.2364579},
year = {2012}
}
@article{Danos2006,
author = {Danos, Vincent and Desharnais, Jos{\'{e}}e and Laviolette, Fran{\c{c}}ois and Panangaden, Prakash},
doi = {10.1016/j.ic.2005.02.004},
file = {:Users/liang-tingchen/Dropbox/References/Danos et al. - 2006 - Bisimulation and cocongruence for probabilistic systems.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {4},
pages = {503--523},
title = {{Bisimulation and cocongruence for probabilistic systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540105001951},
volume = {204},
year = {2006}
}
@article{Beeson1975,
abstract = {The primary purpose of this work is to analyze the constructive interpretations of classical theorems concerning the continuity of effective operations. These theorems are the “recursivizations” of the statements that all functions (on various spaces) are continuous. To discuss the question whether these statements are constructively valid, it would be necessary to analyze the notion of “constructively valid,” which is beyond the scope of this paper. We now proceed to describe our results. We deal with two kinds of effective operations: (i) partial operations on indices of partial functions, and (ii) total operations on indices of total functions. The two principal theorems of the subject assert that each such operation is continuous; for (i) this is due to Myhill-Shepherdson [7] and called MS here; for (ii) it is due to Kreisel, Lacombe, and Shoenfield [5] and called KLS. (Explicit formulations of these and other principles mentioned in the introduction will be given in {\S}1 below.)},
author = {Beeson, Michael J.},
doi = {10.2307/2272158},
file = {:Users/liang-tingchen/Dropbox/References/Beeson - 1975 - The nonderivability in intuitionistic formal systems of theorems on the continuity of effective operations.pdf:pdf},
issn = {0022-4812},
journal = {Journal of Symbolic Logic},
month = {sep},
number = {3},
pages = {321--346},
title = {{The nonderivability in intuitionistic formal systems of theorems on the continuity of effective operations}},
url = {https://www.cambridge.org/core/product/identifier/S0022481200052956/type/journal{\_}article},
volume = {40},
year = {1975}
}
@phdthesis{Appelgate1965,
author = {Appelgate, Harry Wesley},
pages = {90},
school = {Columbia University},
title = {{Acyclic models and resolvent functors}},
year = {1965}
}
@inproceedings{Gaboardi2013,
abstract = {Differential privacy offers a way to answer queries about sensitive information while providing strong, provable privacy guarantees, ensuring that the presence or absence of a single individual in the database has a negligible statistical effect on the query's result. Proving that a given query has this property involves establishing a bound on the query's sensitivity---how much its result can change when a single record is added or removed. A variety of tools have been developed for certifying that a given query differentially private. In one approach, Reed and Pierce [34] proposed a functional programming language, Fuzz, for writing differentially private queries. Fuzz uses linear types to track sensitivity and a probability monad to express randomized computation; it guarantees that any program with a certain type is differentially private. Fuzz can successfully verify many useful queries. However, it fails when the sensitivity analysis depends on values that are not known statically. We present DFuzz, an extension of Fuzz with a combination of linear indexed types and lightweight dependent types. This combination allows a richer sensitivity analysis that is able to certify a larger class of queries as differentially private, including ones whose sensitivity depends on runtime information. As in Fuzz, the differential privacy guarantee follows directly from the soundness theorem of the type system. We demonstrate the enhanced expressivity of DFuzz by certifying differential privacy for a broad class of iterative algorithms that could not be typed previously.},
address = {New York, New York, USA},
author = {Gaboardi, Marco and Haeberlen, Andreas and Hsu, Justin and Narayan, Arjun and Pierce, Benjamin C.},
booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '13},
doi = {10.1145/2429069.2429113},
file = {:Users/liang-tingchen/Dropbox/References/Gaboardi et al. - 2013 - Linear dependent types for differential privacy.pdf:pdf},
isbn = {9781450318327},
issn = {07308566},
keywords = {depen-,differential privacy,linear logic,type systems},
pages = {357},
publisher = {ACM Press},
title = {{Linear dependent types for differential privacy}},
url = {http://dl.acm.org/citation.cfm?doid=2429069.2429113},
year = {2013}
}
@article{Schroder2008,
abstract = {Modal logic has a good claim to being the logic of choice for describing the reactive behaviour of systems modeled as coalgebras. Logics with modal operators obtained from so-called predicate liftings have been shown to be invariant under behavioral equivalence. Expressivity results stating that, conversely, logically indistinguishable states are behaviorally equivalent depend on the existence of separating sets of predicate liftings for the signature functor at hand. Here, we provide a classification result for predicate liftings which leads to an easy criterion for the existence of such separating sets, and we give simple examples of functors that fail to admit expressive normal or monotone modal logics, respectively, or in fact an expressive (unary) modal logic at all. We then move on to polyadic modal logic, where modal operators may take more than one argument formula. We show that every accessible functor admits an expressive polyadic modal logic. Moreover, expressive polyadic modal logics are, unlike unary modal logics, compositional.},
author = {Schr{\"{o}}der, Lutz},
doi = {10.1016/j.tcs.2007.09.023},
editor = {Sassone, Vladimiro},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der - 2008 - Expressivity of coalgebraic modal logic The limits and beyond.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {coalgebra,expressivity,modal logic,predicate lifting},
number = {2-3},
pages = {230--247},
publisher = {Springer; Berlin; http://www.springer.de},
series = {Lecture Notes in Computer Science},
title = {{Expressivity of coalgebraic modal logic: The limits and beyond}},
url = {http://dx.doi.org/10.1016/j.tcs.2007.09.023},
volume = {390},
year = {2008}
}
@inproceedings{Appel2007,
abstract = {We present a model of recursive and impredicatively quantified types with mutable references. We interpret in this model all of the type constructors needed for typed intermediate languages and typed assembly languages used for object-oriented and functional languages. We establish in this purely semantic fashion a soundness proof of the typing systems underlying these TILs and TALs - -ensuring that every well-typed program is safe. The technique is generic, and applies to any small-step semantics including -calculus, labeled transition systems, and von Neumann machines. It is also simple, and reduces mainly to defining a Kripke semantics of the G{\"{o}}del-L{\"{o}}b logic of provability. We have mechanically verified in Coq the soundness of our type system as applied to a von Neumann machine. Copyright {\textcopyright} 2007 ACM.},
address = {New York, New York, USA},
author = {Appel, Andrew W. and Melli{\`{e}}s, Paul-Andr{\'{e}} and Richards, Christopher D. and Vouillon, J{\'{e}}r{\^{o}}me},
booktitle = {Proceedings of the 34th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '07},
doi = {10.1145/1190216.1190235},
file = {:Users/liang-tingchen/Dropbox/References/Appel et al. - 2007 - A very modal model of a modern, major, general type system.pdf:pdf},
isbn = {1595935754},
issn = {07308566},
keywords = {Impredicative polymorphism,Kripke models,Mutable references,Recursive types},
pages = {109},
publisher = {ACM Press},
title = {{A very modal model of a modern, major, general type system}},
url = {http://portal.acm.org/citation.cfm?doid=1190216.1190235},
year = {2007}
}
@article{Kurz2005,
author = {Kurz, Alexander and Pattinson, Dirk},
doi = {10.1017/S0960129505004755},
file = {:Users/liang-tingchen/Dropbox/References/Kurz, Pattinson - 2005 - Coalgebraic modal logic of finite rank.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jun},
number = {3},
pages = {453--473},
title = {{Coalgebraic modal logic of finite rank}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129505004755},
volume = {15},
year = {2005}
}
@incollection{Wood1978,
author = {Wood, R. J.},
booktitle = {Indexed Categories and Their Applications},
doi = {10.1007/BFb0061362},
file = {:Users/liang-tingchen/Dropbox/References/Wood - 1978 - V-indexed categories.pdf:pdf},
pages = {126--140},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Mathematics},
title = {{V-indexed categories}},
year = {1978}
}
@article{Cecaj2016,
abstract = {The analysis of multiple datasets on users' behaviors opens interesting information fusion possibilities and, at the same time, creates a potential for re-identification and de-anonymization of users' data. On the one hand, this kind of approaches can breach users' privacy despite anonymization. On the other hand, combining different datasets is a key enabler for advanced context-awareness in that information from multiple sources can complement and enrich each other. In this work we analyze different anonymized mobility datasets in the direction of highlighting re-identification and information fusion possibilities. In particular we focus on call detail record (CDR) datasets released by mobile telecom operators and datasets comprising geo-localized messages released by social network sites. Results shows that: (1) in line with previous findings, few (about 4) data points are enough to uniquely pin point the majority (90 {\%}) of the users, (2) more than 20 {\%} of CDR users have a single social network user exhibiting a number of matching data points. We speculate that these two users might be the same person. (3) We derive an estimate of the probability of two users begin the same person given the number of data points they have in common, and estimate that for 3 {\%} of the social network users we can find a CDR user very likely ({\textgreater}90 {\%} probability) to be the same person.},
author = {Cecaj, Alket and Mamei, Marco and Zambonelli, Franco},
doi = {10.1007/s12652-015-0303-x},
file = {:Users/liang-tingchen/Dropbox/References/Cecaj, Mamei, Zambonelli - 2016 - Re-identification and information fusion between anonymized CDR and social network data.pdf:pdf},
issn = {1868-5137},
journal = {Journal of Ambient Intelligence and Humanized Computing},
keywords = {De-anonymization,Information fusion,Mobility patterns},
month = {feb},
number = {1},
pages = {83--96},
publisher = {Springer Berlin Heidelberg},
title = {{Re-identification and information fusion between anonymized CDR and social network data}},
url = {http://link.springer.com/10.1007/s12652-015-0303-x},
volume = {7},
year = {2016}
}
@phdthesis{Ziliani2015a,
author = {Ziliani, Beta},
file = {:Users/liang-tingchen/Dropbox/References/Ziliani - 2015 - Interactive Typed Tactic Programming in the Coq Proof Assistant.pdf:pdf},
number = {March},
school = {Saarland University},
title = {{Interactive Typed Tactic Programming in the Coq Proof Assistant}},
year = {2015}
}
@inproceedings{Pitts1998,
abstract = {Existential types have proved useful for classifying various kinds of information hiding in programming languages, such as occurs in abstract datatypes and objects. In this paper we address the question of when two elements of an existential type are semantically equivalent. Of course, it depends what one means by 'semantic equivalence'. Here we take a syntactic approach-so semantic equivalence will mean some kind of operational equivalence. The paper begins by surveying some of the literature on this topic involving 'logical relations'. Matters become quite complicated if the programming language mixes existential types with function types and features involving non-termination (such as recursive definitions). We give an example (suggested by Ian Stark) to show that in this case the existence of suitable relations is sufficient, but not necessary for proving operational equivalences at existential types. Properties of this and other examples are proved using a new form of operationally-based logical relation which does in fact provide a useful characterisation of operational equivalence for existential types.},
author = {Pitts, Andrew M.},
booktitle = {Automata, Languages and Programming. ICALP 1998},
doi = {10.1007/BFb0055063},
editor = {Larsen, Kim G. and Skyum, Sven and Winskel, Glynn},
file = {:Users/liang-tingchen/Dropbox/References/Pitts - 1998 - Existential types Logical relations and operational equivalence.pdf:pdf},
isbn = {3540647813},
issn = {16113349},
number = {1973},
pages = {309--326},
publisher = {Springer, Berlin, Heidelberg},
title = {{Existential types: Logical relations and operational equivalence}},
url = {http://link.springer.com/10.1007/BFb0055063},
volume = {1443},
year = {1998}
}
@inproceedings{Ben-Sasson2014,
abstract = {We build a system that provides succinct non-interactive zero-knowledge proofs (zk-SNARKs) for program executions on a von Neumann RISC architecture. The system has two components: a cryptographic proof system for verifying satisfiability of arithmetic circuits, and a circuit generator to translate program executions to such circuits. Our design of both components improves in functionality and efficiency over prior work, as follows.Our circuit generator is the first to be universal: it does not need to know the program, but only a bound on its running time. Moreover, the size of the output circuit depends additively (rather than multiplicatively) on program size, allowing verification of larger programs.The cryptographic proof system improves proving and verification times, by leveraging new algorithms and a pairing library tailored to the protocol.We evaluated our system for programs with up to 10,000 instructions, running for up to 32,000 machine steps, each of which can arbitrarily access random-access memory; and also demonstrated it executing programs that use just-in-time compilation. Our proofs are 230 bytes long at 80 bits of security, or 288 bytes long at 128 bits of security. Typical verification time is 5 milliseconds, regardless of the original program's running time.},
author = {Ben-Sasson, Eli and Chiesa, Alessandro and Tromer, Eran and Virza, Madars},
booktitle = {Proceedings of the 23rd {\{}USENIX{\}} Security Symposium},
file = {:Users/liang-tingchen/Dropbox/References/Ben-Sasson et al. - 2014 - Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture.pdf:pdf},
isbn = {9781931971157},
keywords = {computationally-sound proofs,succinct arguments,zero-knowledge},
pages = {781--796},
publisher = {{\{}USENIX{\}} Association},
title = {{Succinct Non-Interactive Zero Knowledge for a von Neumann Architecture}},
url = {https://eprint.iacr.org/2013/879},
year = {2014}
}
@incollection{Moura2021a,
abstract = {Lean 4 is a reimplementation of the Lean interactive theorem prover (ITP) in Lean itself. It addresses many shortcomings of the previous versions and contains many new features. Lean 4 is fully extensible: users can modify and extend the parser, elaborator, tactics, decision procedures, pretty printer, and code generator. The new system has a hygienic macro system custom-built for ITPs. It contains a new typeclass resolution procedure based on tabled resolution, addressing significant performance problems reported by the growing user base. Lean 4 is also an efficient functional programming language based on a novel programming paradigm called functional but in-place. Efficient code generation is crucial for Lean users because many write custom proof automation procedures in Lean itself.},
author = {de Moura, Leonardo and Ullrich, Sebastian},
booktitle = {Automated Deduction – CADE 28. CADE 2021},
doi = {10.1007/978-3-030-79876-5_37},
editor = {Platzer, Andr{\'{e}} and Sutcliffe, Geoff},
file = {:Users/liang-tingchen/Dropbox/References/Moura, Ullrich - 2021 - The Lean 4 Theorem Prover and Programming Language.pdf:pdf},
isbn = {9783030798758},
issn = {16113349},
pages = {625--635},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{The Lean 4 Theorem Prover and Programming Language}},
url = {http://dx.doi.org/10.1007/978-3-030-79876-5{\_}37 https://link.springer.com/10.1007/978-3-030-79876-5{\_}37},
volume = {12699},
year = {2021}
}
@inproceedings{Adamek2015b,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Milius, Stefan and Urbat, Henning},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.1},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Milius, Urbat - 2015 - Syntactic Monoids in a Category.pdf:pdf},
keywords = {1,2015,4230,algebra,algebraic automata theory,and phrases syntactic monoid,calco,coalgebra,commutative variety,digital object identifier 10,duality,lipics,symmetric monoidal closed category,transition monoid},
title = {{Syntactic Monoids in a Category}},
year = {2015}
}
@inproceedings{Gonthier1992,
address = {New York, New York, USA},
author = {Gonthier, Georges and Abadi, Martı́n and L{\'{e}}vy, Jean-Jacques},
booktitle = {Proceedings of the 19th ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '92},
doi = {10.1145/143165.143172},
file = {:Users/liang-tingchen/Dropbox/References/Gonthier, Abadi, L{\'{e}}vy - 1992 - The geometry of optimal lambda reduction.pdf:pdf},
isbn = {0897914538},
pages = {15--26},
publisher = {ACM Press},
title = {{The geometry of optimal lambda reduction}},
url = {http://dl.acm.org/citation.cfm?id=143172 http://portal.acm.org/citation.cfm?doid=143165.143172},
year = {1992}
}
@article{Klin2007,
author = {Klin, Bartek},
doi = {10.1016/j.entcs.2007.02.034},
file = {:Users/liang-tingchen/Dropbox/References/Klin - 2007 - Coalgebraic modal logic beyond sets.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {coalgebra,locally presentable category,modal logic},
month = {apr},
pages = {177--201},
title = {{Coalgebraic modal logic beyond sets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066107001065},
volume = {173},
year = {2007}
}
@article{Lai2017,
abstract = {For a small quantaloid {\$}\backslashmathcal{\{}Q{\}}{\$} we consider four fundamental 2-monads {\$}\backslashmathbb{\{}T{\}}{\$} on {\$}\backslashmathcal{\{}Q{\}}\backslashtext{\{}-{\}}{\{}\backslashbf Cat{\}}{\$}, given by the presheaf 2-monad {\$}\backslashmathbb{\{}P{\}}{\$} and the copresheaf 2-monad {\$}\backslashmathbb{\{}P{\}}{\^{}}{\{}\backslashdag{\}}{\$}, as well as their two composite 2-monads, and establish that they all laxly distribute over {\$}\backslashmathbb{\{}P{\}}{\$}. These four 2-monads therefore admit lax extensions to the category {\$}\backslashmathcal{\{}Q{\}}\backslashtext{\{}-{\}}{\{}\backslashbf Dist{\}}{\$} of {\$}\backslashmathcal{\{}Q{\}}{\$}-categories and their distributors. We characterize the corresponding {\$}(\backslashmathbb{\{}T{\}},\backslashmathcal{\{}Q{\}}){\$}-categories in each of the four cases, leading us to both known and novel categorical structures.},
archivePrefix = {arXiv},
arxivId = {1605.04489},
author = {Lai, Hongliang and Shen, Lili and Tholen, Walter},
eprint = {1605.04489},
file = {:Users/liang-tingchen/Dropbox/References/Lai, Shen, Tholen - 2017 - Lax distributive laws for topology, II.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {2016,and phrases,c hongliang lai,copresheaf monad,double copresheaf monad,double presheaf,lax distributive law,lax monad extension,lax $\lambda$ -algebra,lili shen and walter,monad,permission to copy for,presheaf monad,private use granted,q -closure,q -interior space,quantaloid,space,tholen},
number = {21},
pages = {736--768},
title = {{Lax distributive laws for topology, II}},
url = {http://arxiv.org/abs/1605.04489 http://www.tac.mta.ca/tac/volumes/32/21/32-21abs.html},
volume = {32},
year = {2017}
}
@inproceedings{Mcbride2014,
abstract = {I present a datatype-generic treatment of recursive container types whose elements are guaranteed to be stored in increasing order, with the ordering invariant rolled out systematically. Intervals, lists and binary search trees are instances of the generic treatment. On the journey to this treatment, I report a variety of failed experiments and the transferable learning experiences they triggered. I demonstrate that a total element ordering is enough to deliver insertion and flattening algorithms, and show that (with care about the formulation of the types) the implementations remain as usual. Agda's instance arguments and pattern synonyms maximize the proof search done by the typechecker and minimize the appearance of proofs in program text, often eradicating them entirely. Generalizing to indexed recursive container types, invariants such as size and balance can be expressed in addition to ordering. By way of example, I implement insertion and deletion for 2-3 trees, ensuring both order and balance by the discipline of type checking.},
address = {New York, New York, USA},
author = {McBride, Conor Thomas},
booktitle = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
doi = {10.1145/2628136.2628163},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2014 - How to keep your neighbours in order.pdf:pdf},
isbn = {9781450328739},
issn = {15232867},
keywords = {2-3 trees,a precise implementation of,agda,balancing,dependent types,i take the time,insertion and deletion for,ordering,reporting a selection of,sorting,space,to explore the design},
pages = {297--309},
publisher = {ACM Press},
title = {{How to keep your neighbours in order}},
url = {http://dl.acm.org/citation.cfm?doid=2628136.2628163},
year = {2014}
}
@incollection{Fujii2016,
abstract = {In the mid-nineties, Turi and Plotkin gave an elegant categorical treatment of denotational and operational semantics for process algebra-like languages, proving compositionality and adequacy by defining operational semantics as a distributive law of syntax over behaviour. However, its applications to stateful or effectful languages, incorporating (co)models of a countable Lawvere theory, have been elusive so far. We make some progress towards a coalgebraic treatment of such languages, proposing a congruence format related to the evaluation-in-context paradigm. We formalise the denotational semantics in suitable Kleisli categories, and prove adequacy and compositionality of the semantic theory under this congruence format. {\textcopyright} 2013 Springer-Verlag.},
author = {Fujii, Soichiro and Katsumata, Shin-ya and Melli{\`{e}}s, Paul-Andr{\'{e}}},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-662-49630-5_30},
editor = {Jacobs, Bart and L{\"{o}}ding, Christof},
file = {:Users/liang-tingchen/Dropbox/References/Fujii, Katsumata, Melli{\`{e}}s - 2016 - Towards a Formal Theory of Graded Monads.pdf:pdf},
isbn = {978-3-662-49629-9},
issn = {0302-9743},
pages = {513--530},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Towards a Formal Theory of Graded Monads}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84874438740{\&}partnerID=tZOtx3y1 http://link.springer.com/10.1007/978-3-662-49630-5{\_}30},
year = {2016}
}
@incollection{Ancona2009,
author = {Ancona, Davide and Lagorio, Giovanni and Zucca, Elena},
booktitle = {Types for Proofs and Programs},
doi = {10.1007/978-3-642-02444-3_1},
editor = {Berardi, Stefano and Damiani, Ferruccio and De'Liguoro, Ugo},
file = {:Users/liang-tingchen/Dropbox/References/Ancona, Lagorio, Zucca - 2009 - Type inference by coinductive logic programming.pdf:pdf},
keywords = {coinduction,nominal and structural typing,object-oriented languages,type inference},
pages = {1--18},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Type inference by coinductive logic programming}},
year = {2009}
}
@inproceedings{Taha2000a,
abstract = {A multi-stage computation is one involving more than one stage of execution. MetaML is a language for programming multi-stage computations. Previous studies presented big-step semantics, categorical semantics, and sound type systems for MetaML. In this paper, we report on a confluent and sound reduction semantics for untyped call-by name (CBN) MetaML. The reduction semantics can be used to formally justify some optimization performed by a CBN MetaML implementation. The reduction semantics demonstrates that non-trivial equalities hold for object-code, even in the untyped setting. The paper also emphasizes that adding intensional analysis (that is, taking-apart object programs) to MetaML remains an interesting open problem.},
address = {New York, New York, USA},
author = {Taha, Walid},
booktitle = {Proceedings of the 2000 ACM SIGPLAN workshop on Partial evaluation and semantics-based program manipulation - PEPM '00},
doi = {10.1145/328690.328697},
file = {:Users/liang-tingchen/Dropbox/References/Taha - 1999 - A sound reduction semantics for untyped CBN mutli-stage computation. Or, the theory of MetaML is non-trival (extended abst.pdf:pdf},
isbn = {1581132018},
issn = {0362-1340},
pages = {34--43},
publisher = {ACM Press},
title = {{A sound reduction semantics for untyped CBN mutli-stage computation. Or, the theory of MetaML is non-trival (extended abstract)}},
url = {http://portal.acm.org/citation.cfm?doid=328690.328697},
year = {1999}
}
@book{Bird1998,
author = {Bird, Richard},
edition = {2},
file = {:Users/liang-tingchen/Dropbox/References/Bird - 1998 - Introduction to Functional Programming using Haskell.pdf:pdf},
isbn = {9780134843469},
publisher = {Prentice Hall},
title = {{Introduction to Functional Programming using Haskell}},
year = {1998}
}
@incollection{Alfalayleh2016,
abstract = {In this paper, we consider the unordered pseudo-tree matching problem, which is a problem of, given two unordered labeled trees P and T , finding all occurrences of P in T via such many-one embeddings that preserve node labels and parent-child relationship. This problem is closely related to tree pattern matching problem for XPath queries with child axis only. If m {\textgreater} w , we present an efficient algorithm that solves the problem in time using O ( hm / w + m log( w )/ w ) space and O ( m log( w )) preprocessing on a unit-cost arithmetic RAM model with addition, where m is the number of nodes in P , n is the number of nodes in T , h is the height of T , and w is the word length. We also discuss a modification of our algorithm for the unordered tree homeomorphism problem, which corresponds to a tree pattern matching problem for XPath queries with descendant axis only.},
author = {Alfalayleh, Mousa and Brankovic, Ljiljana},
booktitle = {Combinatorial Algorithms. IWOCA 2014},
doi = {10.1007/978-3-319-19315-1_3},
editor = {Jan, Kratochv{\'{i}}l and Miller, Mirka and Froncek, Dalibor},
file = {:Users/liang-tingchen/Dropbox/References/Alfalayleh, Brankovic - 2015 - Quantifying Privacy A Novel Entropy-Based Measure of Disclosure Risk.pdf:pdf},
isbn = {978-3-319-44542-7},
issn = {0018-9219},
pages = {24--36},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Quantifying Privacy: A Novel Entropy-Based Measure of Disclosure Risk}},
url = {http://link.springer.com/10.1007/978-3-319-44543-4 http://link.springer.com/10.1007/978-3-319-19315-1{\_}3},
volume = {8986},
year = {2015}
}
@article{McBride2003,
abstract = {First-order unification algorithms (Robinson, 1965) are traditionally implemented via general recursion, with separate proofs for partial correctness and termination. The latter tends to involve counting the number of unsolved variables and showing that this total decreases each time a substitution enlarges the terms. There are many such proofs in the literature (Manna {\&} Waldinger, 1981; Paulson, 1985; Coen, 1992; Rouyer, 1992; Jaume, 1997; Bove, 1999). This paper shows how a dependent type can relate terms to the set of variables over which they are constructed. As a consequence, first-order unification becomes a structurally recursive program, and a termination proof is no longer required. Both the program and its correctness proof have been checked using the proof assistant LEGO (Luo {\&} Pollack, 1992; McBride, 1999).},
author = {McBride, Conor},
doi = {10.1017/S0956796803004957},
file = {:Users/liang-tingchen/Dropbox/References/McBride - 2003 - First-order unification by structural recursion.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
number = {6},
pages = {1061--1075},
title = {{First-order unification by structural recursion}},
volume = {13},
year = {2003}
}
@techreport{Doberkat2012a,
abstract = {Bisimilarity is a key concept in the investigation of concurrent systems; it can be investigated coalgebraically, opening the road for the coalgebraic treatment of stochas- tic systems, which otherwise would be dicult to undertake. Markov transition systems model probabilistic systems in which the transition among states is represented by prob- abilistic laws. Stochastic relations lie at the mathematical heart of Markov transition systems. We show in this paper that a stochastic relation can be decomposed along a given congruence so that the parts are bisimilar (with the original relation as a mediat- ing component); this result is the bisimulation analogue to the classical decomposition of algebras through complementary congruences. We apply this technique also to Kripke models for modal logics.},
author = {Doberkat, Ernst-Erich},
file = {:Users/liang-tingchen/Dropbox/References/Doberkat - 2012 - Bisimulations For Structuring Markov Transition Systems.pdf:pdf},
institution = {Software Technology and Department of Mathematics Technische Universit{\"{a}}t Dortmund},
month = {may},
pages = {18},
title = {{Bisimulations For Structuring Markov Transition Systems}},
url = {ftp://ls10-ftp.cs.uni-dortmund.de/home/doberkat/public/StochasticRelations/DecompBisim-30v12.pdf},
year = {2012}
}
@article{Desharnais2003,
abstract = {In a recent paper Baier et al. [Lecture Notes in Computer Science, Springer-Verlag, 2000, p. 358] analyzed a new way of model-checking formulas of a logic for continuous-time processes - called continuous stochastic logic (henceforth CSL) - against continuous-time Markov chains - henceforth CTMCs. One of the important results of that paper was the proof that if two CTMCs were bisimilar then they would satisfy exactly the same formulas of CSL. This raises the converse question - does satisfaction of the same collection of CSL formulas imply bisimilarity? In other words, given two CTMCs which are known to satisfy exactly the same formulas of CSL does it have to be the case that they are bisimilar? We prove that the answer to the question just raised is "yes". In fact we prove a significant extension, namely that a subset of CSL suffices even for systems where the state space may be a continuum. Along the way we prove a result to the effect that the set of Zeno paths has measure zero provided that the transition rates are bounded. {\textcopyright} 2002 Published by Elsevier Science Inc.},
author = {Desharnais, Jos{\'{e}}e and Panangaden, Prakash},
doi = {10.1016/S1567-8326(02)00068-1},
file = {:Users/liang-tingchen/Dropbox/References/Desharnais, Panangaden - 2003 - Continuous stochastic logic characterizes bisimulation of continuous-time Markov processes.pdf:pdf},
issn = {15678326},
journal = {The Journal of Logic and Algebraic Programming},
keywords = {Bisimulation,CSL logic,Continuous-time,Markov processes,Zeno paths},
month = {may},
number = {1-2},
pages = {99--115},
title = {{Continuous stochastic logic characterizes bisimulation of continuous-time Markov processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832602000681},
volume = {56},
year = {2003}
}
@article{Pientka2007,
abstract = {This paper sketches a foundation for programming with higher-order abstract syntax and explicit substitutions based on contextual modal type theory [Aleksandar Nanevski, Frank Pfenning, and Brigitte Pientka. Contextual modal type theory. submitted, 2005]. Contextual modal types not only allows us to cleanly separate the representation of data objects from computation, but allow us to recurse over data objects with free variables. In this paper, we extend these ideas even further by adding first-class contexts and substitutions so that a program can pass and access code with free variables and an explicit environment, and link them in a type-safe manner. We sketch the static and operational semantics of this language, and give several examples which illustrate these features. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Pientka, Brigitte},
doi = {10.1016/j.entcs.2006.10.037},
file = {:Users/liang-tingchen/Dropbox/References/Pientka - 2007 - Functional Programming With Higher-order Abstract Syntax and Explicit Substitutions.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {Logical frameworks,type systems},
month = {jun},
number = {7},
pages = {41--60},
publisher = {Elsevier B.V.},
title = {{Functional Programming With Higher-order Abstract Syntax and Explicit Substitutions}},
url = {http://dx.doi.org/10.1016/j.entcs.2006.10.037 https://linkinghub.elsevier.com/retrieve/pii/S1571066107002526},
volume = {174},
year = {2007}
}
@inproceedings{Wang2009,
address = {New York, New York, USA},
author = {Wang, Rui and Li, Yong Fuga and Wang, Xiaofeng and Tang, Haixu and Zhou, Xiaoyong},
booktitle = {Proceedings of the 16th ACM conference on Computer and communications security - CCS '09},
doi = {10.1145/1653662.1653726},
file = {:Users/liang-tingchen/Dropbox/References/Wang et al. - 2009 - Learning your identity and disease from research papers.pdf:pdf},
isbn = {9781605588940},
keywords = {genome wide association study,integer programming,markov model,single nucleotide polymorphism,test statistics},
pages = {534},
publisher = {ACM Press},
title = {{Learning your identity and disease from research papers}},
url = {http://portal.acm.org/citation.cfm?doid=1653662.1653726},
year = {2009}
}
@article{Barr1970a,
author = {Barr, Michael},
doi = {10.1007/BF01111838},
file = {:Users/liang-tingchen/Dropbox/References/Barr - 1970 - Coequalizers and free triples.pdf:pdf},
issn = {0025-5874},
journal = {Mathematische Zeitschrift},
number = {4},
pages = {307--322},
title = {{Coequalizers and free triples}},
url = {http://link.springer.com/10.1007/BF01111838},
volume = {116},
year = {1970}
}
@article{Turi1998a,
author = {Turi, Daniele and Rutten, Jan J.M.M.},
file = {:Users/liang-tingchen/Dropbox/References/Turi, Rutten - 1998 - On the foundations of final coalgebra semantics non-well-founded sets, partial orders, metric spaces.pdf:pdf},
issn = {1469-8072},
journal = {Mathematical Structures in Computer Science},
language = {English},
month = {oct},
number = {5},
pages = {481--540},
title = {{On the foundations of final coalgebra semantics: non-well-founded sets, partial orders, metric spaces}},
type = {Journal article},
url = {http://journals.cambridge.org/abstract{\_}S0960129598002588},
volume = {8},
year = {1998}
}
@incollection{Gibbons2016,
author = {Gibbons, Jeremy},
booktitle = {A List of Successes That Can Change the World: Essays Dedicated to Philip Wadler on the Occasion of His 60th Birthday},
doi = {10.1007/978-3-319-30936-1_7},
editor = {Lindley, Sam and McBride, Conor and Trinder, Phil and Sannella, Don},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2016 - Comprehending Ringads.pdf:pdf},
pages = {132--151},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Comprehending Ringads}},
url = {http://link.springer.com/10.1007/978-3-319-30936-1{\_}7},
year = {2016}
}
@book{Barendregt1984a,
author = {Barendregt, Henk},
isbn = {0444875085},
pages = {621},
publisher = {North Holland},
series = {Studies in Logic},
title = {{The Lambda Calculus: Its Syntax and Semantics}},
volume = {103},
year = {1984}
}
@article{Moggi1991a,
abstract = {The type-theoretic explanation of modules proposed to date (for programming languages like ML) is unsatisfactory, because it does not capture that the evaluation of type-expressions is independent from the evaluation of program expressions. We propose a new explanation based on ‘programming languages as indexed categories' and illustrate how ML can be extended to support higher order modules, by developing a category-theoretic semantics for a calculus of modules with dependent types. The paper also outlines a methodology, which may lead to a modular approach in the study of programming languages.},
author = {Moggi, Eugenio},
doi = {10.1017/S0960129500000074},
file = {:Users/liang-tingchen/Dropbox/References/Moggi - 1991 - A category-theoretic account of program modules.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {mar},
number = {1},
pages = {103--139},
title = {{A category-theoretic account of program modules}},
url = {https://www.cambridge.org/core/product/identifier/S0960129500000074/type/journal{\_}article},
volume = {1},
year = {1991}
}
@article{Pavlovic2014a,
abstract = {In Monoidal Computer I, we introduced a categorical model of computation where the formal reasoning about computability was supported by the simple and popular diagrammatic language of string diagrams. In the present paper, we refine and extend that model of computation to support a formal complexity theory as well. This formalization brings to the foreground the concept of normal complexity measures, which allow decompositions akin to Kleene's normal form. Such measures turn out to be just those where evaluating the complexity of a program does not require substantially more resources than evaluating the program itself. The usual time and space complexity are thus normal measures, whereas the average and the randomized complexity measures are not. While the measures that are not normal provide important design time information about algorithms, and for theoretical analyses, normal measures can also be used at run time, as practical tools of computation, e.g. to set the bounds for hypothesis testing, inductive inference and algorithmic learning.},
archivePrefix = {arXiv},
arxivId = {1402.5687},
author = {Pavlovi{\'{c}}, Dusko},
eprint = {1402.5687},
file = {:Users/liang-tingchen/Dropbox/References/Pavlovi{\'{c}} - 2014 - Monoidal computer II Normal complexity by string diagrams.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Monoidal computer II: Normal complexity by string diagrams}},
url = {http://arxiv.org/abs/1402.5687},
year = {2014}
}
@article{Fiech1996,
author = {Fiech, Adrian},
file = {:Users/liang-tingchen/Dropbox/References/Fiech - 1996 - Colimits in the Category DCPO.pdf:pdf},
journal = {Mathematical Structures in Computer Science},
number = {5},
pages = {455--468},
title = {{Colimits in the Category DCPO}},
url = {http://dblp.uni-trier.de/db/journals/mscs/mscs6.html{\#}Fiech96},
volume = {6},
year = {1996}
}
@article{Pin1995,
author = {Pin, Jean-{\'{E}}ric},
file = {:Users/liang-tingchen/Dropbox/References/Pin - 1995 - A variety theorem without complementation.pdf:pdf},
journal = {Russian Mathematics (Izvestija vuzov.Matematika)},
pages = {80--90},
title = {{A variety theorem without complementation}},
volume = {39},
year = {1995}
}
@article{Nykanen2011,
abstract = {O'Neill (The genuine Sieve of Eratosthenes. J. Funct. Program. 19(1), 2009, 95–106) has$\backslash$n$\backslash$npreviously considered a functional implementation for the genuine Sieve of Eratosthenes,$\backslash$n$\backslash$nbased on the well-known heap data structure. Here, we develop it further by adapting this$\backslash$n$\backslash$ndata structure to this particular application.},
author = {NYK{\"{A}}NEN, MATTI},
doi = {10.1017/S0956796811000128},
file = {:Users/liang-tingchen/Dropbox/References/NYK{\"{A}}NEN - 2011 - A note on the genuine Sieve of Eratosthenes.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {may},
number = {6},
pages = {1--10},
title = {{A note on the genuine Sieve of Eratosthenes}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796811000128},
volume = {21},
year = {2011}
}
@article{Montanari2014,
author = {Montanari, Ugo and Sammartino, Matteo},
doi = {10.1016/j.tcs.2014.03.009},
file = {:Users/liang-tingchen/Dropbox/References/Montanari, Sammartino - 2014 - A network-conscious $\pi$-calculus and its coalgebraic semantics.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {mar},
number = {2010},
pages = {1--37},
publisher = {Elsevier B.V.},
title = {{A network-conscious $\pi$-calculus and its coalgebraic semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397514001844},
volume = {1},
year = {2014}
}
@article{Avery2014,
abstract = {The Giry monad on the category of measurable spaces sends a space to a space of all probability measures on it. There is also a finitely additive Giry monad in which probability measures are replaced by finitely additive probability measures. We give a characterisation of both finitely and countably additive probability measures in terms of integration operators that is a correction and extension of a result claimed by Sturtz. A counterexample to Sturtz's claim is given in the appendix. This correspondence gives a new description of the Giry monads, which is then used to show that the Giry monads arise as the codensity monads of forgetful functors from certain categories of convex sets and affine maps to the category of measurable spaces.},
archivePrefix = {arXiv},
arxivId = {1410.4432},
author = {Avery, Tom},
eprint = {1410.4432},
file = {:Users/liang-tingchen/Dropbox/References/Avery - 2014 - Codensity and the Giry monad.pdf:pdf},
journal = {ArXiv e-prints},
pages = {1--27},
title = {{Codensity and the Giry monad}},
url = {http://arxiv.org/abs/1410.4432},
year = {2014}
}
@inproceedings{Gibbons2012,
author = {Gibbons, Jeremy},
booktitle = {UTP Symposium},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons - 2012 - Unifying Theories of Programming with Monads.pdf:pdf},
month = {aug},
title = {{Unifying Theories of Programming with Monads}},
url = {http://www.cs.ox.ac.uk/people/jeremy.gibbons/publications/utp-monads.pdf},
year = {2012}
}
@phdthesis{Verity1992,
author = {Verity, Dominic},
booktitle = {Reprints in Theory and Applications of Categories},
file = {:Users/liang-tingchen/Dropbox/References/Verity - 2011 - Enriched categories, internal categories and change of base.pdf:pdf},
keywords = {1992,address,and phrases,australia,b,biadjoints,bicategorical enrichment,c dominic r,change of base,enriched and internal categories,equipments,faculty of science,macquarie university,north ryde,nsw 2109,permission to copy for,persistent and flexible limits,private use granted,profunctors,verity},
number = {20},
pages = {1--266},
school = {Cambridge University},
title = {{Enriched categories, internal categories and change of base}},
url = {http://www.emis.ams.org/journals/TAC/reprints/articles/20/tr20.pdf},
year = {2011}
}
@inproceedings{Bonsangue2009,
author = {Bonsangue, Marcello M. and Rutten, Jan J.M.M. and Silva, Alexandra},
booktitle = {24th Annual IEEE Symposium on Logic In Computer Science},
doi = {10.1109/LICS.2009.18},
file = {:Users/liang-tingchen/Dropbox/References/Bonsangue, Rutten, Silva - 2009 - An Algebra for Kripke Polynomial Coalgebras.pdf:pdf},
isbn = {978-0-7695-3746-7},
month = {aug},
pages = {49--58},
publisher = {IEEE},
title = {{An Algebra for Kripke Polynomial Coalgebras}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5230593},
year = {2009}
}
@article{Vidal2010,
author = {Vidal, J Climent and Tur, J Soliveres},
file = {:Users/liang-tingchen/Dropbox/References/Vidal, Tur - 2010 - Kleisli and Eilenberg-Moore Constructions as Parts of Biadjoint Situations.pdf:pdf},
journal = {Extracta Mathematicae},
keywords = {morphism of eilenberg-moore,morphism of kleisli,transformation of kleisli},
number = {1},
pages = {1--61},
title = {{Kleisli and Eilenberg-Moore Constructions as Parts of Biadjoint Situations}},
url = {http://www.eweb.unex.es/eweb/extracta/Vol-25-1/25B1Climent.pdf},
volume = {25},
year = {2010}
}
@article{Cong2018,
abstract = {What makes a good compiler IR? In the context of functional languages, there has been an extensive debate about the merits and drawbacks of continuation-passing-style (CPS). The consensus seems to be that some form of explicit continuations is necessary to model jumps in a functional style, but that they should have a 2nd-class status, separately from regular functions, to ensure efficient code generation. In particular, the most recent contribution to this debate from PLDI 2017 proposes an explicit join-point construct to model labels and jumps in a direct-style IR. We develop this idea further and propose an IR based on exposing continuations selectively through a control operator, similar to call/cc, but suitably restricted for a compiler IR. We further propose a type system that tracks no-escape and no-return behavior, serving as a basis for a type-directed CPS transform that maintains these properties as well as the call-stack behavior of direct style. Our IR supports both direct style and full CPS, as well as any number of selective continuations in-between. Hence, we change the fundamental question from "CPS yes or no" to "as much or as little CPS as you like".},
author = {Cong, Youyou and Osvald, Leo and Essertel, Gr{\'{e}}gory M. and Rompf, Tiark},
doi = {10.1145/3341643},
file = {:Users/liang-tingchen/Dropbox/References/Cong et al. - 2019 - Compiling with continuations, or without whatever.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
month = {jul},
number = {ICFP},
pages = {1--28},
title = {{Compiling with continuations, or without? whatever.}},
url = {https://www.cs.purdue.edu/homes/rompf/papers/cong-preprint201811.pdf http://dl.acm.org/citation.cfm?doid=3352468.3341643},
volume = {3},
year = {2019}
}
@incollection{Makinson2005,
address = {Berlin/Heidelberg},
author = {Makinson, David},
booktitle = {Handbook of Philosophical Logic},
doi = {10.1007/1-4020-3092-4_3},
file = {:Users/liang-tingchen/Dropbox/References/Makinson - 2005 - How to go nonmonotonic.pdf:pdf},
pages = {175--278},
publisher = {Springer-Verlag},
title = {{How to go nonmonotonic}},
url = {http://link.springer.com/10.1007/1-4020-3092-4{\_}3},
volume = {12},
year = {2005}
}
@article{Jardine2019,
abstract = {This paper presents a presheaf theoretic approach to the construction of fuzzy sets, which builds on Barr's description of fuzzy sets as sheaves of monomorphisms on a locale. Presheaves are used to give explicit descriptions of limit and colimit descriptions in fuzzy sets on an interval. The Boolean localization construction for sheaves on a locale specializes to a theory of stalks for sheaves and presheaves on an interval.The system V ∗ ( X ) of Vietoris-Rips complexes for a data set X is both a simplicial fuzzy set and a simplicial sheaf in this general framework. This example is explicitly discussed through a series of examples.},
archivePrefix = {arXiv},
arxivId = {1904.10314},
author = {Jardine, John F.},
doi = {10.32408/compositionality-1-3},
eprint = {1904.10314},
file = {:Users/liang-tingchen/Dropbox/References/Jardine - 2019 - Fuzzy sets and presheaves.pdf:pdf},
issn = {2631-4444},
journal = {Compositionality},
month = {dec},
number = {3},
pages = {3},
title = {{Fuzzy sets and presheaves}},
url = {http://arxiv.org/abs/1904.10314 https://compositionality-journal.org/papers/compositionality-1-3/},
volume = {1},
year = {2019}
}
@article{Adamek1995,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}}},
doi = {10.1016/0022-4049(94)00152-9},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}} - 1995 - On preaccessible categories.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {dec},
number = {3},
pages = {225--232},
title = {{On preaccessible categories}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022404994001529},
volume = {105},
year = {1995}
}
@article{Clementino2004,
author = {Clementino, Maria Manuel and Hofmann, Dirk},
file = {:Users/liang-tingchen/Dropbox/References/Clementino, Hofmann - 2004 - On extensions of lax monads.pdf:pdf},
issn = {1201561X},
journal = {Theory and Applications of Categories},
keywords = {Lax algebra,Lax monad,Relation},
number = {3},
pages = {41--60},
title = {{On extensions of lax monads}},
volume = {13},
year = {2004}
}
@book{Adamek2010,
author = {Ad{\'{a}}mek, Jiř{\'{i}} and Rosick{\'{y}}, Jiř{\'{i}} and Vitale, Enrico M.},
doi = {10.1017/CBO9780511760754},
file = {:Users/liang-tingchen/Dropbox/References/Ad{\'{a}}mek, Rosick{\'{y}}, Vitale - 2010 - Algebraic Theories.pdf:pdf},
isbn = {9780511760754},
publisher = {Cambridge University Press},
title = {{Algebraic Theories}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511760754},
year = {2010}
}
@inproceedings{Milius2015,
author = {Milius, Stefan and Pattinson, Dirk and Schr{\"{o}}der, Lutz},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.253},
editor = {Sobocinski, Lawrence S. Moss and Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Pattinson, Schr{\"{o}}der - 2015 - Generic trace semantics and graded monads.pdf:pdf},
isbn = {978-3-939897-84-2},
issn = {1868-8969},
pages = {253--269},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{Generic trace semantics and graded monads}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5538},
volume = {35},
year = {2015}
}
@inproceedings{Christiansen2014,
address = {New York, New York, USA},
author = {Christiansen, David Raymond},
booktitle = {Proceedings of the 26nd 2014 International Symposium on Implementation and Application of Functional Languages - IFL '14},
doi = {10.1145/2746325.2746326},
file = {:Users/liang-tingchen/Dropbox/References/Christiansen - 2014 - Type-Directed Elaboration of Quasiquotations.pdf:pdf},
isbn = {9781450332842},
keywords = {metaprogramming,proof automation,quasiquotation},
pages = {1--9},
publisher = {ACM Press},
title = {{Type-Directed Elaboration of Quasiquotations}},
url = {http://dl.acm.org/citation.cfm?doid=2746325.2746326},
year = {2014}
}
@inproceedings{Ghani2013a,
abstract = {Data types are undergoing a major leap forward in their sophistication driven by a conjunction of i) theoretical advances in the foundations of data types; and ii) requirements of programmers for ever more control of the data structures they work with. In this paper we develop a theory of indexed data types where, crucially, the indices are generated inductively at the same time as the data. In order to avoid commitment to any specific notion of indexing we take an axiomatic approach to such data types using fibrations - thus giving us a theory of what we call fibred data types. The genesis of these fibred data types can be traced within the literature, most notably to Dybjer and Setzer's introduction of the concept of induction-recursion. This paper, while drawing heavily on their seminal work for inspiration, gives a categorical reformulation of Dybjer and Setzer's original work which leads to a large number of extensions of induction-recursion. Concretely, the paper provides i) conceptual clarity as to what inductionrecursion fundamentally is about; ii) greater expressiveness in allowing not just the inductive-recursive definition of families of sets, or even indexed families of sets, but rather the inductiverecursive definition of a whole host of other structures; iii) a semantics for induction-recursion based not on the specific model of families, but rather an axiomatic model based upon fibrations which therefore encompasses diverse structures (domain theoretic, realisability, games etc) arising in the semantics of programming languages; and iv) technical justification as to why these fibred data types exist using large cardinals from set theory.},
author = {Ghani, Neil and Malatesta, Lorenzo and Forsberg, Fredrik Nordvall and Setzer, Anton},
booktitle = {Proceedings - Symposium on Logic in Computer Science},
doi = {10.1109/LICS.2013.30},
file = {:Users/liang-tingchen/Dropbox/References/Ghani et al. - 2013 - Fibred data types.pdf:pdf},
isbn = {978-1-4799-0413-6},
issn = {10436871},
keywords = {data types,fibrations,initial algebras},
pages = {243--252},
title = {{Fibred data types}},
year = {2013}
}
@article{Bloom1976,
author = {Bloom, Stephen L.},
doi = {10.1016/S0022-0000(76)80030-X},
file = {:Users/liang-tingchen/Dropbox/References/Bloom - 1976 - Varieties of ordered algebras.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
month = {oct},
number = {2},
pages = {200--212},
title = {{Varieties of ordered algebras}},
url = {http://dx.doi.org/10.1016/S0022-0000(76)80030-X},
volume = {13},
year = {1976}
}
@inproceedings{Milius2016,
author = {Milius, Stefan and Pattinson, Dirk and Wi{\ss}mann, Thorsten},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-662-49630-5_7},
editor = {Jacobs, Bart and L{\"{o}}ding, Christof},
file = {:Users/liang-tingchen/Dropbox/References/Milius, Pattinson, Wi{\ss}mann - 2016 - A new foundation for finitary corecursion.pdf:pdf},
isbn = {978-3-662-49629-9},
pages = {107--125},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{A new foundation for finitary corecursion}},
url = {http://link.springer.com/10.1007/978-3-662-49630-5{\_}7},
volume = {9634},
year = {2016}
}
@inproceedings{Hughes1996,
abstract = {We have designed and implemented a type-based analysis for proving some basic properties of reactive systems. The analysis manipulates rich type expressions that contain information about the sizes of recursively defined data structures. Sized types are useful for detecting deadlocks, non-termination, and other errors in embedded programs. To establish the soundness of the analysis we have developed an appropriate semantic model of sized types.},
address = {New York, New York, USA},
author = {Hughes, John and Pareto, Lars and Sabry, Amr},
booktitle = {Proceedings of the 23rd ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '96},
doi = {10.1145/237721.240882},
file = {:Users/liang-tingchen/Dropbox/References/Hughes, Pareto, Sabry - 1996 - Proving the correctness of reactive systems using sized types.pdf:pdf},
isbn = {0897917693},
issn = {07308566},
pages = {410--423},
publisher = {ACM Press},
title = {{Proving the correctness of reactive systems using sized types}},
url = {http://portal.acm.org/citation.cfm?doid=237721.240882},
year = {1996}
}
@inproceedings{10.1007/3-540-56992-8_21,
abstract = {This paper describes a semantics of typed lambda calculi based on relations. The main mathematical tool is a category-theoretic method of sconing, also called glueing or Freyd covers. Its correspondence to logical relations is also examined.},
address = {Berlin, Heidelberg},
author = {Mitchell, John C and Scedrov, Andre},
booktitle = {Computer Science Logic},
doi = {10.1007/3-540-56992-8_21},
editor = {B{\"{o}}rger, E and J{\"{a}}ger, G and {Kleine B{\"{u}}ning}, H and Martini, S and Richter, M M},
file = {:Users/liang-tingchen/Dropbox/References//Mitchell, Scedrov - 1993 - Notes on sconing and relators.pdf:pdf},
isbn = {978-3-540-47890-4},
pages = {352--378},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Notes on sconing and relators}},
url = {http://link.springer.com/10.1007/3-540-56992-8{\_}21},
volume = {702},
year = {1993}
}
@incollection{Antoniou2001,
author = {Antoniou, Grigoris and Billington, David},
booktitle = {AI 2001: Advances in Artificial Intelligence},
doi = {10.1007/3-540-45656-2_2},
editor = {Stumptner, Markus and Corbett, Dan and Brooks, Mike},
file = {:Users/liang-tingchen/Dropbox/References/Antoniou, Billington - 2001 - Relating Defeasible and Default Logic.pdf:pdf},
isbn = {9783540429609},
issn = {16113349},
pages = {13--24},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Relating Defeasible and Default Logic}},
url = {http://link.springer.com/10.1007/3-540-45656-2{\_}2},
volume = {2256},
year = {2001}
}
@incollection{Beeson1991,
author = {Beeson, Michael},
booktitle = {Extensions of Logic Programming},
doi = {10.1007/BFb0038693},
editor = {Schroeder-Heister, Peter},
file = {:Users/liang-tingchen/Dropbox/References/Beeson - 1991 - Some applications of Gentzen's proof theory in automated deduction.pdf:pdf},
pages = {101--156},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Some applications of Gentzen's proof theory in automated deduction}},
url = {https://link.springer.com/chapter/10.1007/BFb0038693},
volume = {475},
year = {1991}
}
@article{Priestley1972,
author = {Priestley, Hilary A.},
file = {:Users/liang-tingchen/Dropbox/References/Priestley - 1972 - Ordered topological spaces and the representation of distributive lattices.pdf:pdf},
journal = {Proceedings of the London Mathematical Society},
number = {3},
pages = {507},
publisher = {Oxford University Press},
title = {{Ordered topological spaces and the representation of distributive lattices}},
type = {Journal article},
volume = {3},
year = {1972}
}
@article{Janelidze2001,
author = {Janelidze, George and Kelly, Gregory Maxwell},
file = {:Users/liang-tingchen/Dropbox/References/Janelidze, Kelly - 2001 - A note on actions of a monoidal category.pdf:pdf},
journal = {Theory and Applications of Categories},
keywords = {2001,action,adjunction,and phrases,c g,enriched category,janelidze and g,kelly,m,monad,monoid,monoidal category,permission to copy for,private use granted},
number = {4},
pages = {61--91},
title = {{A note on actions of a monoidal category}},
volume = {9},
year = {2001}
}
@incollection{Golle2009,
abstract = {Abstract. Many applications benefit from user location data, but lo- cation data raises privacy concerns. Anonymization can protect privacy, but identities can sometimes be inferred from supposedly anonymous data. This paper studies a new attack on the anonymity of location data. We show that if the approximate locations of an individual's home and workplace can both be deduced from a location trace, then the median size of the individual's anonymity set in the U.S. working population is 1, 21 and 34,980, for locations known at the granularity of a census block, census track and county respectively. The location data of people who live and work in different regions can be re-identified even more easily. Our results show that the threat of re-identification for location data is much greater when the individual's home and work locations can both be deduced from the data. To preserve anonymity, we offer guidance for obfuscating location traces before they are disclosed.},
author = {Golle, Philippe and Partridge, Kurt},
booktitle = {Pervasive Computing},
doi = {10.1007/978-3-642-01516-8_26},
file = {:Users/liang-tingchen/Dropbox/References/Golle, Partridge - 2009 - On the Anonymity of HomeWork Location Pairs.pdf:pdf},
pages = {390--397},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{On the Anonymity of Home/Work Location Pairs}},
url = {http://www.springerlink.com/index/E1X00K50565501KV.pdf http://link.springer.com/10.1007/978-3-642-01516-8{\_}26},
volume = {5538},
year = {2009}
}
@incollection{OConnor2005,
author = {O'Connor, Russell},
booktitle = {Theorem Proving in Higher Order Logics. TPHOLs 2005},
doi = {10.1007/11541868_16},
editor = {Hurd, Joe and Melham, Tom},
file = {:Users/liang-tingchen/Dropbox/References/O'Connor - 2005 - Essential Incompleteness of Arithmetic Verified by Coq.pdf:pdf},
pages = {245--260},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Essential Incompleteness of Arithmetic Verified by Coq}},
year = {2005}
}
@article{Ghani2003,
author = {Ghani, Neil and Lth, Christoph and {De Marchi}, Federico and Power, A. John},
doi = {10.1017/S0960129502003912},
file = {:Users/liang-tingchen/Dropbox/References/Ghani et al. - 2003 - Dualising initial algebras.pdf:pdf},
isbn = {0960129502},
issn = {09601295},
journal = {Mathematical Structures in Computer Science},
month = {apr},
number = {2},
pages = {349--370},
title = {{Dualising initial algebras}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129502003912},
volume = {13},
year = {2003}
}
@article{Lenisa2000,
author = {Lenisa, Marina and Power, A. John and Watanabe, Hiroshi},
doi = {10.1016/S1571-0661(05)80350-0},
file = {:Users/liang-tingchen/Dropbox/References/Lenisa, Power, Watanabe - 2000 - Distributivity for endofunctors, pointed and co-pointed endofunctors, monads and comonads.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
month = {jan},
pages = {230--260},
title = {{Distributivity for endofunctors, pointed and co-pointed endofunctors, monads and comonads}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105803500},
volume = {33},
year = {2000}
}
@article{Staton2008,
author = {Staton, Sam},
doi = {10.1109/LICS.2008.43},
file = {:Users/liang-tingchen/Dropbox/References/Staton - 2008 - General Structural Operational Semantics through Categorical Logic.pdf:pdf},
isbn = {978-0-7695-3183-0},
issn = {1043-6871},
journal = {2008 23rd Annual IEEE Symposium on Logic in Computer Science},
month = {jun},
pages = {166--177},
publisher = {Ieee},
title = {{General Structural Operational Semantics through Categorical Logic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4557909},
year = {2008}
}
@inproceedings{Jacobs2015a,
author = {Jacobs, Bart},
booktitle = {6th Conference on Algebra and Coalgebra in Computer Science (CALCO 2015)},
doi = {10.4230/LIPIcs.CALCO.2015.116},
editor = {Sobocinski, Lawrence S. Moss and Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Jacobs - 2015 - A recipe for state-and-effect triangles.pdf:pdf},
isbn = {9783939897842},
issn = {18688969},
keywords = {and phrases duality,predicate transformer,state transformer,state-and-effect tri-},
pages = {116--129},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{A recipe for state-and-effect triangles}},
url = {http://drops.dagstuhl.de/opus/volltexte/2015/5530/},
volume = {35},
year = {2015}
}
@article{Pfenning2005,
abstract = {We describe motivation, design, use, and implementation of higher-order abstract syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or uni cation are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higherorder abstract syntax, a supporting matching and uni cation algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
author = {Pfenning, F. and Elliot, C.},
doi = {10.1145/960116.54010},
file = {:Users/liang-tingchen/Dropbox/References/Pfenning, Elliot - 1988 - Higher-order abstract syntax.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {jul},
number = {7},
pages = {199--208},
title = {{Higher-order abstract syntax}},
url = {http://portal.acm.org/citation.cfm?doid=960116.54010},
volume = {23},
year = {1988}
}
@incollection{Clouston2018,
abstract = {ficial intelligence; computer software; selection and evaluation; formal logic; graph theory; modal logic; petri nets; program compilers; programming language; semantics; separation logic; software engineering; theorem proving; type systems; verification},
author = {Clouston, Ranald},
booktitle = {Foundations of Software Science and Computation Structures. FoSSaCS 2018},
doi = {10.1007/978-3-319-89366-2_14},
editor = {Baier, Christel and Lago, Ugo Dal},
file = {:Users/liang-tingchen/Dropbox/References/Clouston - 2018 - Fitch-Style Modal Lambda Calculi.pdf:pdf},
isbn = {978-3-319-89365-5},
pages = {258--275},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{Fitch-Style Modal Lambda Calculi}},
url = {http://link.springer.com/10.1007/978-3-319-89366-2{\_}14},
volume = {10803},
year = {2018}
}
@incollection{Hughes2003,
author = {Hughes, Jesse and Jacobs, Bart},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/S1571-0661(04)80564-4},
file = {:Users/liang-tingchen/Dropbox/References/Hughes, Jacobs - 2003 - Factorization systems and fibrations.pdf:pdf},
issn = {15710661},
month = {feb},
pages = {156--182},
title = {{Factorization systems and fibrations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066104805644},
volume = {69},
year = {2003}
}
@article{Gehrke2014a,
abstract = {Our main result is that any topological algebra based on a Boolean space is the extended Stone dual space of a certain associated Boolean algebra with additional operations. A particular case of this result is that the profinite completion of any abstract algebra is the extended Stone dual space of the Boolean algebra of recognisable subsets of the abstract algebra endowed with certain residuation operations. These results identify a connection between topological algebra as applied in algebra and Stone duality as applied in logic, and show that the notion of recognition originating in computer science is intrinsic to profinite completion in mathematics in general. This connection underlies a number of recent results in automata theory including a generalisation of Eilenberg-Reiterman theory for regular languages and a new notion of compact recognition applicable beyond the setting of regular languages. The purpose of this paper is to give the underlying duality theoretic result in its general form. Further we illustrate the power of the result by providing a few applications in topological algebra and language theory. In particular, we give a simple proof of the fact that any topological algebra quotient of a profinite algebra which is again based on a Boolean space is again profinite and we derive the conditions dual to the ones of the original Eilenberg theorem in a fully modular manner. We cast our results in the setting of extended Priestley duality for distributive lattices with additional operations as some classes of languages of interest in automata theory fail to be closed under complementation.},
archivePrefix = {arXiv},
arxivId = {1309.2422},
author = {Gehrke, Mai},
doi = {10.1016/j.jpaa.2015.12.007},
eprint = {1309.2422},
file = {:Users/liang-tingchen/Dropbox/References/Gehrke - 2016 - Stone duality, topological algebra, and recognition.pdf:pdf},
issn = {00224049},
journal = {Journal of Pure and Applied Algebra},
month = {jul},
number = {7},
pages = {2711--2747},
publisher = {Elsevier B.V.},
title = {{Stone duality, topological algebra, and recognition}},
url = {http://dx.doi.org/10.1016/j.jpaa.2015.12.007 http://arxiv.org/abs/1309.2422v1 http://linkinghub.elsevier.com/retrieve/pii/S0022404915003503},
volume = {220},
year = {2016}
}
@incollection{Pierce2000,
abstract = {15 Pict: A Programming Language Based on the Pi-Calculus C. and David N. Turner 1 Introduction Milner, Parrow, and Walker's n-calculus [MPW92, Mil91] generalizes the channel-based communication of CCS and its relatives by allowing channels to be},
author = {Pierce, Benjamin C. and Turner, David N.},
booktitle = {Proof, Language and Interaction: Essays in Honour of Robin Milner},
editor = {Plotkin, Gordon and Stirling, Colin and Tofte, Mads},
file = {:Users/liang-tingchen/Dropbox/References/Pierce, Turner - 2000 - A Programming Language Based on the Pi-Calculus.pdf:pdf},
isbn = {0-262-16188-5},
pages = {455--494},
publisher = {MIT Press},
title = {{A Programming Language Based on the Pi-Calculus}},
url = {https://dl.acm.org/citation.cfm?id=345924},
year = {2000}
}
@inproceedings{Gibbons2009a,
address = {New York, New York, USA},
author = {Gibbons, Jeremy and Paterson, Ross},
booktitle = {Proceedings of the 2009 ACM SIGPLAN workshop on Generic programming - WGP '09},
doi = {10.1145/1596614.1596626},
file = {:Users/liang-tingchen/Dropbox/References/Gibbons, Paterson - 2009 - Parametric datatype-genericity.pdf:pdf},
isbn = {9781605585109},
keywords = {folds,free theorems,func-,generic programming,higher-order functions,higher-order natural transformations,parametricity,tional programming,unfolds},
pages = {85},
publisher = {ACM Press},
title = {{Parametric datatype-genericity}},
url = {http://portal.acm.org/citation.cfm?doid=1596614.1596626},
year = {2009}
}
@article{Manes2010,
abstract = {Let T be a submonad of the ultrafilter monad ?? and let G be a subfunctor of the filter functor. The T-algebras are topological spaces whose closed sets are the subalgebras and form thereby an equationally definable full subcategory of topological spaces. For appropriate T, countably generated free algebras provide ZFC examples of separable, Urysohn, countably compact, countably tight spaces which are neither compact nor sequential, and 2c non-homeomorphic such examples exist. For any space X, say that U ??? X is G-open if U belongs to every ultrafilter in GX which converges in U. The full subcategory TopG consists of all G-spaces, those spaces in which every G-open set is open. Each TopG has at least these stability properties: it contains all Alexandroff spaces, and is closed under coproducts, quotients and locally closed subspaces. Examples include sequential spaces, P-spaces and countably tight spaces. T-algebras are characterized as the T-compact, T-Hausdorff T-spaces. Malyhin's theorem on countable tightness generalizes verbatim to TopG for any G ??? ??. For r??? ??{\{}star operator{\}} = ?? ?? $\backslash$ ??, let Gr be the subfunctor of ?? generated by r and let Tr be the generated submonad. If ???RK is the Rudin-Keisler preorder on ??{\{}star operator{\}}, r ???RK s ??? Gr ??? Gs. Let ???c be the Comfort preorder and define the monadic preorderr ???m s to mean Tr ??? Ts. Then r ???RK s ??? r ???m s ??? r ???c s. It follows that there exist 2c monadic types. For each such type Tr, the Tr-algebras form an equationally definable full subcategory of topological spaces with only one operation of countably infinite arity. No two of these varieties are term equivalent nor is any one a full subcategory of another inside topological spaces. Say that r ??? ??{\{}star operator{\}} is an m-point if Gr ??? Tr. Under CH, m-points exist. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Manes, Ernie},
doi = {10.1016/j.topol.2009.12.013},
file = {:Users/liang-tingchen/Dropbox/References/Manes - 2010 - Monads in topology.pdf:pdf},
issn = {01668641},
journal = {Topology and its Applications},
keywords = {Rudin-Keisler and Comfort preorders,Ultrafilter monad,r-Compactness},
number = {5},
pages = {961--989},
publisher = {Elsevier B.V.},
title = {{Monads in topology}},
url = {http://dx.doi.org/10.1016/j.topol.2009.12.013},
volume = {157},
year = {2010}
}
@article{Rondon2008,
abstract = {We present Logically Qualified Data Types, abbreviated to Liquid Types, a system that combines Hindley-Milner type inference with Predicate Abstraction to automatically infer dependent types precise enough to prove a variety of safety properties. Liquid types allow programmers to reap many of the benefits of dependent types, namely static verification of critical properties and the elimination of ex- pensive run-time checks, without paying the heavy price of of manual annotation. We have implemented liquid type inference in Dsolve, which takes as input an Ocaml program and a set of logical qualifiers and infers dependent types for the expressions in the Ocaml program. To demonstrate the utility of our approach, we describe experiments using Dsolve to statically verify the safety of array accesses on a set of Ocaml benchmarks that were previously annotated with dependent types as part of the DML project. We show that when used in conjunction with an elementary method for automatically generat- ing qualifiers from program text, Dsolve reduces the amount of manual annotation required for proving safety from 31{\%} of program text to under 1{\%}.},
archivePrefix = {arXiv},
arxivId = {arXiv:1012.2733v2},
author = {Rondon, Patrick M. and Kawaguci, Ming and Jhala, Ranjit},
doi = {10.1145/1379022.1375602},
eprint = {arXiv:1012.2733v2},
file = {:Users/liang-tingchen/Dropbox/References/Rondon, Kawaguci, Jhala - 2008 - Liquid types.pdf:pdf},
isbn = {9781595938602},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
keywords = {at compile-time,dependent types,dict,hindley-milner,invariants about the run-time,predicate abstrac-,the utility of these,their ability to pre-,tion,type inference,type systems stems from,values com-},
number = {6},
pages = {159},
title = {{Liquid types}},
url = {http://portal.acm.org/citation.cfm?doid=1379022.1375602},
volume = {43},
year = {2008}
}
@phdthesis{Bernardy2011,
abstract = {This thesis revisits the well-known notion of parametric polymorphism in the light of modern developments in type-theory. Additionally, applica- tions of parametric polymorphism are also presented. The first part of the thesis presents a theoretical investigation of the se- mantics of parametric polymorphism of and within type-theories with de- pendent types. It is shown how the meaning of polymorphic, possibly dependent, types can be reflected within type-theory itself, via a simple syntactic transformation. This self-referential property opens the door to internalise the transformation in type-theory, and we study one possible way to do so. We also examine how the translation relates to various spe- cific features of type-theory, such as proof irrelevance and realizability. The second part is concerned an application of parametric polymorphism relevant to software engineers. We present a schema to reduce polymor- phic properties to equivalent monomorphic properties, for the purpose of testing. Our proof uses parametricity and properties of initial algebras.},
author = {Bernardy, Jean-Philippe},
file = {:Users/liang-tingchen/Dropbox/References/Bernardy - 2011 - A Theory of Parametric Polymorphism and an Application.pdf:pdf},
isbn = {9789173855143},
keywords = {Dependent types,Haskell type-classes,Logical relations,Parametricity,Polymorphism,Realizability,Testing,Types},
school = {Chalmers University of Technology and G{\"{o}}teborg University},
title = {{A Theory of Parametric Polymorphism and an Application}},
year = {2011}
}
@article{Barthe2019,
abstract = {In this work we put forward an algorithm for the mechanical verification of an extension of Martin-L{\"{o}}f's theory of types with dependent record types and subtyping. We first give a concise description of that theory and motivate its use for the formalization of algebraic constructions. Then we concentrate on the informal explanation and specification of a proof checker that we have implemented. The logical heart of this proof checker is a type checking algorithm for the forms of judgement of a particular formulation of the extended theory which incorporates a notion of parameter. The algorithm has been proven sound with respect to the latter calculus. We include a discussion on that proof in the present work.},
author = {BETARTE, GUSTAVO},
doi = {10.1017/S0956796899003627},
file = {:Users/liang-tingchen/Dropbox/References/BETARTE - 2000 - Type checking dependent (record) types and subtyping.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
month = {mar},
number = {2},
pages = {137--166},
publisher = {Swansea University Libraries},
title = {{Type checking dependent (record) types and subtyping}},
url = {http://www2.tcs.ifi.lmu.de/{~}mhofmann/appsem2/LectureNotes/{\%}5Cnhttp://www2.tcs.ifi.lmu.de/{~}mhofmann/appsem2/ https://www.cambridge.org/core/product/identifier/S0956796899003627/type/journal{\_}article},
volume = {10},
year = {2000}
}
@incollection{Bizjak2014,
abstract = {We show how to construct a logical relation for countable nondeterminism in a guarded type theory, corresponding to the internal logic of the topos Sh $\omega$ 1 of sheaves over $\omega$ 1. In contrast to earlier work on abstract step-indexed models, we not only construct the logical relations in the guarded type theory, but also give an internal proof of the adequacy of the model with respect to standard contextual equivalence. To state and prove adequacy of the logical relation, we introduce a new propositional modality. In connection with this modality we show why it is necessary to work in the logic of bf Sh$\omega$ 1. {\textcopyright} 2014 Springer International Publishing Switzerland.},
author = {Bizjak, Ale{\v{s}} and Birkedal, Lars and Miculan, Marino},
booktitle = {Rewriting and Typed Lambda Calculi. RTA 2014, TLCA 2014},
doi = {10.1007/978-3-319-08918-8_8},
editor = {Dowek, Gilles},
file = {:Users/liang-tingchen/Dropbox/References/Bizjak, Birkedal, Miculan - 2014 - A Model of Countable Nondeterminism in Guarded Type Theory.pdf:pdf},
isbn = {9783319089171},
issn = {16113349},
pages = {108--123},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{A Model of Countable Nondeterminism in Guarded Type Theory}},
url = {http://link.springer.com/10.1007/978-3-319-08918-8{\_}8},
volume = {8560},
year = {2014}
}
@book{Libkin2004,
address = {Berlin, Heidelberg},
author = {Libkin, Leonid},
doi = {10.1007/978-3-662-07003-1},
file = {:Users/liang-tingchen/Dropbox/References/Libkin - 2004 - Elements of Finite Model Theory.pdf:pdf},
isbn = {978-3-642-05948-3},
pages = {318},
publisher = {Springer Berlin Heidelberg},
series = {Texts in Theoretical Computer Science},
title = {{Elements of Finite Model Theory}},
url = {http://link.springer.com/10.1007/978-3-662-07003-1},
year = {2004}
}
@article{Kozen2014,
author = {Kozen, Dexter and Mardare, Radu and Panangaden, Prakash},
doi = {10.1016/j.entcs.2014.10.012},
file = {:Users/liang-tingchen/Dropbox/References/Kozen, Mardare, Panangaden - 2014 - A Metrized Duality Theorem for Markov Processes.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {aumann algebras,isometry,markov processes,metrics,probabilistic reasoning,quantitative reasoning,stone duality},
month = {oct},
pages = {211--227},
title = {{A Metrized Duality Theorem for Markov Processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066114000796},
volume = {308},
year = {2014}
}
@article{Leinster1998,
archivePrefix = {arXiv},
arxivId = {math/9810017},
author = {Leinster, Tom},
eprint = {9810017},
file = {:Users/liang-tingchen/Dropbox/References/Leinster - 1998 - Basic Bicategories.pdf:pdf},
journal = {ArXiv e-prints},
month = {oct},
pages = {1--10},
primaryClass = {math},
title = {{Basic Bicategories}},
url = {http://arxiv.org/abs/math/9810017v1},
year = {1998}
}
@article{Bench-Capon2012,
abstract = {We provide a retrospective of 25 years of the International Conference on AI and Law, which was first held in 1987. Fifty papers have been selected from the thirteen conferences and each of them is described in a short subsection individually written by one of the 24 authors. These subsections attempt to place the paper discussed in the context of the development of AI and Law, while often offering some personal reactions and reflections. As a whole, the subsections build into a history of the last quarter century of the field, and provide some insights into where it has come from, where it is now, and where it might go.},
author = {Bench-Capon, Trevor and Araszkiewicz, Micha{\l} and Ashley, Kevin and Atkinson, Katie and Bex, Floris and Borges, Filipe and Bourcier, Daniele and Bourgine, Paul and Conrad, Jack G. and Francesconi, Enrico and Gordon, Thomas F. and Governatori, Guido and Leidner, Jochen L. and Lewis, David D. and Loui, Ronald P. and McCarty, L. Thorne and Prakken, Henry and Schilder, Frank and Schweighofer, Erich and Thompson, Paul and Tyrrell, Alex and Verheij, Bart and Walton, Douglas N. and Wyner, Adam Z.},
doi = {10.1007/s10506-012-9131-x},
file = {:Users/liang-tingchen/Dropbox/References/Bench-Capon et al. - 2012 - A history of AI and Law in 50 papers 25 years of the international conference on AI and Law.pdf:pdf},
isbn = {1059-941X (Print)$\backslash$r1059-941X (Linking)},
issn = {0924-8463},
journal = {Artificial Intelligence and Law},
keywords = {Artificial intelligence and law,Legal informatics,Models of legalReasoning},
month = {sep},
number = {3},
pages = {215--319},
pmid = {16650009},
title = {{A history of AI and Law in 50 papers: 25 years of the international conference on AI and Law}},
url = {http://link.springer.com/10.1007/s10506-012-9131-x},
volume = {20},
year = {2012}
}
@article{Atkey2012a,
abstract = {Dependently typed programming languages allow sophisticated properties of data to be expressed within the type system. Of particular use in dependently typed programming are indexed types that refine data by computationally useful information. For example, the N-indexed type of vectors refines lists by their lengths. Other data types may be refined in similar ways, but programmers must produce purpose-specific refinements on an ad hoc basis, developers must anticipate which refinements to include in libraries, and implementations must often store redundant information about data and their refinements. In this paper we show how to generically derive inductive characterisations of refinements of inductive types, and argue that these characterisations can alleviate some of the aforementioned difficulties associated with ad hoc refinements. Our characterisations also ensure that standard techniques for programming with and reasoning about inductive types are applicable to refinements, and that refinements can themselves be further refined.},
archivePrefix = {arXiv},
arxivId = {1205.2492},
author = {Atkey, Robert and Johann, Patricia and Ghani, Neil},
doi = {10.2168/LMCS-8(2:09)2012},
eprint = {1205.2492},
file = {:Users/liang-tingchen/Dropbox/References/Atkey, Johann, Ghani - 2012 - Refining inductive types.pdf:pdf},
issn = {18605974},
journal = {Logical Methods in Computer Science},
keywords = {Category theory,Dependent types,Fibrations,Inductive types,Refinement types},
number = {2:09},
pages = {1--30},
title = {{Refining inductive types}},
url = {http://www.lmcs-online.org/ojs/viewarticle.php?id=1106},
volume = {8},
year = {2012}
}
@incollection{Altenkirch1994,
author = {Altenkirch, Thorsten},
booktitle = {Types for Proofs and Programs. TYPES 1993},
doi = {10.1007/3-540-58085-9_70},
editor = {Barendregt, Henk and Nipkow, Tobias},
file = {:Users/liang-tingchen/Dropbox/References/Altenkirch - 1994 - Proving strong normalization of CC by modifying realizability semantics.pdf:pdf},
isbn = {9783540580850},
issn = {16113349},
pages = {3--18},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Proving strong normalization of CC by modifying realizability semantics}},
url = {http://link.springer.com/10.1007/3-540-58085-9{\_}70},
volume = {806},
year = {1994}
}
@article{Martin1991a,
author = {Martin, C. E. and Hoare, C. A. R. and Jifeng, He},
doi = {10.1017/S0960129500001262},
file = {:Users/liang-tingchen/Dropbox/References/Martin, Hoare, Jifeng - 1991 - Pre-adjunctions in order enriched categories.pdf:pdf},
issn = {0960-1295},
journal = {Mathematical Structures in Computer Science},
month = {jul},
number = {02},
pages = {141},
title = {{Pre-adjunctions in order enriched categories}},
url = {http://www.journals.cambridge.org/abstract{\_}S0960129500001262},
volume = {1},
year = {1991}
}
@article{Ghani2009,
author = {Ghani, Neil and Hancock, Peter and Pattinson, Dirk},
doi = {10.1016/j.entcs.2009.07.081},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Hancock, Pattinson - 2009 - Continuous Functions on Final Coalgebras.pdf:pdf},
issn = {15710661},
journal = {Electronic Notes in Theoretical Computer Science},
keywords = {containers,continuous functions,final coalgebras},
month = {aug},
pages = {3--18},
publisher = {Elsevier B.V.},
title = {{Continuous Functions on Final Coalgebras}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S157106610900303X},
volume = {249},
year = {2009}
}
@article{Power2006,
author = {Power, A. John},
doi = {10.1016/j.tcs.2006.08.006},
file = {:Users/liang-tingchen/Dropbox/References/Power - 2006 - Generic models for computational effects.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {canonical model,conical colimit completion,enriched yoneda embedding,freyd -category},
month = {nov},
number = {2},
pages = {254--269},
title = {{Generic models for computational effects}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397506005330},
volume = {364},
year = {2006}
}
@article{Pawlak2007,
abstract = {Worldwide, there has been a rapid growth in interest in rough set theory and its applications in recent years. Evidence of this can be found in the increasing number of high-quality articles on rough sets and related topics that have been published in a variety of international journals, symposia, workshops, and international conferences in recent years. In addition, many international workshops and conferences have included special sessions on the theory and applications of rough sets in their programs. Rough set theory has led to many interesting applications and extensions. It seems that the rough set approach is fundamentally important in artificial intelligence and cognitive sciences, especially in research areas such as machine learning, intelligent systems, inductive reasoning, pattern recognition, mereology, knowledge discovery, decision analysis, and expert systems. In the article, we present the basic concepts of rough set theory and point out some rough set-based research directions and applications. {\textcopyright} 2006 Elsevier Inc. All rights reserved.},
author = {Pawlak, Zdzis{\l}aw and Skowron, Andrzej},
doi = {10.1016/j.ins.2006.06.003},
file = {:Users/liang-tingchen/Dropbox/References/Pawlak, Skowron - 2007 - Rudiments of rough sets.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {(in)Discernibility,Approximation spaces,Boolean reasoning,Decision rules,Dependencies of attributes,Information and decision systems,Reducts,Rough membership functions,Rough sets,Set approximations,Vague concepts},
month = {jan},
number = {1},
pages = {3--27},
pmid = {22796804},
title = {{Rudiments of rough sets}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025506001484},
volume = {177},
year = {2007}
}
@inproceedings{Levy2015,
author = {Levy, Paul Blain},
booktitle = {Proceedings of the 6th Conference on Algebra and Coalgebra in Computer Science},
doi = {10.4230/LIPIcs.CALCO.2015.221},
editor = {Moss, Lawrence S. and Sobocinski, Pawel},
file = {:Users/liang-tingchen/Dropbox/References/Levy - 2015 - Final coalgebras from corecursive algebras.pdf:pdf},
isbn = {978-3-939897-84-2},
keywords = {and phrases coalgebra,bisimulation,category theory,factorization sys-,modal logic},
pages = {221----237},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics},
title = {{Final coalgebras from corecursive algebras}},
year = {2015}
}
@article{Arieli1998,
author = {Arieli, Ofer and Avron, Arnon},
doi = {10.1016/S0004-3702(98)00032-0},
file = {:Users/liang-tingchen/Dropbox/References/Arieli, Avron - 1998 - The value of the four values.pdf:pdf},
isbn = {9780977858231},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {bilattices,multiple-valued systems,paraconsistency,preferential logics,reasoning},
month = {jun},
number = {1},
pages = {97--141},
title = {{The value of the four values}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370298000320},
volume = {102},
year = {1998}
}
@incollection{Kiselyov2014,
abstract = {MetaOCaml is a superset of OCaml extending it with the data type for program code and operations for constructing and executing such typed code values. It has been used for compiling domain-specific languages and automating tedious and error-prone specializations of high-performance computational kernels. By statically ensuring that the generated code compiles and letting us quickly run it, MetaOCaml makes writing generators less daunting and more productive. The current BER MetaOCaml is a complete re-implementation of the original MetaOCaml by Taha, Calcagno and collaborators. Besides the new organization, new algorithms, new code, BER MetaOCaml adds a scope extrusion check superseding environment classifiers. Attempting to build code values with unbound or mistakenly bound variables (liable to occur due to mutation or other effects) is now caught early, raising an exception with good diagnostics. The guarantee that the generated code always compiles becomes unconditional, no matter what effects were used in generating the code. We describe BER MetaOCaml stressing the design decisions that made the new code modular and maintainable. We explain the implementation of the scope extrusion check. {\textcopyright} 2014 Springer International Publishing.},
author = {Kiselyov, Oleg},
booktitle = {Functional and Logic Programming. FLOPS 2014},
doi = {10.1007/978-3-319-07151-0_6},
editor = {Codish, Michael and Sumii, Eijiro},
file = {:Users/liang-tingchen/Dropbox/References/Kiselyov - 2014 - The Design and Implementation of BER MetaOCaml.pdf:pdf},
isbn = {9783319071503},
issn = {16113349},
pages = {86--102},
publisher = {Springer, Cham},
series = {Lecture Notes in Computer Science},
title = {{The Design and Implementation of BER MetaOCaml}},
url = {http://link.springer.com/10.1007/978-3-319-07151-0{\_}6},
volume = {8475},
year = {2014}
}
@incollection{Goguen2006,
author = {Goguen, Healfdene and McBride, Conor and McKinna, James},
booktitle = {Algebra, Meaning, and Computation},
doi = {10.1007/11780274_27},
editor = {Futatsugi, Kokichi and Jouann, Jean-Pierre and Meseguer, Jos{\'{e}}},
file = {:Users/liang-tingchen/Dropbox/References/Goguen, McBride, McKinna - 2006 - Eliminating Dependent Pattern Matching.pdf:pdf},
pages = {521--540},
publisher = {Springer, Berlin, Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Eliminating Dependent Pattern Matching}},
url = {http://link.springer.com/10.1007/11780274{\_}27},
volume = {4060},
year = {2006}
}
@article{Kelly1993,
abstract = {A right adjoint functor is said to be of descent type if the counit of the adjunction is pointwise a coequalizer. Building on the results of Tholen's doctoral thesis, we give necessary and sufficient conditions for a composite to be of descent type when each factor is so. We apply this to show that every finitary monad on a locally-finitely-presentable enriched category admits a presentation in terms of basic operations and equations between derived operations, the arties here being the finitely-presentable objects of .},
author = {Kelly, Gregory Maxwell and Power, A. John},
doi = {10.1016/0022-4049(93)90092-8},
file = {:Users/liang-tingchen/Dropbox/References/Kelly, Power - 1993 - Adjunctions whose counits are coequalizers, and presentations of finitary enriched monads.pdf:pdf},
journal = {Journal of Pure and Applied Algebra},
number = {1-2},
pages = {163--179},
title = {{Adjunctions whose counits are coequalizers, and presentations of finitary enriched monads}},
url = {http://dx.doi.org/10.1016/0022-4049(93)90092-8},
volume = {89},
year = {1993}
}
@incollection{Kick2002,
author = {Kick, Marco},
booktitle = {Proceedings of the 29th International Collogquium on Automata, Languages, and Programmings, Part II},
doi = {10.1007/3-540-45465-9_45},
file = {:Users/liang-tingchen/Dropbox/References/Kick - 2002 - Bialgebraic Modelling of Timed Processes.pdf:pdf},
pages = {525--536},
title = {{Bialgebraic Modelling of Timed Processes}},
url = {http://link.springer.com/10.1007/3-540-45465-9{\_}45},
year = {2002}
}
@article{Giunti2011,
author = {Giunti, Marco and Mazzola, Claudio},
doi = {10.1142/9789814383332},
file = {:Users/liang-tingchen/Dropbox/References/Giunti, Mazzola - 2011 - Dynamical Systems on Monoids Toward a General Theory of Deterministic Systems and Motion.pdf:pdf},
isbn = {9789814383332},
journal = {{\ldots} Approaches Towards a General Theory of {\ldots}},
keywords = {category theory,dynamical system,irreversibility,reversibility},
number = {iii},
pages = {1--13},
title = {{Dynamical Systems on Monoids: Toward a General Theory of Deterministic Systems and Motion}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=gpetKqfQ8xMC{\&}oi=fnd{\&}pg=PA173{\&}dq=DYNAMICAL+SYSTEMS+ON+MONOIDS+:+TOWARD+A+GENERAL+THEORY+OF+DETERMINISTIC+SYSTEMS+AND+MOTION{\&}ots=dh7mHQd3RH{\&}sig=bKncXEyenFoub1PRi3JwGeu7CYg},
volume = {0},
year = {2011}
}
@incollection{Venema2013,
author = {Venema, Yde and Vosmaer, Jacob},
booktitle = {Leo Esakia on Duality in Modal and Intuitionistic Logics},
doi = {10.1007/978-94-017-8860-1_6},
editor = {Bezhanishvili, Guram},
file = {:Users/liang-tingchen/Dropbox/References/Venema, Vosmaer - 2014 - Modal logic and the Vietoris functor.pdf:pdf},
pages = {119--153},
publisher = {Springer Netherlands},
series = {Outstanding Contributions to Logic},
title = {{Modal logic and the Vietoris functor}},
url = {http://link.springer.com/10.1007/978-94-017-8860-1{\_}6},
volume = {4},
year = {2014}
}
@misc{Lawvere1962,
author = {Lawvere, F William},
file = {:Users/liang-tingchen/Dropbox/References/Lawvere - 1962 - The Category of Probabilistic Mappings.pdf:pdf},
title = {{The Category of Probabilistic Mappings}},
url = {https://plus.google.com/+VenkataRayuduPosina/posts/KJ69q62PzQM},
year = {1962}
}
@article{Pattinson2003,
abstract = {This paper studies finitary modal logics, interpreted over coalgebras for an endofunctor, and establishes soundness, completeness and decidability results. The logics are studied within the abstract framework of coalgebraic modal logic, which can be instantiated with arbitrary endofunctors on the category of sets. This is achieved through the use of predicate liftings, which generalise atomic propositions and modal operators from Kripke models to arbitrary coalgebras. Predicate liftings also allow us to use induction along the terminal sequence of the underlying endofunctor as a proof principle. This induction principle is systematically exploited to establish soundness, completeness and decidability of the logics. We believe that this induction principle also opens new ways for reasoning about modal logics: Our proof of completeness does not rely on a canonical model construction, and the proof of the finite model property does not use filtrations.},
author = {Pattinson, Dirk},
doi = {10.1016/S0304-3975(03)00201-9},
file = {:Users/liang-tingchen/Dropbox/References/Pattinson - 2003 - Coalgebraic modal logic soundness, completeness and decidability of local consequence.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {dec},
number = {1-3},
pages = {177--193},
title = {{Coalgebraic modal logic: soundness, completeness and decidability of local consequence}},
url = {http://dx.doi.org/10.1016/S0304-3975(03)00201-9},
volume = {309},
year = {2003}
}
@article{Holohan2015,
abstract = {We study differential privacy in the abstract setting of probability on metric spaces. Numerical, categorical and functional data can be handled in a uniform manner in this setting. We demonstrate how mechanisms based on data sanitisation and those that rely on adding noise to query responses fit within this framework. We prove that once the sanitisation is differentially private, then so is the query response for any query. We show how to construct sanitisations for high-dimensional databases using simple 1-dimensional mechanisms. We also provide lower bounds on the expected error for differentially private sanitisations in the general metric space setting. Finally, we consider the question of sufficient sets for differential privacy and show that for relaxed differential privacy, any algebra generating the Borel $\sigma$-algebra is a sufficient set for relaxed differential privacy.},
archivePrefix = {arXiv},
arxivId = {1402.6124},
author = {Holohan, Naoise and Leith, Douglas J. and Mason, Oliver},
doi = {10.1016/j.ins.2015.01.021},
eprint = {1402.6124},
file = {:Users/liang-tingchen/Dropbox/References/Holohan, Leith, Mason - 2015 - Differential privacy in metric spaces Numerical, categorical and functional data under the one roof.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Categorical data,Data sanitisation,Differential privacy,Functional data,Metric space},
month = {jun},
pages = {256--268},
publisher = {Elsevier Inc.},
title = {{Differential privacy in metric spaces: Numerical, categorical and functional data under the one roof}},
url = {http://dx.doi.org/10.1016/j.ins.2015.01.021 http://linkinghub.elsevier.com/retrieve/pii/S0020025515000596},
volume = {305},
year = {2015}
}
@article{Ursini1979,
author = {Ursini, Aldo},
doi = {10.1007/BF00405387},
file = {:Users/liang-tingchen/Dropbox/References/Ursini - 1979 - A modal calculus analogous to K4W, based on intuitionistic propositional logic, I.pdf:pdf},
issn = {0039-3215},
journal = {Studia Logica},
number = {3},
pages = {297--311},
title = {{A modal calculus analogous to K4W, based on intuitionistic propositional logic, I?}},
url = {http://link.springer.com/10.1007/BF00405387},
volume = {38},
year = {1979}
}
@phdthesis{Green2009,
abstract = {In 2006 America Online's research division leaked the web search histories of more than 600,000 of their customers. While this data had been stripped of customer names and identifying information, it nevertheless revealed deeply private information about these individuals' identities and interests. Access to information is becoming fundamental to our society, whether it is a web search or a look at one's health records. While much research has considered the problem of securing data within the database, there exist applications where the content of the users' queries is more sensitive. For example, a doctor who queries a medical records database may inadvertently reveal information that can harm his patient's interests (e.g., queries by a disease specialist might indicate a potential infection, and thus impact insurance coverage decisions). In this work we propose privacy-preserving databases in which a central database serves a pool of users without learning their query pattern. These systems will have several competing requirements. First, we require that the database operator learn nothing about which items the user is asking for, or even the user's identity. This guarantee must hold according to a strong security definition that takes into account the possibility of a malicious operator who tampers with the protocol. Secondly, we require that the database operator retain the ability to control access to items within the database. This seems quite challenging, however, since access control appears to be fundamentally incompatible with our desired privacy requirements. A promising technology for constructing oblivious databases is Oblivious Transfer (OT). In a k -out-of-N OT protocol, a Sender with a collection of N messages interacts with a Receiver such that the Receiver obtains any k of the messages, and no information about the rest of the database. For its part, the Sender learns nothing about which messages the Receiver requested. Unfortunately, while a k -items-out-of- N policy can be considered a basic form access control, it is not powerful enough for many practical applications. Furthermore, many existing OT constructions are vulnerable to selective-failure attacks that may effectively compromise user privacy if undertaken by a malicious database operator. In this work we propose several methods that address these problems efficiently and under strong definitions of security. We will then show how these techniques may be combined in order to produce a complete solution. Specifically, we propose: (1) Two new protocols for k -out-of- N Oblivious Transfer (OT) based on techniques from the field of Identity Based Encryption (IBE). Proposed by Shamir [Sha84] and realized by Boneh-Franklin [BF01], IBE is a powerful technology that greatly simplifies key distribution. We formalize the notion of using this system to blindly extract keys, and show how the primitive can be used to construct efficient fully-simulatable OT protocols (previous OT constructions are either inefficient, are proven according to unrealistic security definitions, or require strong complexity assumptions). (2) A third OT protocol that is secure in the strong Universal Composability (UC) model of Canetti [Can01]. Not only does this protocol meet a strong definition of security, but it can be generically composed with any other UC-secure protocol (including itself). This is important in the case of databases where many users may concurrently access the same database. To our knowledge, this is the first efficient adaptive OT construction to meet this definition. (3) A technique for providing strong and history-dependent access control for an oblivious database. In this model, the user is prevented from requesting items that are not permitted by her policy, while the database operator learns nothing more about the content of her requests. Our constructions are based on a new form of stateful anonymous credentials. Finally, we show how these technologies can be combined to produce a practical oblivious database. The contributions of this work are both theoretical and practical. In particular, we believe that the notion of constructing Oblivious Transfer from Identity-Based Encryption may ultimately help to expand our understanding of both primitives. Simultaneously, the constructions we propose achieve high efficiency under strong security definitions. Ultimately, we believe that this is the first work to thoroughly consider the practical tradeoffs of constructing privacy-preserving databases.},
author = {Green, Matthew Daniel},
booktitle = {ProQuest Dissertations and Theses},
file = {:Users/liang-tingchen/Dropbox/References/Green - 2009 - Cryptography for secure and private databases Enabling practical data access without compromising privacy.pdf:pdf},
isbn = {9781109128697},
keywords = {0984:Computer science,Applied sciences,Computer science,Computer security,Cryptography,Databases,Privacy,Secure databases},
pages = {170},
school = {Johns Hopkins University},
title = {{Cryptography for secure and private databases: Enabling practical data access without compromising privacy}},
url = {http://search.proquest.com/docview/304915042?accountid=11054{\%}5Cnhttp://jj2ec6wc6q.search.serialssolutions.com/?ctx{\_}ver=Z39.88-2004{\&}ctx{\_}enc=info:ofi/enc:UTF-8{\&}rfr{\_}id=info:sid/ProQuest+Dissertations+{\%}26+Theses+Global{\&}rft{\_}val{\_}fmt=info:ofi/fmt:kev:mtx:dissert},
year = {2009}
}
@article{Schroder2007,
annote = {From Duplicate 1 ( 




















A finite model construction for coalgebraic modal logic




















- Schr{\"{o}}der, Lutz )







},
author = {Schr{\"{o}}der, Lutz},
doi = {10.1016/j.jlap.2006.11.004},
file = {:Users/liang-tingchen/Dropbox/References/Schr{\"{o}}der - 2007 - A finite model construction for coalgebraic modal logic.pdf:pdf},
issn = {15678326},
journal = {Journal of Logic and Algebraic Programming},
keywords = {coalgebra,decidability,finite models,modal logic,weak completeness},
month = {sep},
number = {1-2},
pages = {97--110},
title = {{A finite model construction for coalgebraic modal logic}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1567832607000380},
volume = {73},
year = {2007}
}
@article{Matthes2004,
abstract = {Inspired from the recent developments in theories of non-wellfounded syntax (coinductively defined languages) and of syntax with binding operators, the structure of algebras of wellfounded and non-wellfounded terms is studied for a very general notion of signature permitting both simple variable binding operators as well as operators of explicit substitution. This is done in an extensional mathematical setting of initial algebras and final coalgebras of endofunctors on a functor category. The main technical tool is a novel concept of heterogeneous substitution systems. {\textcopyright} 2004 Elsevier B. V. All rights reserved.},
author = {Matthes, Ralph and Uustalu, Tarmo},
doi = {10.1016/j.tcs.2004.07.025},
file = {:Users/liang-tingchen/Dropbox/References/Matthes, Uustalu - 2004 - Substitution in non-wellfounded syntax with variable binding.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Final coalgebra,Functor category,Monad,Non-wellfounded syntax,Primitive corecursion,Substitution,Variable binding},
month = {oct},
number = {1-2},
pages = {155--174},
title = {{Substitution in non-wellfounded syntax with variable binding}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397504004475},
volume = {327},
year = {2004}
}
@article{Abadi2002,
author = {Abadi, Martı́n and Fournet, C{\'{e}}dric and Gonthier, Georges},
doi = {10.1006/inco.2002.3086},
file = {:Users/liang-tingchen/Dropbox/References/Abadi, Fournet, Gonthier - 2002 - Secure Implementation of Channel Abstractions.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
month = {apr},
number = {1},
pages = {37--83},
title = {{Secure Implementation of Channel Abstractions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0890540102930865},
volume = {174},
year = {2002}
}
@article{Dimitrakakis2013,
abstract = {Differential privacy formalises privacy-preserving mechanisms that provide access to a database. We pose the question of whether Bayesian inference itself can be used directly to provide private access to data, with no modification. The answer is affirmative: under certain conditions on the prior, sampling from the posterior distribution can be used to achieve a desired level of privacy and utility. To do so, we generalise differential privacy to arbitrary dataset metrics, outcome spaces and distribution families. This allows us to also deal with non-i.i.d or non-tabular datasets. We prove bounds on the sensitivity of the posterior to the data, which gives a measure of robustness. We also show how to use posterior sampling to provide differentially private responses to queries, within a decision-theoretic framework. Finally, we provide bounds on the utility and on the distinguishability of datasets. The latter are complemented by a novel use of Le Cam's method to obtain lower bounds. All our general results hold for arbitrary database metrics, including those for the common definition of differential privacy. For specific choices of the metric, we give a number of examples satisfying our assumptions.},
archivePrefix = {arXiv},
arxivId = {1306.1066},
author = {Dimitrakakis, Christos and Nelson, Blaine and Zhang, and Zuhe and Mitrokotsa, Aikaterini and Rubinstein, Benjamin},
eprint = {1306.1066},
file = {:Users/liang-tingchen/Dropbox/References/Dimitrakakis et al. - 2017 - Differential Privacy for Bayesian Inference through Posterior Sampling.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian inference,adversarial Learning,differential privacy,robustness},
number = {11},
pages = {1--39},
title = {{Differential Privacy for Bayesian Inference through Posterior Sampling}},
url = {http://jmlr.org/papers/v18/15-257.html},
volume = {18},
year = {2017}
}
@incollection{Robinson1987,
author = {Robinson, Edmund P.},
booktitle = {Category Theory and Computer Science},
doi = {10.1007/3-540-18508-9_29},
editor = {Pitt, David H. and Poign{\'{e}}, Axel and Rydeheard, David E.},
file = {:Users/liang-tingchen/Dropbox/References/Robinson - 1987 - Logical aspects of denotational semantics.pdf:pdf},
isbn = {978-3-540-18508-6},
keywords = {Computer Science},
pages = {238--253},
publisher = {Springer Berlin / Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Logical aspects of denotational semantics}},
url = {http://www.springerlink.com/content/y12q3w3141184272/},
volume = {283},
year = {1987}
}
@incollection{Meertens1986,
abstract = {Of the various approaches to program correctness,$\backslash$nthat of ``Transformational Programming'' appears$\backslash$nto be the most helpful in constructing correct$\backslash$nprograms. The essence of the method is to start with$\backslash$nan obviously correct --- but possibly hopelessly$\backslash$ninefficient --- algorithm, and to improve it by$\backslash$nsuccessively applying correctness-preserving$\backslash$ntransformations.$\backslash$nThe manipulations involved are akin to those used in$\backslash$nmathematics. Two important impediments to this method$\backslash$nare the verbosity of algorithmic notations, making$\backslash$nthe process cumbersome, and the semantic baroqueness$\backslash$nof many primitives, making it hard to verify the$\backslash$nvalidity of transformations. Computer Science can profit$\backslash$nhere from the lessons taught by the history of$\backslash$nMathematics. Another major step, comparable to one$\backslash$nmade long ago in Mathematics, is not to insist on the$\backslash$n``executability'' of algorithmic descriptions. This$\backslash$nmakes it possible to treat initial high-level$\backslash$nspecifications in the same framework as the final programs.$\backslash$nJust as Mathematics evolved from ``Transformational$\backslash$nArithmetic'', Transformational Programming may come of$\backslash$nage as ``Algorithmics''.},
address = {Amsterdam},
author = {Meertens, Lambert},
booktitle = {Mathematics and computer science : proceedings of the CWI symposium, Amsterdam},
doi = {10.1105/tpc.110.075333.ulk},
file = {:Users/liang-tingchen/Dropbox/References/Meertens - 1986 - Algorithmics towards programming as a mathematical activity.pdf:pdf},
issn = {0-444-70024-2},
pages = {289--334},
publisher = {North-Holland Publishing Company},
series = {CWI monographs},
title = {{Algorithmics : towards programming as a mathematical activity}},
url = {https://ir.cwi.nl/pub/2686},
volume = {1},
year = {1986}
}
@inproceedings{Allais2013,
abstract = {The definitional equality of an intensional type theory is its test of type compatibility. Today's systems rely on ordinary evaluation semantics to compare expressions in types, frustrating users with type errors arising when evaluation fails to identify two 'obviously' equal terms. If only the machine could decide a richer theory! We propose a way to decide theories which supplement evaluation with '$\nu$-rules', rearranging the neutral parts of normal forms, and report a successful initial experiment. We study a simple $\lambda$-calculus with primitive fold, map and append operations on lists and develop in Agda a sound and complete decision procedure for an equational theory enriched with monoid, functor and fusion laws. {\textcopyright} 2013 by the Association for Computing Machinery, Inc. (ACM).},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1304.0809},
author = {Allais, Guillaume and McBride, Conor and Boutillier, Pierre},
booktitle = {Proceedings of the 2013 ACM SIGPLAN workshop on Dependently-typed programming - DTP '13},
doi = {10.1145/2502409.2502411},
eprint = {1304.0809},
file = {:Users/liang-tingchen/Dropbox/References/Allais, McBride, Boutillier - 2013 - New equations for neutral terms.pdf:pdf},
isbn = {9781450323840},
keywords = {Logical relations,Map fusion,Normalization by evaluation,Simply typed lambda calculus},
pages = {13},
publisher = {ACM Press},
title = {{New equations for neutral terms}},
url = {http://dl.acm.org/citation.cfm?doid=2502409.2502411},
year = {2013}
}
@article{Basold2017,
abstract = {We give general rules for higher inductive types with non-dependent and dependent eimination rules. These can be used to give a formal treatment of data types with laws as has been discussed by David Turner in his earliest papers on Miranda [13]. The non-depedent elimination scheme is particularly useful for defining functions by recursion and pattern matching, while the dependent elimination scheme gives an induction proof principle. We have rules for non-recursive higher inductive types, like the integers, but also for recursive higher inductive types like the truncation. In the present paper we only allow path constructors (so there are no higher pats in our higher inductive types), which is sufficient for treating various interesting examples from functional programming, as we will briefly show in the paper: arithmetic modulo, integers and finite sets.},
author = {Basold, Henning and Geuvers, Herman and van der Weide, Niels},
doi = {10.3217/jucs-023-01-0063},
file = {:Users/liang-tingchen/Dropbox/References/Basold, Geuvers, Weide - 2017 - Higher Inductive Types in Programming.pdf:pdf},
journal = {Journal of Universal Computer Science},
keywords = {Functional programming,Higher inductive types,Homotopy type theory},
month = {dec},
number = {1},
title = {{Higher Inductive Types in Programming}},
url = {http://www.jucs.org/jucs{\_}23{\_}1/higher{\_}inductive{\_}types{\_}in},
volume = {23},
year = {2017}
}
@inproceedings{Bahr2017,
abstract = {Guarded recursion in the sense of Nakano allows general recursive types and terms to be added to type theory without breaking consistency. Recent work has demonstrated applications of guarded recursion such as programming with codata, reasoning about coinductive types, as well as constructing and reasoning about denotational models of general recursive types. As a step towards an implementation of a type theory with guarded recursion, we present Clocked Type Theory, a new type theory for guarded recursion that is more suitable for reduction semantics than the existing ones. We prove confluence, strong normalisation and canonicity for its reduction semantics, constructing the theoretical basis for a future implementation.},
author = {Bahr, Patrick and Grathwohl, Hans Bugge and M{\o}gelberg, Rasmus Ejlers},
booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
doi = {10.1109/LICS.2017.8005097},
file = {:Users/liang-tingchen/Dropbox/References/Bahr, Grathwohl, M{\o}gelberg - 2017 - The clocks are ticking No more delays!.pdf:pdf},
isbn = {978-1-5090-3018-7},
issn = {18688969},
month = {jun},
pages = {1--12},
publisher = {IEEE},
title = {{The clocks are ticking: No more delays!}},
url = {https://ieeexplore.ieee.org/document/8005097/},
volume = {104},
year = {2017}
}
@article{Salehi2007,
abstract = {We consider several aspects of Wilke's [T. Wilke, An algebraic characterization of frontier testable tree languages, Theoret. Comput. Sci. 154 (1996) 85-106] tree algebra formalism for representing binary labelled trees and compare it with approaches that represent trees as terms in the traditional way. A convergent term rewriting system yields normal form representations of binary trees and contexts, as well as a new completeness proof and a computational decision method for the axiomatization of tree algebras. Varieties of binary tree languages are compared with varieties of tree languages studied earlier in the literature. We also prove a variety theorem thus solving a problem noted by several authors. Syntactic tree algebras are studied and compared with ordinary syntactic algebras. The expressive power of the language of tree algebras is demonstrated by giving equational definitions for some well-known varieties of binary tree languages. ?? 2007 Elsevier Ltd. All rights reserved.},
author = {Salehi, Saeed and Steinby, Magnus},
doi = {10.1016/j.tcs.2007.02.006},
file = {:Users/liang-tingchen/Dropbox/References/Salehi, Steinby - 2007 - Tree algebras and varieties of tree languages.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Binary trees,Syntactic tree algebras,Tree algebras,Tree automata,Tree languages,Varieties of tree languages},
month = {may},
number = {1-3},
pages = {1--24},
title = {{Tree algebras and varieties of tree languages}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304397507000771},
volume = {377},
year = {2007}
}
@inproceedings{Peri2016,
author = {Peri, Joseph S. J.},
booktitle = {Signal Processing, Sensor/Information Fusion, and Target Recognition XXV},
doi = {10.1117/12.2228471},
editor = {Kadar, Ivan},
file = {:Users/liang-tingchen/Dropbox/References/Peri - 2016 - Dempster-Shafer information measures in category theory.pdf:pdf},
isbn = {9781510600836},
issn = {1996756X},
month = {may},
pages = {98420W},
title = {{Dempster-Shafer information measures in category theory}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2228471},
volume = {9842},
year = {2016}
}
@article{Kavvos2020,
abstract = {We present natural deduction systems and associated modal lambda calculi for the necessity fragments of the normal modal logics K, T, K4, GL and S4. These systems are in the dual-context style: they feature two distinct zones of assumptions, one of which can be thought as modal, and the other as intuitionistic. We show that these calculi have their roots in in sequent calculi. We then investigate their metatheory, equip them with a confluent and strongly normalizing notion of reduction, and show that they coincide with the usual Hilbert systems up to provability. Finally, we investigate a categorical semantics which interprets the modality as a product-preserving functor.},
author = {Kavvos, G. Alex},
doi = {10.23638/LMCS-16(3:10)2020},
file = {:Users/liang-tingchen/Dropbox/References/Kavvos - 2020 - Dual-context calculi for modal logic.pdf:pdf},
isbn = {9781509030187},
issn = {10436871},
journal = {Logical Methods in Computer Science},
keywords = {a paper presented at,and extended version of,and phrases,categorical semantics,comonads,context,curry howard correspondence,dual,kav17,lics 2017,modal logic,modal type theory,modality,natural deduction,product-preserving functor,proof theory,this is a revised},
number = {3},
pages = {10:1--10:66},
title = {{Dual-context calculi for modal logic}},
url = {https://lmcs.episciences.org/6722},
volume = {16},
year = {2020}
}
@incollection{Ghani2016c,
abstract = {This paper combines reflexive-graph-category structure for relational parametricity with fibrational models of impredicative polymorphism. To achieve this, we modify the definition of fibrational model of impredicative polymorphism by adding one further ingredient to the structure: comprehension in the sense of Lawvere. Our main result is that such comprehensive models, once further endowed with reflexive-graph-category structure, enjoy the expected consequences of parametricity. This is proved using a type-theoretic presentation of the category-theoretic structure, within which the desired consequences of parametricity are derived. The formalisation requires new techniques because equality relations are not available, and standard arguments that exploit equality need to be reworked.},
address = {Berlin, Heidelberg},
author = {Ghani, Neil and {Nordvall Forsberg}, Fredrik and Simpson, Alex},
booktitle = {Foundations of Software Science and Computation Structures},
doi = {10.1007/978-3-662-49630-5_1},
editor = {Jacobs, Bart and L{\"{o}}ding, Christof},
file = {:Users/liang-tingchen/Dropbox/References/Ghani, Nordvall Forsberg, Simpson - 2016 - Comprehensive Parametric Polymorphism Categorical Models and Type Theory.pdf:pdf},
isbn = {978-3-662-49630-5},
issn = {16113349},
pages = {3--19},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Comprehensive Parametric Polymorphism: Categorical Models and Type Theory}},
url = {http://link.springer.com/10.1007/978-3-662-49630-5{\_}1},
volume = {9634},
year = {2016}
}
@inproceedings{Eisenberg2014,
abstract = {Haskell, as implemented in the Glasgow Haskell Compiler (GHC), is enriched with many extensions that support type-level programming, such as promoted datatypes, kind polymorphism, and type families. Yet, the expressiveness of the type-level language remains limited. It is missing many features present at the term level, including case expressions, anonymous functions, partially-applied functions, and let expressions. In this paper, we present an algorithm - with a proof of correctness - to encode these term-level constructs at the type level. Our approach is automated and capable of promoting a wide array of functions to type families. We also highlight and discuss those term-level features that are not promotable. In so doing, we offer a critique on GHC's existing type system, showing what it is already capable of and where it may want improvement. We believe that delineating the mismatch between GHC's term level and its type level is a key step toward supporting dependently typed programming.},
address = {New York, New York, USA},
author = {Eisenberg, Richard A. and Stolarek, Jan},
booktitle = {Proceedings of the 2014 ACM SIGPLAN symposium on Haskell - Haskell '14},
doi = {10.1145/2633357.2633361},
file = {:Users/liang-tingchen/Dropbox/References/Eisenberg, Stolarek - 2014 - Promoting functions to type families in Haskell(2).pdf:pdf},
isbn = {9781450330411},
keywords = {defunctionalization,type-level programming},
pages = {95--106},
publisher = {ACM Press},
title = {{Promoting functions to type families in Haskell}},
url = {http://dl.acm.org/citation.cfm?doid=2633357.2633361},
year = {2014}
}
@inproceedings{Abel2013a,
address = {New York, New York, USA},
author = {Abel, Andreas M. and Pientka, Brigitte},
booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming - ICFP '13},
doi = {10.1145/2500365.2500591},
file = {:Users/liang-tingchen/Dropbox/References/Abel, Pientka - 2013 - Wellfounded recursion with copatterns.pdf:pdf},
isbn = {9781450323260},
keywords = {coinduction,ity,pattern matching,productiv-,recursion,strong normalization,type-based termination},
pages = {185},
publisher = {ACM Press},
title = {{Wellfounded recursion with copatterns}},
url = {http://dl.acm.org/citation.cfm?doid=2500365.2500591},
year = {2013}
}
@book{Pouly2011,
address = {Hoboken, NJ, USA},
author = {Pouly, Marc and Kohlas, J{\"{u}}rg},
doi = {10.1002/9781118010877},
isbn = {9781118010877},
month = {may},
pages = {484},
publisher = {John Wiley $\backslash${\&} Sons, Inc.},
title = {{Generic Inference}},
url = {http://doi.wiley.com/10.1002/9781118010877},
year = {2011}
}
@inproceedings{Krishnaswami2019,
address = {New York, New York, USA},
author = {Krishnaswami, Neelakantan R. and Yallop, Jeremy},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation - PLDI 2019},
doi = {10.1145/3314221.3314625},
file = {:Users/liang-tingchen/Dropbox/References/Krishnaswami, Yallop - 2019 - A typed, algebraic approach to parsing.pdf:pdf},
isbn = {9781450367127},
keywords = {Kleene algebra,context-free languages,parsing,type theory},
pages = {379--393},
publisher = {ACM Press},
title = {{A typed, algebraic approach to parsing}},
url = {http://dl.acm.org/citation.cfm?doid=3314221.3314625},
year = {2019}
}
@article{Society1988,
abstract = {A causal network is used in a number of areas as a depiction of patterns of `influence' among sets of variables. In expert systems it is common to perform `inference' by means of local computations on such large but sparse networks. In general, non-probabilistic methods are used to handle uncertainty when propagating the effects of evidence, and it has appeared that exact probabilistic methods are not computationally feasible. Motivated by an application in electromyography, we counter this claim by exploiting a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in'. The resulting structure allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence. The scheme is first illustrated on a small, fictitious but challenging example, and the underlying theory and computational aspects are then discussed.},
author = {Lauritzen, S. L. and Spiegelhalter, D. J.},
doi = {10.2307/2345762},
file = {:Users/liang-tingchen/Dropbox/References/Lauritzen, Spiegelhalter - 1988 - Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems.pdf:pdf},
isbn = {00359246},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society},
number = {2},
pages = {157--224},
title = {{Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems}},
volume = {50},
year = {1988}
}
@inproceedings{Davies1996,
author = {Davies, Rowan},
booktitle = {Proceedings 11th Annual IEEE Symposium on Logic in Computer Science},
doi = {10.1109/LICS.1996.561317},
file = {:Users/liang-tingchen/Dropbox/References/Davies - 1996 - A temporal-logic approach to binding-time analysis.pdf:pdf},
isbn = {0-8186-7463-6},
pages = {184--195},
publisher = {IEEE Comput. Soc. Press},
title = {{A temporal-logic approach to binding-time analysis}},
url = {http://ieeexplore.ieee.org/document/561317/},
year = {1996}
}
@incollection{Baltag2000,
abstract = {Building on the work of L. Moss on coalgebraic logic, we study in a general setting a class of infinitary modal logics for F-coalgebras, designed to capture simulation and bisimulation. We use work by A. Thijs on coalgebraic modelling of simulation, in terms of relators ?? as extensions of functors. We prove our logics can indeed capture simulation and bisimulation, i.e. the existence of a simulation (or bisimulation) is equivalent to the preservation of (or equivalence with respect to) certain classes of sentences. Moreover, we prove that one can characterize any given coalgebra up to simulation (and, in certain conditions, up to bisimulation) by a single sentence. We show that truth for this logic can be understood as a simulation relation itself, but with respect to a richer functor F moreover, it is the the largest simulation, i.e. the similarity relation between states of the coalgebra and elements of the language. This sheds a new perspective on the classical preservation and characterizability results, and also on logic games. The two kinds of games normally used in logic ("truth games" to define the semantics dynamically, and "similarity games" between two structures) are seen to be the same kind of game at the level of coalgebras: simulation games. This work has been carried out under the project SEN3.4 "PROMACS" . I thank Jan Rutten, Larry Moss, Martin Rossiger and Yde Venema for useful conversations and comments on the topics of this paper. ?? 2000 Published by Elsevier Science B.V.},
author = {Baltag, Alexandru},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/S1571-0661(05)80343-3},
file = {:Users/liang-tingchen/Dropbox/References/Baltag - 2000 - A logic for coalgebraic simulation.pdf:pdf},
issn = {15710661},
pages = {42--60},
title = {{A logic for coalgebraic simulation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066105803433},
volume = {33},
year = {2000}
}
@article{Cerrito1992,
author = {Cerrito, Serenella},
doi = {10.1016/0743-1066(92)90037-4},
file = {:Users/liang-tingchen/Dropbox/References/Cerrito - 1992 - A linear axiomatization of negation as failure.pdf:pdf},
issn = {07431066},
journal = {The Journal of Logic Programming},
month = {jan},
number = {1-2},
pages = {1--24},
title = {{A linear axiomatization of negation as failure}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0743106692900374},
volume = {12},
year = {1992}
}
@article{Kick2006,
abstract = {We give a coalgebraic formulation of timed processes and their operational semantics. We model time by a monoid called a “time domain”, and we model processes by “timed transition systems”, which amount to partial monoid actions of the time domain or, equivalently, coalgebras for an “evolution comonad” generated by the time domain. All our examples of time domains satisfy a partial closure property, yielding a distributive law of a monad for total monoid actions over the evolution comonad, and hence a distributive law of the evolution comonad over a dual comonad for total monoid actions. We show that the induced coalgebras are exactly timed transition systems with delay operators. We then integrate our coalgebraic formulation of time qua timed transition systems into Turi and Plotkin's formulation of structural operational semantics in terms of distributive laws. We combine timing with action via the more general study of the combination of two arbitrary sorts of behaviour whose operational semantics may interact. We give a modular account of the operational semantics for a combination induced by that of each of its components. Our study necessitates the investigation of products of comonads. In particular, we characterise when a monad lifts to the category of coalgebras for a product comonad, providing constructions with which one can readily calculate.},
author = {Kick, Marco and Power, A. John and Simpson, Alex},
doi = {10.1016/j.ic.2005.11.003},
file = {:Users/liang-tingchen/Dropbox/References/Kick, Power, Simpson - 2006 - Coalgebraic semantics for timed processes.pdf:pdf},
issn = {08905401},
journal = {Information and Computation},
keywords = {delay operators,distributive laws,evolution comonads,modularity,structural operational semantics,time domains,timed transition systems},
month = {apr},
number = {4},
pages = {588--609},
title = {{Coalgebraic semantics for timed processes}},
url = {http://dx.doi.org/10.1016/j.ic.2005.11.003},
volume = {204},
year = {2006}
}
@article{Scalas2019,
abstract = {Multiparty Session Types (MPST) are a typing discipline ensuring that a message-passing process implements a given multiparty session protocol, without errors. In this paper, we propose a new, generalised MPST theory. Our contribution is fourfold. (1) We demonstrate that a revision of the theoretical foundations of MPST is necessary: classic MPST have a limited subject reduction property, with inherent restrictions that are easily overlooked, and in previous work have led to flawed type safety proofs; our new theory removes such restrictions and fixes such flaws. (2) We contribute a new MPST theory that is less complicated, and yet more general, than the classic one: it does not require global multiparty session types nor binary session type duality-instead, it is grounded on general behavioural type-level properties, and proves type safety of many more protocols and processes. (3) We produce a detailed analysis of type-level properties, showing how, in our new theory, they allow to ensure decidability of type checking, and statically guarantee that processes enjoy, e.g., deadlock-freedom and liveness at run-time. (4) We show how our new theory can integrate type and model checking: type-level properties can be expressed in modal µ-calculus, and verified with well-established tools.},
author = {Scalas, Alceste and Yoshida, Nobuko},
doi = {10.1145/3290343},
file = {:Users/liang-tingchen/Dropbox/References/Scalas, Yoshida - 2019 - Less is more multiparty session types revisited.pdf:pdf},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
keywords = {deadlock-freedom,duality,liveness,session types},
month = {jan},
number = {POPL},
pages = {1--29},
title = {{Less is more: multiparty session types revisited}},
url = {http://dl.acm.org/citation.cfm?doid=3302515.3290343},
volume = {3},
year = {2019}
}
@inproceedings{Ahrens2022,
abstract = {In previous work ("From signatures to monads in UniMath"),we described a category-theoretic construction of abstract syntax from a signature, mechanized in the UniMath library based on the Coq proof assistant. In the present work, we describe what was necessary to generalize that work to account for simply-typed languages. First, some definitions had to be generalized to account for the natural appearance of non-endofunctors in the simply-typed case. As it turns out, in many cases our mechanized results carried over to the generalized definitions without any code change. Second, an existing mechanized library on -cocontinuous functors had to be extended by constructions and theorems necessary for constructing multi-sorted syntax. Third, the theoretical framework for the semantical signatures had to be generalized from a monoidal to a bicategorical setting, again to account for non-endofunctors arising in the typed case. This uses actions of endofunctors on functors with given source, and the corresponding notion of strong functors between actions, all formalized in UniMath using a recently developed library of bicategory theory. We explain what needed to be done to plug all of these ingredients together, modularly. The main result of our work is a general construction that, when fed with a signature for a simply-typed language, returns an implementation of that language together with suitable boilerplate code, in particular, a certified monadic substitution operation.},
address = {New York, NY, USA},
archivePrefix = {arXiv},
arxivId = {2112.06984},
author = {Ahrens, Benedikt and Matthes, Ralph and M{\"{o}}rtberg, Anders},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs},
doi = {10.1145/3497775.3503678},
eprint = {2112.06984},
file = {:Users/liang-tingchen/Dropbox/References/Ahrens, Matthes, M{\"{o}}rtberg - 2022 - Implementing a category-theoretic framework for typed abstract syntax.pdf:pdf},
isbn = {9781450391825},
keywords = {computer-checked proof,formalization,monad,signature,typed abstract syntax},
month = {jan},
pages = {307--323},
publisher = {ACM},
title = {{Implementing a category-theoretic framework for typed abstract syntax}},
url = {https://dl.acm.org/doi/10.1145/3497775.3503678},
year = {2022}
}
@book{Ribes2010,
address = {Berlin, Heidelberg},
author = {Ribes, Luis and Zalesskii, Pavel},
doi = {10.1007/978-3-642-01642-4},
file = {:Users/liang-tingchen/Dropbox/References/Ribes, Zalesskii - 2010 - Profinite Groups.pdf:pdf},
isbn = {978-3-642-01641-7},
publisher = {Springer Berlin Heidelberg},
series = {A Series of Modern Surveys in Mathematics},
title = {{Profinite Groups}},
url = {http://link.springer.com/10.1007/978-3-642-01642-4},
year = {2010}
}
