%!TEX root = BiSig.tex

\section{Soundness, Completeness, and Mode Preprocessing}\label{sec:pre-synthesis}

\Josh{Overview of the section}

\subsection{Soundness and Completeness}
\label{sec:soundness-and-completeness}

%\Josh{Throughout this sub-section, we quantify over any bidirectional type system~$(\Sigma, \Omega)$, context $\Gamma : \Cxt_\Sigma(\emptyset)$, raw term $\erase\Gamma \vdash_{\Sigma, \erase\Omega} t$, mode~$d$, and type $A : \Type_\Sigma(\emptyset)$.}

Erasure of a bidirectional binding signature removes mode information and keeps everything else intact; this can be straightforwardly extended by induction to remove mode information from a bidirectional typing derivation and arrive at an ordinary typing derivation.

\begin{lemma}[Soundness]\label{thm:term-soundness}
If\/ $\Gamma \vdash_{\Sigma, \Omega} t :^\dir{d} A$, then $\Gamma \vdash_{\Sigma, \erase\Omega} t : A$.
\end{lemma}

\begin{proof}
Induction on the given derivation, mapping every bidirectional typing rule to its mode-less counterpart except $\ChkRule{Sub}$, in which case the induction hypothesis $\Gamma |-_{\Sigma,\erase\Omega} t : B$ suffices due to the premise $B = A$.
\end{proof}

We can also remove typing and retain mode information, arriving at a mode derivation instead.

\begin{proposition}\label{thm:typing-removal}
If\/ $\Gamma \vdash_{\Sigma, \Omega} t :^\dir{d} A$, then $\erase\Gamma \vdash_{\Sigma, \Omega} t^\dir{d}$.
\end{proposition}

\begin{proof}
Induction on the given derivation, mapping every rule to its counterpart.
\end{proof}

Conversely, if we have both mode and typing derivations for the same term, we can combine them and obtain a bidirectional typing derivation.

\begin{lemma}[Completeness]\label{thm:term-completeness}
If\/ $\erase\Gamma |-_{\Sigma, \Omega} t^\dir{d}$ and\/ $\Gamma |-_{\Sigma, \erase\Omega} t : A$, then $\Gamma |-_{\Sigma, \Omega} t :^\dir{d} A$.
\end{lemma}

\begin{proof}
Induction on the given mode derivation.
For \SynRule{Var}, \SynRule{Anno}, and \Rule{Op}, the outermost rule used in the given typing derivation must be the corresponding typing rule, so by the induction hypotheses we have bidirectional typing derivations for all the sub-terms, to which we can then apply the corresponding bidirectional typing rule.
The \ChkRule{Sub} case is similar but slightly simpler: the induction hypothesis directly gives us a derivation of $\Gamma |-_{\Sigma,\Omega} t \syn A$, to which we apply $\ChkRule{Sub}$.
\end{proof}

In short, soundness and completeness are no more than the separation and combination of mode and typing information carried by the three kinds of derivations while keeping their basic structure, which is directed by the same raw term.
Formulating the notion of mode derivation helps to complete this clean picture.

\subsection{Mode Preprocessing}
\label{sec:mode-preprocessing}

\newcommand{\True}{\mathbf{T}}
\newcommand{\False}{\mathbf{F}}

\begin{figure}
  \centering
  \small
  \begin{tabular}{ r r l }
    & & is in mode~$d$, \\
    $\smash{\boxed{V |-_{\Sigma, \Omega} \isTerm{t}^{\dir{d}\,g\,s}}}$
    & The raw term~$\isTerm{t}$\hspace{-.6em}
    & misses some type annotation iff $g = \False$, and \\
    & & is in mode~$d$ due to an outermost mode cast iff $s = \False$
  \end{tabular}
  \begin{mathpar}
    \inferrule{x \in V}{V |-_{\Sigma, \Omega} \isTerm{x}^{\syn\,\True\,\True}}\,\SynRule{Var}
    \and
    \inferrule{\cdot |-_{\Sigma} A \\ V |-_{\Sigma, \Omega}\isTerm{t}^{\chk\,g\,s}}{V |-_{\Sigma, \Omega} (\isTerm{t \annotate A})^{\syn\,g\,\True}}\,\SynRule{Anno}
    \and
    \inferrule{V |-_{\Sigma, \Omega}\isTerm{t}^{\chk\,g\,\True}}{V |-_{\Sigma, \Omega} \isTerm{t}^{\syn\,\False\,\False}}\,\SynRule{Missing}
    \and
    \inferrule{V |-_{\Sigma, \Omega} \isTerm{t}^{\syn\,g\,\True}}{V |-_{\Sigma, \Omega} \isTerm{t}^{\chk\,g\,\False}}\,\ChkRule{Sub}
    \and
    \inferrule{V, \vec x_1 |-_{\Sigma, \Omega} \isTerm{t_1}^{\dir{d_1}\,g_1\,s_1} \\ \cdots \\ V, \vec x_n |-_{\Sigma, \Omega} \isTerm{t_n}^{\dir{d_n}\,g_n\,s_n}}
    {V |-_{\Sigma, \Omega} \tmOpts^{\dir{d}\,(\bigwedge_i g_i)\,\True}}\,\Rule{Op}
  \end{mathpar}
  \caption{Generalised mode derivations}
  \label{fig:generalised-mode-derivations}
\end{figure}

The goal of this sub-section is to construct a mode preprocessor, which decides for any raw term $V |-_{\Sigma,\erase\Omega} t$ and mode~$\dir d$ whether $V |-_{\Sigma,\Omega} t^\dir{d}$ or not.
In fact we will do better:
If a mode preprocessor returns a proof that no mode derivation exists, that proof (of a negation) does not provide useful information for the user.
It will be more helpful if a preprocessor can produce an explanation of why no mode derivation exists, and even how to fix the input term to have a mode derivation.
We will construct such a \emph{generalised mode preprocessor}~(\cref{thm:generalised-mode-preprocessing}), which can be weakened to an ordinary mode preprocessor~(\cref{thm:mode-preprocessing}) if the additional explanation is not needed.

Intuitively, a term does not have a mode derivation exactly when there are not enough type annotations.
To formulate this more concretely, we can point out the places in the term that require annotations.
For a bidirectional type system, an annotation is required wherever a term is `strictly' (which we will explain shortly) in checking mode but required to be in synthesising mode, in which case there is no rule for switching from checking to synthesising, and thus there is no way to construct a mode derivation.
We can, however, consider \emph{generalised mode derivations} defined in \cref{fig:generalised-mode-derivations} that allow the use of an additional $\SynRule{Missing}$ rule for such switching, so that a derivation can always be constructed.
Given a generalised mode derivation, if it uses $\SynRule{Missing}$ in some places, then those places are exactly where annotations should be supplied, which is helpful information to the user; if it does not use $\SynRule{Missing}$, then the derivation is \emph{genuine} in the sense that it corresponds directly to an original mode derivation.
This can be succinctly formulated as \cref{thm:Pre?-true} below by encoding genuineness as a boolean~$g$ in the generalised mode judgement, which is set to~$\False$ only by the $\SynRule{Missing}$ rule.
(Ignore the boolean~$s$ for now.)

\begin{lemma}\label{thm:Pre?-true}
If\/ $V |-_{\Sigma,\Omega} t^{\dir{d}\,\True\,s}$, then $V |-_{\Sigma,\Omega} t^\dir{d}$.
\end{lemma}

\begin{proof}
Induction on the given derivation.
The $\SynRule{Missing}$ rule cannot appear because $g = \True$, and the other rules are mapped to their counterparts.
\end{proof}

We also want a lemma that covers the case where $g = \False$.

\begin{lemma}\label{thm:Pre?-false}
If\/ $V |-_{\Sigma,\Omega} t^{\dir{d}\,\False\,s}$, then $V \not|-_{\Sigma,\Omega} t^\dir{d}$.
\end{lemma}

This lemma would be wrong if the `strictness' boolean~$s$ was left out of the rules:
Having both $\ChkRule{Sub}$ and $\SynRule{Missing}$, which we call \emph{mode casts}, it would be possible to switch between the two modes freely, which unfortunately means that we could insert a pair of $\ChkRule{Sub}$ and $\SynRule{Missing}$ anywhere, constructing a non-genuine derivation even when there is in fact a genuine one.
The `strictness' boolean~$s$ can be thought of as disrupting the formation of such pairs of mode casts:
Every rule other than the mode casts sets~$s$ to~$\True$, meaning that a term is \emph{strictly} in the mode assigned by the rule (i.e.~not altered by a mode cast), whereas the mode casts set~$s$ to~$\False$.
Furthermore, the sub-derivation of a mode cast has to be strict, so it is impossible to have consecutive mode casts.
Another way to understand the role of~$s$ is that it makes the $\SynRule{Missing}$ rule precise: an annotation is truly missing only when a term is \emph{strictly} in checking mode but is required to be in synthesising mode.
Now we can show that non-genuine derivations are `truly non-genuine'.

\begin{proof}[Proof of \cref{thm:Pre?-false}]
Induction on the generalised mode derivation, in each case analysing an arbitrary mode derivation and showing that it cannot exist.
The key case is $\SynRule{Missing}$, where we have a sub-derivation of $V |-_{\Sigma,\Omega} t^{\chk\,g\,\True}$ for some boolean~$g$.
We do not have an induction hypothesis and seem to get stuck, because $g$~is not necessarily~$\False$.
But what matters here is that $t$~is \emph{strictly} in checking mode: if we continue to analyse the sub-derivation, the outermost rule must be $\Rule{Op}$ with $\dir d = {\chk}$, implying that $t$~has to be an operation in checking mode.
Then a case analysis shows that it is impossible to have a (synthesising) mode derivation of $V |-_{\Sigma,\Omega} t^{\syn}$.
%\begin{itemize}
%\item $\SynRule{Anno}$:
%Any mode derivation must also use $\SynRule{Anno}$ as the outermost rule, and then the induction hypothesis suffices.
%\item $\ChkRule{Sub}$:
%We have a sub-derivation of $V |-_{\Sigma,\Omega} t^{\syn\,\False\,\True}$.
%Any mode derivation of $V |-_{\Sigma,\Omega} t^{\chk}$ must use $\ChkRule{Chk}$ as the outermost rule.
%(The $\Rule{Op}$ rule with $\dir d = {\chk}$ is impossible because the sub-derivation shows that $t$~is exactly a synthesising term.)
%We then have a sub-derivation of $V |-_{\Sigma,\Omega} t^{\syn}$, and can use the induction hypothesis.
%\end{itemize}
\end{proof}

Now we are almost ready to construct a generalised mode preprocessor.

\begin{theorem}\label{thm:generalised-mode-preprocessing}
For any raw term $V |-_{\Sigma,\erase\Omega} t$ and mode~$\dir{d}$, there is a derivation of\/ $V |-_{\Sigma,\Omega} t^{\dir{d}\,g\,s}$ for some booleans $g$~and~$s$.
\end{theorem}

The theorem could be proved directly, but that would take some messy case analyses that inspect the input term and apply mode casts depending on what modes are required all at once.
Instead, we distill the case analysis that deals with mode casts into the following \cref{thm:adjustment}, whose antecedent~(\ref{eq:classification}) is then established by induction in the proof of \cref{thm:generalised-mode-preprocessing}, which does not need to deal with mode casts anymore.

\begin{lemma}\label{thm:adjustment}
For any raw term $V |-_{\Sigma,\erase\Omega} t$, if
\begin{equation}\label{eq:classification}
\exists\dir{d'}.\quad V |- t^{\dir{d'}\,\True\,\True} ~~\vee~~ \exists s.~V |- t^{\dir{d'}\,\False\,s}
\end{equation}
then for any mode~$\dir{d}$, there is a derivation of\/ $V |-_{\Sigma,\Omega} t^{\dir{d}\,g\,s}$ for some booleans $g$~and~$s$.
\end{lemma}

\begin{proof}
Exhaustive case analysis on $\dir{d}$, $\dir{d'}$, the disjunction, and~$s$, adding or removing an outermost mode cast to change the given derivation to a different mode if required.
\end{proof}

Statement~(\ref{eq:classification}) is a slightly strengthened classification of a generalised mode derivation based on its genuineness: when the derivation is genuine, the mode~$\dir{d'}$ should be strict.

\begin{proof}[Proof of \cref{thm:generalised-mode-preprocessing}]
By \cref{thm:adjustment}, it suffices to prove statement~(\ref{eq:classification}) by induction on~$t$.
\begin{itemize}
\item $\Rule{Var}$:
A variable is valid, so we establish the first disjunct using $\SynRule{Var}$.
\item $\Rule{Anno}$:
Let $t = (t' \bbcolon A)$.
By the induction hypothesis and \cref{thm:adjustment}, there is a derivation of $V |-_{\Sigma,\Omega} {t'}^{\chk\,g\,s}$ for some booleans $g$~and~$s$, to which we can apply $\Rule{Anno}$, and then we establish the first or second disjunct depending on whether $g$~is $\True$~or~$\False$ (that is, whether $t'$, and therefore~$t$, are valid).
\item $\Rule{Op}$:
Let $t = \tmOpts$.
By the induction hypotheses and \cref{thm:adjustment}, there is a derivation of $V, \vec x_i |-_{\Sigma,\Omega} {t_i}^{\dir{d_i}\,g_i\,s_i}$ for each sub-term~$t_i$; apply $\Rule{Op}$ and we get a derivation of $V |-_{\Sigma,\Omega} t^{\dir d\,g\,\True}$ where $g = \bigwedge_i g_i$, depending on which we establish the appropriate disjunct.
\vspace{-\topsep-\baselineskip}
\end{itemize}
\end{proof}

\begin{corollary}[Mode Preprocessing]\label{thm:mode-preprocessing}
  It is decidable for any raw term $V |-_{\Sigma,\erase\Omega} t$ and mode~$\dir{d}$ whether $V |-_{\Sigma,\Omega} \isTerm{t}^\dir{d}$.
\end{corollary}

\begin{proof}
By \cref{thm:generalised-mode-preprocessing}, there is a derivation of $V |-_{\Sigma,\erase\Omega} t^{\dir{d}\,g\,s}$ for some booleans $g$~and~$s$, and then simply check~$g$ and apply either \cref{thm:Pre?-true} or \cref{thm:Pre?-false} to obtain $V |-_{\Sigma,\Omega} t^\dir{d}$ or $V \not|-_{\Sigma,\Omega} t^\dir{d}$.
\end{proof}

\begin{corollary}\label{thm:toPre?-true}
If\/ $V |-_{\Sigma,\Omega} t^\dir{d}$, then $V |-_{\Sigma,\Omega} t^{\dir{d}\,\True\,s}$ for some boolean~$s$.
\end{corollary}

\begin{corollary}\label{thm:toPre?-false}
If\/ $V \not|-_{\Sigma,\Omega} t^\dir{d}$, then $V |-_{\Sigma,\Omega} t^{\dir{d}\,\False\,s}$ for some boolean~$s$.
\end{corollary}

Whereas it is possible to prove \cref{thm:toPre?-true} directly by induction, converting a mode derivation to a generalised one, the negated antecedent of \cref{thm:toPre?-false} provides little information for constructing a required derivation, and basically we have to construct such a derivation from scratch for a raw term.
But this is exactly what generalised mode preprocessing does, so we can simply reuse \cref{thm:generalised-mode-preprocessing}.
And \cref{thm:toPre?-true} can also be proved easily in the same way.

\begin{proof}[Proofs of \cref{thm:toPre?-true,thm:toPre?-false}]

By \cref{thm:generalised-mode-preprocessing}, there is a derivation of $V |-_{\Sigma,\Omega} t^{\dir{d}\,g\,s}$ for some booleans $g$~and~$s$.
If $V |-_{\Sigma,\Omega} t^\dir{d}$, then $g$~has to be $\True$ since $g = \False$ leads to a contradiction with \cref{thm:Pre?-false}.
Symmetrically, if $V \not|-_{\Sigma,\Omega} t^\dir{d}$, then $g$~has to be~$\False$ so as not to contradict \cref{thm:Pre?-true}.
\end{proof}

\subsection{Annotatability Is Not Completeness}
\label{sec:annotatability}

\Josh{$\frac{1}{2}$~pages}

\begin{figure}
  \centering\small
  \judgbox{\isTerm{t} \sqsupseteq \isTerm{u}}{A raw term $t$ is more annotated than $u$ (for some bidirectional type system $(\Sigma, \Omega)$)}
  \begin{mathpar}
    \inferrule{\isTerm{t} \sqsupseteq \isTerm{u}}
              {(\isTerm{t} \annotate A) \sqsupseteq \isTerm{u}}\;\Rule{More}
    \and
    \inferrule{\vphantom{x : \Identifier}}
              {\isTerm{x} \sqsupseteq \isTerm{x}}
    \and
    \inferrule{\isTerm{t} \sqsupseteq \isTerm{u}}
              {(\isTerm{t} \annotate A) \sqsupseteq (\isTerm{u} \annotate A)}
    \and
    \inferrule{\isTerm{t_1} \sqsupseteq \isTerm{u_1} \quad \cdots \quad \isTerm{t_n} \sqsupseteq{u_n}}
              {\tmOpts \sqsupseteq \tmOpus}
  \end{mathpar}
  
  \caption{Annotation ordering between raw terms}
  \label{fig:annotation-order}
\end{figure}

